{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Akuvasney/ProjetosPLN/blob/main/Atividade4_grupo9.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "xHdYUfzkg9Ne"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y6QILOdpOjwv"
      },
      "source": [
        "# **Processamento de Linguagem Natural [2023.Q3]**\n",
        "Prof. Alexandre Donizeti Alves"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8m67OOx9MX_3"
      },
      "source": [
        "### **ATIVIDADE PRÁTICA 04 [Uso da API da OpenAI com técnicas de PLN]**\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5Gk0nHKabBT-"
      },
      "source": [
        "A **ATIVIDADE PRÁTICA 04** deve ser feita utilizando o **Google Colab** com uma conta sua vinculada ao Gmail. O link do seu notebook, armazenado no Google Drive, além do link de um repositório no GitHub e os principais resultados da atividade, devem ser enviados usando o seguinte formulário:\n",
        "\n",
        "> https://forms.gle/GzwCq3R7ExtE9g9a8\n",
        "\n",
        "\n",
        "**IMPORTANTE**: A submissão deve ser feita até o dia **26/11 (domingo)** APENAS POR UM INTEGRANTE DA EQUIPE, até às 23h59. Por favor, lembre-se de dar permissão de ACESSO IRRESTRITO para o professor da disciplina de PLN."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D7hJlilKM485"
      },
      "source": [
        "### **EQUIPE**\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**POR FAVOR, PREENCHER OS INTEGRANDES DA SUA EQUIPE:**\n",
        "\n",
        "\n",
        "**Integrante 01:**\n",
        "\n",
        "`Amanda Melati Kuvasney 11201811735`\n",
        "\n",
        "**Integrante 02:**\n",
        "\n",
        "`Beatriz Domingos de Oliveira 11202130893`\n",
        "\n",
        "**Integrante 03:**\n",
        "\n",
        "`Gabriel Gomes de Oliveira Costa  11201921471`"
      ],
      "metadata": {
        "id": "tnIArN0QY-Ek"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **LIVRO**\n",
        "---"
      ],
      "metadata": {
        "id": "6yExhaebs-nD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "`Processamento de Linguagem Natural - Conceitos, Técnicas e Aplicações em Português.`\n",
        "\n",
        ">\n",
        "\n",
        "Disponível gratuitamente em:\n",
        "  \n",
        "  > https://brasileiraspln.com/livro-pln/1a-edicao/.\n",
        "\n",
        "\n",
        "**POR FAVOR, PREENCHER OS CAPITULOS SELECIONADOS PARA A SUA EQUIPE:**\n",
        "\n",
        "`Primeiro capítulo: 09`\n",
        "\n",
        "`Segundo capítulo: 17`\n",
        "\n"
      ],
      "metadata": {
        "id": "DjJM_qhEZRy6"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EtjgWQRzNphL"
      },
      "source": [
        "### **DESCRIÇÃO**\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Implementar um `notebook` no `Google Colab` que faça uso da **API da OpenAI** aplicando, no mínimo, 3 técnicas de PLN. As técnicas devem ser aplicadas nos 2 (DOIS) capítulos do livro **Processamento de Linguagem Natural - Conceitos, Técnicas e Aplicações em Português**.\n",
        "\n",
        ">\n",
        "\n",
        "**RESTRIÇÃO**: É obrigatório usar o *endpoint* \"*`Chat Completions`*\".\n",
        "\n",
        ">\n",
        "\n",
        "As seguintes técnicas de PLN podem ser usadas:\n",
        "\n",
        "*   Correção Gramatical\n",
        "*   Classificação de Textos\n",
        "*   Análise de Sentimentos\n",
        "*   Detecção de Emoções\n",
        "*   Extração de Palavras-chave\n",
        "*   Tradução de Textos\n",
        "*   Sumarização de Textos\n",
        "*   **Similaridade de Textos**\n",
        "*   **Reconhecimento de Entidades Nomeadas**\n",
        "*   **Sistemas de Perguntas e Respostas**\n",
        "\n",
        ">\n",
        "\n",
        "Os capítulos devem ser os mesmos selecionados na **ATIVIDADE PRÁTICA 02**. Para consultar os capítulos, considere a seguinte planilha:\n",
        "\n",
        ">\n",
        "\n",
        "> https://docs.google.com/spreadsheets/d/1ZutzQ3v1OJgsgzCvCwxXlRIQ3ChXNlHNvB63JQvYsbo/edit?usp=sharing\n",
        "\n",
        ">\n",
        ">\n",
        "\n",
        "**IMPORTANTE:** É obrigatório usar o e-mail da UFABC. Não é permitido alterar os capítulos já selecionados.\n",
        "\n"
      ],
      "metadata": {
        "id": "fXTwkiiGs2BV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **CRITÉRIOS DE AVALIAÇÃO**\n",
        "---\n"
      ],
      "metadata": {
        "id": "gWsBYQNtxmum"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Serão considerados como critérios de avaliação as técnicas usadas e a criatividade envolvida na aplicação das mesmas.\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "5iHdx4BXYruQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **IMPLEMENTAÇÃO**\n",
        "---"
      ],
      "metadata": {
        "id": "nw09lujGvfjc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Instalando as dependências\n",
        "!pip install openai==0.28.1\n",
        "!pip install requests beautifulsoup4"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P1foW2WLEgr3",
        "outputId": "3b46d543-4859-4c06-f72c-941215bdcd9b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: openai==0.28.1 in /usr/local/lib/python3.10/dist-packages (0.28.1)\n",
            "Requirement already satisfied: requests>=2.20 in /usr/local/lib/python3.10/dist-packages (from openai==0.28.1) (2.31.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from openai==0.28.1) (4.66.1)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from openai==0.28.1) (3.8.6)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai==0.28.1) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai==0.28.1) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai==0.28.1) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai==0.28.1) (2023.7.22)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai==0.28.1) (23.1.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai==0.28.1) (6.0.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai==0.28.1) (4.0.3)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai==0.28.1) (1.9.2)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai==0.28.1) (1.4.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai==0.28.1) (1.3.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (2.31.0)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.10/dist-packages (4.11.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests) (2023.7.22)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4) (2.5)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QRnpCI6rgbF4",
        "outputId": "896fde31-cdc2-450c-d660-288c9a6e53a5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.28.1\n"
          ]
        }
      ],
      "source": [
        "#@title Versão da API da OpenAI\n",
        "\n",
        "import openai\n",
        "\n",
        "print(openai.__version__)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import openai\n",
        "import os\n",
        "\n",
        "#capturando apikey pela variavel de sistema\n",
        "os.environ[\"OPENAI_API_KEY\"] = openai.api_key\n",
        "\n",
        "#testando a conexão com openai\n",
        "resposta = openai.Completion.create(\n",
        "   model = \"text-davinci-003\",\n",
        "   prompt = \"O Brasil é um país\"\n",
        ")\n",
        "\n",
        "print(resposta.choices[0].text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9fd5sN1T_B6S",
        "outputId": "99e4721d-2559-4573-8876-fe3412d43a9d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " na América do Sul. Ele é o 5º país mais\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Introdução"
      ],
      "metadata": {
        "id": "0nytSG_QJSCd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Desafios da implantação:**\n",
        "\n",
        "1.   **Tamanho do texto:** Pelo texto ser muito grande, a API não suportou fazer diversas análises no texto inteiro. Sendo assim, quebramos ele em partes para fazermos as análises de maneira faseada, conforme será demonstrado nas técnicas abaixo. Além disso, em algumas funções foi utilizado o parâmetro \"max_tokens=algum numero\" definindo o número de tokens que ele retornará de acordo com a necessidade.\n",
        "\n",
        "2.   **Limite de tempo:** em alguns casos, a API estoura o tempo máximo de processamento, então utilizamos \"time.sleep(20)\" em cada iteração para não ocorrer esse problema.\n",
        "\n"
      ],
      "metadata": {
        "id": "lnxi9KRuJUNO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Separando o conteúdo dos capítulos em partes de até 4000 caracteres\n",
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "import re\n",
        "\n",
        "\n",
        "#define function to scrap information about the page\n",
        "def scrap_text_information(url) :\n",
        "   response = requests.get(url);\n",
        "   soup = BeautifulSoup(response.content, 'html.parser')\n",
        "   paragraphs = soup.find_all('p')\n",
        "   scraped_text = '\\n'.join(paragraph.get_text() for paragraph in paragraphs)     #correcao bia\n",
        "\n",
        "   #scraped_text = soup.get_text()                                                #codigo origem\n",
        "   return scraped_text\n",
        "\n",
        "def get_paragraphs(text) :\n",
        "  paragraph_pattern = r'([A-Z].*?\\n)'\n",
        "  # Use re.findall to find all paragraph-like patterns\n",
        "  paragraphs = re.findall(paragraph_pattern, text)\n",
        "  return paragraphs\n",
        "\n",
        "\n",
        "# a function that returns True if letter is vowel\n",
        "def valid_sub_chapter(sub_chapter):\n",
        "    return len(sub_chapter) < 400;\n",
        "\n",
        "def extract_chapters(url):\n",
        "\n",
        "    # Define a regular expression pattern for matching chapter headings\n",
        "    chapter_pattern = re.compile(r'^\\d+(\\.\\d+)+\\s+[^\\n]+')\n",
        "\n",
        "    response = requests.get(url);\n",
        "    soup = BeautifulSoup(response.content, 'html.parser')\n",
        "\n",
        "    lines = soup.get_text().split('\\n')\n",
        "\n",
        "    # Extract content between chapter headings\n",
        "    chapters = []\n",
        "    current_chapter = None\n",
        "\n",
        "    for line in lines:\n",
        "        if chapter_pattern.match(line):\n",
        "            # If a new chapter heading is found, start a new chapter\n",
        "            if current_chapter is not None:\n",
        "                chapters.append(current_chapter.strip())\n",
        "            current_chapter = f\"{line}\\n\"\n",
        "        elif current_chapter is not None:\n",
        "            # Add lines to the current chapter content\n",
        "            current_chapter += f\"{line}\\n\"\n",
        "\n",
        "    # Add the last chapter\n",
        "    if current_chapter is not None:\n",
        "        chapters.append(current_chapter.strip())\n",
        "\n",
        "    chapters = list(filter(lambda x: len(x) >= 400, chapters))\n",
        "\n",
        "    return chapters"
      ],
      "metadata": {
        "id": "BRNc1IuUvNPB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "import time\n",
        "\n",
        "def split_text_equally(text):\n",
        "    # Find the index of the middle newline character\n",
        "    middle_index = len(text) // 2\n",
        "    newline_index = text.rfind('\\n', 0, middle_index)\n",
        "\n",
        "    # If there is no newline character in the first half, search in the second half\n",
        "    if newline_index == -1:\n",
        "        newline_index = text.find('\\n', middle_index)\n",
        "\n",
        "    # If there is still no newline character, just split the text in the middle\n",
        "    if newline_index == -1:\n",
        "        newline_index = middle_index\n",
        "\n",
        "    # Split the text at the newline_index\n",
        "    part1 = text[:newline_index]\n",
        "    part2 = text[newline_index:]\n",
        "\n",
        "    return part1, part2\n",
        "\n",
        "def concatenate_into_parts(paragraphs, num_parts=4):\n",
        "    total_paragraphs = len(paragraphs)\n",
        "    paragraphs_per_part = total_paragraphs // num_parts\n",
        "\n",
        "    # Calculate the number of paragraphs in the last part\n",
        "    remaining_paragraphs = total_paragraphs % num_parts\n",
        "\n",
        "    # Initialize variables to keep track of the starting and ending index for each part\n",
        "    start_index = 0\n",
        "    end_index = 0\n",
        "\n",
        "    concatenated_parts = []  # List to store concatenated parts\n",
        "\n",
        "    for part in range(1, num_parts + 1):\n",
        "        # Calculate the ending index for the current part\n",
        "        end_index += paragraphs_per_part + (1 if part <= remaining_paragraphs else 0)\n",
        "\n",
        "        # Concatenate paragraphs for the current part\n",
        "        part_paragraphs = paragraphs[start_index:end_index]\n",
        "        concatenated_part = '\\n'.join(part_paragraphs)\n",
        "\n",
        "        # Append the concatenated part to the list\n",
        "        concatenated_parts.append(concatenated_part)\n",
        "\n",
        "        # Update the starting index for the next part\n",
        "        start_index = end_index\n",
        "\n",
        "    return concatenated_parts"
      ],
      "metadata": {
        "id": "MSpbfj3FHv6x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title\n",
        "# Initialize the constants\n",
        "URL_CHAPTER_9 = 'https://brasileiraspln.com/livro-pln/1a-edicao/parte5/cap9/cap9.html'\n",
        "URL_CHAPTER_17 = 'https://brasileiraspln.com/livro-pln/1a-edicao/parte8/cap17/cap17.html'"
      ],
      "metadata": {
        "id": "WuOEOgMKvVGk",
        "cellView": "code"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text_chapther_9 = scrap_text_information(URL_CHAPTER_9)\n",
        "text_chapther_17 = scrap_text_information(URL_CHAPTER_17)"
      ],
      "metadata": {
        "id": "FIy1QJq3veSd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sub_chapters_from_chapter_9 = extract_chapters(URL_CHAPTER_9)\n",
        "sub_chapters_from_chapter_17 = extract_chapters(URL_CHAPTER_17)"
      ],
      "metadata": {
        "id": "uQ4UHzkn_qWQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Erros de ortográfia\n",
        "\n",
        "Separamos os textos dos capítulos 9 e 17 em 8 partes para realizarmos a análise, pois estavámos atingindo o limite de tokens estabelecido.\n",
        "Além disso, foi necessário colocar uma função `time.sleep(20)` após cada interação com a API, tendo em vista que estavámos recebendo um erro de `RateLimitError: Rate limit reached`.\n",
        "O modelo não detectou erros de ortográfia em nenhuma parte do texto, mas percebemos que em algumas chamadas ocorre alguns falsos negativos, é detectado erroneamente um erro de ortográfia e a correção é exatamente o mesmo texto."
      ],
      "metadata": {
        "id": "Zu8fZ4ZvkIvz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# check if there is a date in the format MM/DD/YYYY or YYYY/MM/DD as the article is in PT-BR so the dates must be DD/MM/YYYY\n",
        "import re\n",
        "import time\n",
        "\n",
        "def get_spelling_errors(text) :\n",
        "   paragraphs = get_paragraphs(text)\n",
        "   # separate the text into 8 parts\n",
        "   concanate_paragraphs = concatenate_into_parts(paragraphs, 8)\n",
        "   count = 0\n",
        "   for paragraph in concanate_paragraphs :\n",
        "      res = openai.Completion.create(\n",
        "        model=\"text-davinci-003\",\n",
        "        prompt=f\"Retorne apenas os erros de ortográfia com a sua respectiva correção, se não existir erro na frase retornar 'NÃO EXISTE ERROS', no seguinte texto :\\n'{paragraph}\",\n",
        "        max_tokens=100,  # Ajuste conforme necessário\n",
        "    )\n",
        "      print(f'PARTE {count + 1} : \\n')\n",
        "      print(res['choices'][0]['text'].strip())\n",
        "      time.sleep(20)\n",
        "      count = count + 1\n"
      ],
      "metadata": {
        "id": "CjNWdFkevl-i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "get_spelling_errors(text_chapther_9)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gxsoi_vXxLVj",
        "outputId": "329f6b9e-4069-49b5-b1e0-19d06942064c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "PARTE 1 : \n",
            "\n",
            "NÃO EXISTEM ERROS\n",
            "PARTE 2 : \n",
            "\n",
            "NÃO EXISTE ERROS\n",
            "PARTE 3 : \n",
            "\n",
            "NÃO EXISTE ERRO\n",
            "PARTE 4 : \n",
            "\n",
            "NÃO EXISTE ERROS\n",
            "PARTE 5 : \n",
            "\n",
            "NÃO EXISTEM ERROS\n",
            "PARTE 6 : \n",
            "\n",
            "NÃO EXISTE ERROS.\n",
            "PARTE 7 : \n",
            "\n",
            "NÃO EXISTE ERROS.\n",
            "PARTE 8 : \n",
            "\n",
            "NÃO EXISTE ERROS\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "get_spelling_errors(text_chapther_17)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wv7tI3onjdkX",
        "outputId": "c78cf081-a5c1-4dab-abd1-9dfcd01aa5d5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "PARTE 1 : \n",
            "\n",
            "NÃO EXISTE ERROS\n",
            "PARTE 2 : \n",
            "\n",
            "NÃO EXISTE ERROS\n",
            "PARTE 3 : \n",
            "\n",
            "NÃO EXISTE ERRO\n",
            "PARTE 4 : \n",
            "\n",
            "NÃO EXISTE ERROS\n",
            "PARTE 5 : \n",
            "\n",
            "NÃO EXISTE ERROS.\n",
            "PARTE 6 : \n",
            "\n",
            "NÃO EXISTE ERRO\n",
            "PARTE 7 : \n",
            "\n",
            "NÃO EXISTE ERRO\n",
            "PARTE 8 : \n",
            "\n",
            "NÃO EXISTE ERRO.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Palavras chaves\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "bFCQtyspsi4G"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "As palavras chaves foram processadas para cada parte do capítulo considerando a limitação de caracteres existente na versão gratuita da API Openai"
      ],
      "metadata": {
        "id": "yvvNYgAHvjZh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Separando o capítulo em 8 partes e buscando as palavras chaves em cada parte**"
      ],
      "metadata": {
        "id": "xFNKtbfpIT_S"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_key_words(text) :\n",
        "   paragraphs = get_paragraphs(text)\n",
        "   # separate the text into 8 parts\n",
        "   concanate_paragraphs = concatenate_into_parts(paragraphs, 8)\n",
        "   count = 0\n",
        "   for paragraph in concanate_paragraphs :\n",
        "      res = openai.Completion.create(\n",
        "        model=\"text-davinci-003\",\n",
        "        prompt=f\"Retorne as palavras chaves do seguinte texto :\\n'{paragraph}\",\n",
        "        max_tokens=100,  # Ajuste conforme necessário\n",
        "    )\n",
        "      print(f'PARTE {count + 1} : \\n')\n",
        "      print(res['choices'][0]['text'].strip())\n",
        "      time.sleep(20)\n",
        "      count = count + 1"
      ],
      "metadata": {
        "id": "zorDHdBNstZ9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "get_key_words(text_chapther_17)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rpyUT4fStAdy",
        "outputId": "4d426da2-bf11-46ba-f82d-01d88c744327"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "PARTE 1 : \n",
            "\n",
            "Palavras Chaves: Extração de Informação, Reconhecimento de Entidades Nomeadas, Extração de Relação, Extração de Eventos, Parsers Sintáticos, Gabarito, Regras, Message Understanding Conference, Métricas de Avaliação.\n",
            "PARTE 2 : \n",
            "\n",
            "Palavras-chave: Extração de Informação, Entidade, Relação, Processamento de Linguagem Natural, Relacionamento Ontológico, Aprendizagem de Máquina.\n",
            "PARTE 3 : \n",
            "\n",
            "Palavras-chave: Extração de Informação, Extração de Informação Aberta, Reconhecimento de Entidades Nomeadas, Extração de Relações, Entidades, Relações, Escopo, EI Tradicional, Aprendizado de Máquina, Arquiteturas Neurais.\n",
            "PARTE 4 : \n",
            "\n",
            "Palavras-Chave: REN, regras lexico-sintáticas, almanaques, classificadores, classificação sequencial, redes neurais profundas, BART, RoBERTa, T5, BERT, GPT-3, HAREM, MALINCHE, NEURA, R3M, RELP-CRF, Word Embeddings, Flair Embeddings, Flair\n",
            "PARTE 5 : \n",
            "\n",
            "Palavras Chaves: Corpus, Rede Neural BiLSTM-CRF, Flair Embeddings, Padrões de Hearst, Aprendizado de Máquina, REN, ER, Kernel, Modelo Escondido de Markov.\n",
            "PARTE 6 : \n",
            "\n",
            "Palavras chaves: Extração de Informação Aberta, ER, REN, EIA, Extração de Relações, língua portuguesa, TextRunner, DepOE, DepPattern, ReVerb.\n",
            "PARTE 7 : \n",
            "\n",
            "Palavras-chave: MUC-2, MUC-3, precisão, cobertura, sobre-geração, sub-geração, RePort, ReVerb, RELP, InferReVerbPT, avaliação sistemática, Multi2OIE, PortNOIE.\n",
            "PARTE 8 : \n",
            "\n",
            "Medidas, precisão, cobertura, média harmônica, F1, recuperação de informação, classificação de texto, avaliação, rendimento, métrica de rendimento, criação, supervisão fraca, transformação.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "get_key_words(text_chapther_9)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EAJ5m8kgzB8I",
        "outputId": "374d828e-3453-4ee8-874a-9227af637b32"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "PARTE 1 : \n",
            "\n",
            "Palavras-chaves: Processamento de Linguagem Natural (PLN), Métodos Simbólicos, Analisadores Semânticos, Representação Lógica, Bases de Conhecimento, Sistemas de Inteligência Artificial (IA).\n",
            "PARTE 2 : \n",
            "\n",
            "Palavras-chave: WordNet, PLN, semântica de linguagem natural, redes semânticas, bases de conhecimento léxico-semânticas, bases de conhecimento de senso comum, recursos léxico-semânticos, Frames, ConceptNet, George A. Miller, Christiane Fellbaum.\n",
            "PARTE 3 : \n",
            "\n",
            "• “assalto” (00783063-n) → “roubo” (01089816-n) \n",
            "• “terminar” (02610845-v) → “acabar” (00038128-v)\n",
            "\n",
            "Palavras-chave: WordNet, Princeton, várias, línguas, português, recursos léxico-semânticos, Wordnet.BR, Onto.PT, PULO, OpenWordNet-PT, PWN, OWN-PT, hiperônimo, Desambiguação do Sentido de Palavras, WSD.\n",
            "PARTE 4 : \n",
            "\n",
            "Palavras chaves: OWN-PT, FrameNet, Commiting_crime, Semantic Role Labeling, WordNet, PropBank, VerbNet, Natural Language Inference, SemLink, FrameNet Brasil, Cometer_crime.\n",
            "PARTE 5 : \n",
            "\n",
            "Palavras chaves : FrameNet, BASE FrameFOR, PFN-PT, Exemplo 9.3, Elemento evocador, Papéis semânticos, ConceptNet, Open Mind Common Sense (OMCS), Nós conceituais, Relações semânticas, Corpus OMCS, Crowdsourcing, Projeto colaborativo.\n",
            "PARTE 6 : \n",
            "\n",
            "Palavras-chave: ConceptNet, afirmação, edge, tripla, linguagem natural, linguagens, JSON, URI, relação, API REST, inferências, senso comum, Open Mind Common Sense – Brasil, InferenceNet-BR.\n",
            "PARTE 7 : \n",
            "\n",
            "Palavras-chave: Assalto, Saidinha bancária, Balear, WordNet, FrameNet, ConceptNet, Parse semântico, OWL, Alinhamento, PWN, OWN-PT.\n",
            "PARTE 8 : \n",
            "\n",
            "Palavras-chave: frame, polissêmica, banco, SemLink, ConceptNet, Wikcionário, relações, linguagem natural.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Buscando as palavras chaves por subcapítulo**"
      ],
      "metadata": {
        "id": "JHeUt5rMICQC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def split_text_equally(text):\n",
        "    # Find the index of the middle newline character\n",
        "    middle_index = len(text) // 2\n",
        "    newline_index = text.rfind('\\n', 0, middle_index)\n",
        "\n",
        "    # If there is no newline character in the first half, search in the second half\n",
        "    if newline_index == -1:\n",
        "        newline_index = text.find('\\n', middle_index)\n",
        "\n",
        "    # If there is still no newline character, just split the text in the middle\n",
        "    if newline_index == -1:\n",
        "        newline_index = middle_index\n",
        "\n",
        "    # Split the text at the newline_index\n",
        "    part1 = text[:newline_index]\n",
        "    part2 = text[newline_index:]\n",
        "\n",
        "    return part1, part2"
      ],
      "metadata": {
        "id": "wUAplqELORNi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_key_words_by_subchapter(subchapters) :\n",
        "   count = 0\n",
        "   for subchapter in subchapters :\n",
        "      if (len(subchapter) > 4800) :\n",
        "          text1, text2 = split_text_equally(subchapter);\n",
        "          res = openai.Completion.create(\n",
        "              model=\"text-davinci-003\",\n",
        "              prompt=f\"Retorne as palavras chaves do seguinte texto :\\n'{text1}\",\n",
        "              max_tokens=100,\n",
        "          )\n",
        "          print(f'Subcapítulo {count + 1} [pt1] : \\n')\n",
        "          print(res['choices'][0]['text'].strip())\n",
        "          time.sleep(20)\n",
        "          res = openai.Completion.create(\n",
        "              model=\"text-davinci-003\",\n",
        "              prompt=f\"Retorne as palavras chaves do seguinte texto :\\n'{text1}\",\n",
        "              max_tokens=100,\n",
        "          )\n",
        "          print(f'Subcapítulo {count + 1} [pt2] : \\n')\n",
        "          print(res['choices'][0]['text'].strip())\n",
        "      else :\n",
        "        res = openai.Completion.create(\n",
        "              model=\"text-davinci-003\",\n",
        "              prompt=f\"Retorne as palavras chaves do seguinte texto :\\n'{subchapter}\",\n",
        "              max_tokens=100,\n",
        "          )\n",
        "        print(f'Subcapítulo {count + 1} : \\n')\n",
        "        print(res['choices'][0]['text'].strip())\n",
        "      time.sleep(20)\n",
        "      count = count + 1"
      ],
      "metadata": {
        "id": "rFgMgCzFH_Sa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "get_key_words_by_subchapter(sub_chapters_from_chapter_9)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bR8LwoDaIBCR",
        "outputId": "274d0e88-1f2b-4d40-d3ca-2ff73b94aa50"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Subcapítulo 1 [pt1] : \n",
            "\n",
            "Palavras-chave:Processamento de Linguagem Natural (PLN), Métodos Simbólicos, Analisadores Semânticos, Representação Semântica, Motores de Inferência, Bases de Conhecimento, Engenharia de Ontologia, Formalismo de Troca de Dados.\n",
            "Subcapítulo 1 [pt2] : \n",
            "\n",
            "Palavras-chaves: Processamento de Linguagem Natural (PLN), Semântica, Técnicas Simbólicas, Analisador Semântico, Representação Semântica, Motor de Inferência, Sintaxe, Ontologias, Reconhecimento de Entidades Nomeadas.\n",
            "Subcapítulo 2 [pt1] : \n",
            "\n",
            "Palavras chaves: Inteligência Artificial, redes semânticas, bases de conhecimento computáveis, frame, PLN, recursos léxico-semânticos, wordnet, PWN, bases de conhecimento de senso comum.\n",
            "Subcapítulo 2 [pt2] : \n",
            "\n",
            "Palavras-Chave: Inteligência Artificial, Redes Semânticas, Representações baseadas em Frames, PLN, Léxico-Semânticos, WordNet, PWN, Senso Comum.\n",
            "Subcapítulo 3 : \n",
            "\n",
            "Palavras-chave: WordNet, Princeton WordNet, synsets, PWN, APIs, Google Scholar, GitHub, relações semânticas, sintagmáticas, causais, MWEs, significado, concordância, línguas, português.\n",
            "Subcapítulo 4 : \n",
            "\n",
            "Wordnets, português, Linguateca, NILC, PortLex, VerbNet.Br, PropBank.Br, Wordnet.BR, Onto.PT, PULO, OpenWordNet-PT, PWN, Open Multilingual WordNet, alinhamento, relações semânticas, entidades, gírias, baixo-calão.\n",
            "Subcapítulo 5 : \n",
            "\n",
            "Palavras Chaves: desambiguação do sentido de palavras (WSD), hiperomínia, synset, associação de palavras, anotação de papéis semânticos (SRL).\n",
            "Subcapítulo 6 [pt1] : \n",
            "\n",
            "já a sentença “He tried to commit the bombing” (em português, “Ele tentou perpetrar o bombardeio”) possui a realização sintática de infinitivo (INF – Infive Phrase).\n",
            "\n",
            "Palavras-chave: FrameNet, Semântica de Frames, Papéis Semânticos, Elementos de Frames, Unidades Lexica\n",
            "Subcapítulo 6 [pt2] : \n",
            "\n",
            "Palavras-chave: FrameNet, da Universidade de Berkeley, Semantic Role Labeling, papéis semânticos, Elementos de frames, Lexical Unit, realizações sintáticas.\n",
            "Subcapítulo 7 : \n",
            "\n",
            "FrameNet, adaptação para o português, corpus FN-Br, FrameFOR, criminal_process, PFN-PT, extração de informação, anotação de papéis semânticos, reconhecimento de entidades nomeadas.\n",
            "Subcapítulo 8 : \n",
            "\n",
            "Palavras-chave: FrameNet, Exemplo Motivador, Robbery, Unidades léxicas, Papéis Semânticos, Place, Time, Perpetrador, Vítima.\n",
            "Subcapítulo 9 [pt1] : \n",
            "\n",
            "Palavras Chaves: ConceptNet, Grafo de Conhecimento, Open Mind Common Sense, Wikcionário, Games with a Purpose, Open Multilingual WordNet, JMDict, OpenCyc, DBPedia.\n",
            "Subcapítulo 9 [pt2] : \n",
            "\n",
            "Palavras-chave: ConceptNet, OpenMind CommonSense, Games With a Purpose, Open Multilingual WordNet, JMDict, OpenCyc, DBPedia\n",
            "Subcapítulo 10 : \n",
            "\n",
            "Palavras-chave: Base Conceitual, Base de Sentenças-Padrão, Relações Semânticas, Rede Semântica, Pré-condição, Pós-condição.\n",
            "Subcapítulo 11 : \n",
            "\n",
            "Palavras Chaves: desambiguação, classe gramatical, polissêmico, português, incipiente, ConceptNet.\n",
            "Subcapítulo 12 [pt1] : \n",
            "\n",
            "GOECKE, D.; WILLITS, J.; COPESTAKE, A. The validity of minimal recursion semantics as a representation for meaning in natural language processing. [s.l.] Amsterdam, Países Baixos: Rodopi, 2005.\n",
            "\n",
            "Palavras-chave: WordNet, FrameNet, ConceptNet, PLN, análise de sentimentos, desambiguação, Frame, conhecimento de\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Similiaridade de textos\n"
      ],
      "metadata": {
        "id": "ILLMLXn6vwix"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def similarity_parties(part1, part2) :\n",
        "  paragraphs1 = get_paragraphs(part1)\n",
        "  paragraphs2 = get_paragraphs(part2)\n",
        "\n",
        "  concanate_paragraphs1 = concatenate_into_parts(paragraphs1, 8);\n",
        "  concanate_paragraphs2 = concatenate_into_parts(paragraphs2, 8);\n",
        "\n",
        "  cont=0\n",
        "\n",
        "  for paragraph1 in concanate_paragraphs1:\n",
        "    cont = cont+1\n",
        "    for paragraph2 in concanate_paragraphs2:\n",
        "      print(\"parte do cap 9\")\n",
        "      print(c)\n",
        "      print(paragraph1)\n",
        "      print(\"parte do cap 17\\n\")\n",
        "      print(paragraph2)\n",
        "\n",
        "\n",
        "similarity_parties(text_chapther_9, text_chapther_17)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g2u1wu1yweQQ",
        "outputId": "a56dc95e-0afd-45f9-9efb-ce696c3f4ec3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "parte do cap 9\n",
            "\n",
            "Eloize Rossi Marques Seno \n",
            "\n",
            "Valéria de Paiva \n",
            "\n",
            "Vládia Pinheiro \n",
            "\n",
            "PDF\n",
            "\n",
            "Métodos Simbólicos em Processamento de Linguagem Natural (PLN) envolvem a utilização de regras e representações formais explícitas para processar e entender textos em linguagem natural. Esses métodos especializam-se na manipulação de símbolos e dados estruturados, como gramáticas, ontologias e bases de conhecimento. Especificamente para o entendimento de textos em linguagem natural usando técnicas simbólicas, existem analisadores semânticos (ou parsers semânticos) e bases de conhecimento semântico, que visam fornecer uma representação semântica dos textos. A partir desta representação, motores de inferência são capazes de realizar raciocínio para que aplicações possam, por exemplo, extrair informações, sumarizar textos, e responder perguntas com base nos textos.\n",
            "\n",
            "A Figura 9.1 apresenta uma arquitetura tradicional para sistemas de entendimento de textos em linguagem natural (Natural Language Understanding – NLU). A partir do texto de entrada, uma camada de processamento sintático realiza uma série de análises no texto, tais como detecção de língua, separação de sentenças, tokenização, análise morfológica e sintática (Capítulo 4). Na fronteira entre o processamento sintático e a análise semântica, outros processamentos linguísticos são necessários, como reconhecimento de entidades nomeadas, identificação de expressões multipalavras etc. Em seguida, o texto analisado (sintaticamente) é enviado ao analisador semântico (parser) que gera uma representação lógica do texto. A representação lógica e a(s) base(s) de conhecimento, no que lhes concerne, são entradas para o motor de inferência. Nesse processo, termos do texto de entrada são associados aos elementos da base de conhecimento e o motor de inferência gera respostas a perguntas (queries) para uma aplicação final.\n",
            "\n",
            "Uma “base de conhecimento” refere-se a um repositório centralizado, processável por máquina, que contém informações, dados, regras e procedimentos que são usados para capturar, representar e armazenar conhecimento geral ou de um domínio específico. Tais bases de conhecimento são fontes de conhecimento de mundo e suportam diversas tarefas e aplicações em PLN. Uma base de conhecimento pode ser estruturada de diversas maneiras, incluindo bancos de dados relacionais, linguagem para ontologias (e.g. a OWL1), formalismos para troca de dados entre sistemas (e.g. o formato JSON2), redes semânticas ou sistemas baseados em regras, dependendo da sua finalidade e da natureza do conhecimento armazenado.\n",
            "\n",
            "Fonte: Adaptada de (Ovchinnikova, 2012, p. 9)\n",
            "\n",
            "Tradicionalmente, sistemas lógicos são usados para representação formal dos textos e seus motores de inferência servem para gerar conclusões a partir dos textos. Podemos citar os sistemas lógicos mais usados em PLN: variações de Lógica Descritiva (Description Logic – DL) (Baader et al., 2003), da Lógica de Primeira Ordem (Blackburn; Bos, 2005; Eijck; Unger, 2010), vários tipos de Programação em Lógica (PROLOG) (Dahl, 1994) e Lógicas Intensionais (Shapiro, 2000).\n",
            "\n",
            "Uma característica importante dos sistemas lógicos usados para a semântica de linguagem natural é que eles dependem fortemente da forma lógica do texto ou argumento. No entanto, muitas conclusões e respostas fornecidas ao se ler um texto são justificadas pela contribuição semântica dos conceitos relacionados, não definida a priori, mas somente enquanto usados em um contexto particular. Por exemplo, considere a inferência que conclui que “Alguém foi assassinado” a partir da premissa que “Alguém foi executado”. A contribuição semântica do conceito “executar” (no sentido de “assassinar”) é que torna esta inferência plausível, e não a forma da sentença. Da mesma forma, a inferência “um relâmpago é visto agora” para “um trovão será ouvido em breve” é autorizada pelo conteúdo dos termos “trovão” e “relâmpago”. Para se realizar inferências desta natureza, alguns filósofos como Sellars (Sellars, 1953) e Brandom (Brandom, 2001) propõem abordagens para expressão do significado que suportam análises semânticas não somente sobre a forma das sentenças, mas são capazes de, com base no domínio dos conteúdos dos termos articulados nas sentenças e textos, descobrir como estes [os conteúdos dos termos] contribuem conjuntamente para o significado das sentenças e para realização de inferências.\n",
            "\n",
            "Este capítulo tem como objetivo examinar, além dos frameworks semânticos, tais como AMR (Abstract Meaning Representation) (Banarescu et al., 2013) e DELPH-IN (Copestake et al., 2005), os tipos de bases de conhecimento mais utilizados em PLN. Nesta versão inicial do capítulo, são apresentadas as bases (também chamadas de recursos léxico-semânticos) WordNet de Princeton (Fellbaum, 1998) e FrameNet (Baker; Fillmore; Lowe, 1998), e suas versões em português: OpenWordNet-PT (De Paiva; Rademaker; Melo, 2012) e FrameNet Brasil (FN-BR) (Torrent; Ellsworth, 2013); bem como bases de conhecimento voltadas ao senso comum, tais como a ConceptNet (Speer; Chin; Havasi, 2016) e iniciativas para o português (OMCS-BR (Anacleto et al., 2006) e a InferenceNet-BR (Pinheiro et al., 2010)). Existem outros tipos de bases de conhecimento na área do PLN, tais como dicionários e ontologias diversas, por exemplo, WikiData (Vrandečić; Krötzsch, 2014), YAGO (Suchanek; Kasneci; Weikum, 2007) ou BabelNet (Navigli; Ponzetto, 2012). No entanto, nossa descrição aqui visa apenas a uma primeira exposição dos distintos paradigmas de expressão de conhecimento semântico. Tendo em vista cada base de conhecimento descrita, analisamos um exemplo de texto motivador. Por fim, apresentamos as considerações finais deste capítulo.\n",
            "\n",
            "Na área da Inteligência Artificial (IA), o interesse por bases de conhecimento computáveis ou processáveis por máquina surgiu na década de 60 com as primeiras redes semânticas e representações baseadas em frames, propostas por Minsky (Minsky, 1975) e Fillmore (Fillmore et al., 1976), respectivamente.\n",
            "\n",
            "parte do cap 17\n",
            "\n",
            "Daniela Barreiro Claro \n",
            "\n",
            "Joaquim Santos \n",
            "\n",
            "Marlo Souza \n",
            "\n",
            "Renata Vieira \n",
            "\n",
            "Vládia Pinheiro \n",
            "\n",
            "PDF\n",
            "\n",
            "A Extração de Informação (EI) é desenvolvida com o objetivo de se obter informação estruturada de dados não-estruturados (Jurafsky; Martin, 2023; Konstantinova, 2014).\n",
            "\n",
            "Os primeiros trabalhos a debruçarem-se sobre o problema remontam à década de 1970, com a aplicação de gramáticas formais e parsers sintáticos para a estruturação de informação em domínios como prontuários médicos (Sager, 1978; Sager; Friedman; Lyman, 1987) e textos jornalísticos (DeJong, 1979). A comunidade científica demonstrou grande interesse pela área nas décadas posteriores devido à sua utilidade prática, seu foco no processamento de dados reais, suas tarefas bem-definidas e a facilidade de mensurar a qualidade dos resultados em comparação com o desempenho humano na mesma tarefa (Cowie; Lehnert, 1996).\n",
            "\n",
            "Para autores como Eisenstein (2019) e Jurafsky; Martin (2023), a EI é normalmente dividida em diversas tarefas de interesse, com foco no tipo de informação a ser extraída do texto. Entre as mais comumente citadas na literatura estão o Reconhecimento de Entidades Nomeadas (REN), a Extração de Relações (ER) e a Extração de Eventos (EE).\n",
            "\n",
            "O Reconhecimento de Entidades Nomeadas (REN) consiste em identificar e classificar entidades mencionadas em textos através de designadores rígidos como nomes próprios, expressões temporais e espécies biológicas (Nadeau, 2007). Esse é considerado por alguns como um primeiro passo na análise semântica de um texto (Santos; Cardoso, 2007a), pois permite identificar as entidades às quais se faz referência nele.\n",
            "\n",
            "A Extração de Relações (ER), também chamada de extração de informação tradicional ou somente extração de informação, por sua vez, diz respeito à identificação de relacionamentos semânticos entre duas ou mais entidades, ou seja, identificar “quem fez o que para quem e quando”. Ananiadou; Mcnaught (2005) a definem como o processo de extrair fatos (em nossa terminologia, relacionamentos) a partir de uma fonte textual e representá-los a partir de um gabarito (em inglês, template). As relações são elementos essenciais para o entendimento da informação relatada no texto e sua identificação é passo essencial para a estruturação da mesma. Assim, identificar relações entre entidades é tarefa essencial para construção de bases de conhecimento e de grande utilidade na construção de soluções para a resposta automática a perguntas (em inglês, query answering), sumarização, recuperação de informação e mais (Nasar; Jaffry; Malik, 2021).\n",
            "\n",
            "A extração de eventos consiste na tarefa de identificação de uma menção a um evento em uma sentença e, se existirem, extração de outras informações sobre o evento. Um evento pode, por sua vez, ser entendido como uma ocorrência específica envolvendo participantes (Consortium, 2005), i.e., algo que acontece e que pode ser descrito como uma mudança de estado da qual participam entidades como agentes. Devido a intrínseca natureza temporal dos eventos, tal problema possui uma natureza mais complexa e costuma possuir tratamento específico.\n",
            "\n",
            "Assim, nesse capítulo, iniciaremos com um pouco de história da Extração de Informação (EI) e sua evolução para Extração de Informação Aberta, e destacaremos as tarefas de Reconhecimeno de Entidades Nomeadas (REN) e Extração de Relação (ER).\n",
            "\n",
            "Os primeiros trabalhos que abordaram o problema de EI dos quais temos conhecimento surgiram no final da década de 1970. Esses primeiros trabalhos da década de 1970 e 1980 tinham como modelo geral a aplicação de regras para a identificação de informações especificadas em um gabarito. Tais sistemas empregavam analisadores sintáticos (parsers) e regras definidas especificamente para o domínio e gênero textual estudado.\n",
            "\n",
            "Entre esses primeiros trabalhos, estão aqueles de Sager (1978), Sager; Friedman; Lyman (1987), de DeJong (1979) e de Cowie (1983). Sager et al. exploraram como identificar informações do estado de saúde de pacientes através dos textos de prontuários médicos. DeJong (1979), por sua vez, descrevem o sistema FRUMP que, a partir de um parser e regras de análise conceitual baseadas em uma arquitetura cognitiva proposta pelos autores e no conceito de dependência conceitual de Schank et al. (1973), processavam textos de notícias e realizavam tarefas como sumarização e identificação de papéis semânticos associados aos constituintes da sentença. Cowie (1983), por fim, descreve um sistema que emprega regras simples de segmentação e análise sintática rasa para identificar propriedades de plantas a partir de textos descritivos no campo da botânica. Diferente dos métodos anteriores, o trabalho dos autores se baseia em grande parte no estudo de padrões de descrição das informações a serem identificadas, em detrimento do emprego de parsers robustos da língua.\n",
            "\n",
            "A década de 1990 traz um grande interesse na área de EI com a implementação das conferências MUC (do inglês, Message Understanding Conference, ou Conferência de Compreensão de Mensagem), promovidas pela Agência de Projetos de Pesquisa Avançada de Defesa (DARPA, do inglês Defense Advanced Research Projects Agency). As conferências MUC, realizadas e financiadas pelo exército americano, representaram um esforço em avançar a tecnologia de EI e consistiam de tarefas de avaliação conjunta de métodos desenvolvidos por pesquisadores para problemas propostos pelos organizadores. As sete conferências realizadas de 1987 a 1997, foram cruciais para definir aspectos centrais da área, como estruturar a tarefa de ER, definindo suas métricas de avaliação, e propor a tarefa de REN (Grishman; Sundheim, 1996).\n",
            "\n",
            "parte do cap 9\n",
            "\n",
            "Eloize Rossi Marques Seno \n",
            "\n",
            "Valéria de Paiva \n",
            "\n",
            "Vládia Pinheiro \n",
            "\n",
            "PDF\n",
            "\n",
            "Métodos Simbólicos em Processamento de Linguagem Natural (PLN) envolvem a utilização de regras e representações formais explícitas para processar e entender textos em linguagem natural. Esses métodos especializam-se na manipulação de símbolos e dados estruturados, como gramáticas, ontologias e bases de conhecimento. Especificamente para o entendimento de textos em linguagem natural usando técnicas simbólicas, existem analisadores semânticos (ou parsers semânticos) e bases de conhecimento semântico, que visam fornecer uma representação semântica dos textos. A partir desta representação, motores de inferência são capazes de realizar raciocínio para que aplicações possam, por exemplo, extrair informações, sumarizar textos, e responder perguntas com base nos textos.\n",
            "\n",
            "A Figura 9.1 apresenta uma arquitetura tradicional para sistemas de entendimento de textos em linguagem natural (Natural Language Understanding – NLU). A partir do texto de entrada, uma camada de processamento sintático realiza uma série de análises no texto, tais como detecção de língua, separação de sentenças, tokenização, análise morfológica e sintática (Capítulo 4). Na fronteira entre o processamento sintático e a análise semântica, outros processamentos linguísticos são necessários, como reconhecimento de entidades nomeadas, identificação de expressões multipalavras etc. Em seguida, o texto analisado (sintaticamente) é enviado ao analisador semântico (parser) que gera uma representação lógica do texto. A representação lógica e a(s) base(s) de conhecimento, no que lhes concerne, são entradas para o motor de inferência. Nesse processo, termos do texto de entrada são associados aos elementos da base de conhecimento e o motor de inferência gera respostas a perguntas (queries) para uma aplicação final.\n",
            "\n",
            "Uma “base de conhecimento” refere-se a um repositório centralizado, processável por máquina, que contém informações, dados, regras e procedimentos que são usados para capturar, representar e armazenar conhecimento geral ou de um domínio específico. Tais bases de conhecimento são fontes de conhecimento de mundo e suportam diversas tarefas e aplicações em PLN. Uma base de conhecimento pode ser estruturada de diversas maneiras, incluindo bancos de dados relacionais, linguagem para ontologias (e.g. a OWL1), formalismos para troca de dados entre sistemas (e.g. o formato JSON2), redes semânticas ou sistemas baseados em regras, dependendo da sua finalidade e da natureza do conhecimento armazenado.\n",
            "\n",
            "Fonte: Adaptada de (Ovchinnikova, 2012, p. 9)\n",
            "\n",
            "Tradicionalmente, sistemas lógicos são usados para representação formal dos textos e seus motores de inferência servem para gerar conclusões a partir dos textos. Podemos citar os sistemas lógicos mais usados em PLN: variações de Lógica Descritiva (Description Logic – DL) (Baader et al., 2003), da Lógica de Primeira Ordem (Blackburn; Bos, 2005; Eijck; Unger, 2010), vários tipos de Programação em Lógica (PROLOG) (Dahl, 1994) e Lógicas Intensionais (Shapiro, 2000).\n",
            "\n",
            "Uma característica importante dos sistemas lógicos usados para a semântica de linguagem natural é que eles dependem fortemente da forma lógica do texto ou argumento. No entanto, muitas conclusões e respostas fornecidas ao se ler um texto são justificadas pela contribuição semântica dos conceitos relacionados, não definida a priori, mas somente enquanto usados em um contexto particular. Por exemplo, considere a inferência que conclui que “Alguém foi assassinado” a partir da premissa que “Alguém foi executado”. A contribuição semântica do conceito “executar” (no sentido de “assassinar”) é que torna esta inferência plausível, e não a forma da sentença. Da mesma forma, a inferência “um relâmpago é visto agora” para “um trovão será ouvido em breve” é autorizada pelo conteúdo dos termos “trovão” e “relâmpago”. Para se realizar inferências desta natureza, alguns filósofos como Sellars (Sellars, 1953) e Brandom (Brandom, 2001) propõem abordagens para expressão do significado que suportam análises semânticas não somente sobre a forma das sentenças, mas são capazes de, com base no domínio dos conteúdos dos termos articulados nas sentenças e textos, descobrir como estes [os conteúdos dos termos] contribuem conjuntamente para o significado das sentenças e para realização de inferências.\n",
            "\n",
            "Este capítulo tem como objetivo examinar, além dos frameworks semânticos, tais como AMR (Abstract Meaning Representation) (Banarescu et al., 2013) e DELPH-IN (Copestake et al., 2005), os tipos de bases de conhecimento mais utilizados em PLN. Nesta versão inicial do capítulo, são apresentadas as bases (também chamadas de recursos léxico-semânticos) WordNet de Princeton (Fellbaum, 1998) e FrameNet (Baker; Fillmore; Lowe, 1998), e suas versões em português: OpenWordNet-PT (De Paiva; Rademaker; Melo, 2012) e FrameNet Brasil (FN-BR) (Torrent; Ellsworth, 2013); bem como bases de conhecimento voltadas ao senso comum, tais como a ConceptNet (Speer; Chin; Havasi, 2016) e iniciativas para o português (OMCS-BR (Anacleto et al., 2006) e a InferenceNet-BR (Pinheiro et al., 2010)). Existem outros tipos de bases de conhecimento na área do PLN, tais como dicionários e ontologias diversas, por exemplo, WikiData (Vrandečić; Krötzsch, 2014), YAGO (Suchanek; Kasneci; Weikum, 2007) ou BabelNet (Navigli; Ponzetto, 2012). No entanto, nossa descrição aqui visa apenas a uma primeira exposição dos distintos paradigmas de expressão de conhecimento semântico. Tendo em vista cada base de conhecimento descrita, analisamos um exemplo de texto motivador. Por fim, apresentamos as considerações finais deste capítulo.\n",
            "\n",
            "Na área da Inteligência Artificial (IA), o interesse por bases de conhecimento computáveis ou processáveis por máquina surgiu na década de 60 com as primeiras redes semânticas e representações baseadas em frames, propostas por Minsky (Minsky, 1975) e Fillmore (Fillmore et al., 1976), respectivamente.\n",
            "\n",
            "parte do cap 17\n",
            "\n",
            "A partir da MUC-3, em 1991, a conferência passa a ter foco no processamento de textos jornalísticos em detrimento dos relatórios militares utilizados anteriormente (DARPA, 1991). Com a disponibilidade de dados e o incentivo no desenvolvimento de soluções para a tarefa, vemos na década de 1990 o surgimento das primeiras aplicações comerciais de EI, como o JASPER (Andersen et al., 1992)., construído para a agência de notícias Reuters.\n",
            "\n",
            "A MUC-6, ocorrida em 1995, introduz a tarefa de REN com o intuito de ser uma tarefa de uso prático, independente de domínio e que poderia ser realizada automaticamente em um futuro próximo (Grishman; Sundheim, 1996). Enquanto os trabalhos em REN se avolumaram a partir de sua proposição na MUC-6, trabalhos anteriores como Rau (1991) e Wolinski; Vichot; Dillet (1995) já se debruçavam sobre o problema de identificação e classificação de nomes próprios. Desde então, o interesse na tarefa cresceu significativamente e outras conferências de avaliação conjunta têm sido dedicadas a essa tarefa, como a Automatic Content Extraction (ACE) e a conferência Avaliação de Sistemas de Reconhecimento de Entidades Mencionadas (HAREM), dedicada exclusivamente à língua portuguesa, com sua primeira edição em 2005 (Santos; Cardoso, 2007a).\n",
            "\n",
            "Por outro lado, houve um crescimento de abordagens baseadas em dados nesta década, a partir da análise de corpora. Tais esforços são impulsionados pelos resultados positivos na área, como o trabalho de Hearst (1992). Logo, métodos baseados em dados passaram também a explorar o emprego de análise estatística e aprendizado de máquina na construção de padrões para a extração de relações (Riloff et al., 1993; Riloff; Jones; et al., 1999; Roark; Charniak, 2000; Soderland et al., 1995)\n",
            "\n",
            "Não foi somente na extração de padrões que métodos de aprendizado de máquina, em particular aprendizado supervisionado, foram aplicados. A década de 2000 viu a proliferação de métodos supervisionados aplicados à ER (Culotta; McCallum; Betz, 2006; Kambhatla, 2004; Zelenko; Aone; Richardella, 2003; Zhao; Grishman, 2005) e ao REN (Asahara; Matsumoto, 2003; McCallum; Li, 2003; Sekine, 1998).\n",
            "\n",
            "Devido à dificuldade de construção de dados para treinamento e padrões para extração, além da pouca adaptabilidade dos sistemas construídos para outros escopos e domínios, nos anos 2000, sistemas baseados em métodos de aprendizado semi-supervisionado, como o DIPRE (Brin, 1998) e Snowball (Agichtein; Gravano, 2000) começaram a aparecer, juntamente com os estudos sobre expansão automatizada de anotações (bootstrapping) (Riloff; Jones; et al., 1999). Também para entidades nomeadas, estudos investigaram como utilizar recursos da Web (Etzioni et al., 2005; Nadeau, 2007) ou corpora (Cucchiarelli; Velardi, 2001) para aprender entidades com pouco ou nenhum esforço de anotação.\n",
            "\n",
            "Buscando superar as dificuldades da limitação de escopo, i.e. das relações-alvo a serem extraídas e categorias de entidades a serem identificadas, ainda restritas à definição de padrões desde a criação dessas tarefas, Banko et al. (2007) propõe a tarefa de extração de informação aberta (EIA), também conhecida como Open Information Extraction, OpenIE ou OIE, a qual busca extrair todas as relações possíveis expressas em um texto, sem necessidade de pré-definição de relações e entidades.\n",
            "\n",
            "Devido ao recente sucesso da aplicação de métodos baseados em redes neurais, em particular deep learning e grandes modelos de linguagem, às tarefas de Processamento de Linguagem Natural, uma tendência atual da área se delineou como o estudo de arquiteturas neurais para os problemas de EI e a geração de grandes conjuntos de dados por supervisão fraca. Surveys recentes, como (Cui; Wei; Zhou, 2018; Konstantinova, 2014; Nasar; Jaffry; Malik, 2021), nos mostram a evolução da área em direção à aplicação de métodos neurais. Na vertente de geração de dados, vemos o emprego da Wikipédia e Freebase como fontes mais usadas para obter anotações de entidades e relações em textos (Nguyen; Theobald; Weikum, 2016; Smirnova; Cudré-Mauroux, 2018; Takamatsu; Sato; Nakagawa, 2012).\n",
            "\n",
            "Porém, toda a tarefa de EI necessita de uma concordância entre as definições de Entidade e Relação. Neste sentido, a próxima seção discute a conceituação de relação adotada neste capítulo, assim como o conceito de entidade.\n",
            "\n",
            "A natureza das relações estudadas na área de Extração de Informação e os critérios para reconhecer sua ocorrência em um texto têm recebido pouca atenção na literatura. Este é um passo importante para estabelecer metodologias adequadas para avaliar os sistemas, bem como para criar conjuntos de dados que possam apoiar a criação de sistemas futuros.\n",
            "\n",
            "Enquanto as noções de Relação e Entidade são de grande importância e já bem estudadas nas áreas de Computação, Linguística, Ciência da Informação e Filosofia da Linguagem, esses conceitos não são empregados de forma consistente entre as áreas, ou mesmo entre suas subáreas.\n",
            "\n",
            "Para Chen (1976), uma entidade é um objeto que pode ser concreto, tal como pessoa, livro, casa ou ainda abstrato, tal como um emprego, um sentimento, uma disciplina. As entidades podem estabelecer relações entre si. Duas ou mais entidades são vinculadas, ou seja conectadas por uma relação1.\n",
            "\n",
            "Tradicionalmente em reconhecimento de entidades nomeadas, as entidades consideradas são aquelas referenciadas por um nome próprio, acrescidas das referências temporais e valores que são expressões numéricas. Essas expressões, portanto, geralmente não constituem uma entrada em uma base lexical. Porém a tarefa se expandiu para domínios especializados, onde as entidades de interesse são mais conceituais. No domínio bio-médico por exemplo, podemos ter como exemplo de entidades de interesse, sintomas e tratamento que não são referenciadas por nomes próprios.\n",
            "\n",
            "Os conceitos de relação e relacionamento são noções fundamentais que vêm sendo estudadas em áreas como Ciência da Computação, Linguística e Filosofia.\n",
            "\n",
            "No campo de bancos de dados e modelagem conceitual, Chen (1976) define um relacionamento, no contexto da modelagem de Entidade-Relacionamento, como uma associação entre entidades. Guarino; Guizzardi (2015), por sua vez, estudando a natureza ontológica dos relacionamentos com base na semântica de veridadores (truthmaker semantics) (Fine, 2017), postulam relacionamentos como entidades que atuam como veridadores (thruthmakers) de alguma proposição relacionando duas ou mais entidades, ou seja, uma relação mantida entre essas entidades. Um veridador é um elemento cuja existência torna verdadeira uma proposição particular. Por exemplo, considerando a sentença (1) “a é uma maçã”, a existência de um objeto denotado pelo nome a que por acaso é uma maçã é uma condição suficiente para a verdade da frase (1). Como tal, dizemos que esse objeto é o veridador de (1). Tal definição nos permite adotar critérios ontológicos para validar a existência de relacionamentos a partir da informação relatada em um texto e, por isso, adotaremos tal definição de relacionamento neste capítulo.\n",
            "\n",
            "O conceito de relações é muito menos consistente na literatura. Ainda na área de modelagem conceitual, Guarino; Guizzardi (2015) definem as relações como proposições para as quais os relacionamentos são veridadores e, portanto, possuem conteúdo proposicional. Assim, podemos entender uma relação como um tipo para entidades como relacionamentos. Ou seja, relações são universais ontológicos que descrevem a natureza dos relacionamentos.\n",
            "\n",
            "Xavier; Lima; Souza (2015), no entanto, argumentam que a noção de relacionamento adotada na área de Extração de Informação é mais geral do que isso, não se limitando àquelas entre objetos e propriedades, mas também àquelas que descrevem ou implicam propriedades de classes gerais como descrito pela sentença (2) “Filósofos são autores de Livros”. Assim, para o contexto de EI consideramos relações como tipos de relacionamentos de primeira ou segunda ordem. Isso significa que uma relação é um tipo de relacionamento que existe entre objetos, suas propriedades e classes de objetos ou suas propriedades.\n",
            "\n",
            "parte do cap 9\n",
            "\n",
            "Eloize Rossi Marques Seno \n",
            "\n",
            "Valéria de Paiva \n",
            "\n",
            "Vládia Pinheiro \n",
            "\n",
            "PDF\n",
            "\n",
            "Métodos Simbólicos em Processamento de Linguagem Natural (PLN) envolvem a utilização de regras e representações formais explícitas para processar e entender textos em linguagem natural. Esses métodos especializam-se na manipulação de símbolos e dados estruturados, como gramáticas, ontologias e bases de conhecimento. Especificamente para o entendimento de textos em linguagem natural usando técnicas simbólicas, existem analisadores semânticos (ou parsers semânticos) e bases de conhecimento semântico, que visam fornecer uma representação semântica dos textos. A partir desta representação, motores de inferência são capazes de realizar raciocínio para que aplicações possam, por exemplo, extrair informações, sumarizar textos, e responder perguntas com base nos textos.\n",
            "\n",
            "A Figura 9.1 apresenta uma arquitetura tradicional para sistemas de entendimento de textos em linguagem natural (Natural Language Understanding – NLU). A partir do texto de entrada, uma camada de processamento sintático realiza uma série de análises no texto, tais como detecção de língua, separação de sentenças, tokenização, análise morfológica e sintática (Capítulo 4). Na fronteira entre o processamento sintático e a análise semântica, outros processamentos linguísticos são necessários, como reconhecimento de entidades nomeadas, identificação de expressões multipalavras etc. Em seguida, o texto analisado (sintaticamente) é enviado ao analisador semântico (parser) que gera uma representação lógica do texto. A representação lógica e a(s) base(s) de conhecimento, no que lhes concerne, são entradas para o motor de inferência. Nesse processo, termos do texto de entrada são associados aos elementos da base de conhecimento e o motor de inferência gera respostas a perguntas (queries) para uma aplicação final.\n",
            "\n",
            "Uma “base de conhecimento” refere-se a um repositório centralizado, processável por máquina, que contém informações, dados, regras e procedimentos que são usados para capturar, representar e armazenar conhecimento geral ou de um domínio específico. Tais bases de conhecimento são fontes de conhecimento de mundo e suportam diversas tarefas e aplicações em PLN. Uma base de conhecimento pode ser estruturada de diversas maneiras, incluindo bancos de dados relacionais, linguagem para ontologias (e.g. a OWL1), formalismos para troca de dados entre sistemas (e.g. o formato JSON2), redes semânticas ou sistemas baseados em regras, dependendo da sua finalidade e da natureza do conhecimento armazenado.\n",
            "\n",
            "Fonte: Adaptada de (Ovchinnikova, 2012, p. 9)\n",
            "\n",
            "Tradicionalmente, sistemas lógicos são usados para representação formal dos textos e seus motores de inferência servem para gerar conclusões a partir dos textos. Podemos citar os sistemas lógicos mais usados em PLN: variações de Lógica Descritiva (Description Logic – DL) (Baader et al., 2003), da Lógica de Primeira Ordem (Blackburn; Bos, 2005; Eijck; Unger, 2010), vários tipos de Programação em Lógica (PROLOG) (Dahl, 1994) e Lógicas Intensionais (Shapiro, 2000).\n",
            "\n",
            "Uma característica importante dos sistemas lógicos usados para a semântica de linguagem natural é que eles dependem fortemente da forma lógica do texto ou argumento. No entanto, muitas conclusões e respostas fornecidas ao se ler um texto são justificadas pela contribuição semântica dos conceitos relacionados, não definida a priori, mas somente enquanto usados em um contexto particular. Por exemplo, considere a inferência que conclui que “Alguém foi assassinado” a partir da premissa que “Alguém foi executado”. A contribuição semântica do conceito “executar” (no sentido de “assassinar”) é que torna esta inferência plausível, e não a forma da sentença. Da mesma forma, a inferência “um relâmpago é visto agora” para “um trovão será ouvido em breve” é autorizada pelo conteúdo dos termos “trovão” e “relâmpago”. Para se realizar inferências desta natureza, alguns filósofos como Sellars (Sellars, 1953) e Brandom (Brandom, 2001) propõem abordagens para expressão do significado que suportam análises semânticas não somente sobre a forma das sentenças, mas são capazes de, com base no domínio dos conteúdos dos termos articulados nas sentenças e textos, descobrir como estes [os conteúdos dos termos] contribuem conjuntamente para o significado das sentenças e para realização de inferências.\n",
            "\n",
            "Este capítulo tem como objetivo examinar, além dos frameworks semânticos, tais como AMR (Abstract Meaning Representation) (Banarescu et al., 2013) e DELPH-IN (Copestake et al., 2005), os tipos de bases de conhecimento mais utilizados em PLN. Nesta versão inicial do capítulo, são apresentadas as bases (também chamadas de recursos léxico-semânticos) WordNet de Princeton (Fellbaum, 1998) e FrameNet (Baker; Fillmore; Lowe, 1998), e suas versões em português: OpenWordNet-PT (De Paiva; Rademaker; Melo, 2012) e FrameNet Brasil (FN-BR) (Torrent; Ellsworth, 2013); bem como bases de conhecimento voltadas ao senso comum, tais como a ConceptNet (Speer; Chin; Havasi, 2016) e iniciativas para o português (OMCS-BR (Anacleto et al., 2006) e a InferenceNet-BR (Pinheiro et al., 2010)). Existem outros tipos de bases de conhecimento na área do PLN, tais como dicionários e ontologias diversas, por exemplo, WikiData (Vrandečić; Krötzsch, 2014), YAGO (Suchanek; Kasneci; Weikum, 2007) ou BabelNet (Navigli; Ponzetto, 2012). No entanto, nossa descrição aqui visa apenas a uma primeira exposição dos distintos paradigmas de expressão de conhecimento semântico. Tendo em vista cada base de conhecimento descrita, analisamos um exemplo de texto motivador. Por fim, apresentamos as considerações finais deste capítulo.\n",
            "\n",
            "Na área da Inteligência Artificial (IA), o interesse por bases de conhecimento computáveis ou processáveis por máquina surgiu na década de 60 com as primeiras redes semânticas e representações baseadas em frames, propostas por Minsky (Minsky, 1975) e Fillmore (Fillmore et al., 1976), respectivamente.\n",
            "\n",
            "parte do cap 17\n",
            "\n",
            "Enquanto os métodos tradicionais de Extração de Informação dependem de um conjunto pré-existente de relações semânticas bem definidas que são relevantes para um domínio específico, a noção de “relação” e “entidade” na literatura da área mais recente, tais como a Extração de Informação Aberta, requer mais aprofundamento por demandar um significado diferente, principalmente com diferente visões de autores. Esta indeterminação terminológica pode trazer problemas para comparar os resultados dos métodos propostos ou para reutilizar os conjuntos de dados criados na área.\n",
            "\n",
            "As seções seguintes exploram essas duas áreas: Extração de Informação e Extração de Informação Aberta.\n",
            "\n",
            "A Extração de Informação é caracterizada por obter informação estruturada a partir de textos, sendo entidades ou fatos, i.e. relacionamentos entre entidades, de tipos previamente definidos, conforme exemplo na Quadro 17.1. Métodos com limitação de escopo possuem como uma de suas principais desvantagens a necessidade de intervenção humana para especificar novos fatos a serem extraídos. Esta limitação impede que sistemas de Extração de Informação, doravante denominados de EI tradicional extraiam fatos fora do escopo pré-definido.\n",
            "\n",
            "Quadro 17.1 Exemplos de relações específicas na EI tradicional\n",
            "\n",
            "Fonte: (Souza; Claro, 2014)\n",
            "\n",
            "O Reconhecimento de Entidades Nomeadas (REN) consiste na tarefa de identificar e classificar expressões linguísticas, denominadas entidades nomeadas (EN), que referenciam entidades específicas num domínio de discurso, como nomes próprios, expressões temporais e espécies biológicas (Mota; Santos; Ranchhod, 2007; Nadeau, 2007). De uma forma geral, o REN pode ser dividido em duas etapas: a identificação (ou delimitação) da expressão, na qual as palavras que formam a EN são selecionadas; a classificação, em que é atribuída uma categoria semântica à EN.\n",
            "\n",
            "A classificação das ENs determina os tipos de entidades a serem consideradas e são especificadas a partir do escopo definido previamente para a tarefa. Algumas das categorias mais comumente utilizadas incluem as entidades que referenciam Pessoas Singulares (antropônimos); Coletivas (empresas e organizações) e Lugares (topônimos) (Mota; Santos; Ranchhod, 2007). Para exemplificar tomemos a sentença: “Renata Silva e Maria Costa palestraram na Universidade Federal da Bahia”. No exemplo temos três ENs: “Renata Silva”, “Maria Costa”, “Universidade Federal da Bahia”, sendo as duas primeiras correspondentes à categoria semântica Pessoa e a última, à categoria semântica Organização. Entretanto, existem outras categorias de ENs, como as menções a Obras (por exemplo, “Código Da Vinci”); Acontecimentos (por exemplo, “Festa de Santo Antônio”), Tempo (por exemplo, “meio-dia”); Coisa (por exemplo, “barco”), entre outras.\n",
            "\n",
            "O REN é uma tarefa com grande importância para o Processamento de Linguagem Natural, pois consiste numa primeira tarefa de análise semântica de um texto, com potencial aplicações a diversas tarefas. Por exemplo, em sistemas de perguntas e respostas, as perguntas frequentemente se referem a informações sobre entidades. Também, métodos de identificação de estruturas mais complexas, como eventos ou relações, dependem do bom desempenho do REN como uma etapa de pré-processamento (Socher et al., 2012; Zelenko; Aone; Richardella, 2003).\n",
            "\n",
            "A tarefa de extração de relações (ou de relacionamentos) (ER) refere-se a identificar relacionamentos entre entidades de um determinado escopo mencionadas em um texto (Jurafsky; Martin, 2023). O escopo, no contexto da ER, refere-se a um conjunto de relações-alvo de um determinado domínio de conhecimento ou aplicação a ser investigado. Por exemplo, o Quadro 17.2 apresenta alguns exemplos de relações no domínio de geografia brasileira. Na descrição das relações, os elementos em negrito referem-se às entidades em um dado relacionamento descrito pelo termo em itálico.\n",
            "\n",
            "Quadro 17.2 Exemplos de relações no domínio da geografia brasileira.\n",
            "\n",
            "Nesse contexto, a delimitação de um escopo ou domínio de interesse, concentra-se na determinação das relações a serem processadas, i.e. nos tipos de relacionamentos de interesse, assim como da natureza das entidades associadas por tais relações.\n",
            "\n",
            "As tarefas de reconhecimento de entidades nomeadas e extração de relações são interdependentes, no sentido de que a definição do escopo a ser estudado delimita tanto as categorias e natureza das entidades a serem extraídas, como também as relações entre essas entidades. Também, note-se que, pelo fato de as relações serem comumente definidas entre entidades de tipo especificado, como o caso da relação Tem_Prefeito no Quadro 17.2 que ocorre entre entidades das classes Cidade e Pessoa, tanto as informações das entidades mencionadas no texto são úteis para a extração de relações, quanto a informação das relações identificadas pode ser útil ao processo de identificação de entidades.\n",
            "\n",
            "De fato, na literatura recente, existem vários trabalhos que consideram a tarefa de extração conjunta de entidades e relações (ERE, do inglês Entity and Relation Joint Extraction), composta das tarefas de REN e ER (Agichtein; Gravano, 2000; Shaowei et al., 2022; Yuan et al., 2021). Enquanto normalmente abordagens estruturam suas soluções de forma sequencial, usualmente realizando REN inicialmente e, posteriormente, realizando ER, como nos trabalhos de (Hasegawa; Sekine; Grishman, 2004) e de (Socher et al., 2012), a literatura recente aponta para as vantagens da identificação conjunta ao permitir um melhor aprendizado de restrições para identificação de entidades e relações, c.f. o recente survey realizado por (Shaowei et al., 2022) sobre métodos para tal tarefa.\n",
            "\n",
            "Várias abordagens foram adotadas para o problema de EI durante seu desenvolvimento histórico. Enquanto abordagens iniciais privilegiavam métodos ricos em conhecimento, como regras e recursos linguísticos e de conhecimento de mundo, a literatura recente na área privilegia métodos baseados em dados, como o aprendizado de máquina, com o recente emprego de arquiteturas neurais aos problemas.\n",
            "\n",
            "A seguir faremos uma breve apresentação das abordagens descritas na literatura para os problemas de EI.\n",
            "\n",
            "parte do cap 9\n",
            "\n",
            "Eloize Rossi Marques Seno \n",
            "\n",
            "Valéria de Paiva \n",
            "\n",
            "Vládia Pinheiro \n",
            "\n",
            "PDF\n",
            "\n",
            "Métodos Simbólicos em Processamento de Linguagem Natural (PLN) envolvem a utilização de regras e representações formais explícitas para processar e entender textos em linguagem natural. Esses métodos especializam-se na manipulação de símbolos e dados estruturados, como gramáticas, ontologias e bases de conhecimento. Especificamente para o entendimento de textos em linguagem natural usando técnicas simbólicas, existem analisadores semânticos (ou parsers semânticos) e bases de conhecimento semântico, que visam fornecer uma representação semântica dos textos. A partir desta representação, motores de inferência são capazes de realizar raciocínio para que aplicações possam, por exemplo, extrair informações, sumarizar textos, e responder perguntas com base nos textos.\n",
            "\n",
            "A Figura 9.1 apresenta uma arquitetura tradicional para sistemas de entendimento de textos em linguagem natural (Natural Language Understanding – NLU). A partir do texto de entrada, uma camada de processamento sintático realiza uma série de análises no texto, tais como detecção de língua, separação de sentenças, tokenização, análise morfológica e sintática (Capítulo 4). Na fronteira entre o processamento sintático e a análise semântica, outros processamentos linguísticos são necessários, como reconhecimento de entidades nomeadas, identificação de expressões multipalavras etc. Em seguida, o texto analisado (sintaticamente) é enviado ao analisador semântico (parser) que gera uma representação lógica do texto. A representação lógica e a(s) base(s) de conhecimento, no que lhes concerne, são entradas para o motor de inferência. Nesse processo, termos do texto de entrada são associados aos elementos da base de conhecimento e o motor de inferência gera respostas a perguntas (queries) para uma aplicação final.\n",
            "\n",
            "Uma “base de conhecimento” refere-se a um repositório centralizado, processável por máquina, que contém informações, dados, regras e procedimentos que são usados para capturar, representar e armazenar conhecimento geral ou de um domínio específico. Tais bases de conhecimento são fontes de conhecimento de mundo e suportam diversas tarefas e aplicações em PLN. Uma base de conhecimento pode ser estruturada de diversas maneiras, incluindo bancos de dados relacionais, linguagem para ontologias (e.g. a OWL1), formalismos para troca de dados entre sistemas (e.g. o formato JSON2), redes semânticas ou sistemas baseados em regras, dependendo da sua finalidade e da natureza do conhecimento armazenado.\n",
            "\n",
            "Fonte: Adaptada de (Ovchinnikova, 2012, p. 9)\n",
            "\n",
            "Tradicionalmente, sistemas lógicos são usados para representação formal dos textos e seus motores de inferência servem para gerar conclusões a partir dos textos. Podemos citar os sistemas lógicos mais usados em PLN: variações de Lógica Descritiva (Description Logic – DL) (Baader et al., 2003), da Lógica de Primeira Ordem (Blackburn; Bos, 2005; Eijck; Unger, 2010), vários tipos de Programação em Lógica (PROLOG) (Dahl, 1994) e Lógicas Intensionais (Shapiro, 2000).\n",
            "\n",
            "Uma característica importante dos sistemas lógicos usados para a semântica de linguagem natural é que eles dependem fortemente da forma lógica do texto ou argumento. No entanto, muitas conclusões e respostas fornecidas ao se ler um texto são justificadas pela contribuição semântica dos conceitos relacionados, não definida a priori, mas somente enquanto usados em um contexto particular. Por exemplo, considere a inferência que conclui que “Alguém foi assassinado” a partir da premissa que “Alguém foi executado”. A contribuição semântica do conceito “executar” (no sentido de “assassinar”) é que torna esta inferência plausível, e não a forma da sentença. Da mesma forma, a inferência “um relâmpago é visto agora” para “um trovão será ouvido em breve” é autorizada pelo conteúdo dos termos “trovão” e “relâmpago”. Para se realizar inferências desta natureza, alguns filósofos como Sellars (Sellars, 1953) e Brandom (Brandom, 2001) propõem abordagens para expressão do significado que suportam análises semânticas não somente sobre a forma das sentenças, mas são capazes de, com base no domínio dos conteúdos dos termos articulados nas sentenças e textos, descobrir como estes [os conteúdos dos termos] contribuem conjuntamente para o significado das sentenças e para realização de inferências.\n",
            "\n",
            "Este capítulo tem como objetivo examinar, além dos frameworks semânticos, tais como AMR (Abstract Meaning Representation) (Banarescu et al., 2013) e DELPH-IN (Copestake et al., 2005), os tipos de bases de conhecimento mais utilizados em PLN. Nesta versão inicial do capítulo, são apresentadas as bases (também chamadas de recursos léxico-semânticos) WordNet de Princeton (Fellbaum, 1998) e FrameNet (Baker; Fillmore; Lowe, 1998), e suas versões em português: OpenWordNet-PT (De Paiva; Rademaker; Melo, 2012) e FrameNet Brasil (FN-BR) (Torrent; Ellsworth, 2013); bem como bases de conhecimento voltadas ao senso comum, tais como a ConceptNet (Speer; Chin; Havasi, 2016) e iniciativas para o português (OMCS-BR (Anacleto et al., 2006) e a InferenceNet-BR (Pinheiro et al., 2010)). Existem outros tipos de bases de conhecimento na área do PLN, tais como dicionários e ontologias diversas, por exemplo, WikiData (Vrandečić; Krötzsch, 2014), YAGO (Suchanek; Kasneci; Weikum, 2007) ou BabelNet (Navigli; Ponzetto, 2012). No entanto, nossa descrição aqui visa apenas a uma primeira exposição dos distintos paradigmas de expressão de conhecimento semântico. Tendo em vista cada base de conhecimento descrita, analisamos um exemplo de texto motivador. Por fim, apresentamos as considerações finais deste capítulo.\n",
            "\n",
            "Na área da Inteligência Artificial (IA), o interesse por bases de conhecimento computáveis ou processáveis por máquina surgiu na década de 60 com as primeiras redes semânticas e representações baseadas em frames, propostas por Minsky (Minsky, 1975) e Fillmore (Fillmore et al., 1976), respectivamente.\n",
            "\n",
            "parte do cap 17\n",
            "\n",
            "As abordagens iniciais para REN baseavam-se, majoritariamente, no emprego de regras lexico-sintáticas e consulta a almanaques (gazeeers). Tais abordagens dependem da construção de listas de nomes próprios como antropônimos, topônimos etc., e outras palavras, como “Ltda.”, “Jr.” etc., que auxiliam no processo de identificação e classificação de ENs complexas ou desconhecidas. Essa é, por exemplo, a abordagem empregada por Wolinski; Vichot; Dillet (1995) que combina almanaques e regras para a identificação e classificação de ENs. Posteriormente, almanaques foram também empregados em conjunção com métodos baseados em dados, como o trabalho de Florian et al. (2003) que os emprega aliados aos classificadores, enquanto Liu; Yao; Lin (2019) os utilizam durante o treinamento de uma rede neural, como um sinal de treinamento (parte da função de perda, ou loss em inglês).\n",
            "\n",
            "Muitos trabalhos debruçaram-se também sobre o problema de construção automática ou semi-automática de almanaques, dos quais os trabalhos de Nadeau (2007), de Riloff; Jones; et al. (1999) e de Etzioni et al. (2005) são alguns dos mais importantes.\n",
            "\n",
            "Enquanto as abordagens iniciais para o problema baseavam-se em regras, com a disponibilidade de dados anotados para a tarefa, tais métodos foram rapidamente suplantados por métodos baseados em dados, tais como: os métodos baseados em classificação (Asahara; Matsumoto, 2003; Sekine, 1998) e classificação sequencial (Bikel; Schwartz; Weischedel, 1999; McCallum; Li, 2003).\n",
            "\n",
            "A redução de REN à tarefa de classificação sequencial merece destaque pelos bons resultados obtidos. Tal redução se dá através de um esquema de codificação do problema que nos permite representar fragmentos textuais e sua classificação como um problema de rotulação ou etiquetação.\n",
            "\n",
            "Partindo-se do pressuposto de que os fragmentos textuais descrevendo entidades nomeadas são contíguos, podemos codificar a tarefa de delimitação de entidades como classificação sequencial empregando rótulos que descrevem os limites de uma EN, e.g. o esquema BIO com os rótulos B (do inglês, begin) para designar a palavra inicial de uma EN, I (do inglês, inside) para designar palavras que fazem parte da EN mas não a iniciam e O (do inglês, outside) para designar palavras que não pertencem a uma entidade. Da mesma forma, podemos estender nosso esquema de codificação para incluir as classes de interesse. Assim, seguindo o esquema BIO, teremos os rótulos B-PER e I-PER para descrever entidades da classe Pessoa.\n",
            "\n",
            "A redução do problema de REN à classificação sequencial está ilustrada no Exemplo 17.1.\n",
            "\n",
            "Exemplo 17.1  \n",
            "\n",
            "Renata/B-PER Silva/I-PER e/O Maria/B-PER Costa/I-PER palestraram/O na/O Universidade/B-ORG Federal/I-ORG da/I-ORG Bahia/I-ORG.\n",
            "\n",
            "Recentemente, destacam-se na literatura abordagens baseadas em redes neurais profundas, com uma grande concentração nos últimos anos em modelos gerativos de linguagem, devido aos resultados positivos obtidos por tais arquiteturas em diversas tarefas.\n",
            "\n",
            "Na literatura são de grande destaque os modelos recentes BART (Lewis et al., 2020), RoBERTa (Liu et al., 2019), T5 (Raffel et al., 2020), BERT (Devlin et al., 2019) e GPT-3 (Brown et al., 2020), conforme descritos no Capítulo 15.\n",
            "\n",
            "Similarmente, na língua portuguesa, nas duas edições do HAREM (Mota; Santos, 2008; Santos; Cardoso, 2007b), o primeiro esforço sistemático de desenvolvimento de soluções para a tarefa na língua, a maioria dos sistemas participantes baseava-se em métodos ricos em conhecimento, como regras e almanaques. De fato, nas duas avaliações, somente os sistemas MALINCHE (Solorio, 2007), NEURA (Ferrández et al., 2007) e R3M (Mota, 2008) não se baseavam em regras. Métodos baseados em classificação sequencial se seguiram para a língua portuguesa, como o RELP-CRF (Amaral; Vieira, 2014) baseado em um classificador sequencial. Mais recentemente, abordagens baseadas em redes neurais e modelos de linguagem foram desenvolvidas tornando-se o estado da arte da tarefa na língua. A Tabela 17.1 apresenta o atual estado da arte em português, com base no corpus HAREM. A métrica de avaliação apresentada, medida F1, será discutida na Seção 17.6.\n",
            "\n",
            "Souza; Nogueira; Lotufo (2020) desenvolveram um modelo BERT para o Português com 2,68 bilhões de tokens e aplicaram o modelo em um classificador CRF. Santos et al., avaliaram o impacto do modelo contextualizado Flair Embeddings aplicado a tarefa de REN junto com uma rede neural BiLSTM-CRF. Os autores também desenvolveram um modelo Flair Embeddings para o português, o FlairBBP, treinado com 4,9 bilhões de tokens (Santos et al., 2019). Castro; Silva; Soares (2018) utilizou uma rede LSTM e um classificador CRF junto com modelos Word Embeddings pré-treinados. Santos; Guimarães (2015) desenvolveram uma rede neural convolucional capaz de capturar características a nível de caracteres e também de incorporar word embeddings pré-treinados.\n",
            "\n",
            "O reconhecimento de entidades tem sido aplicado em muitas áreas específicas, como direito, saúde e geologia. Nesses casos há uma demanda de adaptação dos modelos preditivos de acordo com a nova linguagem especializada do domínio e um novo conjunto de rótulos que devem ser aprendidos. Da mesma forma, são necessários novos conjuntos de dados para o processo de aprendizado, uma vez que abordagens de aprendizado de máquina necessitam de exemplos anotados para se chegar a um modelo preditivo eficaz.\n",
            "\n",
            "Muitos trabalhos endereçam domínios específicos, citamos exemplos em diversas línguas. Para o inglês, uma rede neural BiLSTM-CRF para o domínio biomédico é proposta em (Habibi et al., 2017).\n",
            "\n",
            "Um conjunto de dados do domínio jurídico em língua alemã é apresentado por Leitner; Rehm; Schneider (2019), que empregam redes neurais BiLSTM para a rotulação dos textos. Em (Qiu et al., 2019), uma rede neural BiLSTM-CRF com mecanismo de atenção é aplicada para reconhecer entidades geológicas para a língua chinesa.\n",
            "\n",
            "parte do cap 9\n",
            "\n",
            "Eloize Rossi Marques Seno \n",
            "\n",
            "Valéria de Paiva \n",
            "\n",
            "Vládia Pinheiro \n",
            "\n",
            "PDF\n",
            "\n",
            "Métodos Simbólicos em Processamento de Linguagem Natural (PLN) envolvem a utilização de regras e representações formais explícitas para processar e entender textos em linguagem natural. Esses métodos especializam-se na manipulação de símbolos e dados estruturados, como gramáticas, ontologias e bases de conhecimento. Especificamente para o entendimento de textos em linguagem natural usando técnicas simbólicas, existem analisadores semânticos (ou parsers semânticos) e bases de conhecimento semântico, que visam fornecer uma representação semântica dos textos. A partir desta representação, motores de inferência são capazes de realizar raciocínio para que aplicações possam, por exemplo, extrair informações, sumarizar textos, e responder perguntas com base nos textos.\n",
            "\n",
            "A Figura 9.1 apresenta uma arquitetura tradicional para sistemas de entendimento de textos em linguagem natural (Natural Language Understanding – NLU). A partir do texto de entrada, uma camada de processamento sintático realiza uma série de análises no texto, tais como detecção de língua, separação de sentenças, tokenização, análise morfológica e sintática (Capítulo 4). Na fronteira entre o processamento sintático e a análise semântica, outros processamentos linguísticos são necessários, como reconhecimento de entidades nomeadas, identificação de expressões multipalavras etc. Em seguida, o texto analisado (sintaticamente) é enviado ao analisador semântico (parser) que gera uma representação lógica do texto. A representação lógica e a(s) base(s) de conhecimento, no que lhes concerne, são entradas para o motor de inferência. Nesse processo, termos do texto de entrada são associados aos elementos da base de conhecimento e o motor de inferência gera respostas a perguntas (queries) para uma aplicação final.\n",
            "\n",
            "Uma “base de conhecimento” refere-se a um repositório centralizado, processável por máquina, que contém informações, dados, regras e procedimentos que são usados para capturar, representar e armazenar conhecimento geral ou de um domínio específico. Tais bases de conhecimento são fontes de conhecimento de mundo e suportam diversas tarefas e aplicações em PLN. Uma base de conhecimento pode ser estruturada de diversas maneiras, incluindo bancos de dados relacionais, linguagem para ontologias (e.g. a OWL1), formalismos para troca de dados entre sistemas (e.g. o formato JSON2), redes semânticas ou sistemas baseados em regras, dependendo da sua finalidade e da natureza do conhecimento armazenado.\n",
            "\n",
            "Fonte: Adaptada de (Ovchinnikova, 2012, p. 9)\n",
            "\n",
            "Tradicionalmente, sistemas lógicos são usados para representação formal dos textos e seus motores de inferência servem para gerar conclusões a partir dos textos. Podemos citar os sistemas lógicos mais usados em PLN: variações de Lógica Descritiva (Description Logic – DL) (Baader et al., 2003), da Lógica de Primeira Ordem (Blackburn; Bos, 2005; Eijck; Unger, 2010), vários tipos de Programação em Lógica (PROLOG) (Dahl, 1994) e Lógicas Intensionais (Shapiro, 2000).\n",
            "\n",
            "Uma característica importante dos sistemas lógicos usados para a semântica de linguagem natural é que eles dependem fortemente da forma lógica do texto ou argumento. No entanto, muitas conclusões e respostas fornecidas ao se ler um texto são justificadas pela contribuição semântica dos conceitos relacionados, não definida a priori, mas somente enquanto usados em um contexto particular. Por exemplo, considere a inferência que conclui que “Alguém foi assassinado” a partir da premissa que “Alguém foi executado”. A contribuição semântica do conceito “executar” (no sentido de “assassinar”) é que torna esta inferência plausível, e não a forma da sentença. Da mesma forma, a inferência “um relâmpago é visto agora” para “um trovão será ouvido em breve” é autorizada pelo conteúdo dos termos “trovão” e “relâmpago”. Para se realizar inferências desta natureza, alguns filósofos como Sellars (Sellars, 1953) e Brandom (Brandom, 2001) propõem abordagens para expressão do significado que suportam análises semânticas não somente sobre a forma das sentenças, mas são capazes de, com base no domínio dos conteúdos dos termos articulados nas sentenças e textos, descobrir como estes [os conteúdos dos termos] contribuem conjuntamente para o significado das sentenças e para realização de inferências.\n",
            "\n",
            "Este capítulo tem como objetivo examinar, além dos frameworks semânticos, tais como AMR (Abstract Meaning Representation) (Banarescu et al., 2013) e DELPH-IN (Copestake et al., 2005), os tipos de bases de conhecimento mais utilizados em PLN. Nesta versão inicial do capítulo, são apresentadas as bases (também chamadas de recursos léxico-semânticos) WordNet de Princeton (Fellbaum, 1998) e FrameNet (Baker; Fillmore; Lowe, 1998), e suas versões em português: OpenWordNet-PT (De Paiva; Rademaker; Melo, 2012) e FrameNet Brasil (FN-BR) (Torrent; Ellsworth, 2013); bem como bases de conhecimento voltadas ao senso comum, tais como a ConceptNet (Speer; Chin; Havasi, 2016) e iniciativas para o português (OMCS-BR (Anacleto et al., 2006) e a InferenceNet-BR (Pinheiro et al., 2010)). Existem outros tipos de bases de conhecimento na área do PLN, tais como dicionários e ontologias diversas, por exemplo, WikiData (Vrandečić; Krötzsch, 2014), YAGO (Suchanek; Kasneci; Weikum, 2007) ou BabelNet (Navigli; Ponzetto, 2012). No entanto, nossa descrição aqui visa apenas a uma primeira exposição dos distintos paradigmas de expressão de conhecimento semântico. Tendo em vista cada base de conhecimento descrita, analisamos um exemplo de texto motivador. Por fim, apresentamos as considerações finais deste capítulo.\n",
            "\n",
            "Na área da Inteligência Artificial (IA), o interesse por bases de conhecimento computáveis ou processáveis por máquina surgiu na década de 60 com as primeiras redes semânticas e representações baseadas em frames, propostas por Minsky (Minsky, 1975) e Fillmore (Fillmore et al., 1976), respectivamente.\n",
            "\n",
            "parte do cap 17\n",
            "\n",
            "Para o português, um corpus para detecção de eventos de quedas de pacientes em prontuários eletrônicos é descrito em (Santos; Santos; Vieira, 2020). Os autores usaram uma rede neural BiLSTM-CRF+Flair para gerar um modelo classificador de tokens. Um corpus no domínio jurídico, tendo categorias específicas como legislação e jurisprudência é proposto por  Araujo et al. (2018), que usaram uma rede neural BiLSTM-CRF para criar um primeiro baseline para esse corpus. Ademais, Consoli et al. (2020) analisam um corpus no domínio de geologia usando uma rede neural BiLSTM-CRF com um modelo contextualizado Flair Embeddings.\n",
            "\n",
            "As abordagens iniciais para o problema de ER baseavam-se na definição de gabaritos e regras de extração, com base em informação sintática obtida de analisadores sintáticos rasos ou profundos (Cowie, 1983; Sager, 1978). Tais métodos foram rapidamente suplantados por métodos baseados em dados e padrões obtidos de corpora, como os famosos padrões de Hearst (1992) para identificação de relações de hiponímia.\n",
            "\n",
            "O trabalho de Hearst (1992) se baseou na definição de padrões lexico-sintáticos para expressão de relações de hiponímia e hiperonímia a partir de uma análise de corpus. Ao escolher a relação de hiponímia, que ocorre em todo domínio, e padrões gerais baseados em aspectos da língua, como os representados no Quadro 17.3, o autor garante generalizabilidade dos padrões obtidos para diversos domínios e aplicações.\n",
            "\n",
            "Quadro 17.3 Exemplos de Padrões de Hearst para hiponímia\n",
            "\n",
            "Devido à dificuldade de construção manual das regras, os métodos de Riloff et al. (1993), empregam heurísticas para geração de padrões baseadas em informação gramatical, e de Soderland et al. (1995), que se baseia numa semântica de quadros (frames) empregando um analisador semântico e medidas de qualidade de identificação de exemplos, baseado no percentual de acerto sobre relacionamentos previamente conhecidos, para identificação de quadros relevantes.\n",
            "\n",
            "As abordagens baseadas em aprendizado de máquina, hoje as mais comuns e com melhor desempenho na literatura (Konstantinova, 2014; Nasar; Jaffry; Malik, 2021) dividem-se em abordagens que realizam reconhecimento de entidades e extração de relações de forma conjunta e separada.\n",
            "\n",
            "Abordagens baseadas na realização de REN e ER de forma separada baseiam-se em um fluxo de processamento em que, em geral, as entidades são identificadas primeiro e a tarefa de ER se reduz a identificar quando uma sentença ou fragmento textual denota uma relação semântica entre duas entidades. Consideremos o Exemplo 17.2, retirado de (Socher et al., 2012):\n",
            "\n",
            "Exemplo 17.2  \n",
            "\n",
            "Gripe aviária]\\(_{e1}\\) é uma doença infecciosa causada pelo vírus da [influenza tipo a]\\(_{e2}\\)\n",
            "\n",
            "Podemos, então, reduzir o problema de identificar a relação Causa-Efeito(\\(e1\\),\\(e2\\)) a um problema de classificação textual, identificando se a sentença acima fornece indícios para a expressão da relação de interesse. As soluções propostas na literatura para o problema são variadas e baseadas em diferentes métodos.\n",
            "\n",
            "Zelenko; Aone; Richardella (2003), por exemplo, propõem funções de kernel para árvores sintáticas rasas, i.e. funções que descrevem medidas de similaridade entre tais árvores. Eles empregam tais medidas para treinar um classificador de perceptron com votação (voted perceptron) sobre relações no domínio de organizações extraídas de um corpus de textos jornalísticos. De forma similar, Zhao; Grishman (2005) empregam diferentes funções de kernel sobre informações sintáticas relevantes para a identificação de relação e argumentos visando treinar um classificador SVM sobre o corpus de ER da conferência ACE.\n",
            "\n",
            "Culotta; McCallum; Betz (2006), por outro lado, empregam um classificador sequencial baseado em modelos escondidos de Markov para identificação de relações em um texto. Ao restringir sua análise a textos biográficos, os autores reduzem o processo de identificar instâncias de relações à identificação de fragmento textual que delimita o argumento e sua classificação, tarefa para a qual a classificação sequencial já é comumente utilizada. Consideremos o Exemplo 17.3 sobre George W. Bush, retirado de (Culotta; McCallum; Betz, 2006):\n",
            "\n",
            "Exemplo 17.3  \n",
            "\n",
            "George é filho de \\(\\underbrace{\\mbox{George H. W. Bush}}_{\\mbox{pai}}\\) e \\(\\underbrace{\\mbox{Barbara Bush}}_{\\mbox{mãe}}\\).\n",
            "\n",
            "Ao identificar o papel de pai e mãe, os autores conseguem construir a relação Pai(George H. W. Bush, George W. Bush) e Mãe(Barbara Bush, George W. Bush).\n",
            "\n",
            "parte do cap 9\n",
            "\n",
            "Eloize Rossi Marques Seno \n",
            "\n",
            "Valéria de Paiva \n",
            "\n",
            "Vládia Pinheiro \n",
            "\n",
            "PDF\n",
            "\n",
            "Métodos Simbólicos em Processamento de Linguagem Natural (PLN) envolvem a utilização de regras e representações formais explícitas para processar e entender textos em linguagem natural. Esses métodos especializam-se na manipulação de símbolos e dados estruturados, como gramáticas, ontologias e bases de conhecimento. Especificamente para o entendimento de textos em linguagem natural usando técnicas simbólicas, existem analisadores semânticos (ou parsers semânticos) e bases de conhecimento semântico, que visam fornecer uma representação semântica dos textos. A partir desta representação, motores de inferência são capazes de realizar raciocínio para que aplicações possam, por exemplo, extrair informações, sumarizar textos, e responder perguntas com base nos textos.\n",
            "\n",
            "A Figura 9.1 apresenta uma arquitetura tradicional para sistemas de entendimento de textos em linguagem natural (Natural Language Understanding – NLU). A partir do texto de entrada, uma camada de processamento sintático realiza uma série de análises no texto, tais como detecção de língua, separação de sentenças, tokenização, análise morfológica e sintática (Capítulo 4). Na fronteira entre o processamento sintático e a análise semântica, outros processamentos linguísticos são necessários, como reconhecimento de entidades nomeadas, identificação de expressões multipalavras etc. Em seguida, o texto analisado (sintaticamente) é enviado ao analisador semântico (parser) que gera uma representação lógica do texto. A representação lógica e a(s) base(s) de conhecimento, no que lhes concerne, são entradas para o motor de inferência. Nesse processo, termos do texto de entrada são associados aos elementos da base de conhecimento e o motor de inferência gera respostas a perguntas (queries) para uma aplicação final.\n",
            "\n",
            "Uma “base de conhecimento” refere-se a um repositório centralizado, processável por máquina, que contém informações, dados, regras e procedimentos que são usados para capturar, representar e armazenar conhecimento geral ou de um domínio específico. Tais bases de conhecimento são fontes de conhecimento de mundo e suportam diversas tarefas e aplicações em PLN. Uma base de conhecimento pode ser estruturada de diversas maneiras, incluindo bancos de dados relacionais, linguagem para ontologias (e.g. a OWL1), formalismos para troca de dados entre sistemas (e.g. o formato JSON2), redes semânticas ou sistemas baseados em regras, dependendo da sua finalidade e da natureza do conhecimento armazenado.\n",
            "\n",
            "Fonte: Adaptada de (Ovchinnikova, 2012, p. 9)\n",
            "\n",
            "Tradicionalmente, sistemas lógicos são usados para representação formal dos textos e seus motores de inferência servem para gerar conclusões a partir dos textos. Podemos citar os sistemas lógicos mais usados em PLN: variações de Lógica Descritiva (Description Logic – DL) (Baader et al., 2003), da Lógica de Primeira Ordem (Blackburn; Bos, 2005; Eijck; Unger, 2010), vários tipos de Programação em Lógica (PROLOG) (Dahl, 1994) e Lógicas Intensionais (Shapiro, 2000).\n",
            "\n",
            "Uma característica importante dos sistemas lógicos usados para a semântica de linguagem natural é que eles dependem fortemente da forma lógica do texto ou argumento. No entanto, muitas conclusões e respostas fornecidas ao se ler um texto são justificadas pela contribuição semântica dos conceitos relacionados, não definida a priori, mas somente enquanto usados em um contexto particular. Por exemplo, considere a inferência que conclui que “Alguém foi assassinado” a partir da premissa que “Alguém foi executado”. A contribuição semântica do conceito “executar” (no sentido de “assassinar”) é que torna esta inferência plausível, e não a forma da sentença. Da mesma forma, a inferência “um relâmpago é visto agora” para “um trovão será ouvido em breve” é autorizada pelo conteúdo dos termos “trovão” e “relâmpago”. Para se realizar inferências desta natureza, alguns filósofos como Sellars (Sellars, 1953) e Brandom (Brandom, 2001) propõem abordagens para expressão do significado que suportam análises semânticas não somente sobre a forma das sentenças, mas são capazes de, com base no domínio dos conteúdos dos termos articulados nas sentenças e textos, descobrir como estes [os conteúdos dos termos] contribuem conjuntamente para o significado das sentenças e para realização de inferências.\n",
            "\n",
            "Este capítulo tem como objetivo examinar, além dos frameworks semânticos, tais como AMR (Abstract Meaning Representation) (Banarescu et al., 2013) e DELPH-IN (Copestake et al., 2005), os tipos de bases de conhecimento mais utilizados em PLN. Nesta versão inicial do capítulo, são apresentadas as bases (também chamadas de recursos léxico-semânticos) WordNet de Princeton (Fellbaum, 1998) e FrameNet (Baker; Fillmore; Lowe, 1998), e suas versões em português: OpenWordNet-PT (De Paiva; Rademaker; Melo, 2012) e FrameNet Brasil (FN-BR) (Torrent; Ellsworth, 2013); bem como bases de conhecimento voltadas ao senso comum, tais como a ConceptNet (Speer; Chin; Havasi, 2016) e iniciativas para o português (OMCS-BR (Anacleto et al., 2006) e a InferenceNet-BR (Pinheiro et al., 2010)). Existem outros tipos de bases de conhecimento na área do PLN, tais como dicionários e ontologias diversas, por exemplo, WikiData (Vrandečić; Krötzsch, 2014), YAGO (Suchanek; Kasneci; Weikum, 2007) ou BabelNet (Navigli; Ponzetto, 2012). No entanto, nossa descrição aqui visa apenas a uma primeira exposição dos distintos paradigmas de expressão de conhecimento semântico. Tendo em vista cada base de conhecimento descrita, analisamos um exemplo de texto motivador. Por fim, apresentamos as considerações finais deste capítulo.\n",
            "\n",
            "Na área da Inteligência Artificial (IA), o interesse por bases de conhecimento computáveis ou processáveis por máquina surgiu na década de 60 com as primeiras redes semânticas e representações baseadas em frames, propostas por Minsky (Minsky, 1975) e Fillmore (Fillmore et al., 1976), respectivamente.\n",
            "\n",
            "parte do cap 17\n",
            "\n",
            "Métodos baseados em redes neurais, de forma geral, costumam empregar técnicas de aprendizado de representação (Bengio; Courville; Vincent, 2013) para aprender representações do conteúdo semântico dos fragmentos textuais e reduzem o problema de ER à classificação textual. É o caso de Socher et al. (2012), que propõem a MV-RNN, uma rede neural que constrói um espaço de representação baseado em matrizes e vetores com o objetivo de capturar a composicionalidade de sentido de sintagmas e sentenças e os aplica para ER. Similarmente, Zeng et al. (2014) e Wang et al. (2016) empregam redes neurais convolucionais para obter representações vetoriais de sentenças que serão empregadas no processo de classificação quanto à relação expressa pela mesma.\n",
            "\n",
            "Abordagens baseadas em identificação sequencial de entidades e relações possuem desvantagens observadas na literatura. Primeiramente, como a ER é guiada pelas entidades identificadas no processo de REN, a propagação de erros da primeira tarefa pode ter impacto considerável na performance dos sistemas desenvolvidos. Segundo, uma vez que o contexto determinado limita tanto as tarefas de REN, quanto as de ER, existe uma interdependência entre as tarefas. Assim, propostas visando realizar a extração de entidades e relações de forma conjunta começaram a surgir na literatura recente, ganhando certo interesse da comunidade.\n",
            "\n",
            "As abordagens empregadas para tal tarefa são diversificadas, incluindo desde métodos de aprendizado relacional a redes neurais\n",
            "\n",
            "Roth; Yih (2007) propõem a utilização de métodos de programação inteira ao problema, baseados na teoria estatística de aprendizado relacional. Os autores utilizam classificadores locais para a identificação de entidades e relações e um classificador global que combina as informações dos classificadores locais em uma predição que maximiza a qualidade da extração, codificada por meio de restrições em programação inteira. Também baseados em modelos estatísticos, Yu; Lam (2010) propõem o uso de modelos gráficos globais para identificação de um descritor de relação e uma segmentação do texto para identificação dos argumentos.\n",
            "\n",
            "Li; Ji (2014) e Miwa; Bansal (2016), por sua vez, reduzem a tarefa de ERE à classificação sequencial, utilizando redes neurais recorrentes bidirecionais sequenciais e estruturadas com base na estrutura superficial e na árvore de dependências sintáticas da entrada para identificação conjunta de entidades e relações.\n",
            "\n",
            "A Extração de Informação Aberta (EIA), também conhecida como Open Information Extraction, Open IE ou OIE em inglês, é a tarefa de extrair informações estruturadas de documentos sem necessitar da pré-definição do contexto da tarefa, i.e. das relações e tipos de entidade de interesse. A tarefa foi inicialmente proposta pelo trabalho de (Banko et al., 2007) e ganhou popularidade nas últimas décadas devido à sua aplicabilidade para processar e estruturar o conhecimento a partir de grandes volumes de dados disponíveis na Web, seguindo o paradigma da Web como um Corpus (WaC) (Meyer et al., 2003).\n",
            "\n",
            "A EIA surge visando generalizar a tarefa de Extração de Relações. A principal diferença entre as duas abordagens, porém, reside na dependência da ER de uma especificação prévia do domínio de aplicação, bem como das relações alvo a serem identificadas, que a EIA visa eliminar.\n",
            "\n",
            "Seguindo o trabalho original de Banko et al. (2007), que propôs o sistema TextRunner, vários métodos e sistemas para EIA foram propostos na literatura (Del Corro; Gemulla, 2013; Fader; Soderland; Etzioni, 2011; Xavier; Lima; Souza, 2015), mas, como observado por Glauber; Claro (2018), os principais avanços na área se concentraram principalmente no idioma inglês.\n",
            "\n",
            "A EIA para a língua portuguesa tem uma história bastante recente. A partir dos trabalhos de Souza; Claro (2014), Pereira; Pinheiro (2015) e de (Barbosa; Glauber; Claro, 2016), têm crescido o número de estudos sobre a tarefa assim como os resultados obtidos por esses estudos, com recentes desenvolvimentos de métodos (Oliveira; Claro; Souza, 2022; Sena; Claro, 2019, 2020; Sena; Glauber; Claro, 2017; Souza; Claro; Glauber, 2018), construção do corpus (Glauber et al., 2018) e avaliação dos sistemas disponíveis (Glauber; Claro; Oliveira, 2019; Glauber; Claro; Sena, 2019; Malenchini et al., 2019).\n",
            "\n",
            "Embora a área tenha visto um crescimento recente para o desenvolvimento de métodos para línguas como o inglês, principalmente com a aplicação de métodos supervisionados e redes neurais, esses avanços ainda não foram incorporados na literatura sobre EIA para a língua portuguesa. A razão para isso é principalmente a falta de recursos linguísticos disponíveis para orientar o desenvolvimento de pesquisas para a língua. Embora o foco no idioma inglês possa ser devido ao seu uso generalizado em todo o mundo, foi reconhecido pela comunidade científica que esse foco no inglês com suas características particulares pode introduzir algum viés na área (Bender, 2009).\n",
            "\n",
            "Assim, esta seção aborda EIA para a língua portuguesa, incluindo uma formalização e a evolução das abordagens da área.\n",
            "\n",
            "A tarefa de EIA pode ser formalmente definida sendo \\(X = \\langle x_{1}, x_{2}, \\cdots, x_{n}\\rangle\\) uma sentença composta de tokens \\(x_i\\). Um extrator EIA é uma função que mapeia \\(X\\) em um conjunto \\(Y = \\langle y_{1}, y_{2}, \\cdots, y_{j} \\rangle\\) como um conjunto de tuplas \\(y \\_i = \\langle rel_i, arg1_i, arg2_i, \\cdots, argn_i\\rangle\\), que descrevem as informações expressas na sentença X. Neste capítulo, consideramos que as tuplas estão sempre no formato \\(y = (arg_{1 }, rel, arg_{2})\\), onde \\(arg1\\) e \\(arg2\\) são sintagmas nominais, não necessariamente formados por tokens presentes em X, e \\(rel\\) é um descritor de um relacionamento entre \\(arg_{1}\\) e \\(arg_{2}\\). Não consideraremos extrações formadas por mais de dois argumentos neste capítulo.\n",
            "\n",
            "Os primeiros métodos de EIA empregavam padrões de inspiração linguística para extração, como ArgOE (Gamallo; Garcia, 2015), ou adaptação de métodos para a língua inglesa, como SGS (Souza; Claro; Glauber, 2018), InferReVerbPT Sena; Glauber; Claro (2017) e RePort Pereira; Pinheiro (2015). Os trabalhos são principalmente influenciados por métodos baseados no inglês da chamada segunda geração de EIA (Fader; Soderland; Etzioni, 2011).\n",
            "\n",
            "O primeiro sistema de EIA para o português de que temos conhecimento foi o DepOE (Gamallo; Garcia; Fernández-Lanza, 2012). Ele executa a extração aberta multilíngue de triplas (inglês, espanhol, português e galego) usando o analisador sintático de dependências baseado em regras DepPattern. No entanto, nenhuma avaliação ou resultados são relatados para a língua portuguesa. Os autores apresentam somente uma comparação dos seus resultados com Reverb na língua inglesa.\n",
            "\n",
            "Souza; Claro (2014) se propuseram a analisar o conjunto de características mais representativas da língua portuguesa para a identificação de extrações válidas no contexto de EIA, tal qual empregado na língua inglesa com o sistema ReVerb (Fader; Soderland; Etzioni, 2011).\n",
            "\n",
            "parte do cap 9\n",
            "\n",
            "Eloize Rossi Marques Seno \n",
            "\n",
            "Valéria de Paiva \n",
            "\n",
            "Vládia Pinheiro \n",
            "\n",
            "PDF\n",
            "\n",
            "Métodos Simbólicos em Processamento de Linguagem Natural (PLN) envolvem a utilização de regras e representações formais explícitas para processar e entender textos em linguagem natural. Esses métodos especializam-se na manipulação de símbolos e dados estruturados, como gramáticas, ontologias e bases de conhecimento. Especificamente para o entendimento de textos em linguagem natural usando técnicas simbólicas, existem analisadores semânticos (ou parsers semânticos) e bases de conhecimento semântico, que visam fornecer uma representação semântica dos textos. A partir desta representação, motores de inferência são capazes de realizar raciocínio para que aplicações possam, por exemplo, extrair informações, sumarizar textos, e responder perguntas com base nos textos.\n",
            "\n",
            "A Figura 9.1 apresenta uma arquitetura tradicional para sistemas de entendimento de textos em linguagem natural (Natural Language Understanding – NLU). A partir do texto de entrada, uma camada de processamento sintático realiza uma série de análises no texto, tais como detecção de língua, separação de sentenças, tokenização, análise morfológica e sintática (Capítulo 4). Na fronteira entre o processamento sintático e a análise semântica, outros processamentos linguísticos são necessários, como reconhecimento de entidades nomeadas, identificação de expressões multipalavras etc. Em seguida, o texto analisado (sintaticamente) é enviado ao analisador semântico (parser) que gera uma representação lógica do texto. A representação lógica e a(s) base(s) de conhecimento, no que lhes concerne, são entradas para o motor de inferência. Nesse processo, termos do texto de entrada são associados aos elementos da base de conhecimento e o motor de inferência gera respostas a perguntas (queries) para uma aplicação final.\n",
            "\n",
            "Uma “base de conhecimento” refere-se a um repositório centralizado, processável por máquina, que contém informações, dados, regras e procedimentos que são usados para capturar, representar e armazenar conhecimento geral ou de um domínio específico. Tais bases de conhecimento são fontes de conhecimento de mundo e suportam diversas tarefas e aplicações em PLN. Uma base de conhecimento pode ser estruturada de diversas maneiras, incluindo bancos de dados relacionais, linguagem para ontologias (e.g. a OWL1), formalismos para troca de dados entre sistemas (e.g. o formato JSON2), redes semânticas ou sistemas baseados em regras, dependendo da sua finalidade e da natureza do conhecimento armazenado.\n",
            "\n",
            "Fonte: Adaptada de (Ovchinnikova, 2012, p. 9)\n",
            "\n",
            "Tradicionalmente, sistemas lógicos são usados para representação formal dos textos e seus motores de inferência servem para gerar conclusões a partir dos textos. Podemos citar os sistemas lógicos mais usados em PLN: variações de Lógica Descritiva (Description Logic – DL) (Baader et al., 2003), da Lógica de Primeira Ordem (Blackburn; Bos, 2005; Eijck; Unger, 2010), vários tipos de Programação em Lógica (PROLOG) (Dahl, 1994) e Lógicas Intensionais (Shapiro, 2000).\n",
            "\n",
            "Uma característica importante dos sistemas lógicos usados para a semântica de linguagem natural é que eles dependem fortemente da forma lógica do texto ou argumento. No entanto, muitas conclusões e respostas fornecidas ao se ler um texto são justificadas pela contribuição semântica dos conceitos relacionados, não definida a priori, mas somente enquanto usados em um contexto particular. Por exemplo, considere a inferência que conclui que “Alguém foi assassinado” a partir da premissa que “Alguém foi executado”. A contribuição semântica do conceito “executar” (no sentido de “assassinar”) é que torna esta inferência plausível, e não a forma da sentença. Da mesma forma, a inferência “um relâmpago é visto agora” para “um trovão será ouvido em breve” é autorizada pelo conteúdo dos termos “trovão” e “relâmpago”. Para se realizar inferências desta natureza, alguns filósofos como Sellars (Sellars, 1953) e Brandom (Brandom, 2001) propõem abordagens para expressão do significado que suportam análises semânticas não somente sobre a forma das sentenças, mas são capazes de, com base no domínio dos conteúdos dos termos articulados nas sentenças e textos, descobrir como estes [os conteúdos dos termos] contribuem conjuntamente para o significado das sentenças e para realização de inferências.\n",
            "\n",
            "Este capítulo tem como objetivo examinar, além dos frameworks semânticos, tais como AMR (Abstract Meaning Representation) (Banarescu et al., 2013) e DELPH-IN (Copestake et al., 2005), os tipos de bases de conhecimento mais utilizados em PLN. Nesta versão inicial do capítulo, são apresentadas as bases (também chamadas de recursos léxico-semânticos) WordNet de Princeton (Fellbaum, 1998) e FrameNet (Baker; Fillmore; Lowe, 1998), e suas versões em português: OpenWordNet-PT (De Paiva; Rademaker; Melo, 2012) e FrameNet Brasil (FN-BR) (Torrent; Ellsworth, 2013); bem como bases de conhecimento voltadas ao senso comum, tais como a ConceptNet (Speer; Chin; Havasi, 2016) e iniciativas para o português (OMCS-BR (Anacleto et al., 2006) e a InferenceNet-BR (Pinheiro et al., 2010)). Existem outros tipos de bases de conhecimento na área do PLN, tais como dicionários e ontologias diversas, por exemplo, WikiData (Vrandečić; Krötzsch, 2014), YAGO (Suchanek; Kasneci; Weikum, 2007) ou BabelNet (Navigli; Ponzetto, 2012). No entanto, nossa descrição aqui visa apenas a uma primeira exposição dos distintos paradigmas de expressão de conhecimento semântico. Tendo em vista cada base de conhecimento descrita, analisamos um exemplo de texto motivador. Por fim, apresentamos as considerações finais deste capítulo.\n",
            "\n",
            "Na área da Inteligência Artificial (IA), o interesse por bases de conhecimento computáveis ou processáveis por máquina surgiu na década de 60 com as primeiras redes semânticas e representações baseadas em frames, propostas por Minsky (Minsky, 1975) e Fillmore (Fillmore et al., 1976), respectivamente.\n",
            "\n",
            "parte do cap 17\n",
            "\n",
            "O sistema RePort (Pereira; Pinheiro, 2015), por outro lado, é uma adaptação do ReVerb para a língua portuguesa baseada em análise sintática rasa com regras sintáticas e lexicais. Os autores relatam que suas extrações apresentam grande similaridade com suas correlatas extraídas pelo ReVerb (dos textos traduzidos para o inglês).\n",
            "\n",
            "O RELP, proposto por Abreu; Vieira (2017), é um sistema aberto de extração de relações que extrai relações entre entidades nomeadas em um domínio de organização aplicando classificação sequencial com CRF (Conditional Random Fields). O sistema RelP extrai qualquer descritor de relação que expressa um relacionamento entre pares de entidades nomeadas (Organização, Pessoa ou Lugar), caracterizando-o como uma abordagem híbrida da REN com a EIA.\n",
            "\n",
            "O InferReVerbPT desenvolvido por Sena; Glauber; Claro (2017) baseia-se numa adaptação do sistema ReVerb para a língua portuguesa, expandindo-o com a extração de relacionamentos implícitos obtidos por inferência por propriedades de simetria e transitividade das relações com inferência transitiva e simétrica. Um classificador SVM foi empregado para realizar a inferência baseado nas propriedades semânticas do verbo central no descritor de relação.\n",
            "\n",
            "Souza; Claro; Glauber (2018) analisaram que a maior desvantagem dos estudos baseados em recursos linguísticos, como dados anotados, reside na escassez de tais recursos na maioria dos idiomas além do inglês. Assim, para mitigar esse problema, eles propõem um método de classificação de fatos baseado na similaridade de estruturas gramaticais (SGS). Sua abordagem modela estruturas morfosintáticas dos fatos (triplas descrevendo relacionamentos) para identificar padrões de semelhanças que podem ser usados para distinguir entre fatos válidos e inválidos. Eles aplicaram algoritmos de isomorfismo de grafos para detectar subgrafos descrevendo tais padrões.\n",
            "\n",
            "Um novo sistema de EIA baseado em análise de dependência foi proposto por Gamallo; Garcia (2015), chamado ArgOE. Tal sistema é multilíngue, baseado em heurísticas e utiliza a informação de dependência sintáticas do texto para analisar a estrutura de dependência do verbo, bem como um conjunto de regras para gerar os relacionamentos. A introdução de um Analisador de Dependência em sistemas de EIA focados inteiramente na língua portuguesa foi feita pelos autores Oliveira; Claro; Souza (2022). O DptOIE é baseado em análise de dependência e regras elaboradas manualmente. As sentenças são pré-processadas por meio de um tokenizador, um PoS Tagger e um analisador de dependências. Os autores propõem um acoplamento de três módulos para tratar casos particulares: conjunções coordenadas, orações subordinadas e aposto.\n",
            "\n",
            "Com a evolução dos métodos de EIA para a língua inglesa utilizando os modelos neurais, novas abordagens foram propostas também para a língua portuguesa.\n",
            "\n",
            "O primeiro trabalho que utilizou aprendizado supervisionado com rede neural profunda para o português foi o de Ro; Lee; Kang (2020) que descreve o sistema Multi2OIE. Os autores utilizaram o modelo de linguagem BERT multilíngue (Devlin et al., 2019) para obter representações vetoriais das palavras e reduzem a tarefa de EIA à classificação sequencial, identificado os fragmentos do texto que determinam os argumentos (\\(arg_1, arg_2\\)) e o descritor de relação (\\(rel\\)). Seu sistema foi capaz de produzir extrações para vários idiomas (inglês, português e espanhol), treinados, entretanto, sobre dados traduzidos do inglês.\n",
            "\n",
            "Stanovsky et al. (2018) propuseram uma abordagem de EIA para a língua inglesa baseada em triplas. Os mesmos fazem uso de uma classificação sequencial cuja limitação define uma tripla extraída para cada sentença. Este método utiliza uma arquitetura de Redes Neurais Recursivas (RNN) para realizar EIA. A EIA é formulada como uma tarefa de rotulagem de sequências, utilizando estratégias semelhantes às que foram aplicadas anteriormente a tarefas como o Reconhecimento de Entidades Nomeadas. Já os autores em Cui; Wei; Zhou (2018) e Zhang; Duh; Van Durme (2017) propõem modelar o problema da EIA como um problema de aprendizado sequência a sequência (seq2seq). Eles definem uma estrutura encoder-decoder para aprender argumentos e tuplas de relação inicializadas a partir de um sistema de EIA.\n",
            "\n",
            "Seguindo o trabalho de (Stanovsky et al., 2018), em 2022, Cabral; Souza; Claro (2022) propuseram PortNOIE, uma arquitetura neural para EIA em português que combina representações contextuais de palavras com codificadores neurais para extrair relacionamentos baseado em classificação sequencial iterativa. Diferente de outros métodos de classificação sequencial para EIA, os autores focam na extração de múltiplas triplas de uma mesma sentença.\n",
            "\n",
            "A avaliação sistemática de sistemas de EI foi estabelecida primeiramente nas conferências MUC, em particular na sua segunda edição, com o estabelecimento de gabaritos-padrão que deveriam ser utilizados por todos os sistemas participantes e a adoção de métricas de qualidade, baseadas naquelas usadas na área de recuperação de informação, que foram abordadas no Capítulo 16. Para avaliar a tarefa de extração de relações, a MUC-2 estabeleceu como métricas de qualidade do sistema as medidas de precisão e cobertura, também denominada de Recall ou Revocação.\n",
            "\n",
            "A precisão de um sistema reflete a qualidade de suas extrações, i.e., quantas das extrações realizadas estão corretas, dado um corpus de teste. A medida de precisão pode ser calculada como:\n",
            "\n",
            "P = \\frac{\\#(\\mbox{relacionamentos corretamente extraídos})}{\\#(\\mbox{relacionamentos extraídos pelo sistema})}\n",
            "\n",
            "A cobertura também conhecida como revocação, reflete quão abrangente um sistema é em suas extrações, i.e., quantas das extrações a serem realizadas em um corpus de teste, o sistema é capaz de realizar. A medida de cobertura pode ser calculada como:\n",
            "\n",
            "R = \\frac{\\#(\\mbox{relacionamentos extraídos})}{\\#(\\mbox{relacionamentos no \\textit{corpus}})}\n",
            "\n",
            "Enquanto a MUC-3 adicionou duas novas métricas de avaliação, a saber sobre-geração (overgeneration) e sub-geração (fallout), tais métricas receberam pouco interesse na literatura. De fato, Lehnert; Sundheim (1991) argumentam que tais métricas foram pouco informativas ou difíceis de calcular para a tarefa de EI e, portanto, abandonadas. Foi também empregado nessa conferência um sistema automático de avaliação disponibilizado às equipes participantes que permitiu uma maior compreensão do modelo de avaliação e, como discutem Lehnert; Sundheim (1991), um avanço qualitativo nos sistemas gerados.\n",
            "\n",
            "parte do cap 9\n",
            "\n",
            "Eloize Rossi Marques Seno \n",
            "\n",
            "Valéria de Paiva \n",
            "\n",
            "Vládia Pinheiro \n",
            "\n",
            "PDF\n",
            "\n",
            "Métodos Simbólicos em Processamento de Linguagem Natural (PLN) envolvem a utilização de regras e representações formais explícitas para processar e entender textos em linguagem natural. Esses métodos especializam-se na manipulação de símbolos e dados estruturados, como gramáticas, ontologias e bases de conhecimento. Especificamente para o entendimento de textos em linguagem natural usando técnicas simbólicas, existem analisadores semânticos (ou parsers semânticos) e bases de conhecimento semântico, que visam fornecer uma representação semântica dos textos. A partir desta representação, motores de inferência são capazes de realizar raciocínio para que aplicações possam, por exemplo, extrair informações, sumarizar textos, e responder perguntas com base nos textos.\n",
            "\n",
            "A Figura 9.1 apresenta uma arquitetura tradicional para sistemas de entendimento de textos em linguagem natural (Natural Language Understanding – NLU). A partir do texto de entrada, uma camada de processamento sintático realiza uma série de análises no texto, tais como detecção de língua, separação de sentenças, tokenização, análise morfológica e sintática (Capítulo 4). Na fronteira entre o processamento sintático e a análise semântica, outros processamentos linguísticos são necessários, como reconhecimento de entidades nomeadas, identificação de expressões multipalavras etc. Em seguida, o texto analisado (sintaticamente) é enviado ao analisador semântico (parser) que gera uma representação lógica do texto. A representação lógica e a(s) base(s) de conhecimento, no que lhes concerne, são entradas para o motor de inferência. Nesse processo, termos do texto de entrada são associados aos elementos da base de conhecimento e o motor de inferência gera respostas a perguntas (queries) para uma aplicação final.\n",
            "\n",
            "Uma “base de conhecimento” refere-se a um repositório centralizado, processável por máquina, que contém informações, dados, regras e procedimentos que são usados para capturar, representar e armazenar conhecimento geral ou de um domínio específico. Tais bases de conhecimento são fontes de conhecimento de mundo e suportam diversas tarefas e aplicações em PLN. Uma base de conhecimento pode ser estruturada de diversas maneiras, incluindo bancos de dados relacionais, linguagem para ontologias (e.g. a OWL1), formalismos para troca de dados entre sistemas (e.g. o formato JSON2), redes semânticas ou sistemas baseados em regras, dependendo da sua finalidade e da natureza do conhecimento armazenado.\n",
            "\n",
            "Fonte: Adaptada de (Ovchinnikova, 2012, p. 9)\n",
            "\n",
            "Tradicionalmente, sistemas lógicos são usados para representação formal dos textos e seus motores de inferência servem para gerar conclusões a partir dos textos. Podemos citar os sistemas lógicos mais usados em PLN: variações de Lógica Descritiva (Description Logic – DL) (Baader et al., 2003), da Lógica de Primeira Ordem (Blackburn; Bos, 2005; Eijck; Unger, 2010), vários tipos de Programação em Lógica (PROLOG) (Dahl, 1994) e Lógicas Intensionais (Shapiro, 2000).\n",
            "\n",
            "Uma característica importante dos sistemas lógicos usados para a semântica de linguagem natural é que eles dependem fortemente da forma lógica do texto ou argumento. No entanto, muitas conclusões e respostas fornecidas ao se ler um texto são justificadas pela contribuição semântica dos conceitos relacionados, não definida a priori, mas somente enquanto usados em um contexto particular. Por exemplo, considere a inferência que conclui que “Alguém foi assassinado” a partir da premissa que “Alguém foi executado”. A contribuição semântica do conceito “executar” (no sentido de “assassinar”) é que torna esta inferência plausível, e não a forma da sentença. Da mesma forma, a inferência “um relâmpago é visto agora” para “um trovão será ouvido em breve” é autorizada pelo conteúdo dos termos “trovão” e “relâmpago”. Para se realizar inferências desta natureza, alguns filósofos como Sellars (Sellars, 1953) e Brandom (Brandom, 2001) propõem abordagens para expressão do significado que suportam análises semânticas não somente sobre a forma das sentenças, mas são capazes de, com base no domínio dos conteúdos dos termos articulados nas sentenças e textos, descobrir como estes [os conteúdos dos termos] contribuem conjuntamente para o significado das sentenças e para realização de inferências.\n",
            "\n",
            "Este capítulo tem como objetivo examinar, além dos frameworks semânticos, tais como AMR (Abstract Meaning Representation) (Banarescu et al., 2013) e DELPH-IN (Copestake et al., 2005), os tipos de bases de conhecimento mais utilizados em PLN. Nesta versão inicial do capítulo, são apresentadas as bases (também chamadas de recursos léxico-semânticos) WordNet de Princeton (Fellbaum, 1998) e FrameNet (Baker; Fillmore; Lowe, 1998), e suas versões em português: OpenWordNet-PT (De Paiva; Rademaker; Melo, 2012) e FrameNet Brasil (FN-BR) (Torrent; Ellsworth, 2013); bem como bases de conhecimento voltadas ao senso comum, tais como a ConceptNet (Speer; Chin; Havasi, 2016) e iniciativas para o português (OMCS-BR (Anacleto et al., 2006) e a InferenceNet-BR (Pinheiro et al., 2010)). Existem outros tipos de bases de conhecimento na área do PLN, tais como dicionários e ontologias diversas, por exemplo, WikiData (Vrandečić; Krötzsch, 2014), YAGO (Suchanek; Kasneci; Weikum, 2007) ou BabelNet (Navigli; Ponzetto, 2012). No entanto, nossa descrição aqui visa apenas a uma primeira exposição dos distintos paradigmas de expressão de conhecimento semântico. Tendo em vista cada base de conhecimento descrita, analisamos um exemplo de texto motivador. Por fim, apresentamos as considerações finais deste capítulo.\n",
            "\n",
            "Na área da Inteligência Artificial (IA), o interesse por bases de conhecimento computáveis ou processáveis por máquina surgiu na década de 60 com as primeiras redes semânticas e representações baseadas em frames, propostas por Minsky (Minsky, 1975) e Fillmore (Fillmore et al., 1976), respectivamente.\n",
            "\n",
            "parte do cap 17\n",
            "\n",
            "Além das medidas de precisão e cobertura, assim como em tarefas de classificação de texto e recuperação de informação, utilizamos a média harmônica entre essas medidas, chamada medida F1, a fim de condensar a informação contida nas duas. A medida F1 pode ser calculada como:\n",
            "\n",
            "F1 = \\frac{2*P*R}{P+R}\n",
            "\n",
            "A avaliação da tarefa de REN segue padrões semelhantes aos aplicados à tarefa de ER. De fato, desde a MUC-6 (Grishman; Sundheim, 1996), as medidas de precisão, cobertura e F1 tem sido usada consistentemente como métricas de avaliação da tarefa de REN em diversos esforços de avaliação, como a CoNNL (Sang; De Meulder, 2003), para a língua inglesa, e das duas edições do HAREM (Gonçalo Oliveira et al., 2008; Santos; Cardoso; Seco, 2007), com excessão à ACE (Doddington et al., 2004) que apresenta uma combinação da tarefa de REN com reconhecimento de co-referência entre entidades e utiliza um sistema de pontuação próprio.\n",
            "\n",
            "A avaliação de sistemas de EIA, por sua vez, possui algumas peculiaridades que precisam ser discutidas. Uma vez que a tarefa é postulada por Banko et al. (2007) como a extração de todas as relações identificadas em um dado fragmento textual, sem limitação de domínio de interesse, tal tarefa impõe imensa dificuldade aos esforços de avaliação.\n",
            "\n",
            "De fato, Glauber et al. (2018) relatam um esforço de anotação de dados para a tarefa em língua portuguesa em que foram identificados por anotadores humanos mais de 400 relacionamentos em um corpus de 25 sentenças retiradas de textos jornalísticos e de enciclopédia. Assim, a avaliação de EIA deu-se, em grande parte de seu desenvolvimento e maturação, em conjuntos de dados não anotados, recorrendo a avaliações qualitativas das saídas dos sistemas e comparação direta por humanos das extrações obtidas.\n",
            "\n",
            "Nesses esforços de avaliação, a precisão do sistema pode ser mensurada a partir da avaliação humana das saídas. Não é possível, entretanto, avaliar medidas como cobertura e F1, dada a inexistência de uma referência do conjunto total de relacionamentos a serem identificados. Assim, os autores da área propuseram diferentes métricas a fim de estimar tais valores, como a métrica rendimento (yield) (Fader; Soderland; Etzioni, 2011; Schmitz et al., 2012).\n",
            "\n",
            "A métrica de rendimento consiste no núemro de extrações válidas, i.e. corretas, de um dado sistema. Como calcular tal medida é, na maioria dos casos, impraticável dada a grande quantidade de extrações realizadas pelos sistemas, ela pode ser estimada a partir da precisão do sistema calculada sobre uma amostra aleatória das extrações realizadas (\\(P'\\)). Assim, podemos estimar o rendimento como:\n",
            "\n",
            "Y = P'\\cdot \\#(\\mbox{extrações realizadas})\n",
            "\n",
            "Foi também explorada a estratégia de criação (semi-)automática de conjuntos de dados usando vários sistemas (Del Corro; Gemulla, 2013), estratégias de supervisão fraca (Smirnova; Cudré-Mauroux, 2018), ou a geração de corpora para a tarefa a partir da transformação de anotações de tarefas próximas, como identificação de papéis temáticos (Semantic Role Labeling) por (Stanovsky et al., 2018). Corpora gerados de forma semi-automática vêm ganhando atenção na literatura recente, particularmente para a língua inglesa, devido a necessidade de dados anotados para se utilizar técnicas de aprendizado de máquina e redes neurais em EIA. Corpora como o OIE2016 (Stanovsky et al., 2018), Wire57 (Léchelle; Gotti; Langlais, 2018) e CARB (Bhardwaj; Aggarwal; Mausam, 2019) vêm se tornando corpora de referência em língua inglesa para o problema, apesar dos problemas existentes na construção de tais recursos – a não exaustividade das relações anotadas.\n",
            "\n",
            "Para a língua portuguesa, foram propostas algumas iniciativas para avaliar os sistemas da OIE. Uma avaliação conjunta foi promovida durante o Fórum Ibérico de Avaliação de Línguas (IberLEF) em 2019 (Collovini et al., 2019). A avaliação foi feita usando o corpus proposto por Glauber et al. (2018), que é composto por 442 relacionamentos extraídos de 25 frases de fontes como a seção em português da Wikipédia, o corpus CETENFolha, resenhas de filmes do portal Adoro Cinema2 e o corpus Europarl. Apesar desta tarefa ter contemplado quatro cenários de avaliação, a avaliação geral dos sistemas permaneceu consistente nos diferentes cenários, indicando robustez nos resultados da avaliação. No geral, os sistemas DPTOIE (Oliveira; Claro; Souza, 2022) e Linguakit (Gamallo; Garcia, 2015) tiveram o melhor desempenho, com o Linguakit2 dominando as avaliações de correspondência exata e o DPTOIE as avaliações de correspondências parciais (Collovini et al., 2019).\n",
            "\n",
            "Outra abordagem de avaliação foi idealizada por (Malenchini et al., 2019). Seu foco foi a avaliação extrínseca dos sistemas de EIA através de sua contribuição na tarefa de respostas automáticas a perguntas. Os autores apresentaram um conjunto de dados de referência (benchmark) para avaliação extrínseca de sistemas de EIA em textos de língua portuguesa. Os sistemas que alcançaram os melhores valores na avaliação realizada pelos autores foram os sistemas ArgOE (Gamallo; Garcia, 2015), DependentIE (Glauber; Claro; Oliveira, 2019) e DptOIE (Oliveira; Claro; Souza, 2022).\n",
            "\n",
            "Este capítulo descreveu uma visão geral da área de Extração de Informação, apresentando a Extração de Informação Tradicional e a Extração de Informação Aberta. Transversalmente, apresentamos as formalizações necessárias e os conceitos fundamentais para a compreensão da EIA, assim como a avaliação da área e as heranças de outras áreas afins, tais como RI.\n",
            "\n",
            "Nessa primeira versão, este capítulo descreveu de maneira bem sucinta as abordagens propostas para EI e EIA durante seu desenvolvimento histórico e as abordagens atuais da literatura, como as utilizando modelos de linguagens. Especificamente, a utilização da arquitetura Transformers, descritas no Capítulo 15 para as tarefas de EI e EIA tem sido bastante difundida para a língua inglesa e tem atuado em diversas áreas da PLN.\n",
            "\n",
            "Agradecemos as colaborações dos autores deste Capítulo e suas indicações, assim como agradecemos a Adriana Pagano e Aline Macohin pela revisão e comentários.\n",
            "\n",
            "Em nossa terminologia, por um relacionamento.↩︎\n",
            "\n",
            "parte do cap 9\n",
            "\n",
            "A comunidade de PLN foi rapidamente atraída por tais representações de conhecimento de mundo, pois pareciam prover a solução para problemas de semântica de linguagem natural. As mais antigas abordagens em PLN que utilizaram redes semânticas e frames remontam aos trabalhos de Bates et al. (1982) e Bobrow et al. (1977), conforme citado em (Ovchinnikova, 2012).\n",
            "\n",
            "Neste capítulo, examinaremos dois tipos de bases de conhecimento: (1) recursos léxico-semânticos e (2) bases de conhecimento de senso comum.\n",
            "\n",
            "Antes de iniciar a descrição das bases de conhecimento, introduziremos um exemplo de texto, Exemplo 9.18, em português brasileiro, para ser analisado conforme os insumos de cada base de conhecimento. Após o exemplo, indicamos algumas conclusões e respostas resultantes de inferências que pessoas, inseridas na cultura brasileira e proficientes no português, fariam ao ler o texto.\n",
            "\n",
            "Exemplo 9.1  \n",
            "\n",
            "Um assalto do tipo saidinha bancária, ocorrido na tarde desta terça-feira, terminou com uma mulher de 42 anos baleada pelos assaltantes. O roubo ocorreu na rua Professor Costa Mendes.\n",
            "\n",
            "Conclusões:\n",
            "\n",
            "Nas próximas subseções, são descritas algumas das bases de conhecimento mais representativas para o PLN – Wordnet, FrameNet e a ConceptNet, e suas bases congêneres para o português. No final de cada subseção, discorremos sobre como essas bases contribuem para análise semântica do Exemplo 9.1. A escolha dessas três bases seguiu critérios de abrangência de suas entradas e representatividade para tarefas de PLN. A WordNet de Princeton é, consensualmente, o recurso léxico-semântico mais utilizado em PLN para dar suporte a tarefas como desambiguação de sentido de palavras, perguntas e respostas, e análise semântica. FrameNet é uma das bases mais relevantes para a tarefa de anotação de papéis semânticos (Semantic Role Labeling – SRL), pois atribui papéis semânticos não somente a verbos, mas também a termos das demais classes gramaticais. ConceptNet é a base de conhecimento de senso comum com mais entradas tanto para o inglês quanto para o português.\n",
            "\n",
            "WordNet, desenvolvida por George A. Miller, Christiane Fellbaum e colaboradores, é considerada uma base de conhecimento léxico-semântica que organiza os itens lexicais (palavras ou expressões) em synsets (que vem de synonym sets, ou conjuntos de palavras sinônimas). A primeira wordnet foi desenvolvida para o inglês por George Miller, na Universidade de Princeton, um projeto que se iniciou em 1985, e é ordinariamente chamada de WordNet de Princeton (ou Princeton WordNet, na sigla PWN)9 e é descrita por Fellbaum (1998).\n",
            "\n",
            "Wordnets são redes de palavras amplamente utilizadas em PLN para dar suporte a tarefas como desambiguação de sentido de palavras, perguntas e respostas, e análise semântica em geral. A unidade básica da WordNet são os synsets que representam conjuntos de palavras sinônimas. Cada synset expressa um conceito em particular. Os synsets têm uma glosa, semelhante a uma definição num dicionário e podem conter ainda frases que ilustram o emprego de alguma das suas palavras. A WordNet está dividida em quatro redes semânticas, uma para cada classe aberta de palavras: substantivo, verbo, adjetivo e advérbio.\n",
            "\n",
            "Como exemplo, a Figura 9.2 apresenta os synsets da palavra “murder” (verbo “assassinar”, em português) da PWN. Ao todo são três synsets, um na classe Noun (substantivo) e dois na classe Verb (verbo). O primeiro synset da palavra “murder” (na classe Verb) tem como tropônimos diretos os verbos “burke”, “execute” e hiperônimo direto o synset “kill”.\n",
            "\n",
            "A PWN é a base léxico-semântica mais utilizada em PLN, com interfaces locais (APIs) em alguns dos maiores sistemas de programação (.NET/C#, dBase, Java, MySQL, OCaml, OSX, Perl, PHP, Prolog, Python, REST, SQL, Windows, XML)10, mais de 20 mil citações no Google Scholar e dezenas de projetos que a utilizam. Apesar de ser tão utilizada, a WordNet de Princeton parou de evoluir em 2012, por falta de recursos financeiros. A última edição oficial de PWN foi a versão 3.1, lançada em 2011. Em 2019 um consórcio de pesquisadores, incluindo Christiane Fellbaum (a coordenadora da PWN), resolveu transformar a PWN em um recurso moderno, hospedado em GitHub, de tal forma que possa ser sempre atualizado (McCrae et al., 2019), mas a maior parte das aplicações continua usando PWN 3.0 ou 3.1.\n",
            "\n",
            "Como todas as bases com conhecimento semântico, WordNet não é um projeto acabado e tampouco completo. Algumas lacunas decorrem da divisão e independência entre as redes semânticas, o que dificulta a expressão de relações estruturais (entidade-atributo), de relações semânticas que acontecem entre classes de palavras (verbos e substantivos, por exemplo) em uma particular situação ou contexto; ou informações sintagmáticas: relações que ocorrem entre os termos de um proferimento (entre verbo e substantivo, entre substantivo e adjetivo etc.). No que se refere aos tipos de relações expressas na PWN, essa dispõe de relações causais entre synsets, por exemplo, “snore” implies “sleep”, mas não numa taxa de cobertura suficiente em relação ao conjunto dos synsets. Outra limitação é que recursos como a PWN são mais adequados para substantivos concretos do que para conceitos abstratos como “medo”, “felicidade” etc. Enquanto substantivos concretos como “gato”, “felino”, “mamífero”, “animal” etc. são mais facilmente organizados em taxonomias, tal processo é menos consensual quando aplicado às emoções ou a verbos. Um quarto criticismo diz respeito às expressões multipalavras (MWEs – Capítulo 5). Essas existem em PWN, mas não na quantidade suficiente para a modelagem adequada da língua. De acordo com Sag et al. (2002, p. 2), o número de MWEs em PWN precisaria ser maior do que é. Um quinto criticismo diz respeito ao nível de granularidade das distinções de significado na PWN. Essas distinções são muito refinadas, o que faz com que as medidas de concordância entre anotadores sejam baixas.\n",
            "\n",
            "parte do cap 17\n",
            "\n",
            "Daniela Barreiro Claro \n",
            "\n",
            "Joaquim Santos \n",
            "\n",
            "Marlo Souza \n",
            "\n",
            "Renata Vieira \n",
            "\n",
            "Vládia Pinheiro \n",
            "\n",
            "PDF\n",
            "\n",
            "A Extração de Informação (EI) é desenvolvida com o objetivo de se obter informação estruturada de dados não-estruturados (Jurafsky; Martin, 2023; Konstantinova, 2014).\n",
            "\n",
            "Os primeiros trabalhos a debruçarem-se sobre o problema remontam à década de 1970, com a aplicação de gramáticas formais e parsers sintáticos para a estruturação de informação em domínios como prontuários médicos (Sager, 1978; Sager; Friedman; Lyman, 1987) e textos jornalísticos (DeJong, 1979). A comunidade científica demonstrou grande interesse pela área nas décadas posteriores devido à sua utilidade prática, seu foco no processamento de dados reais, suas tarefas bem-definidas e a facilidade de mensurar a qualidade dos resultados em comparação com o desempenho humano na mesma tarefa (Cowie; Lehnert, 1996).\n",
            "\n",
            "Para autores como Eisenstein (2019) e Jurafsky; Martin (2023), a EI é normalmente dividida em diversas tarefas de interesse, com foco no tipo de informação a ser extraída do texto. Entre as mais comumente citadas na literatura estão o Reconhecimento de Entidades Nomeadas (REN), a Extração de Relações (ER) e a Extração de Eventos (EE).\n",
            "\n",
            "O Reconhecimento de Entidades Nomeadas (REN) consiste em identificar e classificar entidades mencionadas em textos através de designadores rígidos como nomes próprios, expressões temporais e espécies biológicas (Nadeau, 2007). Esse é considerado por alguns como um primeiro passo na análise semântica de um texto (Santos; Cardoso, 2007a), pois permite identificar as entidades às quais se faz referência nele.\n",
            "\n",
            "A Extração de Relações (ER), também chamada de extração de informação tradicional ou somente extração de informação, por sua vez, diz respeito à identificação de relacionamentos semânticos entre duas ou mais entidades, ou seja, identificar “quem fez o que para quem e quando”. Ananiadou; Mcnaught (2005) a definem como o processo de extrair fatos (em nossa terminologia, relacionamentos) a partir de uma fonte textual e representá-los a partir de um gabarito (em inglês, template). As relações são elementos essenciais para o entendimento da informação relatada no texto e sua identificação é passo essencial para a estruturação da mesma. Assim, identificar relações entre entidades é tarefa essencial para construção de bases de conhecimento e de grande utilidade na construção de soluções para a resposta automática a perguntas (em inglês, query answering), sumarização, recuperação de informação e mais (Nasar; Jaffry; Malik, 2021).\n",
            "\n",
            "A extração de eventos consiste na tarefa de identificação de uma menção a um evento em uma sentença e, se existirem, extração de outras informações sobre o evento. Um evento pode, por sua vez, ser entendido como uma ocorrência específica envolvendo participantes (Consortium, 2005), i.e., algo que acontece e que pode ser descrito como uma mudança de estado da qual participam entidades como agentes. Devido a intrínseca natureza temporal dos eventos, tal problema possui uma natureza mais complexa e costuma possuir tratamento específico.\n",
            "\n",
            "Assim, nesse capítulo, iniciaremos com um pouco de história da Extração de Informação (EI) e sua evolução para Extração de Informação Aberta, e destacaremos as tarefas de Reconhecimeno de Entidades Nomeadas (REN) e Extração de Relação (ER).\n",
            "\n",
            "Os primeiros trabalhos que abordaram o problema de EI dos quais temos conhecimento surgiram no final da década de 1970. Esses primeiros trabalhos da década de 1970 e 1980 tinham como modelo geral a aplicação de regras para a identificação de informações especificadas em um gabarito. Tais sistemas empregavam analisadores sintáticos (parsers) e regras definidas especificamente para o domínio e gênero textual estudado.\n",
            "\n",
            "Entre esses primeiros trabalhos, estão aqueles de Sager (1978), Sager; Friedman; Lyman (1987), de DeJong (1979) e de Cowie (1983). Sager et al. exploraram como identificar informações do estado de saúde de pacientes através dos textos de prontuários médicos. DeJong (1979), por sua vez, descrevem o sistema FRUMP que, a partir de um parser e regras de análise conceitual baseadas em uma arquitetura cognitiva proposta pelos autores e no conceito de dependência conceitual de Schank et al. (1973), processavam textos de notícias e realizavam tarefas como sumarização e identificação de papéis semânticos associados aos constituintes da sentença. Cowie (1983), por fim, descreve um sistema que emprega regras simples de segmentação e análise sintática rasa para identificar propriedades de plantas a partir de textos descritivos no campo da botânica. Diferente dos métodos anteriores, o trabalho dos autores se baseia em grande parte no estudo de padrões de descrição das informações a serem identificadas, em detrimento do emprego de parsers robustos da língua.\n",
            "\n",
            "A década de 1990 traz um grande interesse na área de EI com a implementação das conferências MUC (do inglês, Message Understanding Conference, ou Conferência de Compreensão de Mensagem), promovidas pela Agência de Projetos de Pesquisa Avançada de Defesa (DARPA, do inglês Defense Advanced Research Projects Agency). As conferências MUC, realizadas e financiadas pelo exército americano, representaram um esforço em avançar a tecnologia de EI e consistiam de tarefas de avaliação conjunta de métodos desenvolvidos por pesquisadores para problemas propostos pelos organizadores. As sete conferências realizadas de 1987 a 1997, foram cruciais para definir aspectos centrais da área, como estruturar a tarefa de ER, definindo suas métricas de avaliação, e propor a tarefa de REN (Grishman; Sundheim, 1996).\n",
            "\n",
            "parte do cap 9\n",
            "\n",
            "A comunidade de PLN foi rapidamente atraída por tais representações de conhecimento de mundo, pois pareciam prover a solução para problemas de semântica de linguagem natural. As mais antigas abordagens em PLN que utilizaram redes semânticas e frames remontam aos trabalhos de Bates et al. (1982) e Bobrow et al. (1977), conforme citado em (Ovchinnikova, 2012).\n",
            "\n",
            "Neste capítulo, examinaremos dois tipos de bases de conhecimento: (1) recursos léxico-semânticos e (2) bases de conhecimento de senso comum.\n",
            "\n",
            "Antes de iniciar a descrição das bases de conhecimento, introduziremos um exemplo de texto, Exemplo 9.18, em português brasileiro, para ser analisado conforme os insumos de cada base de conhecimento. Após o exemplo, indicamos algumas conclusões e respostas resultantes de inferências que pessoas, inseridas na cultura brasileira e proficientes no português, fariam ao ler o texto.\n",
            "\n",
            "Exemplo 9.1  \n",
            "\n",
            "Um assalto do tipo saidinha bancária, ocorrido na tarde desta terça-feira, terminou com uma mulher de 42 anos baleada pelos assaltantes. O roubo ocorreu na rua Professor Costa Mendes.\n",
            "\n",
            "Conclusões:\n",
            "\n",
            "Nas próximas subseções, são descritas algumas das bases de conhecimento mais representativas para o PLN – Wordnet, FrameNet e a ConceptNet, e suas bases congêneres para o português. No final de cada subseção, discorremos sobre como essas bases contribuem para análise semântica do Exemplo 9.1. A escolha dessas três bases seguiu critérios de abrangência de suas entradas e representatividade para tarefas de PLN. A WordNet de Princeton é, consensualmente, o recurso léxico-semântico mais utilizado em PLN para dar suporte a tarefas como desambiguação de sentido de palavras, perguntas e respostas, e análise semântica. FrameNet é uma das bases mais relevantes para a tarefa de anotação de papéis semânticos (Semantic Role Labeling – SRL), pois atribui papéis semânticos não somente a verbos, mas também a termos das demais classes gramaticais. ConceptNet é a base de conhecimento de senso comum com mais entradas tanto para o inglês quanto para o português.\n",
            "\n",
            "WordNet, desenvolvida por George A. Miller, Christiane Fellbaum e colaboradores, é considerada uma base de conhecimento léxico-semântica que organiza os itens lexicais (palavras ou expressões) em synsets (que vem de synonym sets, ou conjuntos de palavras sinônimas). A primeira wordnet foi desenvolvida para o inglês por George Miller, na Universidade de Princeton, um projeto que se iniciou em 1985, e é ordinariamente chamada de WordNet de Princeton (ou Princeton WordNet, na sigla PWN)9 e é descrita por Fellbaum (1998).\n",
            "\n",
            "Wordnets são redes de palavras amplamente utilizadas em PLN para dar suporte a tarefas como desambiguação de sentido de palavras, perguntas e respostas, e análise semântica em geral. A unidade básica da WordNet são os synsets que representam conjuntos de palavras sinônimas. Cada synset expressa um conceito em particular. Os synsets têm uma glosa, semelhante a uma definição num dicionário e podem conter ainda frases que ilustram o emprego de alguma das suas palavras. A WordNet está dividida em quatro redes semânticas, uma para cada classe aberta de palavras: substantivo, verbo, adjetivo e advérbio.\n",
            "\n",
            "Como exemplo, a Figura 9.2 apresenta os synsets da palavra “murder” (verbo “assassinar”, em português) da PWN. Ao todo são três synsets, um na classe Noun (substantivo) e dois na classe Verb (verbo). O primeiro synset da palavra “murder” (na classe Verb) tem como tropônimos diretos os verbos “burke”, “execute” e hiperônimo direto o synset “kill”.\n",
            "\n",
            "A PWN é a base léxico-semântica mais utilizada em PLN, com interfaces locais (APIs) em alguns dos maiores sistemas de programação (.NET/C#, dBase, Java, MySQL, OCaml, OSX, Perl, PHP, Prolog, Python, REST, SQL, Windows, XML)10, mais de 20 mil citações no Google Scholar e dezenas de projetos que a utilizam. Apesar de ser tão utilizada, a WordNet de Princeton parou de evoluir em 2012, por falta de recursos financeiros. A última edição oficial de PWN foi a versão 3.1, lançada em 2011. Em 2019 um consórcio de pesquisadores, incluindo Christiane Fellbaum (a coordenadora da PWN), resolveu transformar a PWN em um recurso moderno, hospedado em GitHub, de tal forma que possa ser sempre atualizado (McCrae et al., 2019), mas a maior parte das aplicações continua usando PWN 3.0 ou 3.1.\n",
            "\n",
            "Como todas as bases com conhecimento semântico, WordNet não é um projeto acabado e tampouco completo. Algumas lacunas decorrem da divisão e independência entre as redes semânticas, o que dificulta a expressão de relações estruturais (entidade-atributo), de relações semânticas que acontecem entre classes de palavras (verbos e substantivos, por exemplo) em uma particular situação ou contexto; ou informações sintagmáticas: relações que ocorrem entre os termos de um proferimento (entre verbo e substantivo, entre substantivo e adjetivo etc.). No que se refere aos tipos de relações expressas na PWN, essa dispõe de relações causais entre synsets, por exemplo, “snore” implies “sleep”, mas não numa taxa de cobertura suficiente em relação ao conjunto dos synsets. Outra limitação é que recursos como a PWN são mais adequados para substantivos concretos do que para conceitos abstratos como “medo”, “felicidade” etc. Enquanto substantivos concretos como “gato”, “felino”, “mamífero”, “animal” etc. são mais facilmente organizados em taxonomias, tal processo é menos consensual quando aplicado às emoções ou a verbos. Um quarto criticismo diz respeito às expressões multipalavras (MWEs – Capítulo 5). Essas existem em PWN, mas não na quantidade suficiente para a modelagem adequada da língua. De acordo com Sag et al. (2002, p. 2), o número de MWEs em PWN precisaria ser maior do que é. Um quinto criticismo diz respeito ao nível de granularidade das distinções de significado na PWN. Essas distinções são muito refinadas, o que faz com que as medidas de concordância entre anotadores sejam baixas.\n",
            "\n",
            "parte do cap 17\n",
            "\n",
            "A partir da MUC-3, em 1991, a conferência passa a ter foco no processamento de textos jornalísticos em detrimento dos relatórios militares utilizados anteriormente (DARPA, 1991). Com a disponibilidade de dados e o incentivo no desenvolvimento de soluções para a tarefa, vemos na década de 1990 o surgimento das primeiras aplicações comerciais de EI, como o JASPER (Andersen et al., 1992)., construído para a agência de notícias Reuters.\n",
            "\n",
            "A MUC-6, ocorrida em 1995, introduz a tarefa de REN com o intuito de ser uma tarefa de uso prático, independente de domínio e que poderia ser realizada automaticamente em um futuro próximo (Grishman; Sundheim, 1996). Enquanto os trabalhos em REN se avolumaram a partir de sua proposição na MUC-6, trabalhos anteriores como Rau (1991) e Wolinski; Vichot; Dillet (1995) já se debruçavam sobre o problema de identificação e classificação de nomes próprios. Desde então, o interesse na tarefa cresceu significativamente e outras conferências de avaliação conjunta têm sido dedicadas a essa tarefa, como a Automatic Content Extraction (ACE) e a conferência Avaliação de Sistemas de Reconhecimento de Entidades Mencionadas (HAREM), dedicada exclusivamente à língua portuguesa, com sua primeira edição em 2005 (Santos; Cardoso, 2007a).\n",
            "\n",
            "Por outro lado, houve um crescimento de abordagens baseadas em dados nesta década, a partir da análise de corpora. Tais esforços são impulsionados pelos resultados positivos na área, como o trabalho de Hearst (1992). Logo, métodos baseados em dados passaram também a explorar o emprego de análise estatística e aprendizado de máquina na construção de padrões para a extração de relações (Riloff et al., 1993; Riloff; Jones; et al., 1999; Roark; Charniak, 2000; Soderland et al., 1995)\n",
            "\n",
            "Não foi somente na extração de padrões que métodos de aprendizado de máquina, em particular aprendizado supervisionado, foram aplicados. A década de 2000 viu a proliferação de métodos supervisionados aplicados à ER (Culotta; McCallum; Betz, 2006; Kambhatla, 2004; Zelenko; Aone; Richardella, 2003; Zhao; Grishman, 2005) e ao REN (Asahara; Matsumoto, 2003; McCallum; Li, 2003; Sekine, 1998).\n",
            "\n",
            "Devido à dificuldade de construção de dados para treinamento e padrões para extração, além da pouca adaptabilidade dos sistemas construídos para outros escopos e domínios, nos anos 2000, sistemas baseados em métodos de aprendizado semi-supervisionado, como o DIPRE (Brin, 1998) e Snowball (Agichtein; Gravano, 2000) começaram a aparecer, juntamente com os estudos sobre expansão automatizada de anotações (bootstrapping) (Riloff; Jones; et al., 1999). Também para entidades nomeadas, estudos investigaram como utilizar recursos da Web (Etzioni et al., 2005; Nadeau, 2007) ou corpora (Cucchiarelli; Velardi, 2001) para aprender entidades com pouco ou nenhum esforço de anotação.\n",
            "\n",
            "Buscando superar as dificuldades da limitação de escopo, i.e. das relações-alvo a serem extraídas e categorias de entidades a serem identificadas, ainda restritas à definição de padrões desde a criação dessas tarefas, Banko et al. (2007) propõe a tarefa de extração de informação aberta (EIA), também conhecida como Open Information Extraction, OpenIE ou OIE, a qual busca extrair todas as relações possíveis expressas em um texto, sem necessidade de pré-definição de relações e entidades.\n",
            "\n",
            "Devido ao recente sucesso da aplicação de métodos baseados em redes neurais, em particular deep learning e grandes modelos de linguagem, às tarefas de Processamento de Linguagem Natural, uma tendência atual da área se delineou como o estudo de arquiteturas neurais para os problemas de EI e a geração de grandes conjuntos de dados por supervisão fraca. Surveys recentes, como (Cui; Wei; Zhou, 2018; Konstantinova, 2014; Nasar; Jaffry; Malik, 2021), nos mostram a evolução da área em direção à aplicação de métodos neurais. Na vertente de geração de dados, vemos o emprego da Wikipédia e Freebase como fontes mais usadas para obter anotações de entidades e relações em textos (Nguyen; Theobald; Weikum, 2016; Smirnova; Cudré-Mauroux, 2018; Takamatsu; Sato; Nakagawa, 2012).\n",
            "\n",
            "Porém, toda a tarefa de EI necessita de uma concordância entre as definições de Entidade e Relação. Neste sentido, a próxima seção discute a conceituação de relação adotada neste capítulo, assim como o conceito de entidade.\n",
            "\n",
            "A natureza das relações estudadas na área de Extração de Informação e os critérios para reconhecer sua ocorrência em um texto têm recebido pouca atenção na literatura. Este é um passo importante para estabelecer metodologias adequadas para avaliar os sistemas, bem como para criar conjuntos de dados que possam apoiar a criação de sistemas futuros.\n",
            "\n",
            "Enquanto as noções de Relação e Entidade são de grande importância e já bem estudadas nas áreas de Computação, Linguística, Ciência da Informação e Filosofia da Linguagem, esses conceitos não são empregados de forma consistente entre as áreas, ou mesmo entre suas subáreas.\n",
            "\n",
            "Para Chen (1976), uma entidade é um objeto que pode ser concreto, tal como pessoa, livro, casa ou ainda abstrato, tal como um emprego, um sentimento, uma disciplina. As entidades podem estabelecer relações entre si. Duas ou mais entidades são vinculadas, ou seja conectadas por uma relação1.\n",
            "\n",
            "Tradicionalmente em reconhecimento de entidades nomeadas, as entidades consideradas são aquelas referenciadas por um nome próprio, acrescidas das referências temporais e valores que são expressões numéricas. Essas expressões, portanto, geralmente não constituem uma entrada em uma base lexical. Porém a tarefa se expandiu para domínios especializados, onde as entidades de interesse são mais conceituais. No domínio bio-médico por exemplo, podemos ter como exemplo de entidades de interesse, sintomas e tratamento que não são referenciadas por nomes próprios.\n",
            "\n",
            "Os conceitos de relação e relacionamento são noções fundamentais que vêm sendo estudadas em áreas como Ciência da Computação, Linguística e Filosofia.\n",
            "\n",
            "No campo de bancos de dados e modelagem conceitual, Chen (1976) define um relacionamento, no contexto da modelagem de Entidade-Relacionamento, como uma associação entre entidades. Guarino; Guizzardi (2015), por sua vez, estudando a natureza ontológica dos relacionamentos com base na semântica de veridadores (truthmaker semantics) (Fine, 2017), postulam relacionamentos como entidades que atuam como veridadores (thruthmakers) de alguma proposição relacionando duas ou mais entidades, ou seja, uma relação mantida entre essas entidades. Um veridador é um elemento cuja existência torna verdadeira uma proposição particular. Por exemplo, considerando a sentença (1) “a é uma maçã”, a existência de um objeto denotado pelo nome a que por acaso é uma maçã é uma condição suficiente para a verdade da frase (1). Como tal, dizemos que esse objeto é o veridador de (1). Tal definição nos permite adotar critérios ontológicos para validar a existência de relacionamentos a partir da informação relatada em um texto e, por isso, adotaremos tal definição de relacionamento neste capítulo.\n",
            "\n",
            "O conceito de relações é muito menos consistente na literatura. Ainda na área de modelagem conceitual, Guarino; Guizzardi (2015) definem as relações como proposições para as quais os relacionamentos são veridadores e, portanto, possuem conteúdo proposicional. Assim, podemos entender uma relação como um tipo para entidades como relacionamentos. Ou seja, relações são universais ontológicos que descrevem a natureza dos relacionamentos.\n",
            "\n",
            "Xavier; Lima; Souza (2015), no entanto, argumentam que a noção de relacionamento adotada na área de Extração de Informação é mais geral do que isso, não se limitando àquelas entre objetos e propriedades, mas também àquelas que descrevem ou implicam propriedades de classes gerais como descrito pela sentença (2) “Filósofos são autores de Livros”. Assim, para o contexto de EI consideramos relações como tipos de relacionamentos de primeira ou segunda ordem. Isso significa que uma relação é um tipo de relacionamento que existe entre objetos, suas propriedades e classes de objetos ou suas propriedades.\n",
            "\n",
            "parte do cap 9\n",
            "\n",
            "A comunidade de PLN foi rapidamente atraída por tais representações de conhecimento de mundo, pois pareciam prover a solução para problemas de semântica de linguagem natural. As mais antigas abordagens em PLN que utilizaram redes semânticas e frames remontam aos trabalhos de Bates et al. (1982) e Bobrow et al. (1977), conforme citado em (Ovchinnikova, 2012).\n",
            "\n",
            "Neste capítulo, examinaremos dois tipos de bases de conhecimento: (1) recursos léxico-semânticos e (2) bases de conhecimento de senso comum.\n",
            "\n",
            "Antes de iniciar a descrição das bases de conhecimento, introduziremos um exemplo de texto, Exemplo 9.18, em português brasileiro, para ser analisado conforme os insumos de cada base de conhecimento. Após o exemplo, indicamos algumas conclusões e respostas resultantes de inferências que pessoas, inseridas na cultura brasileira e proficientes no português, fariam ao ler o texto.\n",
            "\n",
            "Exemplo 9.1  \n",
            "\n",
            "Um assalto do tipo saidinha bancária, ocorrido na tarde desta terça-feira, terminou com uma mulher de 42 anos baleada pelos assaltantes. O roubo ocorreu na rua Professor Costa Mendes.\n",
            "\n",
            "Conclusões:\n",
            "\n",
            "Nas próximas subseções, são descritas algumas das bases de conhecimento mais representativas para o PLN – Wordnet, FrameNet e a ConceptNet, e suas bases congêneres para o português. No final de cada subseção, discorremos sobre como essas bases contribuem para análise semântica do Exemplo 9.1. A escolha dessas três bases seguiu critérios de abrangência de suas entradas e representatividade para tarefas de PLN. A WordNet de Princeton é, consensualmente, o recurso léxico-semântico mais utilizado em PLN para dar suporte a tarefas como desambiguação de sentido de palavras, perguntas e respostas, e análise semântica. FrameNet é uma das bases mais relevantes para a tarefa de anotação de papéis semânticos (Semantic Role Labeling – SRL), pois atribui papéis semânticos não somente a verbos, mas também a termos das demais classes gramaticais. ConceptNet é a base de conhecimento de senso comum com mais entradas tanto para o inglês quanto para o português.\n",
            "\n",
            "WordNet, desenvolvida por George A. Miller, Christiane Fellbaum e colaboradores, é considerada uma base de conhecimento léxico-semântica que organiza os itens lexicais (palavras ou expressões) em synsets (que vem de synonym sets, ou conjuntos de palavras sinônimas). A primeira wordnet foi desenvolvida para o inglês por George Miller, na Universidade de Princeton, um projeto que se iniciou em 1985, e é ordinariamente chamada de WordNet de Princeton (ou Princeton WordNet, na sigla PWN)9 e é descrita por Fellbaum (1998).\n",
            "\n",
            "Wordnets são redes de palavras amplamente utilizadas em PLN para dar suporte a tarefas como desambiguação de sentido de palavras, perguntas e respostas, e análise semântica em geral. A unidade básica da WordNet são os synsets que representam conjuntos de palavras sinônimas. Cada synset expressa um conceito em particular. Os synsets têm uma glosa, semelhante a uma definição num dicionário e podem conter ainda frases que ilustram o emprego de alguma das suas palavras. A WordNet está dividida em quatro redes semânticas, uma para cada classe aberta de palavras: substantivo, verbo, adjetivo e advérbio.\n",
            "\n",
            "Como exemplo, a Figura 9.2 apresenta os synsets da palavra “murder” (verbo “assassinar”, em português) da PWN. Ao todo são três synsets, um na classe Noun (substantivo) e dois na classe Verb (verbo). O primeiro synset da palavra “murder” (na classe Verb) tem como tropônimos diretos os verbos “burke”, “execute” e hiperônimo direto o synset “kill”.\n",
            "\n",
            "A PWN é a base léxico-semântica mais utilizada em PLN, com interfaces locais (APIs) em alguns dos maiores sistemas de programação (.NET/C#, dBase, Java, MySQL, OCaml, OSX, Perl, PHP, Prolog, Python, REST, SQL, Windows, XML)10, mais de 20 mil citações no Google Scholar e dezenas de projetos que a utilizam. Apesar de ser tão utilizada, a WordNet de Princeton parou de evoluir em 2012, por falta de recursos financeiros. A última edição oficial de PWN foi a versão 3.1, lançada em 2011. Em 2019 um consórcio de pesquisadores, incluindo Christiane Fellbaum (a coordenadora da PWN), resolveu transformar a PWN em um recurso moderno, hospedado em GitHub, de tal forma que possa ser sempre atualizado (McCrae et al., 2019), mas a maior parte das aplicações continua usando PWN 3.0 ou 3.1.\n",
            "\n",
            "Como todas as bases com conhecimento semântico, WordNet não é um projeto acabado e tampouco completo. Algumas lacunas decorrem da divisão e independência entre as redes semânticas, o que dificulta a expressão de relações estruturais (entidade-atributo), de relações semânticas que acontecem entre classes de palavras (verbos e substantivos, por exemplo) em uma particular situação ou contexto; ou informações sintagmáticas: relações que ocorrem entre os termos de um proferimento (entre verbo e substantivo, entre substantivo e adjetivo etc.). No que se refere aos tipos de relações expressas na PWN, essa dispõe de relações causais entre synsets, por exemplo, “snore” implies “sleep”, mas não numa taxa de cobertura suficiente em relação ao conjunto dos synsets. Outra limitação é que recursos como a PWN são mais adequados para substantivos concretos do que para conceitos abstratos como “medo”, “felicidade” etc. Enquanto substantivos concretos como “gato”, “felino”, “mamífero”, “animal” etc. são mais facilmente organizados em taxonomias, tal processo é menos consensual quando aplicado às emoções ou a verbos. Um quarto criticismo diz respeito às expressões multipalavras (MWEs – Capítulo 5). Essas existem em PWN, mas não na quantidade suficiente para a modelagem adequada da língua. De acordo com Sag et al. (2002, p. 2), o número de MWEs em PWN precisaria ser maior do que é. Um quinto criticismo diz respeito ao nível de granularidade das distinções de significado na PWN. Essas distinções são muito refinadas, o que faz com que as medidas de concordância entre anotadores sejam baixas.\n",
            "\n",
            "parte do cap 17\n",
            "\n",
            "Enquanto os métodos tradicionais de Extração de Informação dependem de um conjunto pré-existente de relações semânticas bem definidas que são relevantes para um domínio específico, a noção de “relação” e “entidade” na literatura da área mais recente, tais como a Extração de Informação Aberta, requer mais aprofundamento por demandar um significado diferente, principalmente com diferente visões de autores. Esta indeterminação terminológica pode trazer problemas para comparar os resultados dos métodos propostos ou para reutilizar os conjuntos de dados criados na área.\n",
            "\n",
            "As seções seguintes exploram essas duas áreas: Extração de Informação e Extração de Informação Aberta.\n",
            "\n",
            "A Extração de Informação é caracterizada por obter informação estruturada a partir de textos, sendo entidades ou fatos, i.e. relacionamentos entre entidades, de tipos previamente definidos, conforme exemplo na Quadro 17.1. Métodos com limitação de escopo possuem como uma de suas principais desvantagens a necessidade de intervenção humana para especificar novos fatos a serem extraídos. Esta limitação impede que sistemas de Extração de Informação, doravante denominados de EI tradicional extraiam fatos fora do escopo pré-definido.\n",
            "\n",
            "Quadro 17.1 Exemplos de relações específicas na EI tradicional\n",
            "\n",
            "Fonte: (Souza; Claro, 2014)\n",
            "\n",
            "O Reconhecimento de Entidades Nomeadas (REN) consiste na tarefa de identificar e classificar expressões linguísticas, denominadas entidades nomeadas (EN), que referenciam entidades específicas num domínio de discurso, como nomes próprios, expressões temporais e espécies biológicas (Mota; Santos; Ranchhod, 2007; Nadeau, 2007). De uma forma geral, o REN pode ser dividido em duas etapas: a identificação (ou delimitação) da expressão, na qual as palavras que formam a EN são selecionadas; a classificação, em que é atribuída uma categoria semântica à EN.\n",
            "\n",
            "A classificação das ENs determina os tipos de entidades a serem consideradas e são especificadas a partir do escopo definido previamente para a tarefa. Algumas das categorias mais comumente utilizadas incluem as entidades que referenciam Pessoas Singulares (antropônimos); Coletivas (empresas e organizações) e Lugares (topônimos) (Mota; Santos; Ranchhod, 2007). Para exemplificar tomemos a sentença: “Renata Silva e Maria Costa palestraram na Universidade Federal da Bahia”. No exemplo temos três ENs: “Renata Silva”, “Maria Costa”, “Universidade Federal da Bahia”, sendo as duas primeiras correspondentes à categoria semântica Pessoa e a última, à categoria semântica Organização. Entretanto, existem outras categorias de ENs, como as menções a Obras (por exemplo, “Código Da Vinci”); Acontecimentos (por exemplo, “Festa de Santo Antônio”), Tempo (por exemplo, “meio-dia”); Coisa (por exemplo, “barco”), entre outras.\n",
            "\n",
            "O REN é uma tarefa com grande importância para o Processamento de Linguagem Natural, pois consiste numa primeira tarefa de análise semântica de um texto, com potencial aplicações a diversas tarefas. Por exemplo, em sistemas de perguntas e respostas, as perguntas frequentemente se referem a informações sobre entidades. Também, métodos de identificação de estruturas mais complexas, como eventos ou relações, dependem do bom desempenho do REN como uma etapa de pré-processamento (Socher et al., 2012; Zelenko; Aone; Richardella, 2003).\n",
            "\n",
            "A tarefa de extração de relações (ou de relacionamentos) (ER) refere-se a identificar relacionamentos entre entidades de um determinado escopo mencionadas em um texto (Jurafsky; Martin, 2023). O escopo, no contexto da ER, refere-se a um conjunto de relações-alvo de um determinado domínio de conhecimento ou aplicação a ser investigado. Por exemplo, o Quadro 17.2 apresenta alguns exemplos de relações no domínio de geografia brasileira. Na descrição das relações, os elementos em negrito referem-se às entidades em um dado relacionamento descrito pelo termo em itálico.\n",
            "\n",
            "Quadro 17.2 Exemplos de relações no domínio da geografia brasileira.\n",
            "\n",
            "Nesse contexto, a delimitação de um escopo ou domínio de interesse, concentra-se na determinação das relações a serem processadas, i.e. nos tipos de relacionamentos de interesse, assim como da natureza das entidades associadas por tais relações.\n",
            "\n",
            "As tarefas de reconhecimento de entidades nomeadas e extração de relações são interdependentes, no sentido de que a definição do escopo a ser estudado delimita tanto as categorias e natureza das entidades a serem extraídas, como também as relações entre essas entidades. Também, note-se que, pelo fato de as relações serem comumente definidas entre entidades de tipo especificado, como o caso da relação Tem_Prefeito no Quadro 17.2 que ocorre entre entidades das classes Cidade e Pessoa, tanto as informações das entidades mencionadas no texto são úteis para a extração de relações, quanto a informação das relações identificadas pode ser útil ao processo de identificação de entidades.\n",
            "\n",
            "De fato, na literatura recente, existem vários trabalhos que consideram a tarefa de extração conjunta de entidades e relações (ERE, do inglês Entity and Relation Joint Extraction), composta das tarefas de REN e ER (Agichtein; Gravano, 2000; Shaowei et al., 2022; Yuan et al., 2021). Enquanto normalmente abordagens estruturam suas soluções de forma sequencial, usualmente realizando REN inicialmente e, posteriormente, realizando ER, como nos trabalhos de (Hasegawa; Sekine; Grishman, 2004) e de (Socher et al., 2012), a literatura recente aponta para as vantagens da identificação conjunta ao permitir um melhor aprendizado de restrições para identificação de entidades e relações, c.f. o recente survey realizado por (Shaowei et al., 2022) sobre métodos para tal tarefa.\n",
            "\n",
            "Várias abordagens foram adotadas para o problema de EI durante seu desenvolvimento histórico. Enquanto abordagens iniciais privilegiavam métodos ricos em conhecimento, como regras e recursos linguísticos e de conhecimento de mundo, a literatura recente na área privilegia métodos baseados em dados, como o aprendizado de máquina, com o recente emprego de arquiteturas neurais aos problemas.\n",
            "\n",
            "A seguir faremos uma breve apresentação das abordagens descritas na literatura para os problemas de EI.\n",
            "\n",
            "parte do cap 9\n",
            "\n",
            "A comunidade de PLN foi rapidamente atraída por tais representações de conhecimento de mundo, pois pareciam prover a solução para problemas de semântica de linguagem natural. As mais antigas abordagens em PLN que utilizaram redes semânticas e frames remontam aos trabalhos de Bates et al. (1982) e Bobrow et al. (1977), conforme citado em (Ovchinnikova, 2012).\n",
            "\n",
            "Neste capítulo, examinaremos dois tipos de bases de conhecimento: (1) recursos léxico-semânticos e (2) bases de conhecimento de senso comum.\n",
            "\n",
            "Antes de iniciar a descrição das bases de conhecimento, introduziremos um exemplo de texto, Exemplo 9.18, em português brasileiro, para ser analisado conforme os insumos de cada base de conhecimento. Após o exemplo, indicamos algumas conclusões e respostas resultantes de inferências que pessoas, inseridas na cultura brasileira e proficientes no português, fariam ao ler o texto.\n",
            "\n",
            "Exemplo 9.1  \n",
            "\n",
            "Um assalto do tipo saidinha bancária, ocorrido na tarde desta terça-feira, terminou com uma mulher de 42 anos baleada pelos assaltantes. O roubo ocorreu na rua Professor Costa Mendes.\n",
            "\n",
            "Conclusões:\n",
            "\n",
            "Nas próximas subseções, são descritas algumas das bases de conhecimento mais representativas para o PLN – Wordnet, FrameNet e a ConceptNet, e suas bases congêneres para o português. No final de cada subseção, discorremos sobre como essas bases contribuem para análise semântica do Exemplo 9.1. A escolha dessas três bases seguiu critérios de abrangência de suas entradas e representatividade para tarefas de PLN. A WordNet de Princeton é, consensualmente, o recurso léxico-semântico mais utilizado em PLN para dar suporte a tarefas como desambiguação de sentido de palavras, perguntas e respostas, e análise semântica. FrameNet é uma das bases mais relevantes para a tarefa de anotação de papéis semânticos (Semantic Role Labeling – SRL), pois atribui papéis semânticos não somente a verbos, mas também a termos das demais classes gramaticais. ConceptNet é a base de conhecimento de senso comum com mais entradas tanto para o inglês quanto para o português.\n",
            "\n",
            "WordNet, desenvolvida por George A. Miller, Christiane Fellbaum e colaboradores, é considerada uma base de conhecimento léxico-semântica que organiza os itens lexicais (palavras ou expressões) em synsets (que vem de synonym sets, ou conjuntos de palavras sinônimas). A primeira wordnet foi desenvolvida para o inglês por George Miller, na Universidade de Princeton, um projeto que se iniciou em 1985, e é ordinariamente chamada de WordNet de Princeton (ou Princeton WordNet, na sigla PWN)9 e é descrita por Fellbaum (1998).\n",
            "\n",
            "Wordnets são redes de palavras amplamente utilizadas em PLN para dar suporte a tarefas como desambiguação de sentido de palavras, perguntas e respostas, e análise semântica em geral. A unidade básica da WordNet são os synsets que representam conjuntos de palavras sinônimas. Cada synset expressa um conceito em particular. Os synsets têm uma glosa, semelhante a uma definição num dicionário e podem conter ainda frases que ilustram o emprego de alguma das suas palavras. A WordNet está dividida em quatro redes semânticas, uma para cada classe aberta de palavras: substantivo, verbo, adjetivo e advérbio.\n",
            "\n",
            "Como exemplo, a Figura 9.2 apresenta os synsets da palavra “murder” (verbo “assassinar”, em português) da PWN. Ao todo são três synsets, um na classe Noun (substantivo) e dois na classe Verb (verbo). O primeiro synset da palavra “murder” (na classe Verb) tem como tropônimos diretos os verbos “burke”, “execute” e hiperônimo direto o synset “kill”.\n",
            "\n",
            "A PWN é a base léxico-semântica mais utilizada em PLN, com interfaces locais (APIs) em alguns dos maiores sistemas de programação (.NET/C#, dBase, Java, MySQL, OCaml, OSX, Perl, PHP, Prolog, Python, REST, SQL, Windows, XML)10, mais de 20 mil citações no Google Scholar e dezenas de projetos que a utilizam. Apesar de ser tão utilizada, a WordNet de Princeton parou de evoluir em 2012, por falta de recursos financeiros. A última edição oficial de PWN foi a versão 3.1, lançada em 2011. Em 2019 um consórcio de pesquisadores, incluindo Christiane Fellbaum (a coordenadora da PWN), resolveu transformar a PWN em um recurso moderno, hospedado em GitHub, de tal forma que possa ser sempre atualizado (McCrae et al., 2019), mas a maior parte das aplicações continua usando PWN 3.0 ou 3.1.\n",
            "\n",
            "Como todas as bases com conhecimento semântico, WordNet não é um projeto acabado e tampouco completo. Algumas lacunas decorrem da divisão e independência entre as redes semânticas, o que dificulta a expressão de relações estruturais (entidade-atributo), de relações semânticas que acontecem entre classes de palavras (verbos e substantivos, por exemplo) em uma particular situação ou contexto; ou informações sintagmáticas: relações que ocorrem entre os termos de um proferimento (entre verbo e substantivo, entre substantivo e adjetivo etc.). No que se refere aos tipos de relações expressas na PWN, essa dispõe de relações causais entre synsets, por exemplo, “snore” implies “sleep”, mas não numa taxa de cobertura suficiente em relação ao conjunto dos synsets. Outra limitação é que recursos como a PWN são mais adequados para substantivos concretos do que para conceitos abstratos como “medo”, “felicidade” etc. Enquanto substantivos concretos como “gato”, “felino”, “mamífero”, “animal” etc. são mais facilmente organizados em taxonomias, tal processo é menos consensual quando aplicado às emoções ou a verbos. Um quarto criticismo diz respeito às expressões multipalavras (MWEs – Capítulo 5). Essas existem em PWN, mas não na quantidade suficiente para a modelagem adequada da língua. De acordo com Sag et al. (2002, p. 2), o número de MWEs em PWN precisaria ser maior do que é. Um quinto criticismo diz respeito ao nível de granularidade das distinções de significado na PWN. Essas distinções são muito refinadas, o que faz com que as medidas de concordância entre anotadores sejam baixas.\n",
            "\n",
            "parte do cap 17\n",
            "\n",
            "As abordagens iniciais para REN baseavam-se, majoritariamente, no emprego de regras lexico-sintáticas e consulta a almanaques (gazeeers). Tais abordagens dependem da construção de listas de nomes próprios como antropônimos, topônimos etc., e outras palavras, como “Ltda.”, “Jr.” etc., que auxiliam no processo de identificação e classificação de ENs complexas ou desconhecidas. Essa é, por exemplo, a abordagem empregada por Wolinski; Vichot; Dillet (1995) que combina almanaques e regras para a identificação e classificação de ENs. Posteriormente, almanaques foram também empregados em conjunção com métodos baseados em dados, como o trabalho de Florian et al. (2003) que os emprega aliados aos classificadores, enquanto Liu; Yao; Lin (2019) os utilizam durante o treinamento de uma rede neural, como um sinal de treinamento (parte da função de perda, ou loss em inglês).\n",
            "\n",
            "Muitos trabalhos debruçaram-se também sobre o problema de construção automática ou semi-automática de almanaques, dos quais os trabalhos de Nadeau (2007), de Riloff; Jones; et al. (1999) e de Etzioni et al. (2005) são alguns dos mais importantes.\n",
            "\n",
            "Enquanto as abordagens iniciais para o problema baseavam-se em regras, com a disponibilidade de dados anotados para a tarefa, tais métodos foram rapidamente suplantados por métodos baseados em dados, tais como: os métodos baseados em classificação (Asahara; Matsumoto, 2003; Sekine, 1998) e classificação sequencial (Bikel; Schwartz; Weischedel, 1999; McCallum; Li, 2003).\n",
            "\n",
            "A redução de REN à tarefa de classificação sequencial merece destaque pelos bons resultados obtidos. Tal redução se dá através de um esquema de codificação do problema que nos permite representar fragmentos textuais e sua classificação como um problema de rotulação ou etiquetação.\n",
            "\n",
            "Partindo-se do pressuposto de que os fragmentos textuais descrevendo entidades nomeadas são contíguos, podemos codificar a tarefa de delimitação de entidades como classificação sequencial empregando rótulos que descrevem os limites de uma EN, e.g. o esquema BIO com os rótulos B (do inglês, begin) para designar a palavra inicial de uma EN, I (do inglês, inside) para designar palavras que fazem parte da EN mas não a iniciam e O (do inglês, outside) para designar palavras que não pertencem a uma entidade. Da mesma forma, podemos estender nosso esquema de codificação para incluir as classes de interesse. Assim, seguindo o esquema BIO, teremos os rótulos B-PER e I-PER para descrever entidades da classe Pessoa.\n",
            "\n",
            "A redução do problema de REN à classificação sequencial está ilustrada no Exemplo 17.1.\n",
            "\n",
            "Exemplo 17.1  \n",
            "\n",
            "Renata/B-PER Silva/I-PER e/O Maria/B-PER Costa/I-PER palestraram/O na/O Universidade/B-ORG Federal/I-ORG da/I-ORG Bahia/I-ORG.\n",
            "\n",
            "Recentemente, destacam-se na literatura abordagens baseadas em redes neurais profundas, com uma grande concentração nos últimos anos em modelos gerativos de linguagem, devido aos resultados positivos obtidos por tais arquiteturas em diversas tarefas.\n",
            "\n",
            "Na literatura são de grande destaque os modelos recentes BART (Lewis et al., 2020), RoBERTa (Liu et al., 2019), T5 (Raffel et al., 2020), BERT (Devlin et al., 2019) e GPT-3 (Brown et al., 2020), conforme descritos no Capítulo 15.\n",
            "\n",
            "Similarmente, na língua portuguesa, nas duas edições do HAREM (Mota; Santos, 2008; Santos; Cardoso, 2007b), o primeiro esforço sistemático de desenvolvimento de soluções para a tarefa na língua, a maioria dos sistemas participantes baseava-se em métodos ricos em conhecimento, como regras e almanaques. De fato, nas duas avaliações, somente os sistemas MALINCHE (Solorio, 2007), NEURA (Ferrández et al., 2007) e R3M (Mota, 2008) não se baseavam em regras. Métodos baseados em classificação sequencial se seguiram para a língua portuguesa, como o RELP-CRF (Amaral; Vieira, 2014) baseado em um classificador sequencial. Mais recentemente, abordagens baseadas em redes neurais e modelos de linguagem foram desenvolvidas tornando-se o estado da arte da tarefa na língua. A Tabela 17.1 apresenta o atual estado da arte em português, com base no corpus HAREM. A métrica de avaliação apresentada, medida F1, será discutida na Seção 17.6.\n",
            "\n",
            "Souza; Nogueira; Lotufo (2020) desenvolveram um modelo BERT para o Português com 2,68 bilhões de tokens e aplicaram o modelo em um classificador CRF. Santos et al., avaliaram o impacto do modelo contextualizado Flair Embeddings aplicado a tarefa de REN junto com uma rede neural BiLSTM-CRF. Os autores também desenvolveram um modelo Flair Embeddings para o português, o FlairBBP, treinado com 4,9 bilhões de tokens (Santos et al., 2019). Castro; Silva; Soares (2018) utilizou uma rede LSTM e um classificador CRF junto com modelos Word Embeddings pré-treinados. Santos; Guimarães (2015) desenvolveram uma rede neural convolucional capaz de capturar características a nível de caracteres e também de incorporar word embeddings pré-treinados.\n",
            "\n",
            "O reconhecimento de entidades tem sido aplicado em muitas áreas específicas, como direito, saúde e geologia. Nesses casos há uma demanda de adaptação dos modelos preditivos de acordo com a nova linguagem especializada do domínio e um novo conjunto de rótulos que devem ser aprendidos. Da mesma forma, são necessários novos conjuntos de dados para o processo de aprendizado, uma vez que abordagens de aprendizado de máquina necessitam de exemplos anotados para se chegar a um modelo preditivo eficaz.\n",
            "\n",
            "Muitos trabalhos endereçam domínios específicos, citamos exemplos em diversas línguas. Para o inglês, uma rede neural BiLSTM-CRF para o domínio biomédico é proposta em (Habibi et al., 2017).\n",
            "\n",
            "Um conjunto de dados do domínio jurídico em língua alemã é apresentado por Leitner; Rehm; Schneider (2019), que empregam redes neurais BiLSTM para a rotulação dos textos. Em (Qiu et al., 2019), uma rede neural BiLSTM-CRF com mecanismo de atenção é aplicada para reconhecer entidades geológicas para a língua chinesa.\n",
            "\n",
            "parte do cap 9\n",
            "\n",
            "A comunidade de PLN foi rapidamente atraída por tais representações de conhecimento de mundo, pois pareciam prover a solução para problemas de semântica de linguagem natural. As mais antigas abordagens em PLN que utilizaram redes semânticas e frames remontam aos trabalhos de Bates et al. (1982) e Bobrow et al. (1977), conforme citado em (Ovchinnikova, 2012).\n",
            "\n",
            "Neste capítulo, examinaremos dois tipos de bases de conhecimento: (1) recursos léxico-semânticos e (2) bases de conhecimento de senso comum.\n",
            "\n",
            "Antes de iniciar a descrição das bases de conhecimento, introduziremos um exemplo de texto, Exemplo 9.18, em português brasileiro, para ser analisado conforme os insumos de cada base de conhecimento. Após o exemplo, indicamos algumas conclusões e respostas resultantes de inferências que pessoas, inseridas na cultura brasileira e proficientes no português, fariam ao ler o texto.\n",
            "\n",
            "Exemplo 9.1  \n",
            "\n",
            "Um assalto do tipo saidinha bancária, ocorrido na tarde desta terça-feira, terminou com uma mulher de 42 anos baleada pelos assaltantes. O roubo ocorreu na rua Professor Costa Mendes.\n",
            "\n",
            "Conclusões:\n",
            "\n",
            "Nas próximas subseções, são descritas algumas das bases de conhecimento mais representativas para o PLN – Wordnet, FrameNet e a ConceptNet, e suas bases congêneres para o português. No final de cada subseção, discorremos sobre como essas bases contribuem para análise semântica do Exemplo 9.1. A escolha dessas três bases seguiu critérios de abrangência de suas entradas e representatividade para tarefas de PLN. A WordNet de Princeton é, consensualmente, o recurso léxico-semântico mais utilizado em PLN para dar suporte a tarefas como desambiguação de sentido de palavras, perguntas e respostas, e análise semântica. FrameNet é uma das bases mais relevantes para a tarefa de anotação de papéis semânticos (Semantic Role Labeling – SRL), pois atribui papéis semânticos não somente a verbos, mas também a termos das demais classes gramaticais. ConceptNet é a base de conhecimento de senso comum com mais entradas tanto para o inglês quanto para o português.\n",
            "\n",
            "WordNet, desenvolvida por George A. Miller, Christiane Fellbaum e colaboradores, é considerada uma base de conhecimento léxico-semântica que organiza os itens lexicais (palavras ou expressões) em synsets (que vem de synonym sets, ou conjuntos de palavras sinônimas). A primeira wordnet foi desenvolvida para o inglês por George Miller, na Universidade de Princeton, um projeto que se iniciou em 1985, e é ordinariamente chamada de WordNet de Princeton (ou Princeton WordNet, na sigla PWN)9 e é descrita por Fellbaum (1998).\n",
            "\n",
            "Wordnets são redes de palavras amplamente utilizadas em PLN para dar suporte a tarefas como desambiguação de sentido de palavras, perguntas e respostas, e análise semântica em geral. A unidade básica da WordNet são os synsets que representam conjuntos de palavras sinônimas. Cada synset expressa um conceito em particular. Os synsets têm uma glosa, semelhante a uma definição num dicionário e podem conter ainda frases que ilustram o emprego de alguma das suas palavras. A WordNet está dividida em quatro redes semânticas, uma para cada classe aberta de palavras: substantivo, verbo, adjetivo e advérbio.\n",
            "\n",
            "Como exemplo, a Figura 9.2 apresenta os synsets da palavra “murder” (verbo “assassinar”, em português) da PWN. Ao todo são três synsets, um na classe Noun (substantivo) e dois na classe Verb (verbo). O primeiro synset da palavra “murder” (na classe Verb) tem como tropônimos diretos os verbos “burke”, “execute” e hiperônimo direto o synset “kill”.\n",
            "\n",
            "A PWN é a base léxico-semântica mais utilizada em PLN, com interfaces locais (APIs) em alguns dos maiores sistemas de programação (.NET/C#, dBase, Java, MySQL, OCaml, OSX, Perl, PHP, Prolog, Python, REST, SQL, Windows, XML)10, mais de 20 mil citações no Google Scholar e dezenas de projetos que a utilizam. Apesar de ser tão utilizada, a WordNet de Princeton parou de evoluir em 2012, por falta de recursos financeiros. A última edição oficial de PWN foi a versão 3.1, lançada em 2011. Em 2019 um consórcio de pesquisadores, incluindo Christiane Fellbaum (a coordenadora da PWN), resolveu transformar a PWN em um recurso moderno, hospedado em GitHub, de tal forma que possa ser sempre atualizado (McCrae et al., 2019), mas a maior parte das aplicações continua usando PWN 3.0 ou 3.1.\n",
            "\n",
            "Como todas as bases com conhecimento semântico, WordNet não é um projeto acabado e tampouco completo. Algumas lacunas decorrem da divisão e independência entre as redes semânticas, o que dificulta a expressão de relações estruturais (entidade-atributo), de relações semânticas que acontecem entre classes de palavras (verbos e substantivos, por exemplo) em uma particular situação ou contexto; ou informações sintagmáticas: relações que ocorrem entre os termos de um proferimento (entre verbo e substantivo, entre substantivo e adjetivo etc.). No que se refere aos tipos de relações expressas na PWN, essa dispõe de relações causais entre synsets, por exemplo, “snore” implies “sleep”, mas não numa taxa de cobertura suficiente em relação ao conjunto dos synsets. Outra limitação é que recursos como a PWN são mais adequados para substantivos concretos do que para conceitos abstratos como “medo”, “felicidade” etc. Enquanto substantivos concretos como “gato”, “felino”, “mamífero”, “animal” etc. são mais facilmente organizados em taxonomias, tal processo é menos consensual quando aplicado às emoções ou a verbos. Um quarto criticismo diz respeito às expressões multipalavras (MWEs – Capítulo 5). Essas existem em PWN, mas não na quantidade suficiente para a modelagem adequada da língua. De acordo com Sag et al. (2002, p. 2), o número de MWEs em PWN precisaria ser maior do que é. Um quinto criticismo diz respeito ao nível de granularidade das distinções de significado na PWN. Essas distinções são muito refinadas, o que faz com que as medidas de concordância entre anotadores sejam baixas.\n",
            "\n",
            "parte do cap 17\n",
            "\n",
            "Para o português, um corpus para detecção de eventos de quedas de pacientes em prontuários eletrônicos é descrito em (Santos; Santos; Vieira, 2020). Os autores usaram uma rede neural BiLSTM-CRF+Flair para gerar um modelo classificador de tokens. Um corpus no domínio jurídico, tendo categorias específicas como legislação e jurisprudência é proposto por  Araujo et al. (2018), que usaram uma rede neural BiLSTM-CRF para criar um primeiro baseline para esse corpus. Ademais, Consoli et al. (2020) analisam um corpus no domínio de geologia usando uma rede neural BiLSTM-CRF com um modelo contextualizado Flair Embeddings.\n",
            "\n",
            "As abordagens iniciais para o problema de ER baseavam-se na definição de gabaritos e regras de extração, com base em informação sintática obtida de analisadores sintáticos rasos ou profundos (Cowie, 1983; Sager, 1978). Tais métodos foram rapidamente suplantados por métodos baseados em dados e padrões obtidos de corpora, como os famosos padrões de Hearst (1992) para identificação de relações de hiponímia.\n",
            "\n",
            "O trabalho de Hearst (1992) se baseou na definição de padrões lexico-sintáticos para expressão de relações de hiponímia e hiperonímia a partir de uma análise de corpus. Ao escolher a relação de hiponímia, que ocorre em todo domínio, e padrões gerais baseados em aspectos da língua, como os representados no Quadro 17.3, o autor garante generalizabilidade dos padrões obtidos para diversos domínios e aplicações.\n",
            "\n",
            "Quadro 17.3 Exemplos de Padrões de Hearst para hiponímia\n",
            "\n",
            "Devido à dificuldade de construção manual das regras, os métodos de Riloff et al. (1993), empregam heurísticas para geração de padrões baseadas em informação gramatical, e de Soderland et al. (1995), que se baseia numa semântica de quadros (frames) empregando um analisador semântico e medidas de qualidade de identificação de exemplos, baseado no percentual de acerto sobre relacionamentos previamente conhecidos, para identificação de quadros relevantes.\n",
            "\n",
            "As abordagens baseadas em aprendizado de máquina, hoje as mais comuns e com melhor desempenho na literatura (Konstantinova, 2014; Nasar; Jaffry; Malik, 2021) dividem-se em abordagens que realizam reconhecimento de entidades e extração de relações de forma conjunta e separada.\n",
            "\n",
            "Abordagens baseadas na realização de REN e ER de forma separada baseiam-se em um fluxo de processamento em que, em geral, as entidades são identificadas primeiro e a tarefa de ER se reduz a identificar quando uma sentença ou fragmento textual denota uma relação semântica entre duas entidades. Consideremos o Exemplo 17.2, retirado de (Socher et al., 2012):\n",
            "\n",
            "Exemplo 17.2  \n",
            "\n",
            "Gripe aviária]\\(_{e1}\\) é uma doença infecciosa causada pelo vírus da [influenza tipo a]\\(_{e2}\\)\n",
            "\n",
            "Podemos, então, reduzir o problema de identificar a relação Causa-Efeito(\\(e1\\),\\(e2\\)) a um problema de classificação textual, identificando se a sentença acima fornece indícios para a expressão da relação de interesse. As soluções propostas na literatura para o problema são variadas e baseadas em diferentes métodos.\n",
            "\n",
            "Zelenko; Aone; Richardella (2003), por exemplo, propõem funções de kernel para árvores sintáticas rasas, i.e. funções que descrevem medidas de similaridade entre tais árvores. Eles empregam tais medidas para treinar um classificador de perceptron com votação (voted perceptron) sobre relações no domínio de organizações extraídas de um corpus de textos jornalísticos. De forma similar, Zhao; Grishman (2005) empregam diferentes funções de kernel sobre informações sintáticas relevantes para a identificação de relação e argumentos visando treinar um classificador SVM sobre o corpus de ER da conferência ACE.\n",
            "\n",
            "Culotta; McCallum; Betz (2006), por outro lado, empregam um classificador sequencial baseado em modelos escondidos de Markov para identificação de relações em um texto. Ao restringir sua análise a textos biográficos, os autores reduzem o processo de identificar instâncias de relações à identificação de fragmento textual que delimita o argumento e sua classificação, tarefa para a qual a classificação sequencial já é comumente utilizada. Consideremos o Exemplo 17.3 sobre George W. Bush, retirado de (Culotta; McCallum; Betz, 2006):\n",
            "\n",
            "Exemplo 17.3  \n",
            "\n",
            "George é filho de \\(\\underbrace{\\mbox{George H. W. Bush}}_{\\mbox{pai}}\\) e \\(\\underbrace{\\mbox{Barbara Bush}}_{\\mbox{mãe}}\\).\n",
            "\n",
            "Ao identificar o papel de pai e mãe, os autores conseguem construir a relação Pai(George H. W. Bush, George W. Bush) e Mãe(Barbara Bush, George W. Bush).\n",
            "\n",
            "parte do cap 9\n",
            "\n",
            "A comunidade de PLN foi rapidamente atraída por tais representações de conhecimento de mundo, pois pareciam prover a solução para problemas de semântica de linguagem natural. As mais antigas abordagens em PLN que utilizaram redes semânticas e frames remontam aos trabalhos de Bates et al. (1982) e Bobrow et al. (1977), conforme citado em (Ovchinnikova, 2012).\n",
            "\n",
            "Neste capítulo, examinaremos dois tipos de bases de conhecimento: (1) recursos léxico-semânticos e (2) bases de conhecimento de senso comum.\n",
            "\n",
            "Antes de iniciar a descrição das bases de conhecimento, introduziremos um exemplo de texto, Exemplo 9.18, em português brasileiro, para ser analisado conforme os insumos de cada base de conhecimento. Após o exemplo, indicamos algumas conclusões e respostas resultantes de inferências que pessoas, inseridas na cultura brasileira e proficientes no português, fariam ao ler o texto.\n",
            "\n",
            "Exemplo 9.1  \n",
            "\n",
            "Um assalto do tipo saidinha bancária, ocorrido na tarde desta terça-feira, terminou com uma mulher de 42 anos baleada pelos assaltantes. O roubo ocorreu na rua Professor Costa Mendes.\n",
            "\n",
            "Conclusões:\n",
            "\n",
            "Nas próximas subseções, são descritas algumas das bases de conhecimento mais representativas para o PLN – Wordnet, FrameNet e a ConceptNet, e suas bases congêneres para o português. No final de cada subseção, discorremos sobre como essas bases contribuem para análise semântica do Exemplo 9.1. A escolha dessas três bases seguiu critérios de abrangência de suas entradas e representatividade para tarefas de PLN. A WordNet de Princeton é, consensualmente, o recurso léxico-semântico mais utilizado em PLN para dar suporte a tarefas como desambiguação de sentido de palavras, perguntas e respostas, e análise semântica. FrameNet é uma das bases mais relevantes para a tarefa de anotação de papéis semânticos (Semantic Role Labeling – SRL), pois atribui papéis semânticos não somente a verbos, mas também a termos das demais classes gramaticais. ConceptNet é a base de conhecimento de senso comum com mais entradas tanto para o inglês quanto para o português.\n",
            "\n",
            "WordNet, desenvolvida por George A. Miller, Christiane Fellbaum e colaboradores, é considerada uma base de conhecimento léxico-semântica que organiza os itens lexicais (palavras ou expressões) em synsets (que vem de synonym sets, ou conjuntos de palavras sinônimas). A primeira wordnet foi desenvolvida para o inglês por George Miller, na Universidade de Princeton, um projeto que se iniciou em 1985, e é ordinariamente chamada de WordNet de Princeton (ou Princeton WordNet, na sigla PWN)9 e é descrita por Fellbaum (1998).\n",
            "\n",
            "Wordnets são redes de palavras amplamente utilizadas em PLN para dar suporte a tarefas como desambiguação de sentido de palavras, perguntas e respostas, e análise semântica em geral. A unidade básica da WordNet são os synsets que representam conjuntos de palavras sinônimas. Cada synset expressa um conceito em particular. Os synsets têm uma glosa, semelhante a uma definição num dicionário e podem conter ainda frases que ilustram o emprego de alguma das suas palavras. A WordNet está dividida em quatro redes semânticas, uma para cada classe aberta de palavras: substantivo, verbo, adjetivo e advérbio.\n",
            "\n",
            "Como exemplo, a Figura 9.2 apresenta os synsets da palavra “murder” (verbo “assassinar”, em português) da PWN. Ao todo são três synsets, um na classe Noun (substantivo) e dois na classe Verb (verbo). O primeiro synset da palavra “murder” (na classe Verb) tem como tropônimos diretos os verbos “burke”, “execute” e hiperônimo direto o synset “kill”.\n",
            "\n",
            "A PWN é a base léxico-semântica mais utilizada em PLN, com interfaces locais (APIs) em alguns dos maiores sistemas de programação (.NET/C#, dBase, Java, MySQL, OCaml, OSX, Perl, PHP, Prolog, Python, REST, SQL, Windows, XML)10, mais de 20 mil citações no Google Scholar e dezenas de projetos que a utilizam. Apesar de ser tão utilizada, a WordNet de Princeton parou de evoluir em 2012, por falta de recursos financeiros. A última edição oficial de PWN foi a versão 3.1, lançada em 2011. Em 2019 um consórcio de pesquisadores, incluindo Christiane Fellbaum (a coordenadora da PWN), resolveu transformar a PWN em um recurso moderno, hospedado em GitHub, de tal forma que possa ser sempre atualizado (McCrae et al., 2019), mas a maior parte das aplicações continua usando PWN 3.0 ou 3.1.\n",
            "\n",
            "Como todas as bases com conhecimento semântico, WordNet não é um projeto acabado e tampouco completo. Algumas lacunas decorrem da divisão e independência entre as redes semânticas, o que dificulta a expressão de relações estruturais (entidade-atributo), de relações semânticas que acontecem entre classes de palavras (verbos e substantivos, por exemplo) em uma particular situação ou contexto; ou informações sintagmáticas: relações que ocorrem entre os termos de um proferimento (entre verbo e substantivo, entre substantivo e adjetivo etc.). No que se refere aos tipos de relações expressas na PWN, essa dispõe de relações causais entre synsets, por exemplo, “snore” implies “sleep”, mas não numa taxa de cobertura suficiente em relação ao conjunto dos synsets. Outra limitação é que recursos como a PWN são mais adequados para substantivos concretos do que para conceitos abstratos como “medo”, “felicidade” etc. Enquanto substantivos concretos como “gato”, “felino”, “mamífero”, “animal” etc. são mais facilmente organizados em taxonomias, tal processo é menos consensual quando aplicado às emoções ou a verbos. Um quarto criticismo diz respeito às expressões multipalavras (MWEs – Capítulo 5). Essas existem em PWN, mas não na quantidade suficiente para a modelagem adequada da língua. De acordo com Sag et al. (2002, p. 2), o número de MWEs em PWN precisaria ser maior do que é. Um quinto criticismo diz respeito ao nível de granularidade das distinções de significado na PWN. Essas distinções são muito refinadas, o que faz com que as medidas de concordância entre anotadores sejam baixas.\n",
            "\n",
            "parte do cap 17\n",
            "\n",
            "Métodos baseados em redes neurais, de forma geral, costumam empregar técnicas de aprendizado de representação (Bengio; Courville; Vincent, 2013) para aprender representações do conteúdo semântico dos fragmentos textuais e reduzem o problema de ER à classificação textual. É o caso de Socher et al. (2012), que propõem a MV-RNN, uma rede neural que constrói um espaço de representação baseado em matrizes e vetores com o objetivo de capturar a composicionalidade de sentido de sintagmas e sentenças e os aplica para ER. Similarmente, Zeng et al. (2014) e Wang et al. (2016) empregam redes neurais convolucionais para obter representações vetoriais de sentenças que serão empregadas no processo de classificação quanto à relação expressa pela mesma.\n",
            "\n",
            "Abordagens baseadas em identificação sequencial de entidades e relações possuem desvantagens observadas na literatura. Primeiramente, como a ER é guiada pelas entidades identificadas no processo de REN, a propagação de erros da primeira tarefa pode ter impacto considerável na performance dos sistemas desenvolvidos. Segundo, uma vez que o contexto determinado limita tanto as tarefas de REN, quanto as de ER, existe uma interdependência entre as tarefas. Assim, propostas visando realizar a extração de entidades e relações de forma conjunta começaram a surgir na literatura recente, ganhando certo interesse da comunidade.\n",
            "\n",
            "As abordagens empregadas para tal tarefa são diversificadas, incluindo desde métodos de aprendizado relacional a redes neurais\n",
            "\n",
            "Roth; Yih (2007) propõem a utilização de métodos de programação inteira ao problema, baseados na teoria estatística de aprendizado relacional. Os autores utilizam classificadores locais para a identificação de entidades e relações e um classificador global que combina as informações dos classificadores locais em uma predição que maximiza a qualidade da extração, codificada por meio de restrições em programação inteira. Também baseados em modelos estatísticos, Yu; Lam (2010) propõem o uso de modelos gráficos globais para identificação de um descritor de relação e uma segmentação do texto para identificação dos argumentos.\n",
            "\n",
            "Li; Ji (2014) e Miwa; Bansal (2016), por sua vez, reduzem a tarefa de ERE à classificação sequencial, utilizando redes neurais recorrentes bidirecionais sequenciais e estruturadas com base na estrutura superficial e na árvore de dependências sintáticas da entrada para identificação conjunta de entidades e relações.\n",
            "\n",
            "A Extração de Informação Aberta (EIA), também conhecida como Open Information Extraction, Open IE ou OIE em inglês, é a tarefa de extrair informações estruturadas de documentos sem necessitar da pré-definição do contexto da tarefa, i.e. das relações e tipos de entidade de interesse. A tarefa foi inicialmente proposta pelo trabalho de (Banko et al., 2007) e ganhou popularidade nas últimas décadas devido à sua aplicabilidade para processar e estruturar o conhecimento a partir de grandes volumes de dados disponíveis na Web, seguindo o paradigma da Web como um Corpus (WaC) (Meyer et al., 2003).\n",
            "\n",
            "A EIA surge visando generalizar a tarefa de Extração de Relações. A principal diferença entre as duas abordagens, porém, reside na dependência da ER de uma especificação prévia do domínio de aplicação, bem como das relações alvo a serem identificadas, que a EIA visa eliminar.\n",
            "\n",
            "Seguindo o trabalho original de Banko et al. (2007), que propôs o sistema TextRunner, vários métodos e sistemas para EIA foram propostos na literatura (Del Corro; Gemulla, 2013; Fader; Soderland; Etzioni, 2011; Xavier; Lima; Souza, 2015), mas, como observado por Glauber; Claro (2018), os principais avanços na área se concentraram principalmente no idioma inglês.\n",
            "\n",
            "A EIA para a língua portuguesa tem uma história bastante recente. A partir dos trabalhos de Souza; Claro (2014), Pereira; Pinheiro (2015) e de (Barbosa; Glauber; Claro, 2016), têm crescido o número de estudos sobre a tarefa assim como os resultados obtidos por esses estudos, com recentes desenvolvimentos de métodos (Oliveira; Claro; Souza, 2022; Sena; Claro, 2019, 2020; Sena; Glauber; Claro, 2017; Souza; Claro; Glauber, 2018), construção do corpus (Glauber et al., 2018) e avaliação dos sistemas disponíveis (Glauber; Claro; Oliveira, 2019; Glauber; Claro; Sena, 2019; Malenchini et al., 2019).\n",
            "\n",
            "Embora a área tenha visto um crescimento recente para o desenvolvimento de métodos para línguas como o inglês, principalmente com a aplicação de métodos supervisionados e redes neurais, esses avanços ainda não foram incorporados na literatura sobre EIA para a língua portuguesa. A razão para isso é principalmente a falta de recursos linguísticos disponíveis para orientar o desenvolvimento de pesquisas para a língua. Embora o foco no idioma inglês possa ser devido ao seu uso generalizado em todo o mundo, foi reconhecido pela comunidade científica que esse foco no inglês com suas características particulares pode introduzir algum viés na área (Bender, 2009).\n",
            "\n",
            "Assim, esta seção aborda EIA para a língua portuguesa, incluindo uma formalização e a evolução das abordagens da área.\n",
            "\n",
            "A tarefa de EIA pode ser formalmente definida sendo \\(X = \\langle x_{1}, x_{2}, \\cdots, x_{n}\\rangle\\) uma sentença composta de tokens \\(x_i\\). Um extrator EIA é uma função que mapeia \\(X\\) em um conjunto \\(Y = \\langle y_{1}, y_{2}, \\cdots, y_{j} \\rangle\\) como um conjunto de tuplas \\(y \\_i = \\langle rel_i, arg1_i, arg2_i, \\cdots, argn_i\\rangle\\), que descrevem as informações expressas na sentença X. Neste capítulo, consideramos que as tuplas estão sempre no formato \\(y = (arg_{1 }, rel, arg_{2})\\), onde \\(arg1\\) e \\(arg2\\) são sintagmas nominais, não necessariamente formados por tokens presentes em X, e \\(rel\\) é um descritor de um relacionamento entre \\(arg_{1}\\) e \\(arg_{2}\\). Não consideraremos extrações formadas por mais de dois argumentos neste capítulo.\n",
            "\n",
            "Os primeiros métodos de EIA empregavam padrões de inspiração linguística para extração, como ArgOE (Gamallo; Garcia, 2015), ou adaptação de métodos para a língua inglesa, como SGS (Souza; Claro; Glauber, 2018), InferReVerbPT Sena; Glauber; Claro (2017) e RePort Pereira; Pinheiro (2015). Os trabalhos são principalmente influenciados por métodos baseados no inglês da chamada segunda geração de EIA (Fader; Soderland; Etzioni, 2011).\n",
            "\n",
            "O primeiro sistema de EIA para o português de que temos conhecimento foi o DepOE (Gamallo; Garcia; Fernández-Lanza, 2012). Ele executa a extração aberta multilíngue de triplas (inglês, espanhol, português e galego) usando o analisador sintático de dependências baseado em regras DepPattern. No entanto, nenhuma avaliação ou resultados são relatados para a língua portuguesa. Os autores apresentam somente uma comparação dos seus resultados com Reverb na língua inglesa.\n",
            "\n",
            "Souza; Claro (2014) se propuseram a analisar o conjunto de características mais representativas da língua portuguesa para a identificação de extrações válidas no contexto de EIA, tal qual empregado na língua inglesa com o sistema ReVerb (Fader; Soderland; Etzioni, 2011).\n",
            "\n",
            "parte do cap 9\n",
            "\n",
            "A comunidade de PLN foi rapidamente atraída por tais representações de conhecimento de mundo, pois pareciam prover a solução para problemas de semântica de linguagem natural. As mais antigas abordagens em PLN que utilizaram redes semânticas e frames remontam aos trabalhos de Bates et al. (1982) e Bobrow et al. (1977), conforme citado em (Ovchinnikova, 2012).\n",
            "\n",
            "Neste capítulo, examinaremos dois tipos de bases de conhecimento: (1) recursos léxico-semânticos e (2) bases de conhecimento de senso comum.\n",
            "\n",
            "Antes de iniciar a descrição das bases de conhecimento, introduziremos um exemplo de texto, Exemplo 9.18, em português brasileiro, para ser analisado conforme os insumos de cada base de conhecimento. Após o exemplo, indicamos algumas conclusões e respostas resultantes de inferências que pessoas, inseridas na cultura brasileira e proficientes no português, fariam ao ler o texto.\n",
            "\n",
            "Exemplo 9.1  \n",
            "\n",
            "Um assalto do tipo saidinha bancária, ocorrido na tarde desta terça-feira, terminou com uma mulher de 42 anos baleada pelos assaltantes. O roubo ocorreu na rua Professor Costa Mendes.\n",
            "\n",
            "Conclusões:\n",
            "\n",
            "Nas próximas subseções, são descritas algumas das bases de conhecimento mais representativas para o PLN – Wordnet, FrameNet e a ConceptNet, e suas bases congêneres para o português. No final de cada subseção, discorremos sobre como essas bases contribuem para análise semântica do Exemplo 9.1. A escolha dessas três bases seguiu critérios de abrangência de suas entradas e representatividade para tarefas de PLN. A WordNet de Princeton é, consensualmente, o recurso léxico-semântico mais utilizado em PLN para dar suporte a tarefas como desambiguação de sentido de palavras, perguntas e respostas, e análise semântica. FrameNet é uma das bases mais relevantes para a tarefa de anotação de papéis semânticos (Semantic Role Labeling – SRL), pois atribui papéis semânticos não somente a verbos, mas também a termos das demais classes gramaticais. ConceptNet é a base de conhecimento de senso comum com mais entradas tanto para o inglês quanto para o português.\n",
            "\n",
            "WordNet, desenvolvida por George A. Miller, Christiane Fellbaum e colaboradores, é considerada uma base de conhecimento léxico-semântica que organiza os itens lexicais (palavras ou expressões) em synsets (que vem de synonym sets, ou conjuntos de palavras sinônimas). A primeira wordnet foi desenvolvida para o inglês por George Miller, na Universidade de Princeton, um projeto que se iniciou em 1985, e é ordinariamente chamada de WordNet de Princeton (ou Princeton WordNet, na sigla PWN)9 e é descrita por Fellbaum (1998).\n",
            "\n",
            "Wordnets são redes de palavras amplamente utilizadas em PLN para dar suporte a tarefas como desambiguação de sentido de palavras, perguntas e respostas, e análise semântica em geral. A unidade básica da WordNet são os synsets que representam conjuntos de palavras sinônimas. Cada synset expressa um conceito em particular. Os synsets têm uma glosa, semelhante a uma definição num dicionário e podem conter ainda frases que ilustram o emprego de alguma das suas palavras. A WordNet está dividida em quatro redes semânticas, uma para cada classe aberta de palavras: substantivo, verbo, adjetivo e advérbio.\n",
            "\n",
            "Como exemplo, a Figura 9.2 apresenta os synsets da palavra “murder” (verbo “assassinar”, em português) da PWN. Ao todo são três synsets, um na classe Noun (substantivo) e dois na classe Verb (verbo). O primeiro synset da palavra “murder” (na classe Verb) tem como tropônimos diretos os verbos “burke”, “execute” e hiperônimo direto o synset “kill”.\n",
            "\n",
            "A PWN é a base léxico-semântica mais utilizada em PLN, com interfaces locais (APIs) em alguns dos maiores sistemas de programação (.NET/C#, dBase, Java, MySQL, OCaml, OSX, Perl, PHP, Prolog, Python, REST, SQL, Windows, XML)10, mais de 20 mil citações no Google Scholar e dezenas de projetos que a utilizam. Apesar de ser tão utilizada, a WordNet de Princeton parou de evoluir em 2012, por falta de recursos financeiros. A última edição oficial de PWN foi a versão 3.1, lançada em 2011. Em 2019 um consórcio de pesquisadores, incluindo Christiane Fellbaum (a coordenadora da PWN), resolveu transformar a PWN em um recurso moderno, hospedado em GitHub, de tal forma que possa ser sempre atualizado (McCrae et al., 2019), mas a maior parte das aplicações continua usando PWN 3.0 ou 3.1.\n",
            "\n",
            "Como todas as bases com conhecimento semântico, WordNet não é um projeto acabado e tampouco completo. Algumas lacunas decorrem da divisão e independência entre as redes semânticas, o que dificulta a expressão de relações estruturais (entidade-atributo), de relações semânticas que acontecem entre classes de palavras (verbos e substantivos, por exemplo) em uma particular situação ou contexto; ou informações sintagmáticas: relações que ocorrem entre os termos de um proferimento (entre verbo e substantivo, entre substantivo e adjetivo etc.). No que se refere aos tipos de relações expressas na PWN, essa dispõe de relações causais entre synsets, por exemplo, “snore” implies “sleep”, mas não numa taxa de cobertura suficiente em relação ao conjunto dos synsets. Outra limitação é que recursos como a PWN são mais adequados para substantivos concretos do que para conceitos abstratos como “medo”, “felicidade” etc. Enquanto substantivos concretos como “gato”, “felino”, “mamífero”, “animal” etc. são mais facilmente organizados em taxonomias, tal processo é menos consensual quando aplicado às emoções ou a verbos. Um quarto criticismo diz respeito às expressões multipalavras (MWEs – Capítulo 5). Essas existem em PWN, mas não na quantidade suficiente para a modelagem adequada da língua. De acordo com Sag et al. (2002, p. 2), o número de MWEs em PWN precisaria ser maior do que é. Um quinto criticismo diz respeito ao nível de granularidade das distinções de significado na PWN. Essas distinções são muito refinadas, o que faz com que as medidas de concordância entre anotadores sejam baixas.\n",
            "\n",
            "parte do cap 17\n",
            "\n",
            "O sistema RePort (Pereira; Pinheiro, 2015), por outro lado, é uma adaptação do ReVerb para a língua portuguesa baseada em análise sintática rasa com regras sintáticas e lexicais. Os autores relatam que suas extrações apresentam grande similaridade com suas correlatas extraídas pelo ReVerb (dos textos traduzidos para o inglês).\n",
            "\n",
            "O RELP, proposto por Abreu; Vieira (2017), é um sistema aberto de extração de relações que extrai relações entre entidades nomeadas em um domínio de organização aplicando classificação sequencial com CRF (Conditional Random Fields). O sistema RelP extrai qualquer descritor de relação que expressa um relacionamento entre pares de entidades nomeadas (Organização, Pessoa ou Lugar), caracterizando-o como uma abordagem híbrida da REN com a EIA.\n",
            "\n",
            "O InferReVerbPT desenvolvido por Sena; Glauber; Claro (2017) baseia-se numa adaptação do sistema ReVerb para a língua portuguesa, expandindo-o com a extração de relacionamentos implícitos obtidos por inferência por propriedades de simetria e transitividade das relações com inferência transitiva e simétrica. Um classificador SVM foi empregado para realizar a inferência baseado nas propriedades semânticas do verbo central no descritor de relação.\n",
            "\n",
            "Souza; Claro; Glauber (2018) analisaram que a maior desvantagem dos estudos baseados em recursos linguísticos, como dados anotados, reside na escassez de tais recursos na maioria dos idiomas além do inglês. Assim, para mitigar esse problema, eles propõem um método de classificação de fatos baseado na similaridade de estruturas gramaticais (SGS). Sua abordagem modela estruturas morfosintáticas dos fatos (triplas descrevendo relacionamentos) para identificar padrões de semelhanças que podem ser usados para distinguir entre fatos válidos e inválidos. Eles aplicaram algoritmos de isomorfismo de grafos para detectar subgrafos descrevendo tais padrões.\n",
            "\n",
            "Um novo sistema de EIA baseado em análise de dependência foi proposto por Gamallo; Garcia (2015), chamado ArgOE. Tal sistema é multilíngue, baseado em heurísticas e utiliza a informação de dependência sintáticas do texto para analisar a estrutura de dependência do verbo, bem como um conjunto de regras para gerar os relacionamentos. A introdução de um Analisador de Dependência em sistemas de EIA focados inteiramente na língua portuguesa foi feita pelos autores Oliveira; Claro; Souza (2022). O DptOIE é baseado em análise de dependência e regras elaboradas manualmente. As sentenças são pré-processadas por meio de um tokenizador, um PoS Tagger e um analisador de dependências. Os autores propõem um acoplamento de três módulos para tratar casos particulares: conjunções coordenadas, orações subordinadas e aposto.\n",
            "\n",
            "Com a evolução dos métodos de EIA para a língua inglesa utilizando os modelos neurais, novas abordagens foram propostas também para a língua portuguesa.\n",
            "\n",
            "O primeiro trabalho que utilizou aprendizado supervisionado com rede neural profunda para o português foi o de Ro; Lee; Kang (2020) que descreve o sistema Multi2OIE. Os autores utilizaram o modelo de linguagem BERT multilíngue (Devlin et al., 2019) para obter representações vetoriais das palavras e reduzem a tarefa de EIA à classificação sequencial, identificado os fragmentos do texto que determinam os argumentos (\\(arg_1, arg_2\\)) e o descritor de relação (\\(rel\\)). Seu sistema foi capaz de produzir extrações para vários idiomas (inglês, português e espanhol), treinados, entretanto, sobre dados traduzidos do inglês.\n",
            "\n",
            "Stanovsky et al. (2018) propuseram uma abordagem de EIA para a língua inglesa baseada em triplas. Os mesmos fazem uso de uma classificação sequencial cuja limitação define uma tripla extraída para cada sentença. Este método utiliza uma arquitetura de Redes Neurais Recursivas (RNN) para realizar EIA. A EIA é formulada como uma tarefa de rotulagem de sequências, utilizando estratégias semelhantes às que foram aplicadas anteriormente a tarefas como o Reconhecimento de Entidades Nomeadas. Já os autores em Cui; Wei; Zhou (2018) e Zhang; Duh; Van Durme (2017) propõem modelar o problema da EIA como um problema de aprendizado sequência a sequência (seq2seq). Eles definem uma estrutura encoder-decoder para aprender argumentos e tuplas de relação inicializadas a partir de um sistema de EIA.\n",
            "\n",
            "Seguindo o trabalho de (Stanovsky et al., 2018), em 2022, Cabral; Souza; Claro (2022) propuseram PortNOIE, uma arquitetura neural para EIA em português que combina representações contextuais de palavras com codificadores neurais para extrair relacionamentos baseado em classificação sequencial iterativa. Diferente de outros métodos de classificação sequencial para EIA, os autores focam na extração de múltiplas triplas de uma mesma sentença.\n",
            "\n",
            "A avaliação sistemática de sistemas de EI foi estabelecida primeiramente nas conferências MUC, em particular na sua segunda edição, com o estabelecimento de gabaritos-padrão que deveriam ser utilizados por todos os sistemas participantes e a adoção de métricas de qualidade, baseadas naquelas usadas na área de recuperação de informação, que foram abordadas no Capítulo 16. Para avaliar a tarefa de extração de relações, a MUC-2 estabeleceu como métricas de qualidade do sistema as medidas de precisão e cobertura, também denominada de Recall ou Revocação.\n",
            "\n",
            "A precisão de um sistema reflete a qualidade de suas extrações, i.e., quantas das extrações realizadas estão corretas, dado um corpus de teste. A medida de precisão pode ser calculada como:\n",
            "\n",
            "P = \\frac{\\#(\\mbox{relacionamentos corretamente extraídos})}{\\#(\\mbox{relacionamentos extraídos pelo sistema})}\n",
            "\n",
            "A cobertura também conhecida como revocação, reflete quão abrangente um sistema é em suas extrações, i.e., quantas das extrações a serem realizadas em um corpus de teste, o sistema é capaz de realizar. A medida de cobertura pode ser calculada como:\n",
            "\n",
            "R = \\frac{\\#(\\mbox{relacionamentos extraídos})}{\\#(\\mbox{relacionamentos no \\textit{corpus}})}\n",
            "\n",
            "Enquanto a MUC-3 adicionou duas novas métricas de avaliação, a saber sobre-geração (overgeneration) e sub-geração (fallout), tais métricas receberam pouco interesse na literatura. De fato, Lehnert; Sundheim (1991) argumentam que tais métricas foram pouco informativas ou difíceis de calcular para a tarefa de EI e, portanto, abandonadas. Foi também empregado nessa conferência um sistema automático de avaliação disponibilizado às equipes participantes que permitiu uma maior compreensão do modelo de avaliação e, como discutem Lehnert; Sundheim (1991), um avanço qualitativo nos sistemas gerados.\n",
            "\n",
            "parte do cap 9\n",
            "\n",
            "A comunidade de PLN foi rapidamente atraída por tais representações de conhecimento de mundo, pois pareciam prover a solução para problemas de semântica de linguagem natural. As mais antigas abordagens em PLN que utilizaram redes semânticas e frames remontam aos trabalhos de Bates et al. (1982) e Bobrow et al. (1977), conforme citado em (Ovchinnikova, 2012).\n",
            "\n",
            "Neste capítulo, examinaremos dois tipos de bases de conhecimento: (1) recursos léxico-semânticos e (2) bases de conhecimento de senso comum.\n",
            "\n",
            "Antes de iniciar a descrição das bases de conhecimento, introduziremos um exemplo de texto, Exemplo 9.18, em português brasileiro, para ser analisado conforme os insumos de cada base de conhecimento. Após o exemplo, indicamos algumas conclusões e respostas resultantes de inferências que pessoas, inseridas na cultura brasileira e proficientes no português, fariam ao ler o texto.\n",
            "\n",
            "Exemplo 9.1  \n",
            "\n",
            "Um assalto do tipo saidinha bancária, ocorrido na tarde desta terça-feira, terminou com uma mulher de 42 anos baleada pelos assaltantes. O roubo ocorreu na rua Professor Costa Mendes.\n",
            "\n",
            "Conclusões:\n",
            "\n",
            "Nas próximas subseções, são descritas algumas das bases de conhecimento mais representativas para o PLN – Wordnet, FrameNet e a ConceptNet, e suas bases congêneres para o português. No final de cada subseção, discorremos sobre como essas bases contribuem para análise semântica do Exemplo 9.1. A escolha dessas três bases seguiu critérios de abrangência de suas entradas e representatividade para tarefas de PLN. A WordNet de Princeton é, consensualmente, o recurso léxico-semântico mais utilizado em PLN para dar suporte a tarefas como desambiguação de sentido de palavras, perguntas e respostas, e análise semântica. FrameNet é uma das bases mais relevantes para a tarefa de anotação de papéis semânticos (Semantic Role Labeling – SRL), pois atribui papéis semânticos não somente a verbos, mas também a termos das demais classes gramaticais. ConceptNet é a base de conhecimento de senso comum com mais entradas tanto para o inglês quanto para o português.\n",
            "\n",
            "WordNet, desenvolvida por George A. Miller, Christiane Fellbaum e colaboradores, é considerada uma base de conhecimento léxico-semântica que organiza os itens lexicais (palavras ou expressões) em synsets (que vem de synonym sets, ou conjuntos de palavras sinônimas). A primeira wordnet foi desenvolvida para o inglês por George Miller, na Universidade de Princeton, um projeto que se iniciou em 1985, e é ordinariamente chamada de WordNet de Princeton (ou Princeton WordNet, na sigla PWN)9 e é descrita por Fellbaum (1998).\n",
            "\n",
            "Wordnets são redes de palavras amplamente utilizadas em PLN para dar suporte a tarefas como desambiguação de sentido de palavras, perguntas e respostas, e análise semântica em geral. A unidade básica da WordNet são os synsets que representam conjuntos de palavras sinônimas. Cada synset expressa um conceito em particular. Os synsets têm uma glosa, semelhante a uma definição num dicionário e podem conter ainda frases que ilustram o emprego de alguma das suas palavras. A WordNet está dividida em quatro redes semânticas, uma para cada classe aberta de palavras: substantivo, verbo, adjetivo e advérbio.\n",
            "\n",
            "Como exemplo, a Figura 9.2 apresenta os synsets da palavra “murder” (verbo “assassinar”, em português) da PWN. Ao todo são três synsets, um na classe Noun (substantivo) e dois na classe Verb (verbo). O primeiro synset da palavra “murder” (na classe Verb) tem como tropônimos diretos os verbos “burke”, “execute” e hiperônimo direto o synset “kill”.\n",
            "\n",
            "A PWN é a base léxico-semântica mais utilizada em PLN, com interfaces locais (APIs) em alguns dos maiores sistemas de programação (.NET/C#, dBase, Java, MySQL, OCaml, OSX, Perl, PHP, Prolog, Python, REST, SQL, Windows, XML)10, mais de 20 mil citações no Google Scholar e dezenas de projetos que a utilizam. Apesar de ser tão utilizada, a WordNet de Princeton parou de evoluir em 2012, por falta de recursos financeiros. A última edição oficial de PWN foi a versão 3.1, lançada em 2011. Em 2019 um consórcio de pesquisadores, incluindo Christiane Fellbaum (a coordenadora da PWN), resolveu transformar a PWN em um recurso moderno, hospedado em GitHub, de tal forma que possa ser sempre atualizado (McCrae et al., 2019), mas a maior parte das aplicações continua usando PWN 3.0 ou 3.1.\n",
            "\n",
            "Como todas as bases com conhecimento semântico, WordNet não é um projeto acabado e tampouco completo. Algumas lacunas decorrem da divisão e independência entre as redes semânticas, o que dificulta a expressão de relações estruturais (entidade-atributo), de relações semânticas que acontecem entre classes de palavras (verbos e substantivos, por exemplo) em uma particular situação ou contexto; ou informações sintagmáticas: relações que ocorrem entre os termos de um proferimento (entre verbo e substantivo, entre substantivo e adjetivo etc.). No que se refere aos tipos de relações expressas na PWN, essa dispõe de relações causais entre synsets, por exemplo, “snore” implies “sleep”, mas não numa taxa de cobertura suficiente em relação ao conjunto dos synsets. Outra limitação é que recursos como a PWN são mais adequados para substantivos concretos do que para conceitos abstratos como “medo”, “felicidade” etc. Enquanto substantivos concretos como “gato”, “felino”, “mamífero”, “animal” etc. são mais facilmente organizados em taxonomias, tal processo é menos consensual quando aplicado às emoções ou a verbos. Um quarto criticismo diz respeito às expressões multipalavras (MWEs – Capítulo 5). Essas existem em PWN, mas não na quantidade suficiente para a modelagem adequada da língua. De acordo com Sag et al. (2002, p. 2), o número de MWEs em PWN precisaria ser maior do que é. Um quinto criticismo diz respeito ao nível de granularidade das distinções de significado na PWN. Essas distinções são muito refinadas, o que faz com que as medidas de concordância entre anotadores sejam baixas.\n",
            "\n",
            "parte do cap 17\n",
            "\n",
            "Além das medidas de precisão e cobertura, assim como em tarefas de classificação de texto e recuperação de informação, utilizamos a média harmônica entre essas medidas, chamada medida F1, a fim de condensar a informação contida nas duas. A medida F1 pode ser calculada como:\n",
            "\n",
            "F1 = \\frac{2*P*R}{P+R}\n",
            "\n",
            "A avaliação da tarefa de REN segue padrões semelhantes aos aplicados à tarefa de ER. De fato, desde a MUC-6 (Grishman; Sundheim, 1996), as medidas de precisão, cobertura e F1 tem sido usada consistentemente como métricas de avaliação da tarefa de REN em diversos esforços de avaliação, como a CoNNL (Sang; De Meulder, 2003), para a língua inglesa, e das duas edições do HAREM (Gonçalo Oliveira et al., 2008; Santos; Cardoso; Seco, 2007), com excessão à ACE (Doddington et al., 2004) que apresenta uma combinação da tarefa de REN com reconhecimento de co-referência entre entidades e utiliza um sistema de pontuação próprio.\n",
            "\n",
            "A avaliação de sistemas de EIA, por sua vez, possui algumas peculiaridades que precisam ser discutidas. Uma vez que a tarefa é postulada por Banko et al. (2007) como a extração de todas as relações identificadas em um dado fragmento textual, sem limitação de domínio de interesse, tal tarefa impõe imensa dificuldade aos esforços de avaliação.\n",
            "\n",
            "De fato, Glauber et al. (2018) relatam um esforço de anotação de dados para a tarefa em língua portuguesa em que foram identificados por anotadores humanos mais de 400 relacionamentos em um corpus de 25 sentenças retiradas de textos jornalísticos e de enciclopédia. Assim, a avaliação de EIA deu-se, em grande parte de seu desenvolvimento e maturação, em conjuntos de dados não anotados, recorrendo a avaliações qualitativas das saídas dos sistemas e comparação direta por humanos das extrações obtidas.\n",
            "\n",
            "Nesses esforços de avaliação, a precisão do sistema pode ser mensurada a partir da avaliação humana das saídas. Não é possível, entretanto, avaliar medidas como cobertura e F1, dada a inexistência de uma referência do conjunto total de relacionamentos a serem identificados. Assim, os autores da área propuseram diferentes métricas a fim de estimar tais valores, como a métrica rendimento (yield) (Fader; Soderland; Etzioni, 2011; Schmitz et al., 2012).\n",
            "\n",
            "A métrica de rendimento consiste no núemro de extrações válidas, i.e. corretas, de um dado sistema. Como calcular tal medida é, na maioria dos casos, impraticável dada a grande quantidade de extrações realizadas pelos sistemas, ela pode ser estimada a partir da precisão do sistema calculada sobre uma amostra aleatória das extrações realizadas (\\(P'\\)). Assim, podemos estimar o rendimento como:\n",
            "\n",
            "Y = P'\\cdot \\#(\\mbox{extrações realizadas})\n",
            "\n",
            "Foi também explorada a estratégia de criação (semi-)automática de conjuntos de dados usando vários sistemas (Del Corro; Gemulla, 2013), estratégias de supervisão fraca (Smirnova; Cudré-Mauroux, 2018), ou a geração de corpora para a tarefa a partir da transformação de anotações de tarefas próximas, como identificação de papéis temáticos (Semantic Role Labeling) por (Stanovsky et al., 2018). Corpora gerados de forma semi-automática vêm ganhando atenção na literatura recente, particularmente para a língua inglesa, devido a necessidade de dados anotados para se utilizar técnicas de aprendizado de máquina e redes neurais em EIA. Corpora como o OIE2016 (Stanovsky et al., 2018), Wire57 (Léchelle; Gotti; Langlais, 2018) e CARB (Bhardwaj; Aggarwal; Mausam, 2019) vêm se tornando corpora de referência em língua inglesa para o problema, apesar dos problemas existentes na construção de tais recursos – a não exaustividade das relações anotadas.\n",
            "\n",
            "Para a língua portuguesa, foram propostas algumas iniciativas para avaliar os sistemas da OIE. Uma avaliação conjunta foi promovida durante o Fórum Ibérico de Avaliação de Línguas (IberLEF) em 2019 (Collovini et al., 2019). A avaliação foi feita usando o corpus proposto por Glauber et al. (2018), que é composto por 442 relacionamentos extraídos de 25 frases de fontes como a seção em português da Wikipédia, o corpus CETENFolha, resenhas de filmes do portal Adoro Cinema2 e o corpus Europarl. Apesar desta tarefa ter contemplado quatro cenários de avaliação, a avaliação geral dos sistemas permaneceu consistente nos diferentes cenários, indicando robustez nos resultados da avaliação. No geral, os sistemas DPTOIE (Oliveira; Claro; Souza, 2022) e Linguakit (Gamallo; Garcia, 2015) tiveram o melhor desempenho, com o Linguakit2 dominando as avaliações de correspondência exata e o DPTOIE as avaliações de correspondências parciais (Collovini et al., 2019).\n",
            "\n",
            "Outra abordagem de avaliação foi idealizada por (Malenchini et al., 2019). Seu foco foi a avaliação extrínseca dos sistemas de EIA através de sua contribuição na tarefa de respostas automáticas a perguntas. Os autores apresentaram um conjunto de dados de referência (benchmark) para avaliação extrínseca de sistemas de EIA em textos de língua portuguesa. Os sistemas que alcançaram os melhores valores na avaliação realizada pelos autores foram os sistemas ArgOE (Gamallo; Garcia, 2015), DependentIE (Glauber; Claro; Oliveira, 2019) e DptOIE (Oliveira; Claro; Souza, 2022).\n",
            "\n",
            "Este capítulo descreveu uma visão geral da área de Extração de Informação, apresentando a Extração de Informação Tradicional e a Extração de Informação Aberta. Transversalmente, apresentamos as formalizações necessárias e os conceitos fundamentais para a compreensão da EIA, assim como a avaliação da área e as heranças de outras áreas afins, tais como RI.\n",
            "\n",
            "Nessa primeira versão, este capítulo descreveu de maneira bem sucinta as abordagens propostas para EI e EIA durante seu desenvolvimento histórico e as abordagens atuais da literatura, como as utilizando modelos de linguagens. Especificamente, a utilização da arquitetura Transformers, descritas no Capítulo 15 para as tarefas de EI e EIA tem sido bastante difundida para a língua inglesa e tem atuado em diversas áreas da PLN.\n",
            "\n",
            "Agradecemos as colaborações dos autores deste Capítulo e suas indicações, assim como agradecemos a Adriana Pagano e Aline Macohin pela revisão e comentários.\n",
            "\n",
            "Em nossa terminologia, por um relacionamento.↩︎\n",
            "\n",
            "parte do cap 9\n",
            "\n",
            "A partir da WordNet de Princeton, várias wordnets foram propostas para diversas línguas, entre elas o português, conforme será descrito na seção a seguir.\n",
            "\n",
            "Vários recursos léxico-semânticos foram criados para o português nos últimos anos. Alguns deles são listados na página da Linguateca11. O NILC12 tem uma coleção de recursos listados no portal PortLex13, entre os quais se encontram, entre outros, VerbNet.Br (Scarton; Aluisio, 2012) e PropBank.Br (Duran; Aluísio, 2012).\n",
            "\n",
            "Há várias versões de wordnets para o português, como Wordnet.BR (Dias-da-Silva, 2005), Onto.PT (Gonçalo Oliveira, 2014), PULO (Simões; Guinovart, 2014) e OpenWordNet-PT14 (De Paiva; Rademaker; Melo, 2012). Essas wordnets são discutidas detalhadamente em (De Paiva et al., 2016; Gonçalo Oliveira, 2014), portanto, aqui simplesmente reiteramos a mensagem principal dessas comparações.\n",
            "\n",
            "Apesar de existirem várias alternativas de wordnets para o português, todas são menores e menos desenvolvidas do que a PWN. PWN é um recurso relativamente grande com 16MB, incluindo 155.327 palavras organizadas em 175.979 synsets num total de 207.016 pares de palavra-significado. A OpenWordNet-PT (OWN-PT) (De Paiva; Rademaker; Melo, 2012), alinhada à PWN, conta com 47.702 synsets (somente 27% da PWN), dos quais 32.855 correspondem a substantivos, 5.060 a verbos, 8.753 a adjetivos e 1.034 a advérbios. O número de projetos usando OWN-PT é muito limitado, possivelmente porque, construída de forma semi-automática, usando aprendizado de máquina no conjunto de wikipedias multilinguais (Melo; Weikum, 2009) e manualmente melhorando os dados obtidos.\n",
            "\n",
            "Como exemplo, a Figura 9.3 apresenta os synsets da palavra “assassinar” na OWN-PT. Ao todo são quatro synsets, um na classe Noun (substantivo) e três na classe Verbo. O terceiro synset (02482425-v) refere-se a “matar intencionalmente e com premeditação” (glosa) e possui como hiperônimo direto o synset “matar” (01323958-v).\n",
            "\n",
            "Outras wordnets são ainda menores (PULO (Simões; Guinovart, 2014)), ou menos acuradas, pois, construídas numa abordagem mais dinâmica (ONTO.PT (Gonçalo Oliveira, 2014)), podem mudar completamente de uma versão para a seguinte.\n",
            "\n",
            "Algumas decisões de projeto de uma wordnet, assim como de outras bases de conhecimento, parecem claras e já são consenso na comunidade do PLN. Wordnets devem ser recursos abertos, grátis e fáceis de utilizar. Devem ter versões adequadas a usuários humanos e a agentes computacionais, isto é, devem ter interfaces de busca para usuários e interfaces ou bibliotecas para usos computacionais. Tais recursos linguísticos precisam ser mantidos e melhorados, pois nenhum é perfeito e as linguagens naturais são sistemas vivos, dinâmicos e em constante e contínua evolução.\n",
            "\n",
            "Porém, outras decisões permanecem em aberto: uma alternativa só para o português brasileiro e outra para o português de Portugal? Ou uma alternativa para ambas variantes do português? Alternativas multilinguais tais como Open Multilingual WordNet (OMW)15 (Bond; Foster, 2013) ou somente em português? Somente alternativas alinhadas a PWN ou o alinhamento16 não é necessário? Somente as relações semânticas de PWN ou outras também? As entidades nomeadas devem ser incluídas no recurso ou não? Qual deve ser o registro do recurso? Deve incluir gírias e palavras de baixo-calão ou não?\n",
            "\n",
            "Usaremos a OWN-PT para analisar o exemplo motivador Exemplo 9.1 apresentado no início da Seção 9.1. No Exemplo 9.2, foram sublinhadas algumas palavras que foram associadas a synsets na OWN-PT. Para realizar esta associação, é necessário definir o sentido ou significado da palavra usada no texto. Esta tarefa em PLN denominamos de Desambiguação do Sentido de Palavras (Word Sense Desambiguation – WSD). Após o exemplo, são listadas algumas afirmações (especificamente de hiperomínia) entre o synset da palavra usada no texto e outro synset.\n",
            "\n",
            "Exemplo 9.2  \n",
            "\n",
            "Um assalto do tipo saidinha bancária, ocorrido na tarde desta terça-feira, terminou com uma mulher de 42 anos baleada pelos assaltantes. O roubo ocorreu na rua Professor Costa Mendes.\n",
            "\n",
            "Usando a OWN-PT, definimos os seguintes synsets para as palavras sublinhadas em Exemplo 9.2: “assalto” (00783063-n), “terminar” (02610845-v). Não foi encontrado nenhum synset para o termo “balear”. A seguir, algumas afirmações de hiperonímia entre esses synsets e outros:\n",
            "\n",
            "parte do cap 17\n",
            "\n",
            "Daniela Barreiro Claro \n",
            "\n",
            "Joaquim Santos \n",
            "\n",
            "Marlo Souza \n",
            "\n",
            "Renata Vieira \n",
            "\n",
            "Vládia Pinheiro \n",
            "\n",
            "PDF\n",
            "\n",
            "A Extração de Informação (EI) é desenvolvida com o objetivo de se obter informação estruturada de dados não-estruturados (Jurafsky; Martin, 2023; Konstantinova, 2014).\n",
            "\n",
            "Os primeiros trabalhos a debruçarem-se sobre o problema remontam à década de 1970, com a aplicação de gramáticas formais e parsers sintáticos para a estruturação de informação em domínios como prontuários médicos (Sager, 1978; Sager; Friedman; Lyman, 1987) e textos jornalísticos (DeJong, 1979). A comunidade científica demonstrou grande interesse pela área nas décadas posteriores devido à sua utilidade prática, seu foco no processamento de dados reais, suas tarefas bem-definidas e a facilidade de mensurar a qualidade dos resultados em comparação com o desempenho humano na mesma tarefa (Cowie; Lehnert, 1996).\n",
            "\n",
            "Para autores como Eisenstein (2019) e Jurafsky; Martin (2023), a EI é normalmente dividida em diversas tarefas de interesse, com foco no tipo de informação a ser extraída do texto. Entre as mais comumente citadas na literatura estão o Reconhecimento de Entidades Nomeadas (REN), a Extração de Relações (ER) e a Extração de Eventos (EE).\n",
            "\n",
            "O Reconhecimento de Entidades Nomeadas (REN) consiste em identificar e classificar entidades mencionadas em textos através de designadores rígidos como nomes próprios, expressões temporais e espécies biológicas (Nadeau, 2007). Esse é considerado por alguns como um primeiro passo na análise semântica de um texto (Santos; Cardoso, 2007a), pois permite identificar as entidades às quais se faz referência nele.\n",
            "\n",
            "A Extração de Relações (ER), também chamada de extração de informação tradicional ou somente extração de informação, por sua vez, diz respeito à identificação de relacionamentos semânticos entre duas ou mais entidades, ou seja, identificar “quem fez o que para quem e quando”. Ananiadou; Mcnaught (2005) a definem como o processo de extrair fatos (em nossa terminologia, relacionamentos) a partir de uma fonte textual e representá-los a partir de um gabarito (em inglês, template). As relações são elementos essenciais para o entendimento da informação relatada no texto e sua identificação é passo essencial para a estruturação da mesma. Assim, identificar relações entre entidades é tarefa essencial para construção de bases de conhecimento e de grande utilidade na construção de soluções para a resposta automática a perguntas (em inglês, query answering), sumarização, recuperação de informação e mais (Nasar; Jaffry; Malik, 2021).\n",
            "\n",
            "A extração de eventos consiste na tarefa de identificação de uma menção a um evento em uma sentença e, se existirem, extração de outras informações sobre o evento. Um evento pode, por sua vez, ser entendido como uma ocorrência específica envolvendo participantes (Consortium, 2005), i.e., algo que acontece e que pode ser descrito como uma mudança de estado da qual participam entidades como agentes. Devido a intrínseca natureza temporal dos eventos, tal problema possui uma natureza mais complexa e costuma possuir tratamento específico.\n",
            "\n",
            "Assim, nesse capítulo, iniciaremos com um pouco de história da Extração de Informação (EI) e sua evolução para Extração de Informação Aberta, e destacaremos as tarefas de Reconhecimeno de Entidades Nomeadas (REN) e Extração de Relação (ER).\n",
            "\n",
            "Os primeiros trabalhos que abordaram o problema de EI dos quais temos conhecimento surgiram no final da década de 1970. Esses primeiros trabalhos da década de 1970 e 1980 tinham como modelo geral a aplicação de regras para a identificação de informações especificadas em um gabarito. Tais sistemas empregavam analisadores sintáticos (parsers) e regras definidas especificamente para o domínio e gênero textual estudado.\n",
            "\n",
            "Entre esses primeiros trabalhos, estão aqueles de Sager (1978), Sager; Friedman; Lyman (1987), de DeJong (1979) e de Cowie (1983). Sager et al. exploraram como identificar informações do estado de saúde de pacientes através dos textos de prontuários médicos. DeJong (1979), por sua vez, descrevem o sistema FRUMP que, a partir de um parser e regras de análise conceitual baseadas em uma arquitetura cognitiva proposta pelos autores e no conceito de dependência conceitual de Schank et al. (1973), processavam textos de notícias e realizavam tarefas como sumarização e identificação de papéis semânticos associados aos constituintes da sentença. Cowie (1983), por fim, descreve um sistema que emprega regras simples de segmentação e análise sintática rasa para identificar propriedades de plantas a partir de textos descritivos no campo da botânica. Diferente dos métodos anteriores, o trabalho dos autores se baseia em grande parte no estudo de padrões de descrição das informações a serem identificadas, em detrimento do emprego de parsers robustos da língua.\n",
            "\n",
            "A década de 1990 traz um grande interesse na área de EI com a implementação das conferências MUC (do inglês, Message Understanding Conference, ou Conferência de Compreensão de Mensagem), promovidas pela Agência de Projetos de Pesquisa Avançada de Defesa (DARPA, do inglês Defense Advanced Research Projects Agency). As conferências MUC, realizadas e financiadas pelo exército americano, representaram um esforço em avançar a tecnologia de EI e consistiam de tarefas de avaliação conjunta de métodos desenvolvidos por pesquisadores para problemas propostos pelos organizadores. As sete conferências realizadas de 1987 a 1997, foram cruciais para definir aspectos centrais da área, como estruturar a tarefa de ER, definindo suas métricas de avaliação, e propor a tarefa de REN (Grishman; Sundheim, 1996).\n",
            "\n",
            "parte do cap 9\n",
            "\n",
            "A partir da WordNet de Princeton, várias wordnets foram propostas para diversas línguas, entre elas o português, conforme será descrito na seção a seguir.\n",
            "\n",
            "Vários recursos léxico-semânticos foram criados para o português nos últimos anos. Alguns deles são listados na página da Linguateca11. O NILC12 tem uma coleção de recursos listados no portal PortLex13, entre os quais se encontram, entre outros, VerbNet.Br (Scarton; Aluisio, 2012) e PropBank.Br (Duran; Aluísio, 2012).\n",
            "\n",
            "Há várias versões de wordnets para o português, como Wordnet.BR (Dias-da-Silva, 2005), Onto.PT (Gonçalo Oliveira, 2014), PULO (Simões; Guinovart, 2014) e OpenWordNet-PT14 (De Paiva; Rademaker; Melo, 2012). Essas wordnets são discutidas detalhadamente em (De Paiva et al., 2016; Gonçalo Oliveira, 2014), portanto, aqui simplesmente reiteramos a mensagem principal dessas comparações.\n",
            "\n",
            "Apesar de existirem várias alternativas de wordnets para o português, todas são menores e menos desenvolvidas do que a PWN. PWN é um recurso relativamente grande com 16MB, incluindo 155.327 palavras organizadas em 175.979 synsets num total de 207.016 pares de palavra-significado. A OpenWordNet-PT (OWN-PT) (De Paiva; Rademaker; Melo, 2012), alinhada à PWN, conta com 47.702 synsets (somente 27% da PWN), dos quais 32.855 correspondem a substantivos, 5.060 a verbos, 8.753 a adjetivos e 1.034 a advérbios. O número de projetos usando OWN-PT é muito limitado, possivelmente porque, construída de forma semi-automática, usando aprendizado de máquina no conjunto de wikipedias multilinguais (Melo; Weikum, 2009) e manualmente melhorando os dados obtidos.\n",
            "\n",
            "Como exemplo, a Figura 9.3 apresenta os synsets da palavra “assassinar” na OWN-PT. Ao todo são quatro synsets, um na classe Noun (substantivo) e três na classe Verbo. O terceiro synset (02482425-v) refere-se a “matar intencionalmente e com premeditação” (glosa) e possui como hiperônimo direto o synset “matar” (01323958-v).\n",
            "\n",
            "Outras wordnets são ainda menores (PULO (Simões; Guinovart, 2014)), ou menos acuradas, pois, construídas numa abordagem mais dinâmica (ONTO.PT (Gonçalo Oliveira, 2014)), podem mudar completamente de uma versão para a seguinte.\n",
            "\n",
            "Algumas decisões de projeto de uma wordnet, assim como de outras bases de conhecimento, parecem claras e já são consenso na comunidade do PLN. Wordnets devem ser recursos abertos, grátis e fáceis de utilizar. Devem ter versões adequadas a usuários humanos e a agentes computacionais, isto é, devem ter interfaces de busca para usuários e interfaces ou bibliotecas para usos computacionais. Tais recursos linguísticos precisam ser mantidos e melhorados, pois nenhum é perfeito e as linguagens naturais são sistemas vivos, dinâmicos e em constante e contínua evolução.\n",
            "\n",
            "Porém, outras decisões permanecem em aberto: uma alternativa só para o português brasileiro e outra para o português de Portugal? Ou uma alternativa para ambas variantes do português? Alternativas multilinguais tais como Open Multilingual WordNet (OMW)15 (Bond; Foster, 2013) ou somente em português? Somente alternativas alinhadas a PWN ou o alinhamento16 não é necessário? Somente as relações semânticas de PWN ou outras também? As entidades nomeadas devem ser incluídas no recurso ou não? Qual deve ser o registro do recurso? Deve incluir gírias e palavras de baixo-calão ou não?\n",
            "\n",
            "Usaremos a OWN-PT para analisar o exemplo motivador Exemplo 9.1 apresentado no início da Seção 9.1. No Exemplo 9.2, foram sublinhadas algumas palavras que foram associadas a synsets na OWN-PT. Para realizar esta associação, é necessário definir o sentido ou significado da palavra usada no texto. Esta tarefa em PLN denominamos de Desambiguação do Sentido de Palavras (Word Sense Desambiguation – WSD). Após o exemplo, são listadas algumas afirmações (especificamente de hiperomínia) entre o synset da palavra usada no texto e outro synset.\n",
            "\n",
            "Exemplo 9.2  \n",
            "\n",
            "Um assalto do tipo saidinha bancária, ocorrido na tarde desta terça-feira, terminou com uma mulher de 42 anos baleada pelos assaltantes. O roubo ocorreu na rua Professor Costa Mendes.\n",
            "\n",
            "Usando a OWN-PT, definimos os seguintes synsets para as palavras sublinhadas em Exemplo 9.2: “assalto” (00783063-n), “terminar” (02610845-v). Não foi encontrado nenhum synset para o termo “balear”. A seguir, algumas afirmações de hiperonímia entre esses synsets e outros:\n",
            "\n",
            "parte do cap 17\n",
            "\n",
            "A partir da MUC-3, em 1991, a conferência passa a ter foco no processamento de textos jornalísticos em detrimento dos relatórios militares utilizados anteriormente (DARPA, 1991). Com a disponibilidade de dados e o incentivo no desenvolvimento de soluções para a tarefa, vemos na década de 1990 o surgimento das primeiras aplicações comerciais de EI, como o JASPER (Andersen et al., 1992)., construído para a agência de notícias Reuters.\n",
            "\n",
            "A MUC-6, ocorrida em 1995, introduz a tarefa de REN com o intuito de ser uma tarefa de uso prático, independente de domínio e que poderia ser realizada automaticamente em um futuro próximo (Grishman; Sundheim, 1996). Enquanto os trabalhos em REN se avolumaram a partir de sua proposição na MUC-6, trabalhos anteriores como Rau (1991) e Wolinski; Vichot; Dillet (1995) já se debruçavam sobre o problema de identificação e classificação de nomes próprios. Desde então, o interesse na tarefa cresceu significativamente e outras conferências de avaliação conjunta têm sido dedicadas a essa tarefa, como a Automatic Content Extraction (ACE) e a conferência Avaliação de Sistemas de Reconhecimento de Entidades Mencionadas (HAREM), dedicada exclusivamente à língua portuguesa, com sua primeira edição em 2005 (Santos; Cardoso, 2007a).\n",
            "\n",
            "Por outro lado, houve um crescimento de abordagens baseadas em dados nesta década, a partir da análise de corpora. Tais esforços são impulsionados pelos resultados positivos na área, como o trabalho de Hearst (1992). Logo, métodos baseados em dados passaram também a explorar o emprego de análise estatística e aprendizado de máquina na construção de padrões para a extração de relações (Riloff et al., 1993; Riloff; Jones; et al., 1999; Roark; Charniak, 2000; Soderland et al., 1995)\n",
            "\n",
            "Não foi somente na extração de padrões que métodos de aprendizado de máquina, em particular aprendizado supervisionado, foram aplicados. A década de 2000 viu a proliferação de métodos supervisionados aplicados à ER (Culotta; McCallum; Betz, 2006; Kambhatla, 2004; Zelenko; Aone; Richardella, 2003; Zhao; Grishman, 2005) e ao REN (Asahara; Matsumoto, 2003; McCallum; Li, 2003; Sekine, 1998).\n",
            "\n",
            "Devido à dificuldade de construção de dados para treinamento e padrões para extração, além da pouca adaptabilidade dos sistemas construídos para outros escopos e domínios, nos anos 2000, sistemas baseados em métodos de aprendizado semi-supervisionado, como o DIPRE (Brin, 1998) e Snowball (Agichtein; Gravano, 2000) começaram a aparecer, juntamente com os estudos sobre expansão automatizada de anotações (bootstrapping) (Riloff; Jones; et al., 1999). Também para entidades nomeadas, estudos investigaram como utilizar recursos da Web (Etzioni et al., 2005; Nadeau, 2007) ou corpora (Cucchiarelli; Velardi, 2001) para aprender entidades com pouco ou nenhum esforço de anotação.\n",
            "\n",
            "Buscando superar as dificuldades da limitação de escopo, i.e. das relações-alvo a serem extraídas e categorias de entidades a serem identificadas, ainda restritas à definição de padrões desde a criação dessas tarefas, Banko et al. (2007) propõe a tarefa de extração de informação aberta (EIA), também conhecida como Open Information Extraction, OpenIE ou OIE, a qual busca extrair todas as relações possíveis expressas em um texto, sem necessidade de pré-definição de relações e entidades.\n",
            "\n",
            "Devido ao recente sucesso da aplicação de métodos baseados em redes neurais, em particular deep learning e grandes modelos de linguagem, às tarefas de Processamento de Linguagem Natural, uma tendência atual da área se delineou como o estudo de arquiteturas neurais para os problemas de EI e a geração de grandes conjuntos de dados por supervisão fraca. Surveys recentes, como (Cui; Wei; Zhou, 2018; Konstantinova, 2014; Nasar; Jaffry; Malik, 2021), nos mostram a evolução da área em direção à aplicação de métodos neurais. Na vertente de geração de dados, vemos o emprego da Wikipédia e Freebase como fontes mais usadas para obter anotações de entidades e relações em textos (Nguyen; Theobald; Weikum, 2016; Smirnova; Cudré-Mauroux, 2018; Takamatsu; Sato; Nakagawa, 2012).\n",
            "\n",
            "Porém, toda a tarefa de EI necessita de uma concordância entre as definições de Entidade e Relação. Neste sentido, a próxima seção discute a conceituação de relação adotada neste capítulo, assim como o conceito de entidade.\n",
            "\n",
            "A natureza das relações estudadas na área de Extração de Informação e os critérios para reconhecer sua ocorrência em um texto têm recebido pouca atenção na literatura. Este é um passo importante para estabelecer metodologias adequadas para avaliar os sistemas, bem como para criar conjuntos de dados que possam apoiar a criação de sistemas futuros.\n",
            "\n",
            "Enquanto as noções de Relação e Entidade são de grande importância e já bem estudadas nas áreas de Computação, Linguística, Ciência da Informação e Filosofia da Linguagem, esses conceitos não são empregados de forma consistente entre as áreas, ou mesmo entre suas subáreas.\n",
            "\n",
            "Para Chen (1976), uma entidade é um objeto que pode ser concreto, tal como pessoa, livro, casa ou ainda abstrato, tal como um emprego, um sentimento, uma disciplina. As entidades podem estabelecer relações entre si. Duas ou mais entidades são vinculadas, ou seja conectadas por uma relação1.\n",
            "\n",
            "Tradicionalmente em reconhecimento de entidades nomeadas, as entidades consideradas são aquelas referenciadas por um nome próprio, acrescidas das referências temporais e valores que são expressões numéricas. Essas expressões, portanto, geralmente não constituem uma entrada em uma base lexical. Porém a tarefa se expandiu para domínios especializados, onde as entidades de interesse são mais conceituais. No domínio bio-médico por exemplo, podemos ter como exemplo de entidades de interesse, sintomas e tratamento que não são referenciadas por nomes próprios.\n",
            "\n",
            "Os conceitos de relação e relacionamento são noções fundamentais que vêm sendo estudadas em áreas como Ciência da Computação, Linguística e Filosofia.\n",
            "\n",
            "No campo de bancos de dados e modelagem conceitual, Chen (1976) define um relacionamento, no contexto da modelagem de Entidade-Relacionamento, como uma associação entre entidades. Guarino; Guizzardi (2015), por sua vez, estudando a natureza ontológica dos relacionamentos com base na semântica de veridadores (truthmaker semantics) (Fine, 2017), postulam relacionamentos como entidades que atuam como veridadores (thruthmakers) de alguma proposição relacionando duas ou mais entidades, ou seja, uma relação mantida entre essas entidades. Um veridador é um elemento cuja existência torna verdadeira uma proposição particular. Por exemplo, considerando a sentença (1) “a é uma maçã”, a existência de um objeto denotado pelo nome a que por acaso é uma maçã é uma condição suficiente para a verdade da frase (1). Como tal, dizemos que esse objeto é o veridador de (1). Tal definição nos permite adotar critérios ontológicos para validar a existência de relacionamentos a partir da informação relatada em um texto e, por isso, adotaremos tal definição de relacionamento neste capítulo.\n",
            "\n",
            "O conceito de relações é muito menos consistente na literatura. Ainda na área de modelagem conceitual, Guarino; Guizzardi (2015) definem as relações como proposições para as quais os relacionamentos são veridadores e, portanto, possuem conteúdo proposicional. Assim, podemos entender uma relação como um tipo para entidades como relacionamentos. Ou seja, relações são universais ontológicos que descrevem a natureza dos relacionamentos.\n",
            "\n",
            "Xavier; Lima; Souza (2015), no entanto, argumentam que a noção de relacionamento adotada na área de Extração de Informação é mais geral do que isso, não se limitando àquelas entre objetos e propriedades, mas também àquelas que descrevem ou implicam propriedades de classes gerais como descrito pela sentença (2) “Filósofos são autores de Livros”. Assim, para o contexto de EI consideramos relações como tipos de relacionamentos de primeira ou segunda ordem. Isso significa que uma relação é um tipo de relacionamento que existe entre objetos, suas propriedades e classes de objetos ou suas propriedades.\n",
            "\n",
            "parte do cap 9\n",
            "\n",
            "A partir da WordNet de Princeton, várias wordnets foram propostas para diversas línguas, entre elas o português, conforme será descrito na seção a seguir.\n",
            "\n",
            "Vários recursos léxico-semânticos foram criados para o português nos últimos anos. Alguns deles são listados na página da Linguateca11. O NILC12 tem uma coleção de recursos listados no portal PortLex13, entre os quais se encontram, entre outros, VerbNet.Br (Scarton; Aluisio, 2012) e PropBank.Br (Duran; Aluísio, 2012).\n",
            "\n",
            "Há várias versões de wordnets para o português, como Wordnet.BR (Dias-da-Silva, 2005), Onto.PT (Gonçalo Oliveira, 2014), PULO (Simões; Guinovart, 2014) e OpenWordNet-PT14 (De Paiva; Rademaker; Melo, 2012). Essas wordnets são discutidas detalhadamente em (De Paiva et al., 2016; Gonçalo Oliveira, 2014), portanto, aqui simplesmente reiteramos a mensagem principal dessas comparações.\n",
            "\n",
            "Apesar de existirem várias alternativas de wordnets para o português, todas são menores e menos desenvolvidas do que a PWN. PWN é um recurso relativamente grande com 16MB, incluindo 155.327 palavras organizadas em 175.979 synsets num total de 207.016 pares de palavra-significado. A OpenWordNet-PT (OWN-PT) (De Paiva; Rademaker; Melo, 2012), alinhada à PWN, conta com 47.702 synsets (somente 27% da PWN), dos quais 32.855 correspondem a substantivos, 5.060 a verbos, 8.753 a adjetivos e 1.034 a advérbios. O número de projetos usando OWN-PT é muito limitado, possivelmente porque, construída de forma semi-automática, usando aprendizado de máquina no conjunto de wikipedias multilinguais (Melo; Weikum, 2009) e manualmente melhorando os dados obtidos.\n",
            "\n",
            "Como exemplo, a Figura 9.3 apresenta os synsets da palavra “assassinar” na OWN-PT. Ao todo são quatro synsets, um na classe Noun (substantivo) e três na classe Verbo. O terceiro synset (02482425-v) refere-se a “matar intencionalmente e com premeditação” (glosa) e possui como hiperônimo direto o synset “matar” (01323958-v).\n",
            "\n",
            "Outras wordnets são ainda menores (PULO (Simões; Guinovart, 2014)), ou menos acuradas, pois, construídas numa abordagem mais dinâmica (ONTO.PT (Gonçalo Oliveira, 2014)), podem mudar completamente de uma versão para a seguinte.\n",
            "\n",
            "Algumas decisões de projeto de uma wordnet, assim como de outras bases de conhecimento, parecem claras e já são consenso na comunidade do PLN. Wordnets devem ser recursos abertos, grátis e fáceis de utilizar. Devem ter versões adequadas a usuários humanos e a agentes computacionais, isto é, devem ter interfaces de busca para usuários e interfaces ou bibliotecas para usos computacionais. Tais recursos linguísticos precisam ser mantidos e melhorados, pois nenhum é perfeito e as linguagens naturais são sistemas vivos, dinâmicos e em constante e contínua evolução.\n",
            "\n",
            "Porém, outras decisões permanecem em aberto: uma alternativa só para o português brasileiro e outra para o português de Portugal? Ou uma alternativa para ambas variantes do português? Alternativas multilinguais tais como Open Multilingual WordNet (OMW)15 (Bond; Foster, 2013) ou somente em português? Somente alternativas alinhadas a PWN ou o alinhamento16 não é necessário? Somente as relações semânticas de PWN ou outras também? As entidades nomeadas devem ser incluídas no recurso ou não? Qual deve ser o registro do recurso? Deve incluir gírias e palavras de baixo-calão ou não?\n",
            "\n",
            "Usaremos a OWN-PT para analisar o exemplo motivador Exemplo 9.1 apresentado no início da Seção 9.1. No Exemplo 9.2, foram sublinhadas algumas palavras que foram associadas a synsets na OWN-PT. Para realizar esta associação, é necessário definir o sentido ou significado da palavra usada no texto. Esta tarefa em PLN denominamos de Desambiguação do Sentido de Palavras (Word Sense Desambiguation – WSD). Após o exemplo, são listadas algumas afirmações (especificamente de hiperomínia) entre o synset da palavra usada no texto e outro synset.\n",
            "\n",
            "Exemplo 9.2  \n",
            "\n",
            "Um assalto do tipo saidinha bancária, ocorrido na tarde desta terça-feira, terminou com uma mulher de 42 anos baleada pelos assaltantes. O roubo ocorreu na rua Professor Costa Mendes.\n",
            "\n",
            "Usando a OWN-PT, definimos os seguintes synsets para as palavras sublinhadas em Exemplo 9.2: “assalto” (00783063-n), “terminar” (02610845-v). Não foi encontrado nenhum synset para o termo “balear”. A seguir, algumas afirmações de hiperonímia entre esses synsets e outros:\n",
            "\n",
            "parte do cap 17\n",
            "\n",
            "Enquanto os métodos tradicionais de Extração de Informação dependem de um conjunto pré-existente de relações semânticas bem definidas que são relevantes para um domínio específico, a noção de “relação” e “entidade” na literatura da área mais recente, tais como a Extração de Informação Aberta, requer mais aprofundamento por demandar um significado diferente, principalmente com diferente visões de autores. Esta indeterminação terminológica pode trazer problemas para comparar os resultados dos métodos propostos ou para reutilizar os conjuntos de dados criados na área.\n",
            "\n",
            "As seções seguintes exploram essas duas áreas: Extração de Informação e Extração de Informação Aberta.\n",
            "\n",
            "A Extração de Informação é caracterizada por obter informação estruturada a partir de textos, sendo entidades ou fatos, i.e. relacionamentos entre entidades, de tipos previamente definidos, conforme exemplo na Quadro 17.1. Métodos com limitação de escopo possuem como uma de suas principais desvantagens a necessidade de intervenção humana para especificar novos fatos a serem extraídos. Esta limitação impede que sistemas de Extração de Informação, doravante denominados de EI tradicional extraiam fatos fora do escopo pré-definido.\n",
            "\n",
            "Quadro 17.1 Exemplos de relações específicas na EI tradicional\n",
            "\n",
            "Fonte: (Souza; Claro, 2014)\n",
            "\n",
            "O Reconhecimento de Entidades Nomeadas (REN) consiste na tarefa de identificar e classificar expressões linguísticas, denominadas entidades nomeadas (EN), que referenciam entidades específicas num domínio de discurso, como nomes próprios, expressões temporais e espécies biológicas (Mota; Santos; Ranchhod, 2007; Nadeau, 2007). De uma forma geral, o REN pode ser dividido em duas etapas: a identificação (ou delimitação) da expressão, na qual as palavras que formam a EN são selecionadas; a classificação, em que é atribuída uma categoria semântica à EN.\n",
            "\n",
            "A classificação das ENs determina os tipos de entidades a serem consideradas e são especificadas a partir do escopo definido previamente para a tarefa. Algumas das categorias mais comumente utilizadas incluem as entidades que referenciam Pessoas Singulares (antropônimos); Coletivas (empresas e organizações) e Lugares (topônimos) (Mota; Santos; Ranchhod, 2007). Para exemplificar tomemos a sentença: “Renata Silva e Maria Costa palestraram na Universidade Federal da Bahia”. No exemplo temos três ENs: “Renata Silva”, “Maria Costa”, “Universidade Federal da Bahia”, sendo as duas primeiras correspondentes à categoria semântica Pessoa e a última, à categoria semântica Organização. Entretanto, existem outras categorias de ENs, como as menções a Obras (por exemplo, “Código Da Vinci”); Acontecimentos (por exemplo, “Festa de Santo Antônio”), Tempo (por exemplo, “meio-dia”); Coisa (por exemplo, “barco”), entre outras.\n",
            "\n",
            "O REN é uma tarefa com grande importância para o Processamento de Linguagem Natural, pois consiste numa primeira tarefa de análise semântica de um texto, com potencial aplicações a diversas tarefas. Por exemplo, em sistemas de perguntas e respostas, as perguntas frequentemente se referem a informações sobre entidades. Também, métodos de identificação de estruturas mais complexas, como eventos ou relações, dependem do bom desempenho do REN como uma etapa de pré-processamento (Socher et al., 2012; Zelenko; Aone; Richardella, 2003).\n",
            "\n",
            "A tarefa de extração de relações (ou de relacionamentos) (ER) refere-se a identificar relacionamentos entre entidades de um determinado escopo mencionadas em um texto (Jurafsky; Martin, 2023). O escopo, no contexto da ER, refere-se a um conjunto de relações-alvo de um determinado domínio de conhecimento ou aplicação a ser investigado. Por exemplo, o Quadro 17.2 apresenta alguns exemplos de relações no domínio de geografia brasileira. Na descrição das relações, os elementos em negrito referem-se às entidades em um dado relacionamento descrito pelo termo em itálico.\n",
            "\n",
            "Quadro 17.2 Exemplos de relações no domínio da geografia brasileira.\n",
            "\n",
            "Nesse contexto, a delimitação de um escopo ou domínio de interesse, concentra-se na determinação das relações a serem processadas, i.e. nos tipos de relacionamentos de interesse, assim como da natureza das entidades associadas por tais relações.\n",
            "\n",
            "As tarefas de reconhecimento de entidades nomeadas e extração de relações são interdependentes, no sentido de que a definição do escopo a ser estudado delimita tanto as categorias e natureza das entidades a serem extraídas, como também as relações entre essas entidades. Também, note-se que, pelo fato de as relações serem comumente definidas entre entidades de tipo especificado, como o caso da relação Tem_Prefeito no Quadro 17.2 que ocorre entre entidades das classes Cidade e Pessoa, tanto as informações das entidades mencionadas no texto são úteis para a extração de relações, quanto a informação das relações identificadas pode ser útil ao processo de identificação de entidades.\n",
            "\n",
            "De fato, na literatura recente, existem vários trabalhos que consideram a tarefa de extração conjunta de entidades e relações (ERE, do inglês Entity and Relation Joint Extraction), composta das tarefas de REN e ER (Agichtein; Gravano, 2000; Shaowei et al., 2022; Yuan et al., 2021). Enquanto normalmente abordagens estruturam suas soluções de forma sequencial, usualmente realizando REN inicialmente e, posteriormente, realizando ER, como nos trabalhos de (Hasegawa; Sekine; Grishman, 2004) e de (Socher et al., 2012), a literatura recente aponta para as vantagens da identificação conjunta ao permitir um melhor aprendizado de restrições para identificação de entidades e relações, c.f. o recente survey realizado por (Shaowei et al., 2022) sobre métodos para tal tarefa.\n",
            "\n",
            "Várias abordagens foram adotadas para o problema de EI durante seu desenvolvimento histórico. Enquanto abordagens iniciais privilegiavam métodos ricos em conhecimento, como regras e recursos linguísticos e de conhecimento de mundo, a literatura recente na área privilegia métodos baseados em dados, como o aprendizado de máquina, com o recente emprego de arquiteturas neurais aos problemas.\n",
            "\n",
            "A seguir faremos uma breve apresentação das abordagens descritas na literatura para os problemas de EI.\n",
            "\n",
            "parte do cap 9\n",
            "\n",
            "A partir da WordNet de Princeton, várias wordnets foram propostas para diversas línguas, entre elas o português, conforme será descrito na seção a seguir.\n",
            "\n",
            "Vários recursos léxico-semânticos foram criados para o português nos últimos anos. Alguns deles são listados na página da Linguateca11. O NILC12 tem uma coleção de recursos listados no portal PortLex13, entre os quais se encontram, entre outros, VerbNet.Br (Scarton; Aluisio, 2012) e PropBank.Br (Duran; Aluísio, 2012).\n",
            "\n",
            "Há várias versões de wordnets para o português, como Wordnet.BR (Dias-da-Silva, 2005), Onto.PT (Gonçalo Oliveira, 2014), PULO (Simões; Guinovart, 2014) e OpenWordNet-PT14 (De Paiva; Rademaker; Melo, 2012). Essas wordnets são discutidas detalhadamente em (De Paiva et al., 2016; Gonçalo Oliveira, 2014), portanto, aqui simplesmente reiteramos a mensagem principal dessas comparações.\n",
            "\n",
            "Apesar de existirem várias alternativas de wordnets para o português, todas são menores e menos desenvolvidas do que a PWN. PWN é um recurso relativamente grande com 16MB, incluindo 155.327 palavras organizadas em 175.979 synsets num total de 207.016 pares de palavra-significado. A OpenWordNet-PT (OWN-PT) (De Paiva; Rademaker; Melo, 2012), alinhada à PWN, conta com 47.702 synsets (somente 27% da PWN), dos quais 32.855 correspondem a substantivos, 5.060 a verbos, 8.753 a adjetivos e 1.034 a advérbios. O número de projetos usando OWN-PT é muito limitado, possivelmente porque, construída de forma semi-automática, usando aprendizado de máquina no conjunto de wikipedias multilinguais (Melo; Weikum, 2009) e manualmente melhorando os dados obtidos.\n",
            "\n",
            "Como exemplo, a Figura 9.3 apresenta os synsets da palavra “assassinar” na OWN-PT. Ao todo são quatro synsets, um na classe Noun (substantivo) e três na classe Verbo. O terceiro synset (02482425-v) refere-se a “matar intencionalmente e com premeditação” (glosa) e possui como hiperônimo direto o synset “matar” (01323958-v).\n",
            "\n",
            "Outras wordnets são ainda menores (PULO (Simões; Guinovart, 2014)), ou menos acuradas, pois, construídas numa abordagem mais dinâmica (ONTO.PT (Gonçalo Oliveira, 2014)), podem mudar completamente de uma versão para a seguinte.\n",
            "\n",
            "Algumas decisões de projeto de uma wordnet, assim como de outras bases de conhecimento, parecem claras e já são consenso na comunidade do PLN. Wordnets devem ser recursos abertos, grátis e fáceis de utilizar. Devem ter versões adequadas a usuários humanos e a agentes computacionais, isto é, devem ter interfaces de busca para usuários e interfaces ou bibliotecas para usos computacionais. Tais recursos linguísticos precisam ser mantidos e melhorados, pois nenhum é perfeito e as linguagens naturais são sistemas vivos, dinâmicos e em constante e contínua evolução.\n",
            "\n",
            "Porém, outras decisões permanecem em aberto: uma alternativa só para o português brasileiro e outra para o português de Portugal? Ou uma alternativa para ambas variantes do português? Alternativas multilinguais tais como Open Multilingual WordNet (OMW)15 (Bond; Foster, 2013) ou somente em português? Somente alternativas alinhadas a PWN ou o alinhamento16 não é necessário? Somente as relações semânticas de PWN ou outras também? As entidades nomeadas devem ser incluídas no recurso ou não? Qual deve ser o registro do recurso? Deve incluir gírias e palavras de baixo-calão ou não?\n",
            "\n",
            "Usaremos a OWN-PT para analisar o exemplo motivador Exemplo 9.1 apresentado no início da Seção 9.1. No Exemplo 9.2, foram sublinhadas algumas palavras que foram associadas a synsets na OWN-PT. Para realizar esta associação, é necessário definir o sentido ou significado da palavra usada no texto. Esta tarefa em PLN denominamos de Desambiguação do Sentido de Palavras (Word Sense Desambiguation – WSD). Após o exemplo, são listadas algumas afirmações (especificamente de hiperomínia) entre o synset da palavra usada no texto e outro synset.\n",
            "\n",
            "Exemplo 9.2  \n",
            "\n",
            "Um assalto do tipo saidinha bancária, ocorrido na tarde desta terça-feira, terminou com uma mulher de 42 anos baleada pelos assaltantes. O roubo ocorreu na rua Professor Costa Mendes.\n",
            "\n",
            "Usando a OWN-PT, definimos os seguintes synsets para as palavras sublinhadas em Exemplo 9.2: “assalto” (00783063-n), “terminar” (02610845-v). Não foi encontrado nenhum synset para o termo “balear”. A seguir, algumas afirmações de hiperonímia entre esses synsets e outros:\n",
            "\n",
            "parte do cap 17\n",
            "\n",
            "As abordagens iniciais para REN baseavam-se, majoritariamente, no emprego de regras lexico-sintáticas e consulta a almanaques (gazeeers). Tais abordagens dependem da construção de listas de nomes próprios como antropônimos, topônimos etc., e outras palavras, como “Ltda.”, “Jr.” etc., que auxiliam no processo de identificação e classificação de ENs complexas ou desconhecidas. Essa é, por exemplo, a abordagem empregada por Wolinski; Vichot; Dillet (1995) que combina almanaques e regras para a identificação e classificação de ENs. Posteriormente, almanaques foram também empregados em conjunção com métodos baseados em dados, como o trabalho de Florian et al. (2003) que os emprega aliados aos classificadores, enquanto Liu; Yao; Lin (2019) os utilizam durante o treinamento de uma rede neural, como um sinal de treinamento (parte da função de perda, ou loss em inglês).\n",
            "\n",
            "Muitos trabalhos debruçaram-se também sobre o problema de construção automática ou semi-automática de almanaques, dos quais os trabalhos de Nadeau (2007), de Riloff; Jones; et al. (1999) e de Etzioni et al. (2005) são alguns dos mais importantes.\n",
            "\n",
            "Enquanto as abordagens iniciais para o problema baseavam-se em regras, com a disponibilidade de dados anotados para a tarefa, tais métodos foram rapidamente suplantados por métodos baseados em dados, tais como: os métodos baseados em classificação (Asahara; Matsumoto, 2003; Sekine, 1998) e classificação sequencial (Bikel; Schwartz; Weischedel, 1999; McCallum; Li, 2003).\n",
            "\n",
            "A redução de REN à tarefa de classificação sequencial merece destaque pelos bons resultados obtidos. Tal redução se dá através de um esquema de codificação do problema que nos permite representar fragmentos textuais e sua classificação como um problema de rotulação ou etiquetação.\n",
            "\n",
            "Partindo-se do pressuposto de que os fragmentos textuais descrevendo entidades nomeadas são contíguos, podemos codificar a tarefa de delimitação de entidades como classificação sequencial empregando rótulos que descrevem os limites de uma EN, e.g. o esquema BIO com os rótulos B (do inglês, begin) para designar a palavra inicial de uma EN, I (do inglês, inside) para designar palavras que fazem parte da EN mas não a iniciam e O (do inglês, outside) para designar palavras que não pertencem a uma entidade. Da mesma forma, podemos estender nosso esquema de codificação para incluir as classes de interesse. Assim, seguindo o esquema BIO, teremos os rótulos B-PER e I-PER para descrever entidades da classe Pessoa.\n",
            "\n",
            "A redução do problema de REN à classificação sequencial está ilustrada no Exemplo 17.1.\n",
            "\n",
            "Exemplo 17.1  \n",
            "\n",
            "Renata/B-PER Silva/I-PER e/O Maria/B-PER Costa/I-PER palestraram/O na/O Universidade/B-ORG Federal/I-ORG da/I-ORG Bahia/I-ORG.\n",
            "\n",
            "Recentemente, destacam-se na literatura abordagens baseadas em redes neurais profundas, com uma grande concentração nos últimos anos em modelos gerativos de linguagem, devido aos resultados positivos obtidos por tais arquiteturas em diversas tarefas.\n",
            "\n",
            "Na literatura são de grande destaque os modelos recentes BART (Lewis et al., 2020), RoBERTa (Liu et al., 2019), T5 (Raffel et al., 2020), BERT (Devlin et al., 2019) e GPT-3 (Brown et al., 2020), conforme descritos no Capítulo 15.\n",
            "\n",
            "Similarmente, na língua portuguesa, nas duas edições do HAREM (Mota; Santos, 2008; Santos; Cardoso, 2007b), o primeiro esforço sistemático de desenvolvimento de soluções para a tarefa na língua, a maioria dos sistemas participantes baseava-se em métodos ricos em conhecimento, como regras e almanaques. De fato, nas duas avaliações, somente os sistemas MALINCHE (Solorio, 2007), NEURA (Ferrández et al., 2007) e R3M (Mota, 2008) não se baseavam em regras. Métodos baseados em classificação sequencial se seguiram para a língua portuguesa, como o RELP-CRF (Amaral; Vieira, 2014) baseado em um classificador sequencial. Mais recentemente, abordagens baseadas em redes neurais e modelos de linguagem foram desenvolvidas tornando-se o estado da arte da tarefa na língua. A Tabela 17.1 apresenta o atual estado da arte em português, com base no corpus HAREM. A métrica de avaliação apresentada, medida F1, será discutida na Seção 17.6.\n",
            "\n",
            "Souza; Nogueira; Lotufo (2020) desenvolveram um modelo BERT para o Português com 2,68 bilhões de tokens e aplicaram o modelo em um classificador CRF. Santos et al., avaliaram o impacto do modelo contextualizado Flair Embeddings aplicado a tarefa de REN junto com uma rede neural BiLSTM-CRF. Os autores também desenvolveram um modelo Flair Embeddings para o português, o FlairBBP, treinado com 4,9 bilhões de tokens (Santos et al., 2019). Castro; Silva; Soares (2018) utilizou uma rede LSTM e um classificador CRF junto com modelos Word Embeddings pré-treinados. Santos; Guimarães (2015) desenvolveram uma rede neural convolucional capaz de capturar características a nível de caracteres e também de incorporar word embeddings pré-treinados.\n",
            "\n",
            "O reconhecimento de entidades tem sido aplicado em muitas áreas específicas, como direito, saúde e geologia. Nesses casos há uma demanda de adaptação dos modelos preditivos de acordo com a nova linguagem especializada do domínio e um novo conjunto de rótulos que devem ser aprendidos. Da mesma forma, são necessários novos conjuntos de dados para o processo de aprendizado, uma vez que abordagens de aprendizado de máquina necessitam de exemplos anotados para se chegar a um modelo preditivo eficaz.\n",
            "\n",
            "Muitos trabalhos endereçam domínios específicos, citamos exemplos em diversas línguas. Para o inglês, uma rede neural BiLSTM-CRF para o domínio biomédico é proposta em (Habibi et al., 2017).\n",
            "\n",
            "Um conjunto de dados do domínio jurídico em língua alemã é apresentado por Leitner; Rehm; Schneider (2019), que empregam redes neurais BiLSTM para a rotulação dos textos. Em (Qiu et al., 2019), uma rede neural BiLSTM-CRF com mecanismo de atenção é aplicada para reconhecer entidades geológicas para a língua chinesa.\n",
            "\n",
            "parte do cap 9\n",
            "\n",
            "A partir da WordNet de Princeton, várias wordnets foram propostas para diversas línguas, entre elas o português, conforme será descrito na seção a seguir.\n",
            "\n",
            "Vários recursos léxico-semânticos foram criados para o português nos últimos anos. Alguns deles são listados na página da Linguateca11. O NILC12 tem uma coleção de recursos listados no portal PortLex13, entre os quais se encontram, entre outros, VerbNet.Br (Scarton; Aluisio, 2012) e PropBank.Br (Duran; Aluísio, 2012).\n",
            "\n",
            "Há várias versões de wordnets para o português, como Wordnet.BR (Dias-da-Silva, 2005), Onto.PT (Gonçalo Oliveira, 2014), PULO (Simões; Guinovart, 2014) e OpenWordNet-PT14 (De Paiva; Rademaker; Melo, 2012). Essas wordnets são discutidas detalhadamente em (De Paiva et al., 2016; Gonçalo Oliveira, 2014), portanto, aqui simplesmente reiteramos a mensagem principal dessas comparações.\n",
            "\n",
            "Apesar de existirem várias alternativas de wordnets para o português, todas são menores e menos desenvolvidas do que a PWN. PWN é um recurso relativamente grande com 16MB, incluindo 155.327 palavras organizadas em 175.979 synsets num total de 207.016 pares de palavra-significado. A OpenWordNet-PT (OWN-PT) (De Paiva; Rademaker; Melo, 2012), alinhada à PWN, conta com 47.702 synsets (somente 27% da PWN), dos quais 32.855 correspondem a substantivos, 5.060 a verbos, 8.753 a adjetivos e 1.034 a advérbios. O número de projetos usando OWN-PT é muito limitado, possivelmente porque, construída de forma semi-automática, usando aprendizado de máquina no conjunto de wikipedias multilinguais (Melo; Weikum, 2009) e manualmente melhorando os dados obtidos.\n",
            "\n",
            "Como exemplo, a Figura 9.3 apresenta os synsets da palavra “assassinar” na OWN-PT. Ao todo são quatro synsets, um na classe Noun (substantivo) e três na classe Verbo. O terceiro synset (02482425-v) refere-se a “matar intencionalmente e com premeditação” (glosa) e possui como hiperônimo direto o synset “matar” (01323958-v).\n",
            "\n",
            "Outras wordnets são ainda menores (PULO (Simões; Guinovart, 2014)), ou menos acuradas, pois, construídas numa abordagem mais dinâmica (ONTO.PT (Gonçalo Oliveira, 2014)), podem mudar completamente de uma versão para a seguinte.\n",
            "\n",
            "Algumas decisões de projeto de uma wordnet, assim como de outras bases de conhecimento, parecem claras e já são consenso na comunidade do PLN. Wordnets devem ser recursos abertos, grátis e fáceis de utilizar. Devem ter versões adequadas a usuários humanos e a agentes computacionais, isto é, devem ter interfaces de busca para usuários e interfaces ou bibliotecas para usos computacionais. Tais recursos linguísticos precisam ser mantidos e melhorados, pois nenhum é perfeito e as linguagens naturais são sistemas vivos, dinâmicos e em constante e contínua evolução.\n",
            "\n",
            "Porém, outras decisões permanecem em aberto: uma alternativa só para o português brasileiro e outra para o português de Portugal? Ou uma alternativa para ambas variantes do português? Alternativas multilinguais tais como Open Multilingual WordNet (OMW)15 (Bond; Foster, 2013) ou somente em português? Somente alternativas alinhadas a PWN ou o alinhamento16 não é necessário? Somente as relações semânticas de PWN ou outras também? As entidades nomeadas devem ser incluídas no recurso ou não? Qual deve ser o registro do recurso? Deve incluir gírias e palavras de baixo-calão ou não?\n",
            "\n",
            "Usaremos a OWN-PT para analisar o exemplo motivador Exemplo 9.1 apresentado no início da Seção 9.1. No Exemplo 9.2, foram sublinhadas algumas palavras que foram associadas a synsets na OWN-PT. Para realizar esta associação, é necessário definir o sentido ou significado da palavra usada no texto. Esta tarefa em PLN denominamos de Desambiguação do Sentido de Palavras (Word Sense Desambiguation – WSD). Após o exemplo, são listadas algumas afirmações (especificamente de hiperomínia) entre o synset da palavra usada no texto e outro synset.\n",
            "\n",
            "Exemplo 9.2  \n",
            "\n",
            "Um assalto do tipo saidinha bancária, ocorrido na tarde desta terça-feira, terminou com uma mulher de 42 anos baleada pelos assaltantes. O roubo ocorreu na rua Professor Costa Mendes.\n",
            "\n",
            "Usando a OWN-PT, definimos os seguintes synsets para as palavras sublinhadas em Exemplo 9.2: “assalto” (00783063-n), “terminar” (02610845-v). Não foi encontrado nenhum synset para o termo “balear”. A seguir, algumas afirmações de hiperonímia entre esses synsets e outros:\n",
            "\n",
            "parte do cap 17\n",
            "\n",
            "Para o português, um corpus para detecção de eventos de quedas de pacientes em prontuários eletrônicos é descrito em (Santos; Santos; Vieira, 2020). Os autores usaram uma rede neural BiLSTM-CRF+Flair para gerar um modelo classificador de tokens. Um corpus no domínio jurídico, tendo categorias específicas como legislação e jurisprudência é proposto por  Araujo et al. (2018), que usaram uma rede neural BiLSTM-CRF para criar um primeiro baseline para esse corpus. Ademais, Consoli et al. (2020) analisam um corpus no domínio de geologia usando uma rede neural BiLSTM-CRF com um modelo contextualizado Flair Embeddings.\n",
            "\n",
            "As abordagens iniciais para o problema de ER baseavam-se na definição de gabaritos e regras de extração, com base em informação sintática obtida de analisadores sintáticos rasos ou profundos (Cowie, 1983; Sager, 1978). Tais métodos foram rapidamente suplantados por métodos baseados em dados e padrões obtidos de corpora, como os famosos padrões de Hearst (1992) para identificação de relações de hiponímia.\n",
            "\n",
            "O trabalho de Hearst (1992) se baseou na definição de padrões lexico-sintáticos para expressão de relações de hiponímia e hiperonímia a partir de uma análise de corpus. Ao escolher a relação de hiponímia, que ocorre em todo domínio, e padrões gerais baseados em aspectos da língua, como os representados no Quadro 17.3, o autor garante generalizabilidade dos padrões obtidos para diversos domínios e aplicações.\n",
            "\n",
            "Quadro 17.3 Exemplos de Padrões de Hearst para hiponímia\n",
            "\n",
            "Devido à dificuldade de construção manual das regras, os métodos de Riloff et al. (1993), empregam heurísticas para geração de padrões baseadas em informação gramatical, e de Soderland et al. (1995), que se baseia numa semântica de quadros (frames) empregando um analisador semântico e medidas de qualidade de identificação de exemplos, baseado no percentual de acerto sobre relacionamentos previamente conhecidos, para identificação de quadros relevantes.\n",
            "\n",
            "As abordagens baseadas em aprendizado de máquina, hoje as mais comuns e com melhor desempenho na literatura (Konstantinova, 2014; Nasar; Jaffry; Malik, 2021) dividem-se em abordagens que realizam reconhecimento de entidades e extração de relações de forma conjunta e separada.\n",
            "\n",
            "Abordagens baseadas na realização de REN e ER de forma separada baseiam-se em um fluxo de processamento em que, em geral, as entidades são identificadas primeiro e a tarefa de ER se reduz a identificar quando uma sentença ou fragmento textual denota uma relação semântica entre duas entidades. Consideremos o Exemplo 17.2, retirado de (Socher et al., 2012):\n",
            "\n",
            "Exemplo 17.2  \n",
            "\n",
            "Gripe aviária]\\(_{e1}\\) é uma doença infecciosa causada pelo vírus da [influenza tipo a]\\(_{e2}\\)\n",
            "\n",
            "Podemos, então, reduzir o problema de identificar a relação Causa-Efeito(\\(e1\\),\\(e2\\)) a um problema de classificação textual, identificando se a sentença acima fornece indícios para a expressão da relação de interesse. As soluções propostas na literatura para o problema são variadas e baseadas em diferentes métodos.\n",
            "\n",
            "Zelenko; Aone; Richardella (2003), por exemplo, propõem funções de kernel para árvores sintáticas rasas, i.e. funções que descrevem medidas de similaridade entre tais árvores. Eles empregam tais medidas para treinar um classificador de perceptron com votação (voted perceptron) sobre relações no domínio de organizações extraídas de um corpus de textos jornalísticos. De forma similar, Zhao; Grishman (2005) empregam diferentes funções de kernel sobre informações sintáticas relevantes para a identificação de relação e argumentos visando treinar um classificador SVM sobre o corpus de ER da conferência ACE.\n",
            "\n",
            "Culotta; McCallum; Betz (2006), por outro lado, empregam um classificador sequencial baseado em modelos escondidos de Markov para identificação de relações em um texto. Ao restringir sua análise a textos biográficos, os autores reduzem o processo de identificar instâncias de relações à identificação de fragmento textual que delimita o argumento e sua classificação, tarefa para a qual a classificação sequencial já é comumente utilizada. Consideremos o Exemplo 17.3 sobre George W. Bush, retirado de (Culotta; McCallum; Betz, 2006):\n",
            "\n",
            "Exemplo 17.3  \n",
            "\n",
            "George é filho de \\(\\underbrace{\\mbox{George H. W. Bush}}_{\\mbox{pai}}\\) e \\(\\underbrace{\\mbox{Barbara Bush}}_{\\mbox{mãe}}\\).\n",
            "\n",
            "Ao identificar o papel de pai e mãe, os autores conseguem construir a relação Pai(George H. W. Bush, George W. Bush) e Mãe(Barbara Bush, George W. Bush).\n",
            "\n",
            "parte do cap 9\n",
            "\n",
            "A partir da WordNet de Princeton, várias wordnets foram propostas para diversas línguas, entre elas o português, conforme será descrito na seção a seguir.\n",
            "\n",
            "Vários recursos léxico-semânticos foram criados para o português nos últimos anos. Alguns deles são listados na página da Linguateca11. O NILC12 tem uma coleção de recursos listados no portal PortLex13, entre os quais se encontram, entre outros, VerbNet.Br (Scarton; Aluisio, 2012) e PropBank.Br (Duran; Aluísio, 2012).\n",
            "\n",
            "Há várias versões de wordnets para o português, como Wordnet.BR (Dias-da-Silva, 2005), Onto.PT (Gonçalo Oliveira, 2014), PULO (Simões; Guinovart, 2014) e OpenWordNet-PT14 (De Paiva; Rademaker; Melo, 2012). Essas wordnets são discutidas detalhadamente em (De Paiva et al., 2016; Gonçalo Oliveira, 2014), portanto, aqui simplesmente reiteramos a mensagem principal dessas comparações.\n",
            "\n",
            "Apesar de existirem várias alternativas de wordnets para o português, todas são menores e menos desenvolvidas do que a PWN. PWN é um recurso relativamente grande com 16MB, incluindo 155.327 palavras organizadas em 175.979 synsets num total de 207.016 pares de palavra-significado. A OpenWordNet-PT (OWN-PT) (De Paiva; Rademaker; Melo, 2012), alinhada à PWN, conta com 47.702 synsets (somente 27% da PWN), dos quais 32.855 correspondem a substantivos, 5.060 a verbos, 8.753 a adjetivos e 1.034 a advérbios. O número de projetos usando OWN-PT é muito limitado, possivelmente porque, construída de forma semi-automática, usando aprendizado de máquina no conjunto de wikipedias multilinguais (Melo; Weikum, 2009) e manualmente melhorando os dados obtidos.\n",
            "\n",
            "Como exemplo, a Figura 9.3 apresenta os synsets da palavra “assassinar” na OWN-PT. Ao todo são quatro synsets, um na classe Noun (substantivo) e três na classe Verbo. O terceiro synset (02482425-v) refere-se a “matar intencionalmente e com premeditação” (glosa) e possui como hiperônimo direto o synset “matar” (01323958-v).\n",
            "\n",
            "Outras wordnets são ainda menores (PULO (Simões; Guinovart, 2014)), ou menos acuradas, pois, construídas numa abordagem mais dinâmica (ONTO.PT (Gonçalo Oliveira, 2014)), podem mudar completamente de uma versão para a seguinte.\n",
            "\n",
            "Algumas decisões de projeto de uma wordnet, assim como de outras bases de conhecimento, parecem claras e já são consenso na comunidade do PLN. Wordnets devem ser recursos abertos, grátis e fáceis de utilizar. Devem ter versões adequadas a usuários humanos e a agentes computacionais, isto é, devem ter interfaces de busca para usuários e interfaces ou bibliotecas para usos computacionais. Tais recursos linguísticos precisam ser mantidos e melhorados, pois nenhum é perfeito e as linguagens naturais são sistemas vivos, dinâmicos e em constante e contínua evolução.\n",
            "\n",
            "Porém, outras decisões permanecem em aberto: uma alternativa só para o português brasileiro e outra para o português de Portugal? Ou uma alternativa para ambas variantes do português? Alternativas multilinguais tais como Open Multilingual WordNet (OMW)15 (Bond; Foster, 2013) ou somente em português? Somente alternativas alinhadas a PWN ou o alinhamento16 não é necessário? Somente as relações semânticas de PWN ou outras também? As entidades nomeadas devem ser incluídas no recurso ou não? Qual deve ser o registro do recurso? Deve incluir gírias e palavras de baixo-calão ou não?\n",
            "\n",
            "Usaremos a OWN-PT para analisar o exemplo motivador Exemplo 9.1 apresentado no início da Seção 9.1. No Exemplo 9.2, foram sublinhadas algumas palavras que foram associadas a synsets na OWN-PT. Para realizar esta associação, é necessário definir o sentido ou significado da palavra usada no texto. Esta tarefa em PLN denominamos de Desambiguação do Sentido de Palavras (Word Sense Desambiguation – WSD). Após o exemplo, são listadas algumas afirmações (especificamente de hiperomínia) entre o synset da palavra usada no texto e outro synset.\n",
            "\n",
            "Exemplo 9.2  \n",
            "\n",
            "Um assalto do tipo saidinha bancária, ocorrido na tarde desta terça-feira, terminou com uma mulher de 42 anos baleada pelos assaltantes. O roubo ocorreu na rua Professor Costa Mendes.\n",
            "\n",
            "Usando a OWN-PT, definimos os seguintes synsets para as palavras sublinhadas em Exemplo 9.2: “assalto” (00783063-n), “terminar” (02610845-v). Não foi encontrado nenhum synset para o termo “balear”. A seguir, algumas afirmações de hiperonímia entre esses synsets e outros:\n",
            "\n",
            "parte do cap 17\n",
            "\n",
            "Métodos baseados em redes neurais, de forma geral, costumam empregar técnicas de aprendizado de representação (Bengio; Courville; Vincent, 2013) para aprender representações do conteúdo semântico dos fragmentos textuais e reduzem o problema de ER à classificação textual. É o caso de Socher et al. (2012), que propõem a MV-RNN, uma rede neural que constrói um espaço de representação baseado em matrizes e vetores com o objetivo de capturar a composicionalidade de sentido de sintagmas e sentenças e os aplica para ER. Similarmente, Zeng et al. (2014) e Wang et al. (2016) empregam redes neurais convolucionais para obter representações vetoriais de sentenças que serão empregadas no processo de classificação quanto à relação expressa pela mesma.\n",
            "\n",
            "Abordagens baseadas em identificação sequencial de entidades e relações possuem desvantagens observadas na literatura. Primeiramente, como a ER é guiada pelas entidades identificadas no processo de REN, a propagação de erros da primeira tarefa pode ter impacto considerável na performance dos sistemas desenvolvidos. Segundo, uma vez que o contexto determinado limita tanto as tarefas de REN, quanto as de ER, existe uma interdependência entre as tarefas. Assim, propostas visando realizar a extração de entidades e relações de forma conjunta começaram a surgir na literatura recente, ganhando certo interesse da comunidade.\n",
            "\n",
            "As abordagens empregadas para tal tarefa são diversificadas, incluindo desde métodos de aprendizado relacional a redes neurais\n",
            "\n",
            "Roth; Yih (2007) propõem a utilização de métodos de programação inteira ao problema, baseados na teoria estatística de aprendizado relacional. Os autores utilizam classificadores locais para a identificação de entidades e relações e um classificador global que combina as informações dos classificadores locais em uma predição que maximiza a qualidade da extração, codificada por meio de restrições em programação inteira. Também baseados em modelos estatísticos, Yu; Lam (2010) propõem o uso de modelos gráficos globais para identificação de um descritor de relação e uma segmentação do texto para identificação dos argumentos.\n",
            "\n",
            "Li; Ji (2014) e Miwa; Bansal (2016), por sua vez, reduzem a tarefa de ERE à classificação sequencial, utilizando redes neurais recorrentes bidirecionais sequenciais e estruturadas com base na estrutura superficial e na árvore de dependências sintáticas da entrada para identificação conjunta de entidades e relações.\n",
            "\n",
            "A Extração de Informação Aberta (EIA), também conhecida como Open Information Extraction, Open IE ou OIE em inglês, é a tarefa de extrair informações estruturadas de documentos sem necessitar da pré-definição do contexto da tarefa, i.e. das relações e tipos de entidade de interesse. A tarefa foi inicialmente proposta pelo trabalho de (Banko et al., 2007) e ganhou popularidade nas últimas décadas devido à sua aplicabilidade para processar e estruturar o conhecimento a partir de grandes volumes de dados disponíveis na Web, seguindo o paradigma da Web como um Corpus (WaC) (Meyer et al., 2003).\n",
            "\n",
            "A EIA surge visando generalizar a tarefa de Extração de Relações. A principal diferença entre as duas abordagens, porém, reside na dependência da ER de uma especificação prévia do domínio de aplicação, bem como das relações alvo a serem identificadas, que a EIA visa eliminar.\n",
            "\n",
            "Seguindo o trabalho original de Banko et al. (2007), que propôs o sistema TextRunner, vários métodos e sistemas para EIA foram propostos na literatura (Del Corro; Gemulla, 2013; Fader; Soderland; Etzioni, 2011; Xavier; Lima; Souza, 2015), mas, como observado por Glauber; Claro (2018), os principais avanços na área se concentraram principalmente no idioma inglês.\n",
            "\n",
            "A EIA para a língua portuguesa tem uma história bastante recente. A partir dos trabalhos de Souza; Claro (2014), Pereira; Pinheiro (2015) e de (Barbosa; Glauber; Claro, 2016), têm crescido o número de estudos sobre a tarefa assim como os resultados obtidos por esses estudos, com recentes desenvolvimentos de métodos (Oliveira; Claro; Souza, 2022; Sena; Claro, 2019, 2020; Sena; Glauber; Claro, 2017; Souza; Claro; Glauber, 2018), construção do corpus (Glauber et al., 2018) e avaliação dos sistemas disponíveis (Glauber; Claro; Oliveira, 2019; Glauber; Claro; Sena, 2019; Malenchini et al., 2019).\n",
            "\n",
            "Embora a área tenha visto um crescimento recente para o desenvolvimento de métodos para línguas como o inglês, principalmente com a aplicação de métodos supervisionados e redes neurais, esses avanços ainda não foram incorporados na literatura sobre EIA para a língua portuguesa. A razão para isso é principalmente a falta de recursos linguísticos disponíveis para orientar o desenvolvimento de pesquisas para a língua. Embora o foco no idioma inglês possa ser devido ao seu uso generalizado em todo o mundo, foi reconhecido pela comunidade científica que esse foco no inglês com suas características particulares pode introduzir algum viés na área (Bender, 2009).\n",
            "\n",
            "Assim, esta seção aborda EIA para a língua portuguesa, incluindo uma formalização e a evolução das abordagens da área.\n",
            "\n",
            "A tarefa de EIA pode ser formalmente definida sendo \\(X = \\langle x_{1}, x_{2}, \\cdots, x_{n}\\rangle\\) uma sentença composta de tokens \\(x_i\\). Um extrator EIA é uma função que mapeia \\(X\\) em um conjunto \\(Y = \\langle y_{1}, y_{2}, \\cdots, y_{j} \\rangle\\) como um conjunto de tuplas \\(y \\_i = \\langle rel_i, arg1_i, arg2_i, \\cdots, argn_i\\rangle\\), que descrevem as informações expressas na sentença X. Neste capítulo, consideramos que as tuplas estão sempre no formato \\(y = (arg_{1 }, rel, arg_{2})\\), onde \\(arg1\\) e \\(arg2\\) são sintagmas nominais, não necessariamente formados por tokens presentes em X, e \\(rel\\) é um descritor de um relacionamento entre \\(arg_{1}\\) e \\(arg_{2}\\). Não consideraremos extrações formadas por mais de dois argumentos neste capítulo.\n",
            "\n",
            "Os primeiros métodos de EIA empregavam padrões de inspiração linguística para extração, como ArgOE (Gamallo; Garcia, 2015), ou adaptação de métodos para a língua inglesa, como SGS (Souza; Claro; Glauber, 2018), InferReVerbPT Sena; Glauber; Claro (2017) e RePort Pereira; Pinheiro (2015). Os trabalhos são principalmente influenciados por métodos baseados no inglês da chamada segunda geração de EIA (Fader; Soderland; Etzioni, 2011).\n",
            "\n",
            "O primeiro sistema de EIA para o português de que temos conhecimento foi o DepOE (Gamallo; Garcia; Fernández-Lanza, 2012). Ele executa a extração aberta multilíngue de triplas (inglês, espanhol, português e galego) usando o analisador sintático de dependências baseado em regras DepPattern. No entanto, nenhuma avaliação ou resultados são relatados para a língua portuguesa. Os autores apresentam somente uma comparação dos seus resultados com Reverb na língua inglesa.\n",
            "\n",
            "Souza; Claro (2014) se propuseram a analisar o conjunto de características mais representativas da língua portuguesa para a identificação de extrações válidas no contexto de EIA, tal qual empregado na língua inglesa com o sistema ReVerb (Fader; Soderland; Etzioni, 2011).\n",
            "\n",
            "parte do cap 9\n",
            "\n",
            "A partir da WordNet de Princeton, várias wordnets foram propostas para diversas línguas, entre elas o português, conforme será descrito na seção a seguir.\n",
            "\n",
            "Vários recursos léxico-semânticos foram criados para o português nos últimos anos. Alguns deles são listados na página da Linguateca11. O NILC12 tem uma coleção de recursos listados no portal PortLex13, entre os quais se encontram, entre outros, VerbNet.Br (Scarton; Aluisio, 2012) e PropBank.Br (Duran; Aluísio, 2012).\n",
            "\n",
            "Há várias versões de wordnets para o português, como Wordnet.BR (Dias-da-Silva, 2005), Onto.PT (Gonçalo Oliveira, 2014), PULO (Simões; Guinovart, 2014) e OpenWordNet-PT14 (De Paiva; Rademaker; Melo, 2012). Essas wordnets são discutidas detalhadamente em (De Paiva et al., 2016; Gonçalo Oliveira, 2014), portanto, aqui simplesmente reiteramos a mensagem principal dessas comparações.\n",
            "\n",
            "Apesar de existirem várias alternativas de wordnets para o português, todas são menores e menos desenvolvidas do que a PWN. PWN é um recurso relativamente grande com 16MB, incluindo 155.327 palavras organizadas em 175.979 synsets num total de 207.016 pares de palavra-significado. A OpenWordNet-PT (OWN-PT) (De Paiva; Rademaker; Melo, 2012), alinhada à PWN, conta com 47.702 synsets (somente 27% da PWN), dos quais 32.855 correspondem a substantivos, 5.060 a verbos, 8.753 a adjetivos e 1.034 a advérbios. O número de projetos usando OWN-PT é muito limitado, possivelmente porque, construída de forma semi-automática, usando aprendizado de máquina no conjunto de wikipedias multilinguais (Melo; Weikum, 2009) e manualmente melhorando os dados obtidos.\n",
            "\n",
            "Como exemplo, a Figura 9.3 apresenta os synsets da palavra “assassinar” na OWN-PT. Ao todo são quatro synsets, um na classe Noun (substantivo) e três na classe Verbo. O terceiro synset (02482425-v) refere-se a “matar intencionalmente e com premeditação” (glosa) e possui como hiperônimo direto o synset “matar” (01323958-v).\n",
            "\n",
            "Outras wordnets são ainda menores (PULO (Simões; Guinovart, 2014)), ou menos acuradas, pois, construídas numa abordagem mais dinâmica (ONTO.PT (Gonçalo Oliveira, 2014)), podem mudar completamente de uma versão para a seguinte.\n",
            "\n",
            "Algumas decisões de projeto de uma wordnet, assim como de outras bases de conhecimento, parecem claras e já são consenso na comunidade do PLN. Wordnets devem ser recursos abertos, grátis e fáceis de utilizar. Devem ter versões adequadas a usuários humanos e a agentes computacionais, isto é, devem ter interfaces de busca para usuários e interfaces ou bibliotecas para usos computacionais. Tais recursos linguísticos precisam ser mantidos e melhorados, pois nenhum é perfeito e as linguagens naturais são sistemas vivos, dinâmicos e em constante e contínua evolução.\n",
            "\n",
            "Porém, outras decisões permanecem em aberto: uma alternativa só para o português brasileiro e outra para o português de Portugal? Ou uma alternativa para ambas variantes do português? Alternativas multilinguais tais como Open Multilingual WordNet (OMW)15 (Bond; Foster, 2013) ou somente em português? Somente alternativas alinhadas a PWN ou o alinhamento16 não é necessário? Somente as relações semânticas de PWN ou outras também? As entidades nomeadas devem ser incluídas no recurso ou não? Qual deve ser o registro do recurso? Deve incluir gírias e palavras de baixo-calão ou não?\n",
            "\n",
            "Usaremos a OWN-PT para analisar o exemplo motivador Exemplo 9.1 apresentado no início da Seção 9.1. No Exemplo 9.2, foram sublinhadas algumas palavras que foram associadas a synsets na OWN-PT. Para realizar esta associação, é necessário definir o sentido ou significado da palavra usada no texto. Esta tarefa em PLN denominamos de Desambiguação do Sentido de Palavras (Word Sense Desambiguation – WSD). Após o exemplo, são listadas algumas afirmações (especificamente de hiperomínia) entre o synset da palavra usada no texto e outro synset.\n",
            "\n",
            "Exemplo 9.2  \n",
            "\n",
            "Um assalto do tipo saidinha bancária, ocorrido na tarde desta terça-feira, terminou com uma mulher de 42 anos baleada pelos assaltantes. O roubo ocorreu na rua Professor Costa Mendes.\n",
            "\n",
            "Usando a OWN-PT, definimos os seguintes synsets para as palavras sublinhadas em Exemplo 9.2: “assalto” (00783063-n), “terminar” (02610845-v). Não foi encontrado nenhum synset para o termo “balear”. A seguir, algumas afirmações de hiperonímia entre esses synsets e outros:\n",
            "\n",
            "parte do cap 17\n",
            "\n",
            "O sistema RePort (Pereira; Pinheiro, 2015), por outro lado, é uma adaptação do ReVerb para a língua portuguesa baseada em análise sintática rasa com regras sintáticas e lexicais. Os autores relatam que suas extrações apresentam grande similaridade com suas correlatas extraídas pelo ReVerb (dos textos traduzidos para o inglês).\n",
            "\n",
            "O RELP, proposto por Abreu; Vieira (2017), é um sistema aberto de extração de relações que extrai relações entre entidades nomeadas em um domínio de organização aplicando classificação sequencial com CRF (Conditional Random Fields). O sistema RelP extrai qualquer descritor de relação que expressa um relacionamento entre pares de entidades nomeadas (Organização, Pessoa ou Lugar), caracterizando-o como uma abordagem híbrida da REN com a EIA.\n",
            "\n",
            "O InferReVerbPT desenvolvido por Sena; Glauber; Claro (2017) baseia-se numa adaptação do sistema ReVerb para a língua portuguesa, expandindo-o com a extração de relacionamentos implícitos obtidos por inferência por propriedades de simetria e transitividade das relações com inferência transitiva e simétrica. Um classificador SVM foi empregado para realizar a inferência baseado nas propriedades semânticas do verbo central no descritor de relação.\n",
            "\n",
            "Souza; Claro; Glauber (2018) analisaram que a maior desvantagem dos estudos baseados em recursos linguísticos, como dados anotados, reside na escassez de tais recursos na maioria dos idiomas além do inglês. Assim, para mitigar esse problema, eles propõem um método de classificação de fatos baseado na similaridade de estruturas gramaticais (SGS). Sua abordagem modela estruturas morfosintáticas dos fatos (triplas descrevendo relacionamentos) para identificar padrões de semelhanças que podem ser usados para distinguir entre fatos válidos e inválidos. Eles aplicaram algoritmos de isomorfismo de grafos para detectar subgrafos descrevendo tais padrões.\n",
            "\n",
            "Um novo sistema de EIA baseado em análise de dependência foi proposto por Gamallo; Garcia (2015), chamado ArgOE. Tal sistema é multilíngue, baseado em heurísticas e utiliza a informação de dependência sintáticas do texto para analisar a estrutura de dependência do verbo, bem como um conjunto de regras para gerar os relacionamentos. A introdução de um Analisador de Dependência em sistemas de EIA focados inteiramente na língua portuguesa foi feita pelos autores Oliveira; Claro; Souza (2022). O DptOIE é baseado em análise de dependência e regras elaboradas manualmente. As sentenças são pré-processadas por meio de um tokenizador, um PoS Tagger e um analisador de dependências. Os autores propõem um acoplamento de três módulos para tratar casos particulares: conjunções coordenadas, orações subordinadas e aposto.\n",
            "\n",
            "Com a evolução dos métodos de EIA para a língua inglesa utilizando os modelos neurais, novas abordagens foram propostas também para a língua portuguesa.\n",
            "\n",
            "O primeiro trabalho que utilizou aprendizado supervisionado com rede neural profunda para o português foi o de Ro; Lee; Kang (2020) que descreve o sistema Multi2OIE. Os autores utilizaram o modelo de linguagem BERT multilíngue (Devlin et al., 2019) para obter representações vetoriais das palavras e reduzem a tarefa de EIA à classificação sequencial, identificado os fragmentos do texto que determinam os argumentos (\\(arg_1, arg_2\\)) e o descritor de relação (\\(rel\\)). Seu sistema foi capaz de produzir extrações para vários idiomas (inglês, português e espanhol), treinados, entretanto, sobre dados traduzidos do inglês.\n",
            "\n",
            "Stanovsky et al. (2018) propuseram uma abordagem de EIA para a língua inglesa baseada em triplas. Os mesmos fazem uso de uma classificação sequencial cuja limitação define uma tripla extraída para cada sentença. Este método utiliza uma arquitetura de Redes Neurais Recursivas (RNN) para realizar EIA. A EIA é formulada como uma tarefa de rotulagem de sequências, utilizando estratégias semelhantes às que foram aplicadas anteriormente a tarefas como o Reconhecimento de Entidades Nomeadas. Já os autores em Cui; Wei; Zhou (2018) e Zhang; Duh; Van Durme (2017) propõem modelar o problema da EIA como um problema de aprendizado sequência a sequência (seq2seq). Eles definem uma estrutura encoder-decoder para aprender argumentos e tuplas de relação inicializadas a partir de um sistema de EIA.\n",
            "\n",
            "Seguindo o trabalho de (Stanovsky et al., 2018), em 2022, Cabral; Souza; Claro (2022) propuseram PortNOIE, uma arquitetura neural para EIA em português que combina representações contextuais de palavras com codificadores neurais para extrair relacionamentos baseado em classificação sequencial iterativa. Diferente de outros métodos de classificação sequencial para EIA, os autores focam na extração de múltiplas triplas de uma mesma sentença.\n",
            "\n",
            "A avaliação sistemática de sistemas de EI foi estabelecida primeiramente nas conferências MUC, em particular na sua segunda edição, com o estabelecimento de gabaritos-padrão que deveriam ser utilizados por todos os sistemas participantes e a adoção de métricas de qualidade, baseadas naquelas usadas na área de recuperação de informação, que foram abordadas no Capítulo 16. Para avaliar a tarefa de extração de relações, a MUC-2 estabeleceu como métricas de qualidade do sistema as medidas de precisão e cobertura, também denominada de Recall ou Revocação.\n",
            "\n",
            "A precisão de um sistema reflete a qualidade de suas extrações, i.e., quantas das extrações realizadas estão corretas, dado um corpus de teste. A medida de precisão pode ser calculada como:\n",
            "\n",
            "P = \\frac{\\#(\\mbox{relacionamentos corretamente extraídos})}{\\#(\\mbox{relacionamentos extraídos pelo sistema})}\n",
            "\n",
            "A cobertura também conhecida como revocação, reflete quão abrangente um sistema é em suas extrações, i.e., quantas das extrações a serem realizadas em um corpus de teste, o sistema é capaz de realizar. A medida de cobertura pode ser calculada como:\n",
            "\n",
            "R = \\frac{\\#(\\mbox{relacionamentos extraídos})}{\\#(\\mbox{relacionamentos no \\textit{corpus}})}\n",
            "\n",
            "Enquanto a MUC-3 adicionou duas novas métricas de avaliação, a saber sobre-geração (overgeneration) e sub-geração (fallout), tais métricas receberam pouco interesse na literatura. De fato, Lehnert; Sundheim (1991) argumentam que tais métricas foram pouco informativas ou difíceis de calcular para a tarefa de EI e, portanto, abandonadas. Foi também empregado nessa conferência um sistema automático de avaliação disponibilizado às equipes participantes que permitiu uma maior compreensão do modelo de avaliação e, como discutem Lehnert; Sundheim (1991), um avanço qualitativo nos sistemas gerados.\n",
            "\n",
            "parte do cap 9\n",
            "\n",
            "A partir da WordNet de Princeton, várias wordnets foram propostas para diversas línguas, entre elas o português, conforme será descrito na seção a seguir.\n",
            "\n",
            "Vários recursos léxico-semânticos foram criados para o português nos últimos anos. Alguns deles são listados na página da Linguateca11. O NILC12 tem uma coleção de recursos listados no portal PortLex13, entre os quais se encontram, entre outros, VerbNet.Br (Scarton; Aluisio, 2012) e PropBank.Br (Duran; Aluísio, 2012).\n",
            "\n",
            "Há várias versões de wordnets para o português, como Wordnet.BR (Dias-da-Silva, 2005), Onto.PT (Gonçalo Oliveira, 2014), PULO (Simões; Guinovart, 2014) e OpenWordNet-PT14 (De Paiva; Rademaker; Melo, 2012). Essas wordnets são discutidas detalhadamente em (De Paiva et al., 2016; Gonçalo Oliveira, 2014), portanto, aqui simplesmente reiteramos a mensagem principal dessas comparações.\n",
            "\n",
            "Apesar de existirem várias alternativas de wordnets para o português, todas são menores e menos desenvolvidas do que a PWN. PWN é um recurso relativamente grande com 16MB, incluindo 155.327 palavras organizadas em 175.979 synsets num total de 207.016 pares de palavra-significado. A OpenWordNet-PT (OWN-PT) (De Paiva; Rademaker; Melo, 2012), alinhada à PWN, conta com 47.702 synsets (somente 27% da PWN), dos quais 32.855 correspondem a substantivos, 5.060 a verbos, 8.753 a adjetivos e 1.034 a advérbios. O número de projetos usando OWN-PT é muito limitado, possivelmente porque, construída de forma semi-automática, usando aprendizado de máquina no conjunto de wikipedias multilinguais (Melo; Weikum, 2009) e manualmente melhorando os dados obtidos.\n",
            "\n",
            "Como exemplo, a Figura 9.3 apresenta os synsets da palavra “assassinar” na OWN-PT. Ao todo são quatro synsets, um na classe Noun (substantivo) e três na classe Verbo. O terceiro synset (02482425-v) refere-se a “matar intencionalmente e com premeditação” (glosa) e possui como hiperônimo direto o synset “matar” (01323958-v).\n",
            "\n",
            "Outras wordnets são ainda menores (PULO (Simões; Guinovart, 2014)), ou menos acuradas, pois, construídas numa abordagem mais dinâmica (ONTO.PT (Gonçalo Oliveira, 2014)), podem mudar completamente de uma versão para a seguinte.\n",
            "\n",
            "Algumas decisões de projeto de uma wordnet, assim como de outras bases de conhecimento, parecem claras e já são consenso na comunidade do PLN. Wordnets devem ser recursos abertos, grátis e fáceis de utilizar. Devem ter versões adequadas a usuários humanos e a agentes computacionais, isto é, devem ter interfaces de busca para usuários e interfaces ou bibliotecas para usos computacionais. Tais recursos linguísticos precisam ser mantidos e melhorados, pois nenhum é perfeito e as linguagens naturais são sistemas vivos, dinâmicos e em constante e contínua evolução.\n",
            "\n",
            "Porém, outras decisões permanecem em aberto: uma alternativa só para o português brasileiro e outra para o português de Portugal? Ou uma alternativa para ambas variantes do português? Alternativas multilinguais tais como Open Multilingual WordNet (OMW)15 (Bond; Foster, 2013) ou somente em português? Somente alternativas alinhadas a PWN ou o alinhamento16 não é necessário? Somente as relações semânticas de PWN ou outras também? As entidades nomeadas devem ser incluídas no recurso ou não? Qual deve ser o registro do recurso? Deve incluir gírias e palavras de baixo-calão ou não?\n",
            "\n",
            "Usaremos a OWN-PT para analisar o exemplo motivador Exemplo 9.1 apresentado no início da Seção 9.1. No Exemplo 9.2, foram sublinhadas algumas palavras que foram associadas a synsets na OWN-PT. Para realizar esta associação, é necessário definir o sentido ou significado da palavra usada no texto. Esta tarefa em PLN denominamos de Desambiguação do Sentido de Palavras (Word Sense Desambiguation – WSD). Após o exemplo, são listadas algumas afirmações (especificamente de hiperomínia) entre o synset da palavra usada no texto e outro synset.\n",
            "\n",
            "Exemplo 9.2  \n",
            "\n",
            "Um assalto do tipo saidinha bancária, ocorrido na tarde desta terça-feira, terminou com uma mulher de 42 anos baleada pelos assaltantes. O roubo ocorreu na rua Professor Costa Mendes.\n",
            "\n",
            "Usando a OWN-PT, definimos os seguintes synsets para as palavras sublinhadas em Exemplo 9.2: “assalto” (00783063-n), “terminar” (02610845-v). Não foi encontrado nenhum synset para o termo “balear”. A seguir, algumas afirmações de hiperonímia entre esses synsets e outros:\n",
            "\n",
            "parte do cap 17\n",
            "\n",
            "Além das medidas de precisão e cobertura, assim como em tarefas de classificação de texto e recuperação de informação, utilizamos a média harmônica entre essas medidas, chamada medida F1, a fim de condensar a informação contida nas duas. A medida F1 pode ser calculada como:\n",
            "\n",
            "F1 = \\frac{2*P*R}{P+R}\n",
            "\n",
            "A avaliação da tarefa de REN segue padrões semelhantes aos aplicados à tarefa de ER. De fato, desde a MUC-6 (Grishman; Sundheim, 1996), as medidas de precisão, cobertura e F1 tem sido usada consistentemente como métricas de avaliação da tarefa de REN em diversos esforços de avaliação, como a CoNNL (Sang; De Meulder, 2003), para a língua inglesa, e das duas edições do HAREM (Gonçalo Oliveira et al., 2008; Santos; Cardoso; Seco, 2007), com excessão à ACE (Doddington et al., 2004) que apresenta uma combinação da tarefa de REN com reconhecimento de co-referência entre entidades e utiliza um sistema de pontuação próprio.\n",
            "\n",
            "A avaliação de sistemas de EIA, por sua vez, possui algumas peculiaridades que precisam ser discutidas. Uma vez que a tarefa é postulada por Banko et al. (2007) como a extração de todas as relações identificadas em um dado fragmento textual, sem limitação de domínio de interesse, tal tarefa impõe imensa dificuldade aos esforços de avaliação.\n",
            "\n",
            "De fato, Glauber et al. (2018) relatam um esforço de anotação de dados para a tarefa em língua portuguesa em que foram identificados por anotadores humanos mais de 400 relacionamentos em um corpus de 25 sentenças retiradas de textos jornalísticos e de enciclopédia. Assim, a avaliação de EIA deu-se, em grande parte de seu desenvolvimento e maturação, em conjuntos de dados não anotados, recorrendo a avaliações qualitativas das saídas dos sistemas e comparação direta por humanos das extrações obtidas.\n",
            "\n",
            "Nesses esforços de avaliação, a precisão do sistema pode ser mensurada a partir da avaliação humana das saídas. Não é possível, entretanto, avaliar medidas como cobertura e F1, dada a inexistência de uma referência do conjunto total de relacionamentos a serem identificados. Assim, os autores da área propuseram diferentes métricas a fim de estimar tais valores, como a métrica rendimento (yield) (Fader; Soderland; Etzioni, 2011; Schmitz et al., 2012).\n",
            "\n",
            "A métrica de rendimento consiste no núemro de extrações válidas, i.e. corretas, de um dado sistema. Como calcular tal medida é, na maioria dos casos, impraticável dada a grande quantidade de extrações realizadas pelos sistemas, ela pode ser estimada a partir da precisão do sistema calculada sobre uma amostra aleatória das extrações realizadas (\\(P'\\)). Assim, podemos estimar o rendimento como:\n",
            "\n",
            "Y = P'\\cdot \\#(\\mbox{extrações realizadas})\n",
            "\n",
            "Foi também explorada a estratégia de criação (semi-)automática de conjuntos de dados usando vários sistemas (Del Corro; Gemulla, 2013), estratégias de supervisão fraca (Smirnova; Cudré-Mauroux, 2018), ou a geração de corpora para a tarefa a partir da transformação de anotações de tarefas próximas, como identificação de papéis temáticos (Semantic Role Labeling) por (Stanovsky et al., 2018). Corpora gerados de forma semi-automática vêm ganhando atenção na literatura recente, particularmente para a língua inglesa, devido a necessidade de dados anotados para se utilizar técnicas de aprendizado de máquina e redes neurais em EIA. Corpora como o OIE2016 (Stanovsky et al., 2018), Wire57 (Léchelle; Gotti; Langlais, 2018) e CARB (Bhardwaj; Aggarwal; Mausam, 2019) vêm se tornando corpora de referência em língua inglesa para o problema, apesar dos problemas existentes na construção de tais recursos – a não exaustividade das relações anotadas.\n",
            "\n",
            "Para a língua portuguesa, foram propostas algumas iniciativas para avaliar os sistemas da OIE. Uma avaliação conjunta foi promovida durante o Fórum Ibérico de Avaliação de Línguas (IberLEF) em 2019 (Collovini et al., 2019). A avaliação foi feita usando o corpus proposto por Glauber et al. (2018), que é composto por 442 relacionamentos extraídos de 25 frases de fontes como a seção em português da Wikipédia, o corpus CETENFolha, resenhas de filmes do portal Adoro Cinema2 e o corpus Europarl. Apesar desta tarefa ter contemplado quatro cenários de avaliação, a avaliação geral dos sistemas permaneceu consistente nos diferentes cenários, indicando robustez nos resultados da avaliação. No geral, os sistemas DPTOIE (Oliveira; Claro; Souza, 2022) e Linguakit (Gamallo; Garcia, 2015) tiveram o melhor desempenho, com o Linguakit2 dominando as avaliações de correspondência exata e o DPTOIE as avaliações de correspondências parciais (Collovini et al., 2019).\n",
            "\n",
            "Outra abordagem de avaliação foi idealizada por (Malenchini et al., 2019). Seu foco foi a avaliação extrínseca dos sistemas de EIA através de sua contribuição na tarefa de respostas automáticas a perguntas. Os autores apresentaram um conjunto de dados de referência (benchmark) para avaliação extrínseca de sistemas de EIA em textos de língua portuguesa. Os sistemas que alcançaram os melhores valores na avaliação realizada pelos autores foram os sistemas ArgOE (Gamallo; Garcia, 2015), DependentIE (Glauber; Claro; Oliveira, 2019) e DptOIE (Oliveira; Claro; Souza, 2022).\n",
            "\n",
            "Este capítulo descreveu uma visão geral da área de Extração de Informação, apresentando a Extração de Informação Tradicional e a Extração de Informação Aberta. Transversalmente, apresentamos as formalizações necessárias e os conceitos fundamentais para a compreensão da EIA, assim como a avaliação da área e as heranças de outras áreas afins, tais como RI.\n",
            "\n",
            "Nessa primeira versão, este capítulo descreveu de maneira bem sucinta as abordagens propostas para EI e EIA durante seu desenvolvimento histórico e as abordagens atuais da literatura, como as utilizando modelos de linguagens. Especificamente, a utilização da arquitetura Transformers, descritas no Capítulo 15 para as tarefas de EI e EIA tem sido bastante difundida para a língua inglesa e tem atuado em diversas áreas da PLN.\n",
            "\n",
            "Agradecemos as colaborações dos autores deste Capítulo e suas indicações, assim como agradecemos a Adriana Pagano e Aline Macohin pela revisão e comentários.\n",
            "\n",
            "Em nossa terminologia, por um relacionamento.↩︎\n",
            "\n",
            "parte do cap 9\n",
            "\n",
            "Algumas dificuldades com a análise do exemplo, à luz da OWN-PT, foram:\n",
            "\n",
            "A partir da associação de uma palavra a um synset, um parser semântico pode, por exemplo, expandir o texto com tais informações semânticas, servindo como entrada para sistemas de entendimento de linguagem natural.\n",
            "\n",
            "Como dito anteriormente, as bases não são sempre corretas e, definitivamente, não são completas. A língua muda, evolue o tempo todo e os significados das palavras seguem essa evolução. Nesse sentido, outros recursos léxico-semânticos são propostos e visam preencher lacunas na semântica das linguagens naturais. Na próxima subseção, detalharemos o recurso léxico-semântico FrameNet. Essa base se tornou relevante para a tarefa de Anotação de Papéis Semânticos (Semantic Role Labeling – SRL) pela abrangência e por incluir os papéis semânticos associados a substantivos e adjetivos.\n",
            "\n",
            "FrameNet (Baker; Fillmore; Lowe, 1998), da Universidade de Berkeley17, é um recurso com conhecimento léxico e semântico baseado na semântica de frames (Fillmore et al., 1976) e na teoria de frames de (Minsky, 1975). Um frame é uma estrutura hierárquica conceitual que define uma situação, objeto ou evento por meio de seus participantes e relacionamentos. FrameNet faz parte da classe de recursos léxico-semânticos que suportam a tarefa de Anotação de Papéis Semânticos (Semantic Role Labeling - SRL), pois provê uma base de relações semânticas entre predicados e argumentos. Por exemplo, no evento de cometimento de crime, definido pelo frame Commiting_crime, são definidas as seguintes relações entre os verbos “cometer” ou “perpetrar” e os argumentos “criminoso”, “crime”, “explicação”, “frequência”, “instrumento”, “maneira”, dentre outros. Essas relações são denominadas de papéis semânticos, pois expressam funções que os diferentes constituintes de uma sentença desempenham em relação ao verbo ou predicado da sentença. FrameNet difere-se de outros recursos para SRL, como PropBank (Palmer; Gildea; Kingsbury, 2005) e VerbNet (Kipper; Dang; Palmer, 2000), na medida em que associa papéis semânticos não somente a verbos, mas também a substantivos, a adjetivos, a advérbios, e até a proposições.\n",
            "\n",
            "A Figura 9.4 apresenta um recorte da definição e componentes do frame Commiting_crime18.\n",
            "\n",
            "Como se pode observar na Figura 9.4, o frame é formado por vários componentes, descritos a seguir:\n",
            "\n",
            "Além da definição individual de cada frame, a FrameNet possui relações semânticas entre frames, denominadas relações frame-to-frame. Alguns exemplos são: Inherits_from (herda de), Is_Inherited_by (é herdado por), Is_Used_by` (é usado por). Em (Ruppenhofer et al., 2006, pp. 104-111), tem-se a descrição das relações frame-to-frame* suportadas pela FrameNet.\n",
            "\n",
            "Atualmente, a FrameNet contém 1224 frames, 10.478 elementos de frames (papéis semânticos), e 13.687 unidades lexicais20.\n",
            "\n",
            "FrameNet fornece uma nova perspectiva para um recurso léxico-semântico. O significado de palavras ou unidades lexicais é dado no contexto das situações em que podem participar (frames), por meio dos papéis que podem assumir. FrameNet não poderia substituir completamente a WordNet porque falta à primeira muitas das relações semânticas úteis como meronímia e hiperonímia. Embora haja uma interseção entre essas bases, elas se distinguem em boa parte. Enquanto a WordNet foca em relações entre synsets organizando uma hierarquia e taxonomia do mundo, a FrameNet foca nas relações que ocorrem em eventos.\n",
            "\n",
            "Alguns projetos visam relacionar as entradas lexicais dessas duas bases. É o caso do projeto SemLink21, cujo objetivo é vincular diferentes recursos léxico-semânticos por meio de um conjunto de mapeamentos. Estes mapeamentos permitirão combinar as diferentes informações fornecidas por esses diferentes recursos lexicais para tarefas como inferência em linguagem natural (Natural Language Inference – NLI). Os recursos mapeados pelo SemLink são WordNet, FrameNet, VerbNet e PropBank.\n",
            "\n",
            "FrameNet Brasil (FN-Br)22 (Salomão, 2009), iniciativa de pesquisa lexicográfica, em desenvolvimento na Universidade Federal de Juiz de Fora (UFJF) desde 2008, tem o objetivo de construir e evoluir, para o português, a contraparte linguística da rede semântica original FrameNet. Atualmente, a base da FN-Br é a base mais robusta e representativa do paradigma da Semântica de Frames para o português. Foi construída através da tradução automática dos frames existentes na FrameNet original, e posterior adaptação para o português brasileiro. Este processo de adaptação envolveu traduzir e ajustar a descrição e os elementos dos frames para garantir que eles sejam relevantes e aplicáveis ao contexto brasileiro. Além da adaptação dos frames originais da FrameNet, no âmbito de alguns projetos, como o COPA 2014 (Torrent et al., 2014) e FLAME23, relativos aos domínios de esporte e turismo, respectivamente, foram criados novos frames para representar conceitos e situações específicos da cultura e do português brasileiro. O corpus FN-Br é constituído pela combinação de mais de 16 corpora, todos caracterizados por permitir acesso público e que representam usos do português europeu e do português brasileiro. Em 2009, de acordo com (Salomão, 2009), os corpora totalizavam pouco mais de 280 milhões de palavras.\n",
            "\n",
            "A Figura 9.5 apresenta um recorte da definição e componentes do frame Cometer_crime da FN-Br24, adaptado do frame Commiting_crime da FrameNet de Berkeley (vide Figura 9.4).\n",
            "\n",
            "parte do cap 17\n",
            "\n",
            "Daniela Barreiro Claro \n",
            "\n",
            "Joaquim Santos \n",
            "\n",
            "Marlo Souza \n",
            "\n",
            "Renata Vieira \n",
            "\n",
            "Vládia Pinheiro \n",
            "\n",
            "PDF\n",
            "\n",
            "A Extração de Informação (EI) é desenvolvida com o objetivo de se obter informação estruturada de dados não-estruturados (Jurafsky; Martin, 2023; Konstantinova, 2014).\n",
            "\n",
            "Os primeiros trabalhos a debruçarem-se sobre o problema remontam à década de 1970, com a aplicação de gramáticas formais e parsers sintáticos para a estruturação de informação em domínios como prontuários médicos (Sager, 1978; Sager; Friedman; Lyman, 1987) e textos jornalísticos (DeJong, 1979). A comunidade científica demonstrou grande interesse pela área nas décadas posteriores devido à sua utilidade prática, seu foco no processamento de dados reais, suas tarefas bem-definidas e a facilidade de mensurar a qualidade dos resultados em comparação com o desempenho humano na mesma tarefa (Cowie; Lehnert, 1996).\n",
            "\n",
            "Para autores como Eisenstein (2019) e Jurafsky; Martin (2023), a EI é normalmente dividida em diversas tarefas de interesse, com foco no tipo de informação a ser extraída do texto. Entre as mais comumente citadas na literatura estão o Reconhecimento de Entidades Nomeadas (REN), a Extração de Relações (ER) e a Extração de Eventos (EE).\n",
            "\n",
            "O Reconhecimento de Entidades Nomeadas (REN) consiste em identificar e classificar entidades mencionadas em textos através de designadores rígidos como nomes próprios, expressões temporais e espécies biológicas (Nadeau, 2007). Esse é considerado por alguns como um primeiro passo na análise semântica de um texto (Santos; Cardoso, 2007a), pois permite identificar as entidades às quais se faz referência nele.\n",
            "\n",
            "A Extração de Relações (ER), também chamada de extração de informação tradicional ou somente extração de informação, por sua vez, diz respeito à identificação de relacionamentos semânticos entre duas ou mais entidades, ou seja, identificar “quem fez o que para quem e quando”. Ananiadou; Mcnaught (2005) a definem como o processo de extrair fatos (em nossa terminologia, relacionamentos) a partir de uma fonte textual e representá-los a partir de um gabarito (em inglês, template). As relações são elementos essenciais para o entendimento da informação relatada no texto e sua identificação é passo essencial para a estruturação da mesma. Assim, identificar relações entre entidades é tarefa essencial para construção de bases de conhecimento e de grande utilidade na construção de soluções para a resposta automática a perguntas (em inglês, query answering), sumarização, recuperação de informação e mais (Nasar; Jaffry; Malik, 2021).\n",
            "\n",
            "A extração de eventos consiste na tarefa de identificação de uma menção a um evento em uma sentença e, se existirem, extração de outras informações sobre o evento. Um evento pode, por sua vez, ser entendido como uma ocorrência específica envolvendo participantes (Consortium, 2005), i.e., algo que acontece e que pode ser descrito como uma mudança de estado da qual participam entidades como agentes. Devido a intrínseca natureza temporal dos eventos, tal problema possui uma natureza mais complexa e costuma possuir tratamento específico.\n",
            "\n",
            "Assim, nesse capítulo, iniciaremos com um pouco de história da Extração de Informação (EI) e sua evolução para Extração de Informação Aberta, e destacaremos as tarefas de Reconhecimeno de Entidades Nomeadas (REN) e Extração de Relação (ER).\n",
            "\n",
            "Os primeiros trabalhos que abordaram o problema de EI dos quais temos conhecimento surgiram no final da década de 1970. Esses primeiros trabalhos da década de 1970 e 1980 tinham como modelo geral a aplicação de regras para a identificação de informações especificadas em um gabarito. Tais sistemas empregavam analisadores sintáticos (parsers) e regras definidas especificamente para o domínio e gênero textual estudado.\n",
            "\n",
            "Entre esses primeiros trabalhos, estão aqueles de Sager (1978), Sager; Friedman; Lyman (1987), de DeJong (1979) e de Cowie (1983). Sager et al. exploraram como identificar informações do estado de saúde de pacientes através dos textos de prontuários médicos. DeJong (1979), por sua vez, descrevem o sistema FRUMP que, a partir de um parser e regras de análise conceitual baseadas em uma arquitetura cognitiva proposta pelos autores e no conceito de dependência conceitual de Schank et al. (1973), processavam textos de notícias e realizavam tarefas como sumarização e identificação de papéis semânticos associados aos constituintes da sentença. Cowie (1983), por fim, descreve um sistema que emprega regras simples de segmentação e análise sintática rasa para identificar propriedades de plantas a partir de textos descritivos no campo da botânica. Diferente dos métodos anteriores, o trabalho dos autores se baseia em grande parte no estudo de padrões de descrição das informações a serem identificadas, em detrimento do emprego de parsers robustos da língua.\n",
            "\n",
            "A década de 1990 traz um grande interesse na área de EI com a implementação das conferências MUC (do inglês, Message Understanding Conference, ou Conferência de Compreensão de Mensagem), promovidas pela Agência de Projetos de Pesquisa Avançada de Defesa (DARPA, do inglês Defense Advanced Research Projects Agency). As conferências MUC, realizadas e financiadas pelo exército americano, representaram um esforço em avançar a tecnologia de EI e consistiam de tarefas de avaliação conjunta de métodos desenvolvidos por pesquisadores para problemas propostos pelos organizadores. As sete conferências realizadas de 1987 a 1997, foram cruciais para definir aspectos centrais da área, como estruturar a tarefa de ER, definindo suas métricas de avaliação, e propor a tarefa de REN (Grishman; Sundheim, 1996).\n",
            "\n",
            "parte do cap 9\n",
            "\n",
            "Algumas dificuldades com a análise do exemplo, à luz da OWN-PT, foram:\n",
            "\n",
            "A partir da associação de uma palavra a um synset, um parser semântico pode, por exemplo, expandir o texto com tais informações semânticas, servindo como entrada para sistemas de entendimento de linguagem natural.\n",
            "\n",
            "Como dito anteriormente, as bases não são sempre corretas e, definitivamente, não são completas. A língua muda, evolue o tempo todo e os significados das palavras seguem essa evolução. Nesse sentido, outros recursos léxico-semânticos são propostos e visam preencher lacunas na semântica das linguagens naturais. Na próxima subseção, detalharemos o recurso léxico-semântico FrameNet. Essa base se tornou relevante para a tarefa de Anotação de Papéis Semânticos (Semantic Role Labeling – SRL) pela abrangência e por incluir os papéis semânticos associados a substantivos e adjetivos.\n",
            "\n",
            "FrameNet (Baker; Fillmore; Lowe, 1998), da Universidade de Berkeley17, é um recurso com conhecimento léxico e semântico baseado na semântica de frames (Fillmore et al., 1976) e na teoria de frames de (Minsky, 1975). Um frame é uma estrutura hierárquica conceitual que define uma situação, objeto ou evento por meio de seus participantes e relacionamentos. FrameNet faz parte da classe de recursos léxico-semânticos que suportam a tarefa de Anotação de Papéis Semânticos (Semantic Role Labeling - SRL), pois provê uma base de relações semânticas entre predicados e argumentos. Por exemplo, no evento de cometimento de crime, definido pelo frame Commiting_crime, são definidas as seguintes relações entre os verbos “cometer” ou “perpetrar” e os argumentos “criminoso”, “crime”, “explicação”, “frequência”, “instrumento”, “maneira”, dentre outros. Essas relações são denominadas de papéis semânticos, pois expressam funções que os diferentes constituintes de uma sentença desempenham em relação ao verbo ou predicado da sentença. FrameNet difere-se de outros recursos para SRL, como PropBank (Palmer; Gildea; Kingsbury, 2005) e VerbNet (Kipper; Dang; Palmer, 2000), na medida em que associa papéis semânticos não somente a verbos, mas também a substantivos, a adjetivos, a advérbios, e até a proposições.\n",
            "\n",
            "A Figura 9.4 apresenta um recorte da definição e componentes do frame Commiting_crime18.\n",
            "\n",
            "Como se pode observar na Figura 9.4, o frame é formado por vários componentes, descritos a seguir:\n",
            "\n",
            "Além da definição individual de cada frame, a FrameNet possui relações semânticas entre frames, denominadas relações frame-to-frame. Alguns exemplos são: Inherits_from (herda de), Is_Inherited_by (é herdado por), Is_Used_by` (é usado por). Em (Ruppenhofer et al., 2006, pp. 104-111), tem-se a descrição das relações frame-to-frame* suportadas pela FrameNet.\n",
            "\n",
            "Atualmente, a FrameNet contém 1224 frames, 10.478 elementos de frames (papéis semânticos), e 13.687 unidades lexicais20.\n",
            "\n",
            "FrameNet fornece uma nova perspectiva para um recurso léxico-semântico. O significado de palavras ou unidades lexicais é dado no contexto das situações em que podem participar (frames), por meio dos papéis que podem assumir. FrameNet não poderia substituir completamente a WordNet porque falta à primeira muitas das relações semânticas úteis como meronímia e hiperonímia. Embora haja uma interseção entre essas bases, elas se distinguem em boa parte. Enquanto a WordNet foca em relações entre synsets organizando uma hierarquia e taxonomia do mundo, a FrameNet foca nas relações que ocorrem em eventos.\n",
            "\n",
            "Alguns projetos visam relacionar as entradas lexicais dessas duas bases. É o caso do projeto SemLink21, cujo objetivo é vincular diferentes recursos léxico-semânticos por meio de um conjunto de mapeamentos. Estes mapeamentos permitirão combinar as diferentes informações fornecidas por esses diferentes recursos lexicais para tarefas como inferência em linguagem natural (Natural Language Inference – NLI). Os recursos mapeados pelo SemLink são WordNet, FrameNet, VerbNet e PropBank.\n",
            "\n",
            "FrameNet Brasil (FN-Br)22 (Salomão, 2009), iniciativa de pesquisa lexicográfica, em desenvolvimento na Universidade Federal de Juiz de Fora (UFJF) desde 2008, tem o objetivo de construir e evoluir, para o português, a contraparte linguística da rede semântica original FrameNet. Atualmente, a base da FN-Br é a base mais robusta e representativa do paradigma da Semântica de Frames para o português. Foi construída através da tradução automática dos frames existentes na FrameNet original, e posterior adaptação para o português brasileiro. Este processo de adaptação envolveu traduzir e ajustar a descrição e os elementos dos frames para garantir que eles sejam relevantes e aplicáveis ao contexto brasileiro. Além da adaptação dos frames originais da FrameNet, no âmbito de alguns projetos, como o COPA 2014 (Torrent et al., 2014) e FLAME23, relativos aos domínios de esporte e turismo, respectivamente, foram criados novos frames para representar conceitos e situações específicos da cultura e do português brasileiro. O corpus FN-Br é constituído pela combinação de mais de 16 corpora, todos caracterizados por permitir acesso público e que representam usos do português europeu e do português brasileiro. Em 2009, de acordo com (Salomão, 2009), os corpora totalizavam pouco mais de 280 milhões de palavras.\n",
            "\n",
            "A Figura 9.5 apresenta um recorte da definição e componentes do frame Cometer_crime da FN-Br24, adaptado do frame Commiting_crime da FrameNet de Berkeley (vide Figura 9.4).\n",
            "\n",
            "parte do cap 17\n",
            "\n",
            "A partir da MUC-3, em 1991, a conferência passa a ter foco no processamento de textos jornalísticos em detrimento dos relatórios militares utilizados anteriormente (DARPA, 1991). Com a disponibilidade de dados e o incentivo no desenvolvimento de soluções para a tarefa, vemos na década de 1990 o surgimento das primeiras aplicações comerciais de EI, como o JASPER (Andersen et al., 1992)., construído para a agência de notícias Reuters.\n",
            "\n",
            "A MUC-6, ocorrida em 1995, introduz a tarefa de REN com o intuito de ser uma tarefa de uso prático, independente de domínio e que poderia ser realizada automaticamente em um futuro próximo (Grishman; Sundheim, 1996). Enquanto os trabalhos em REN se avolumaram a partir de sua proposição na MUC-6, trabalhos anteriores como Rau (1991) e Wolinski; Vichot; Dillet (1995) já se debruçavam sobre o problema de identificação e classificação de nomes próprios. Desde então, o interesse na tarefa cresceu significativamente e outras conferências de avaliação conjunta têm sido dedicadas a essa tarefa, como a Automatic Content Extraction (ACE) e a conferência Avaliação de Sistemas de Reconhecimento de Entidades Mencionadas (HAREM), dedicada exclusivamente à língua portuguesa, com sua primeira edição em 2005 (Santos; Cardoso, 2007a).\n",
            "\n",
            "Por outro lado, houve um crescimento de abordagens baseadas em dados nesta década, a partir da análise de corpora. Tais esforços são impulsionados pelos resultados positivos na área, como o trabalho de Hearst (1992). Logo, métodos baseados em dados passaram também a explorar o emprego de análise estatística e aprendizado de máquina na construção de padrões para a extração de relações (Riloff et al., 1993; Riloff; Jones; et al., 1999; Roark; Charniak, 2000; Soderland et al., 1995)\n",
            "\n",
            "Não foi somente na extração de padrões que métodos de aprendizado de máquina, em particular aprendizado supervisionado, foram aplicados. A década de 2000 viu a proliferação de métodos supervisionados aplicados à ER (Culotta; McCallum; Betz, 2006; Kambhatla, 2004; Zelenko; Aone; Richardella, 2003; Zhao; Grishman, 2005) e ao REN (Asahara; Matsumoto, 2003; McCallum; Li, 2003; Sekine, 1998).\n",
            "\n",
            "Devido à dificuldade de construção de dados para treinamento e padrões para extração, além da pouca adaptabilidade dos sistemas construídos para outros escopos e domínios, nos anos 2000, sistemas baseados em métodos de aprendizado semi-supervisionado, como o DIPRE (Brin, 1998) e Snowball (Agichtein; Gravano, 2000) começaram a aparecer, juntamente com os estudos sobre expansão automatizada de anotações (bootstrapping) (Riloff; Jones; et al., 1999). Também para entidades nomeadas, estudos investigaram como utilizar recursos da Web (Etzioni et al., 2005; Nadeau, 2007) ou corpora (Cucchiarelli; Velardi, 2001) para aprender entidades com pouco ou nenhum esforço de anotação.\n",
            "\n",
            "Buscando superar as dificuldades da limitação de escopo, i.e. das relações-alvo a serem extraídas e categorias de entidades a serem identificadas, ainda restritas à definição de padrões desde a criação dessas tarefas, Banko et al. (2007) propõe a tarefa de extração de informação aberta (EIA), também conhecida como Open Information Extraction, OpenIE ou OIE, a qual busca extrair todas as relações possíveis expressas em um texto, sem necessidade de pré-definição de relações e entidades.\n",
            "\n",
            "Devido ao recente sucesso da aplicação de métodos baseados em redes neurais, em particular deep learning e grandes modelos de linguagem, às tarefas de Processamento de Linguagem Natural, uma tendência atual da área se delineou como o estudo de arquiteturas neurais para os problemas de EI e a geração de grandes conjuntos de dados por supervisão fraca. Surveys recentes, como (Cui; Wei; Zhou, 2018; Konstantinova, 2014; Nasar; Jaffry; Malik, 2021), nos mostram a evolução da área em direção à aplicação de métodos neurais. Na vertente de geração de dados, vemos o emprego da Wikipédia e Freebase como fontes mais usadas para obter anotações de entidades e relações em textos (Nguyen; Theobald; Weikum, 2016; Smirnova; Cudré-Mauroux, 2018; Takamatsu; Sato; Nakagawa, 2012).\n",
            "\n",
            "Porém, toda a tarefa de EI necessita de uma concordância entre as definições de Entidade e Relação. Neste sentido, a próxima seção discute a conceituação de relação adotada neste capítulo, assim como o conceito de entidade.\n",
            "\n",
            "A natureza das relações estudadas na área de Extração de Informação e os critérios para reconhecer sua ocorrência em um texto têm recebido pouca atenção na literatura. Este é um passo importante para estabelecer metodologias adequadas para avaliar os sistemas, bem como para criar conjuntos de dados que possam apoiar a criação de sistemas futuros.\n",
            "\n",
            "Enquanto as noções de Relação e Entidade são de grande importância e já bem estudadas nas áreas de Computação, Linguística, Ciência da Informação e Filosofia da Linguagem, esses conceitos não são empregados de forma consistente entre as áreas, ou mesmo entre suas subáreas.\n",
            "\n",
            "Para Chen (1976), uma entidade é um objeto que pode ser concreto, tal como pessoa, livro, casa ou ainda abstrato, tal como um emprego, um sentimento, uma disciplina. As entidades podem estabelecer relações entre si. Duas ou mais entidades são vinculadas, ou seja conectadas por uma relação1.\n",
            "\n",
            "Tradicionalmente em reconhecimento de entidades nomeadas, as entidades consideradas são aquelas referenciadas por um nome próprio, acrescidas das referências temporais e valores que são expressões numéricas. Essas expressões, portanto, geralmente não constituem uma entrada em uma base lexical. Porém a tarefa se expandiu para domínios especializados, onde as entidades de interesse são mais conceituais. No domínio bio-médico por exemplo, podemos ter como exemplo de entidades de interesse, sintomas e tratamento que não são referenciadas por nomes próprios.\n",
            "\n",
            "Os conceitos de relação e relacionamento são noções fundamentais que vêm sendo estudadas em áreas como Ciência da Computação, Linguística e Filosofia.\n",
            "\n",
            "No campo de bancos de dados e modelagem conceitual, Chen (1976) define um relacionamento, no contexto da modelagem de Entidade-Relacionamento, como uma associação entre entidades. Guarino; Guizzardi (2015), por sua vez, estudando a natureza ontológica dos relacionamentos com base na semântica de veridadores (truthmaker semantics) (Fine, 2017), postulam relacionamentos como entidades que atuam como veridadores (thruthmakers) de alguma proposição relacionando duas ou mais entidades, ou seja, uma relação mantida entre essas entidades. Um veridador é um elemento cuja existência torna verdadeira uma proposição particular. Por exemplo, considerando a sentença (1) “a é uma maçã”, a existência de um objeto denotado pelo nome a que por acaso é uma maçã é uma condição suficiente para a verdade da frase (1). Como tal, dizemos que esse objeto é o veridador de (1). Tal definição nos permite adotar critérios ontológicos para validar a existência de relacionamentos a partir da informação relatada em um texto e, por isso, adotaremos tal definição de relacionamento neste capítulo.\n",
            "\n",
            "O conceito de relações é muito menos consistente na literatura. Ainda na área de modelagem conceitual, Guarino; Guizzardi (2015) definem as relações como proposições para as quais os relacionamentos são veridadores e, portanto, possuem conteúdo proposicional. Assim, podemos entender uma relação como um tipo para entidades como relacionamentos. Ou seja, relações são universais ontológicos que descrevem a natureza dos relacionamentos.\n",
            "\n",
            "Xavier; Lima; Souza (2015), no entanto, argumentam que a noção de relacionamento adotada na área de Extração de Informação é mais geral do que isso, não se limitando àquelas entre objetos e propriedades, mas também àquelas que descrevem ou implicam propriedades de classes gerais como descrito pela sentença (2) “Filósofos são autores de Livros”. Assim, para o contexto de EI consideramos relações como tipos de relacionamentos de primeira ou segunda ordem. Isso significa que uma relação é um tipo de relacionamento que existe entre objetos, suas propriedades e classes de objetos ou suas propriedades.\n",
            "\n",
            "parte do cap 9\n",
            "\n",
            "Algumas dificuldades com a análise do exemplo, à luz da OWN-PT, foram:\n",
            "\n",
            "A partir da associação de uma palavra a um synset, um parser semântico pode, por exemplo, expandir o texto com tais informações semânticas, servindo como entrada para sistemas de entendimento de linguagem natural.\n",
            "\n",
            "Como dito anteriormente, as bases não são sempre corretas e, definitivamente, não são completas. A língua muda, evolue o tempo todo e os significados das palavras seguem essa evolução. Nesse sentido, outros recursos léxico-semânticos são propostos e visam preencher lacunas na semântica das linguagens naturais. Na próxima subseção, detalharemos o recurso léxico-semântico FrameNet. Essa base se tornou relevante para a tarefa de Anotação de Papéis Semânticos (Semantic Role Labeling – SRL) pela abrangência e por incluir os papéis semânticos associados a substantivos e adjetivos.\n",
            "\n",
            "FrameNet (Baker; Fillmore; Lowe, 1998), da Universidade de Berkeley17, é um recurso com conhecimento léxico e semântico baseado na semântica de frames (Fillmore et al., 1976) e na teoria de frames de (Minsky, 1975). Um frame é uma estrutura hierárquica conceitual que define uma situação, objeto ou evento por meio de seus participantes e relacionamentos. FrameNet faz parte da classe de recursos léxico-semânticos que suportam a tarefa de Anotação de Papéis Semânticos (Semantic Role Labeling - SRL), pois provê uma base de relações semânticas entre predicados e argumentos. Por exemplo, no evento de cometimento de crime, definido pelo frame Commiting_crime, são definidas as seguintes relações entre os verbos “cometer” ou “perpetrar” e os argumentos “criminoso”, “crime”, “explicação”, “frequência”, “instrumento”, “maneira”, dentre outros. Essas relações são denominadas de papéis semânticos, pois expressam funções que os diferentes constituintes de uma sentença desempenham em relação ao verbo ou predicado da sentença. FrameNet difere-se de outros recursos para SRL, como PropBank (Palmer; Gildea; Kingsbury, 2005) e VerbNet (Kipper; Dang; Palmer, 2000), na medida em que associa papéis semânticos não somente a verbos, mas também a substantivos, a adjetivos, a advérbios, e até a proposições.\n",
            "\n",
            "A Figura 9.4 apresenta um recorte da definição e componentes do frame Commiting_crime18.\n",
            "\n",
            "Como se pode observar na Figura 9.4, o frame é formado por vários componentes, descritos a seguir:\n",
            "\n",
            "Além da definição individual de cada frame, a FrameNet possui relações semânticas entre frames, denominadas relações frame-to-frame. Alguns exemplos são: Inherits_from (herda de), Is_Inherited_by (é herdado por), Is_Used_by` (é usado por). Em (Ruppenhofer et al., 2006, pp. 104-111), tem-se a descrição das relações frame-to-frame* suportadas pela FrameNet.\n",
            "\n",
            "Atualmente, a FrameNet contém 1224 frames, 10.478 elementos de frames (papéis semânticos), e 13.687 unidades lexicais20.\n",
            "\n",
            "FrameNet fornece uma nova perspectiva para um recurso léxico-semântico. O significado de palavras ou unidades lexicais é dado no contexto das situações em que podem participar (frames), por meio dos papéis que podem assumir. FrameNet não poderia substituir completamente a WordNet porque falta à primeira muitas das relações semânticas úteis como meronímia e hiperonímia. Embora haja uma interseção entre essas bases, elas se distinguem em boa parte. Enquanto a WordNet foca em relações entre synsets organizando uma hierarquia e taxonomia do mundo, a FrameNet foca nas relações que ocorrem em eventos.\n",
            "\n",
            "Alguns projetos visam relacionar as entradas lexicais dessas duas bases. É o caso do projeto SemLink21, cujo objetivo é vincular diferentes recursos léxico-semânticos por meio de um conjunto de mapeamentos. Estes mapeamentos permitirão combinar as diferentes informações fornecidas por esses diferentes recursos lexicais para tarefas como inferência em linguagem natural (Natural Language Inference – NLI). Os recursos mapeados pelo SemLink são WordNet, FrameNet, VerbNet e PropBank.\n",
            "\n",
            "FrameNet Brasil (FN-Br)22 (Salomão, 2009), iniciativa de pesquisa lexicográfica, em desenvolvimento na Universidade Federal de Juiz de Fora (UFJF) desde 2008, tem o objetivo de construir e evoluir, para o português, a contraparte linguística da rede semântica original FrameNet. Atualmente, a base da FN-Br é a base mais robusta e representativa do paradigma da Semântica de Frames para o português. Foi construída através da tradução automática dos frames existentes na FrameNet original, e posterior adaptação para o português brasileiro. Este processo de adaptação envolveu traduzir e ajustar a descrição e os elementos dos frames para garantir que eles sejam relevantes e aplicáveis ao contexto brasileiro. Além da adaptação dos frames originais da FrameNet, no âmbito de alguns projetos, como o COPA 2014 (Torrent et al., 2014) e FLAME23, relativos aos domínios de esporte e turismo, respectivamente, foram criados novos frames para representar conceitos e situações específicos da cultura e do português brasileiro. O corpus FN-Br é constituído pela combinação de mais de 16 corpora, todos caracterizados por permitir acesso público e que representam usos do português europeu e do português brasileiro. Em 2009, de acordo com (Salomão, 2009), os corpora totalizavam pouco mais de 280 milhões de palavras.\n",
            "\n",
            "A Figura 9.5 apresenta um recorte da definição e componentes do frame Cometer_crime da FN-Br24, adaptado do frame Commiting_crime da FrameNet de Berkeley (vide Figura 9.4).\n",
            "\n",
            "parte do cap 17\n",
            "\n",
            "Enquanto os métodos tradicionais de Extração de Informação dependem de um conjunto pré-existente de relações semânticas bem definidas que são relevantes para um domínio específico, a noção de “relação” e “entidade” na literatura da área mais recente, tais como a Extração de Informação Aberta, requer mais aprofundamento por demandar um significado diferente, principalmente com diferente visões de autores. Esta indeterminação terminológica pode trazer problemas para comparar os resultados dos métodos propostos ou para reutilizar os conjuntos de dados criados na área.\n",
            "\n",
            "As seções seguintes exploram essas duas áreas: Extração de Informação e Extração de Informação Aberta.\n",
            "\n",
            "A Extração de Informação é caracterizada por obter informação estruturada a partir de textos, sendo entidades ou fatos, i.e. relacionamentos entre entidades, de tipos previamente definidos, conforme exemplo na Quadro 17.1. Métodos com limitação de escopo possuem como uma de suas principais desvantagens a necessidade de intervenção humana para especificar novos fatos a serem extraídos. Esta limitação impede que sistemas de Extração de Informação, doravante denominados de EI tradicional extraiam fatos fora do escopo pré-definido.\n",
            "\n",
            "Quadro 17.1 Exemplos de relações específicas na EI tradicional\n",
            "\n",
            "Fonte: (Souza; Claro, 2014)\n",
            "\n",
            "O Reconhecimento de Entidades Nomeadas (REN) consiste na tarefa de identificar e classificar expressões linguísticas, denominadas entidades nomeadas (EN), que referenciam entidades específicas num domínio de discurso, como nomes próprios, expressões temporais e espécies biológicas (Mota; Santos; Ranchhod, 2007; Nadeau, 2007). De uma forma geral, o REN pode ser dividido em duas etapas: a identificação (ou delimitação) da expressão, na qual as palavras que formam a EN são selecionadas; a classificação, em que é atribuída uma categoria semântica à EN.\n",
            "\n",
            "A classificação das ENs determina os tipos de entidades a serem consideradas e são especificadas a partir do escopo definido previamente para a tarefa. Algumas das categorias mais comumente utilizadas incluem as entidades que referenciam Pessoas Singulares (antropônimos); Coletivas (empresas e organizações) e Lugares (topônimos) (Mota; Santos; Ranchhod, 2007). Para exemplificar tomemos a sentença: “Renata Silva e Maria Costa palestraram na Universidade Federal da Bahia”. No exemplo temos três ENs: “Renata Silva”, “Maria Costa”, “Universidade Federal da Bahia”, sendo as duas primeiras correspondentes à categoria semântica Pessoa e a última, à categoria semântica Organização. Entretanto, existem outras categorias de ENs, como as menções a Obras (por exemplo, “Código Da Vinci”); Acontecimentos (por exemplo, “Festa de Santo Antônio”), Tempo (por exemplo, “meio-dia”); Coisa (por exemplo, “barco”), entre outras.\n",
            "\n",
            "O REN é uma tarefa com grande importância para o Processamento de Linguagem Natural, pois consiste numa primeira tarefa de análise semântica de um texto, com potencial aplicações a diversas tarefas. Por exemplo, em sistemas de perguntas e respostas, as perguntas frequentemente se referem a informações sobre entidades. Também, métodos de identificação de estruturas mais complexas, como eventos ou relações, dependem do bom desempenho do REN como uma etapa de pré-processamento (Socher et al., 2012; Zelenko; Aone; Richardella, 2003).\n",
            "\n",
            "A tarefa de extração de relações (ou de relacionamentos) (ER) refere-se a identificar relacionamentos entre entidades de um determinado escopo mencionadas em um texto (Jurafsky; Martin, 2023). O escopo, no contexto da ER, refere-se a um conjunto de relações-alvo de um determinado domínio de conhecimento ou aplicação a ser investigado. Por exemplo, o Quadro 17.2 apresenta alguns exemplos de relações no domínio de geografia brasileira. Na descrição das relações, os elementos em negrito referem-se às entidades em um dado relacionamento descrito pelo termo em itálico.\n",
            "\n",
            "Quadro 17.2 Exemplos de relações no domínio da geografia brasileira.\n",
            "\n",
            "Nesse contexto, a delimitação de um escopo ou domínio de interesse, concentra-se na determinação das relações a serem processadas, i.e. nos tipos de relacionamentos de interesse, assim como da natureza das entidades associadas por tais relações.\n",
            "\n",
            "As tarefas de reconhecimento de entidades nomeadas e extração de relações são interdependentes, no sentido de que a definição do escopo a ser estudado delimita tanto as categorias e natureza das entidades a serem extraídas, como também as relações entre essas entidades. Também, note-se que, pelo fato de as relações serem comumente definidas entre entidades de tipo especificado, como o caso da relação Tem_Prefeito no Quadro 17.2 que ocorre entre entidades das classes Cidade e Pessoa, tanto as informações das entidades mencionadas no texto são úteis para a extração de relações, quanto a informação das relações identificadas pode ser útil ao processo de identificação de entidades.\n",
            "\n",
            "De fato, na literatura recente, existem vários trabalhos que consideram a tarefa de extração conjunta de entidades e relações (ERE, do inglês Entity and Relation Joint Extraction), composta das tarefas de REN e ER (Agichtein; Gravano, 2000; Shaowei et al., 2022; Yuan et al., 2021). Enquanto normalmente abordagens estruturam suas soluções de forma sequencial, usualmente realizando REN inicialmente e, posteriormente, realizando ER, como nos trabalhos de (Hasegawa; Sekine; Grishman, 2004) e de (Socher et al., 2012), a literatura recente aponta para as vantagens da identificação conjunta ao permitir um melhor aprendizado de restrições para identificação de entidades e relações, c.f. o recente survey realizado por (Shaowei et al., 2022) sobre métodos para tal tarefa.\n",
            "\n",
            "Várias abordagens foram adotadas para o problema de EI durante seu desenvolvimento histórico. Enquanto abordagens iniciais privilegiavam métodos ricos em conhecimento, como regras e recursos linguísticos e de conhecimento de mundo, a literatura recente na área privilegia métodos baseados em dados, como o aprendizado de máquina, com o recente emprego de arquiteturas neurais aos problemas.\n",
            "\n",
            "A seguir faremos uma breve apresentação das abordagens descritas na literatura para os problemas de EI.\n",
            "\n",
            "parte do cap 9\n",
            "\n",
            "Algumas dificuldades com a análise do exemplo, à luz da OWN-PT, foram:\n",
            "\n",
            "A partir da associação de uma palavra a um synset, um parser semântico pode, por exemplo, expandir o texto com tais informações semânticas, servindo como entrada para sistemas de entendimento de linguagem natural.\n",
            "\n",
            "Como dito anteriormente, as bases não são sempre corretas e, definitivamente, não são completas. A língua muda, evolue o tempo todo e os significados das palavras seguem essa evolução. Nesse sentido, outros recursos léxico-semânticos são propostos e visam preencher lacunas na semântica das linguagens naturais. Na próxima subseção, detalharemos o recurso léxico-semântico FrameNet. Essa base se tornou relevante para a tarefa de Anotação de Papéis Semânticos (Semantic Role Labeling – SRL) pela abrangência e por incluir os papéis semânticos associados a substantivos e adjetivos.\n",
            "\n",
            "FrameNet (Baker; Fillmore; Lowe, 1998), da Universidade de Berkeley17, é um recurso com conhecimento léxico e semântico baseado na semântica de frames (Fillmore et al., 1976) e na teoria de frames de (Minsky, 1975). Um frame é uma estrutura hierárquica conceitual que define uma situação, objeto ou evento por meio de seus participantes e relacionamentos. FrameNet faz parte da classe de recursos léxico-semânticos que suportam a tarefa de Anotação de Papéis Semânticos (Semantic Role Labeling - SRL), pois provê uma base de relações semânticas entre predicados e argumentos. Por exemplo, no evento de cometimento de crime, definido pelo frame Commiting_crime, são definidas as seguintes relações entre os verbos “cometer” ou “perpetrar” e os argumentos “criminoso”, “crime”, “explicação”, “frequência”, “instrumento”, “maneira”, dentre outros. Essas relações são denominadas de papéis semânticos, pois expressam funções que os diferentes constituintes de uma sentença desempenham em relação ao verbo ou predicado da sentença. FrameNet difere-se de outros recursos para SRL, como PropBank (Palmer; Gildea; Kingsbury, 2005) e VerbNet (Kipper; Dang; Palmer, 2000), na medida em que associa papéis semânticos não somente a verbos, mas também a substantivos, a adjetivos, a advérbios, e até a proposições.\n",
            "\n",
            "A Figura 9.4 apresenta um recorte da definição e componentes do frame Commiting_crime18.\n",
            "\n",
            "Como se pode observar na Figura 9.4, o frame é formado por vários componentes, descritos a seguir:\n",
            "\n",
            "Além da definição individual de cada frame, a FrameNet possui relações semânticas entre frames, denominadas relações frame-to-frame. Alguns exemplos são: Inherits_from (herda de), Is_Inherited_by (é herdado por), Is_Used_by` (é usado por). Em (Ruppenhofer et al., 2006, pp. 104-111), tem-se a descrição das relações frame-to-frame* suportadas pela FrameNet.\n",
            "\n",
            "Atualmente, a FrameNet contém 1224 frames, 10.478 elementos de frames (papéis semânticos), e 13.687 unidades lexicais20.\n",
            "\n",
            "FrameNet fornece uma nova perspectiva para um recurso léxico-semântico. O significado de palavras ou unidades lexicais é dado no contexto das situações em que podem participar (frames), por meio dos papéis que podem assumir. FrameNet não poderia substituir completamente a WordNet porque falta à primeira muitas das relações semânticas úteis como meronímia e hiperonímia. Embora haja uma interseção entre essas bases, elas se distinguem em boa parte. Enquanto a WordNet foca em relações entre synsets organizando uma hierarquia e taxonomia do mundo, a FrameNet foca nas relações que ocorrem em eventos.\n",
            "\n",
            "Alguns projetos visam relacionar as entradas lexicais dessas duas bases. É o caso do projeto SemLink21, cujo objetivo é vincular diferentes recursos léxico-semânticos por meio de um conjunto de mapeamentos. Estes mapeamentos permitirão combinar as diferentes informações fornecidas por esses diferentes recursos lexicais para tarefas como inferência em linguagem natural (Natural Language Inference – NLI). Os recursos mapeados pelo SemLink são WordNet, FrameNet, VerbNet e PropBank.\n",
            "\n",
            "FrameNet Brasil (FN-Br)22 (Salomão, 2009), iniciativa de pesquisa lexicográfica, em desenvolvimento na Universidade Federal de Juiz de Fora (UFJF) desde 2008, tem o objetivo de construir e evoluir, para o português, a contraparte linguística da rede semântica original FrameNet. Atualmente, a base da FN-Br é a base mais robusta e representativa do paradigma da Semântica de Frames para o português. Foi construída através da tradução automática dos frames existentes na FrameNet original, e posterior adaptação para o português brasileiro. Este processo de adaptação envolveu traduzir e ajustar a descrição e os elementos dos frames para garantir que eles sejam relevantes e aplicáveis ao contexto brasileiro. Além da adaptação dos frames originais da FrameNet, no âmbito de alguns projetos, como o COPA 2014 (Torrent et al., 2014) e FLAME23, relativos aos domínios de esporte e turismo, respectivamente, foram criados novos frames para representar conceitos e situações específicos da cultura e do português brasileiro. O corpus FN-Br é constituído pela combinação de mais de 16 corpora, todos caracterizados por permitir acesso público e que representam usos do português europeu e do português brasileiro. Em 2009, de acordo com (Salomão, 2009), os corpora totalizavam pouco mais de 280 milhões de palavras.\n",
            "\n",
            "A Figura 9.5 apresenta um recorte da definição e componentes do frame Cometer_crime da FN-Br24, adaptado do frame Commiting_crime da FrameNet de Berkeley (vide Figura 9.4).\n",
            "\n",
            "parte do cap 17\n",
            "\n",
            "As abordagens iniciais para REN baseavam-se, majoritariamente, no emprego de regras lexico-sintáticas e consulta a almanaques (gazeeers). Tais abordagens dependem da construção de listas de nomes próprios como antropônimos, topônimos etc., e outras palavras, como “Ltda.”, “Jr.” etc., que auxiliam no processo de identificação e classificação de ENs complexas ou desconhecidas. Essa é, por exemplo, a abordagem empregada por Wolinski; Vichot; Dillet (1995) que combina almanaques e regras para a identificação e classificação de ENs. Posteriormente, almanaques foram também empregados em conjunção com métodos baseados em dados, como o trabalho de Florian et al. (2003) que os emprega aliados aos classificadores, enquanto Liu; Yao; Lin (2019) os utilizam durante o treinamento de uma rede neural, como um sinal de treinamento (parte da função de perda, ou loss em inglês).\n",
            "\n",
            "Muitos trabalhos debruçaram-se também sobre o problema de construção automática ou semi-automática de almanaques, dos quais os trabalhos de Nadeau (2007), de Riloff; Jones; et al. (1999) e de Etzioni et al. (2005) são alguns dos mais importantes.\n",
            "\n",
            "Enquanto as abordagens iniciais para o problema baseavam-se em regras, com a disponibilidade de dados anotados para a tarefa, tais métodos foram rapidamente suplantados por métodos baseados em dados, tais como: os métodos baseados em classificação (Asahara; Matsumoto, 2003; Sekine, 1998) e classificação sequencial (Bikel; Schwartz; Weischedel, 1999; McCallum; Li, 2003).\n",
            "\n",
            "A redução de REN à tarefa de classificação sequencial merece destaque pelos bons resultados obtidos. Tal redução se dá através de um esquema de codificação do problema que nos permite representar fragmentos textuais e sua classificação como um problema de rotulação ou etiquetação.\n",
            "\n",
            "Partindo-se do pressuposto de que os fragmentos textuais descrevendo entidades nomeadas são contíguos, podemos codificar a tarefa de delimitação de entidades como classificação sequencial empregando rótulos que descrevem os limites de uma EN, e.g. o esquema BIO com os rótulos B (do inglês, begin) para designar a palavra inicial de uma EN, I (do inglês, inside) para designar palavras que fazem parte da EN mas não a iniciam e O (do inglês, outside) para designar palavras que não pertencem a uma entidade. Da mesma forma, podemos estender nosso esquema de codificação para incluir as classes de interesse. Assim, seguindo o esquema BIO, teremos os rótulos B-PER e I-PER para descrever entidades da classe Pessoa.\n",
            "\n",
            "A redução do problema de REN à classificação sequencial está ilustrada no Exemplo 17.1.\n",
            "\n",
            "Exemplo 17.1  \n",
            "\n",
            "Renata/B-PER Silva/I-PER e/O Maria/B-PER Costa/I-PER palestraram/O na/O Universidade/B-ORG Federal/I-ORG da/I-ORG Bahia/I-ORG.\n",
            "\n",
            "Recentemente, destacam-se na literatura abordagens baseadas em redes neurais profundas, com uma grande concentração nos últimos anos em modelos gerativos de linguagem, devido aos resultados positivos obtidos por tais arquiteturas em diversas tarefas.\n",
            "\n",
            "Na literatura são de grande destaque os modelos recentes BART (Lewis et al., 2020), RoBERTa (Liu et al., 2019), T5 (Raffel et al., 2020), BERT (Devlin et al., 2019) e GPT-3 (Brown et al., 2020), conforme descritos no Capítulo 15.\n",
            "\n",
            "Similarmente, na língua portuguesa, nas duas edições do HAREM (Mota; Santos, 2008; Santos; Cardoso, 2007b), o primeiro esforço sistemático de desenvolvimento de soluções para a tarefa na língua, a maioria dos sistemas participantes baseava-se em métodos ricos em conhecimento, como regras e almanaques. De fato, nas duas avaliações, somente os sistemas MALINCHE (Solorio, 2007), NEURA (Ferrández et al., 2007) e R3M (Mota, 2008) não se baseavam em regras. Métodos baseados em classificação sequencial se seguiram para a língua portuguesa, como o RELP-CRF (Amaral; Vieira, 2014) baseado em um classificador sequencial. Mais recentemente, abordagens baseadas em redes neurais e modelos de linguagem foram desenvolvidas tornando-se o estado da arte da tarefa na língua. A Tabela 17.1 apresenta o atual estado da arte em português, com base no corpus HAREM. A métrica de avaliação apresentada, medida F1, será discutida na Seção 17.6.\n",
            "\n",
            "Souza; Nogueira; Lotufo (2020) desenvolveram um modelo BERT para o Português com 2,68 bilhões de tokens e aplicaram o modelo em um classificador CRF. Santos et al., avaliaram o impacto do modelo contextualizado Flair Embeddings aplicado a tarefa de REN junto com uma rede neural BiLSTM-CRF. Os autores também desenvolveram um modelo Flair Embeddings para o português, o FlairBBP, treinado com 4,9 bilhões de tokens (Santos et al., 2019). Castro; Silva; Soares (2018) utilizou uma rede LSTM e um classificador CRF junto com modelos Word Embeddings pré-treinados. Santos; Guimarães (2015) desenvolveram uma rede neural convolucional capaz de capturar características a nível de caracteres e também de incorporar word embeddings pré-treinados.\n",
            "\n",
            "O reconhecimento de entidades tem sido aplicado em muitas áreas específicas, como direito, saúde e geologia. Nesses casos há uma demanda de adaptação dos modelos preditivos de acordo com a nova linguagem especializada do domínio e um novo conjunto de rótulos que devem ser aprendidos. Da mesma forma, são necessários novos conjuntos de dados para o processo de aprendizado, uma vez que abordagens de aprendizado de máquina necessitam de exemplos anotados para se chegar a um modelo preditivo eficaz.\n",
            "\n",
            "Muitos trabalhos endereçam domínios específicos, citamos exemplos em diversas línguas. Para o inglês, uma rede neural BiLSTM-CRF para o domínio biomédico é proposta em (Habibi et al., 2017).\n",
            "\n",
            "Um conjunto de dados do domínio jurídico em língua alemã é apresentado por Leitner; Rehm; Schneider (2019), que empregam redes neurais BiLSTM para a rotulação dos textos. Em (Qiu et al., 2019), uma rede neural BiLSTM-CRF com mecanismo de atenção é aplicada para reconhecer entidades geológicas para a língua chinesa.\n",
            "\n",
            "parte do cap 9\n",
            "\n",
            "Algumas dificuldades com a análise do exemplo, à luz da OWN-PT, foram:\n",
            "\n",
            "A partir da associação de uma palavra a um synset, um parser semântico pode, por exemplo, expandir o texto com tais informações semânticas, servindo como entrada para sistemas de entendimento de linguagem natural.\n",
            "\n",
            "Como dito anteriormente, as bases não são sempre corretas e, definitivamente, não são completas. A língua muda, evolue o tempo todo e os significados das palavras seguem essa evolução. Nesse sentido, outros recursos léxico-semânticos são propostos e visam preencher lacunas na semântica das linguagens naturais. Na próxima subseção, detalharemos o recurso léxico-semântico FrameNet. Essa base se tornou relevante para a tarefa de Anotação de Papéis Semânticos (Semantic Role Labeling – SRL) pela abrangência e por incluir os papéis semânticos associados a substantivos e adjetivos.\n",
            "\n",
            "FrameNet (Baker; Fillmore; Lowe, 1998), da Universidade de Berkeley17, é um recurso com conhecimento léxico e semântico baseado na semântica de frames (Fillmore et al., 1976) e na teoria de frames de (Minsky, 1975). Um frame é uma estrutura hierárquica conceitual que define uma situação, objeto ou evento por meio de seus participantes e relacionamentos. FrameNet faz parte da classe de recursos léxico-semânticos que suportam a tarefa de Anotação de Papéis Semânticos (Semantic Role Labeling - SRL), pois provê uma base de relações semânticas entre predicados e argumentos. Por exemplo, no evento de cometimento de crime, definido pelo frame Commiting_crime, são definidas as seguintes relações entre os verbos “cometer” ou “perpetrar” e os argumentos “criminoso”, “crime”, “explicação”, “frequência”, “instrumento”, “maneira”, dentre outros. Essas relações são denominadas de papéis semânticos, pois expressam funções que os diferentes constituintes de uma sentença desempenham em relação ao verbo ou predicado da sentença. FrameNet difere-se de outros recursos para SRL, como PropBank (Palmer; Gildea; Kingsbury, 2005) e VerbNet (Kipper; Dang; Palmer, 2000), na medida em que associa papéis semânticos não somente a verbos, mas também a substantivos, a adjetivos, a advérbios, e até a proposições.\n",
            "\n",
            "A Figura 9.4 apresenta um recorte da definição e componentes do frame Commiting_crime18.\n",
            "\n",
            "Como se pode observar na Figura 9.4, o frame é formado por vários componentes, descritos a seguir:\n",
            "\n",
            "Além da definição individual de cada frame, a FrameNet possui relações semânticas entre frames, denominadas relações frame-to-frame. Alguns exemplos são: Inherits_from (herda de), Is_Inherited_by (é herdado por), Is_Used_by` (é usado por). Em (Ruppenhofer et al., 2006, pp. 104-111), tem-se a descrição das relações frame-to-frame* suportadas pela FrameNet.\n",
            "\n",
            "Atualmente, a FrameNet contém 1224 frames, 10.478 elementos de frames (papéis semânticos), e 13.687 unidades lexicais20.\n",
            "\n",
            "FrameNet fornece uma nova perspectiva para um recurso léxico-semântico. O significado de palavras ou unidades lexicais é dado no contexto das situações em que podem participar (frames), por meio dos papéis que podem assumir. FrameNet não poderia substituir completamente a WordNet porque falta à primeira muitas das relações semânticas úteis como meronímia e hiperonímia. Embora haja uma interseção entre essas bases, elas se distinguem em boa parte. Enquanto a WordNet foca em relações entre synsets organizando uma hierarquia e taxonomia do mundo, a FrameNet foca nas relações que ocorrem em eventos.\n",
            "\n",
            "Alguns projetos visam relacionar as entradas lexicais dessas duas bases. É o caso do projeto SemLink21, cujo objetivo é vincular diferentes recursos léxico-semânticos por meio de um conjunto de mapeamentos. Estes mapeamentos permitirão combinar as diferentes informações fornecidas por esses diferentes recursos lexicais para tarefas como inferência em linguagem natural (Natural Language Inference – NLI). Os recursos mapeados pelo SemLink são WordNet, FrameNet, VerbNet e PropBank.\n",
            "\n",
            "FrameNet Brasil (FN-Br)22 (Salomão, 2009), iniciativa de pesquisa lexicográfica, em desenvolvimento na Universidade Federal de Juiz de Fora (UFJF) desde 2008, tem o objetivo de construir e evoluir, para o português, a contraparte linguística da rede semântica original FrameNet. Atualmente, a base da FN-Br é a base mais robusta e representativa do paradigma da Semântica de Frames para o português. Foi construída através da tradução automática dos frames existentes na FrameNet original, e posterior adaptação para o português brasileiro. Este processo de adaptação envolveu traduzir e ajustar a descrição e os elementos dos frames para garantir que eles sejam relevantes e aplicáveis ao contexto brasileiro. Além da adaptação dos frames originais da FrameNet, no âmbito de alguns projetos, como o COPA 2014 (Torrent et al., 2014) e FLAME23, relativos aos domínios de esporte e turismo, respectivamente, foram criados novos frames para representar conceitos e situações específicos da cultura e do português brasileiro. O corpus FN-Br é constituído pela combinação de mais de 16 corpora, todos caracterizados por permitir acesso público e que representam usos do português europeu e do português brasileiro. Em 2009, de acordo com (Salomão, 2009), os corpora totalizavam pouco mais de 280 milhões de palavras.\n",
            "\n",
            "A Figura 9.5 apresenta um recorte da definição e componentes do frame Cometer_crime da FN-Br24, adaptado do frame Commiting_crime da FrameNet de Berkeley (vide Figura 9.4).\n",
            "\n",
            "parte do cap 17\n",
            "\n",
            "Para o português, um corpus para detecção de eventos de quedas de pacientes em prontuários eletrônicos é descrito em (Santos; Santos; Vieira, 2020). Os autores usaram uma rede neural BiLSTM-CRF+Flair para gerar um modelo classificador de tokens. Um corpus no domínio jurídico, tendo categorias específicas como legislação e jurisprudência é proposto por  Araujo et al. (2018), que usaram uma rede neural BiLSTM-CRF para criar um primeiro baseline para esse corpus. Ademais, Consoli et al. (2020) analisam um corpus no domínio de geologia usando uma rede neural BiLSTM-CRF com um modelo contextualizado Flair Embeddings.\n",
            "\n",
            "As abordagens iniciais para o problema de ER baseavam-se na definição de gabaritos e regras de extração, com base em informação sintática obtida de analisadores sintáticos rasos ou profundos (Cowie, 1983; Sager, 1978). Tais métodos foram rapidamente suplantados por métodos baseados em dados e padrões obtidos de corpora, como os famosos padrões de Hearst (1992) para identificação de relações de hiponímia.\n",
            "\n",
            "O trabalho de Hearst (1992) se baseou na definição de padrões lexico-sintáticos para expressão de relações de hiponímia e hiperonímia a partir de uma análise de corpus. Ao escolher a relação de hiponímia, que ocorre em todo domínio, e padrões gerais baseados em aspectos da língua, como os representados no Quadro 17.3, o autor garante generalizabilidade dos padrões obtidos para diversos domínios e aplicações.\n",
            "\n",
            "Quadro 17.3 Exemplos de Padrões de Hearst para hiponímia\n",
            "\n",
            "Devido à dificuldade de construção manual das regras, os métodos de Riloff et al. (1993), empregam heurísticas para geração de padrões baseadas em informação gramatical, e de Soderland et al. (1995), que se baseia numa semântica de quadros (frames) empregando um analisador semântico e medidas de qualidade de identificação de exemplos, baseado no percentual de acerto sobre relacionamentos previamente conhecidos, para identificação de quadros relevantes.\n",
            "\n",
            "As abordagens baseadas em aprendizado de máquina, hoje as mais comuns e com melhor desempenho na literatura (Konstantinova, 2014; Nasar; Jaffry; Malik, 2021) dividem-se em abordagens que realizam reconhecimento de entidades e extração de relações de forma conjunta e separada.\n",
            "\n",
            "Abordagens baseadas na realização de REN e ER de forma separada baseiam-se em um fluxo de processamento em que, em geral, as entidades são identificadas primeiro e a tarefa de ER se reduz a identificar quando uma sentença ou fragmento textual denota uma relação semântica entre duas entidades. Consideremos o Exemplo 17.2, retirado de (Socher et al., 2012):\n",
            "\n",
            "Exemplo 17.2  \n",
            "\n",
            "Gripe aviária]\\(_{e1}\\) é uma doença infecciosa causada pelo vírus da [influenza tipo a]\\(_{e2}\\)\n",
            "\n",
            "Podemos, então, reduzir o problema de identificar a relação Causa-Efeito(\\(e1\\),\\(e2\\)) a um problema de classificação textual, identificando se a sentença acima fornece indícios para a expressão da relação de interesse. As soluções propostas na literatura para o problema são variadas e baseadas em diferentes métodos.\n",
            "\n",
            "Zelenko; Aone; Richardella (2003), por exemplo, propõem funções de kernel para árvores sintáticas rasas, i.e. funções que descrevem medidas de similaridade entre tais árvores. Eles empregam tais medidas para treinar um classificador de perceptron com votação (voted perceptron) sobre relações no domínio de organizações extraídas de um corpus de textos jornalísticos. De forma similar, Zhao; Grishman (2005) empregam diferentes funções de kernel sobre informações sintáticas relevantes para a identificação de relação e argumentos visando treinar um classificador SVM sobre o corpus de ER da conferência ACE.\n",
            "\n",
            "Culotta; McCallum; Betz (2006), por outro lado, empregam um classificador sequencial baseado em modelos escondidos de Markov para identificação de relações em um texto. Ao restringir sua análise a textos biográficos, os autores reduzem o processo de identificar instâncias de relações à identificação de fragmento textual que delimita o argumento e sua classificação, tarefa para a qual a classificação sequencial já é comumente utilizada. Consideremos o Exemplo 17.3 sobre George W. Bush, retirado de (Culotta; McCallum; Betz, 2006):\n",
            "\n",
            "Exemplo 17.3  \n",
            "\n",
            "George é filho de \\(\\underbrace{\\mbox{George H. W. Bush}}_{\\mbox{pai}}\\) e \\(\\underbrace{\\mbox{Barbara Bush}}_{\\mbox{mãe}}\\).\n",
            "\n",
            "Ao identificar o papel de pai e mãe, os autores conseguem construir a relação Pai(George H. W. Bush, George W. Bush) e Mãe(Barbara Bush, George W. Bush).\n",
            "\n",
            "parte do cap 9\n",
            "\n",
            "Algumas dificuldades com a análise do exemplo, à luz da OWN-PT, foram:\n",
            "\n",
            "A partir da associação de uma palavra a um synset, um parser semântico pode, por exemplo, expandir o texto com tais informações semânticas, servindo como entrada para sistemas de entendimento de linguagem natural.\n",
            "\n",
            "Como dito anteriormente, as bases não são sempre corretas e, definitivamente, não são completas. A língua muda, evolue o tempo todo e os significados das palavras seguem essa evolução. Nesse sentido, outros recursos léxico-semânticos são propostos e visam preencher lacunas na semântica das linguagens naturais. Na próxima subseção, detalharemos o recurso léxico-semântico FrameNet. Essa base se tornou relevante para a tarefa de Anotação de Papéis Semânticos (Semantic Role Labeling – SRL) pela abrangência e por incluir os papéis semânticos associados a substantivos e adjetivos.\n",
            "\n",
            "FrameNet (Baker; Fillmore; Lowe, 1998), da Universidade de Berkeley17, é um recurso com conhecimento léxico e semântico baseado na semântica de frames (Fillmore et al., 1976) e na teoria de frames de (Minsky, 1975). Um frame é uma estrutura hierárquica conceitual que define uma situação, objeto ou evento por meio de seus participantes e relacionamentos. FrameNet faz parte da classe de recursos léxico-semânticos que suportam a tarefa de Anotação de Papéis Semânticos (Semantic Role Labeling - SRL), pois provê uma base de relações semânticas entre predicados e argumentos. Por exemplo, no evento de cometimento de crime, definido pelo frame Commiting_crime, são definidas as seguintes relações entre os verbos “cometer” ou “perpetrar” e os argumentos “criminoso”, “crime”, “explicação”, “frequência”, “instrumento”, “maneira”, dentre outros. Essas relações são denominadas de papéis semânticos, pois expressam funções que os diferentes constituintes de uma sentença desempenham em relação ao verbo ou predicado da sentença. FrameNet difere-se de outros recursos para SRL, como PropBank (Palmer; Gildea; Kingsbury, 2005) e VerbNet (Kipper; Dang; Palmer, 2000), na medida em que associa papéis semânticos não somente a verbos, mas também a substantivos, a adjetivos, a advérbios, e até a proposições.\n",
            "\n",
            "A Figura 9.4 apresenta um recorte da definição e componentes do frame Commiting_crime18.\n",
            "\n",
            "Como se pode observar na Figura 9.4, o frame é formado por vários componentes, descritos a seguir:\n",
            "\n",
            "Além da definição individual de cada frame, a FrameNet possui relações semânticas entre frames, denominadas relações frame-to-frame. Alguns exemplos são: Inherits_from (herda de), Is_Inherited_by (é herdado por), Is_Used_by` (é usado por). Em (Ruppenhofer et al., 2006, pp. 104-111), tem-se a descrição das relações frame-to-frame* suportadas pela FrameNet.\n",
            "\n",
            "Atualmente, a FrameNet contém 1224 frames, 10.478 elementos de frames (papéis semânticos), e 13.687 unidades lexicais20.\n",
            "\n",
            "FrameNet fornece uma nova perspectiva para um recurso léxico-semântico. O significado de palavras ou unidades lexicais é dado no contexto das situações em que podem participar (frames), por meio dos papéis que podem assumir. FrameNet não poderia substituir completamente a WordNet porque falta à primeira muitas das relações semânticas úteis como meronímia e hiperonímia. Embora haja uma interseção entre essas bases, elas se distinguem em boa parte. Enquanto a WordNet foca em relações entre synsets organizando uma hierarquia e taxonomia do mundo, a FrameNet foca nas relações que ocorrem em eventos.\n",
            "\n",
            "Alguns projetos visam relacionar as entradas lexicais dessas duas bases. É o caso do projeto SemLink21, cujo objetivo é vincular diferentes recursos léxico-semânticos por meio de um conjunto de mapeamentos. Estes mapeamentos permitirão combinar as diferentes informações fornecidas por esses diferentes recursos lexicais para tarefas como inferência em linguagem natural (Natural Language Inference – NLI). Os recursos mapeados pelo SemLink são WordNet, FrameNet, VerbNet e PropBank.\n",
            "\n",
            "FrameNet Brasil (FN-Br)22 (Salomão, 2009), iniciativa de pesquisa lexicográfica, em desenvolvimento na Universidade Federal de Juiz de Fora (UFJF) desde 2008, tem o objetivo de construir e evoluir, para o português, a contraparte linguística da rede semântica original FrameNet. Atualmente, a base da FN-Br é a base mais robusta e representativa do paradigma da Semântica de Frames para o português. Foi construída através da tradução automática dos frames existentes na FrameNet original, e posterior adaptação para o português brasileiro. Este processo de adaptação envolveu traduzir e ajustar a descrição e os elementos dos frames para garantir que eles sejam relevantes e aplicáveis ao contexto brasileiro. Além da adaptação dos frames originais da FrameNet, no âmbito de alguns projetos, como o COPA 2014 (Torrent et al., 2014) e FLAME23, relativos aos domínios de esporte e turismo, respectivamente, foram criados novos frames para representar conceitos e situações específicos da cultura e do português brasileiro. O corpus FN-Br é constituído pela combinação de mais de 16 corpora, todos caracterizados por permitir acesso público e que representam usos do português europeu e do português brasileiro. Em 2009, de acordo com (Salomão, 2009), os corpora totalizavam pouco mais de 280 milhões de palavras.\n",
            "\n",
            "A Figura 9.5 apresenta um recorte da definição e componentes do frame Cometer_crime da FN-Br24, adaptado do frame Commiting_crime da FrameNet de Berkeley (vide Figura 9.4).\n",
            "\n",
            "parte do cap 17\n",
            "\n",
            "Métodos baseados em redes neurais, de forma geral, costumam empregar técnicas de aprendizado de representação (Bengio; Courville; Vincent, 2013) para aprender representações do conteúdo semântico dos fragmentos textuais e reduzem o problema de ER à classificação textual. É o caso de Socher et al. (2012), que propõem a MV-RNN, uma rede neural que constrói um espaço de representação baseado em matrizes e vetores com o objetivo de capturar a composicionalidade de sentido de sintagmas e sentenças e os aplica para ER. Similarmente, Zeng et al. (2014) e Wang et al. (2016) empregam redes neurais convolucionais para obter representações vetoriais de sentenças que serão empregadas no processo de classificação quanto à relação expressa pela mesma.\n",
            "\n",
            "Abordagens baseadas em identificação sequencial de entidades e relações possuem desvantagens observadas na literatura. Primeiramente, como a ER é guiada pelas entidades identificadas no processo de REN, a propagação de erros da primeira tarefa pode ter impacto considerável na performance dos sistemas desenvolvidos. Segundo, uma vez que o contexto determinado limita tanto as tarefas de REN, quanto as de ER, existe uma interdependência entre as tarefas. Assim, propostas visando realizar a extração de entidades e relações de forma conjunta começaram a surgir na literatura recente, ganhando certo interesse da comunidade.\n",
            "\n",
            "As abordagens empregadas para tal tarefa são diversificadas, incluindo desde métodos de aprendizado relacional a redes neurais\n",
            "\n",
            "Roth; Yih (2007) propõem a utilização de métodos de programação inteira ao problema, baseados na teoria estatística de aprendizado relacional. Os autores utilizam classificadores locais para a identificação de entidades e relações e um classificador global que combina as informações dos classificadores locais em uma predição que maximiza a qualidade da extração, codificada por meio de restrições em programação inteira. Também baseados em modelos estatísticos, Yu; Lam (2010) propõem o uso de modelos gráficos globais para identificação de um descritor de relação e uma segmentação do texto para identificação dos argumentos.\n",
            "\n",
            "Li; Ji (2014) e Miwa; Bansal (2016), por sua vez, reduzem a tarefa de ERE à classificação sequencial, utilizando redes neurais recorrentes bidirecionais sequenciais e estruturadas com base na estrutura superficial e na árvore de dependências sintáticas da entrada para identificação conjunta de entidades e relações.\n",
            "\n",
            "A Extração de Informação Aberta (EIA), também conhecida como Open Information Extraction, Open IE ou OIE em inglês, é a tarefa de extrair informações estruturadas de documentos sem necessitar da pré-definição do contexto da tarefa, i.e. das relações e tipos de entidade de interesse. A tarefa foi inicialmente proposta pelo trabalho de (Banko et al., 2007) e ganhou popularidade nas últimas décadas devido à sua aplicabilidade para processar e estruturar o conhecimento a partir de grandes volumes de dados disponíveis na Web, seguindo o paradigma da Web como um Corpus (WaC) (Meyer et al., 2003).\n",
            "\n",
            "A EIA surge visando generalizar a tarefa de Extração de Relações. A principal diferença entre as duas abordagens, porém, reside na dependência da ER de uma especificação prévia do domínio de aplicação, bem como das relações alvo a serem identificadas, que a EIA visa eliminar.\n",
            "\n",
            "Seguindo o trabalho original de Banko et al. (2007), que propôs o sistema TextRunner, vários métodos e sistemas para EIA foram propostos na literatura (Del Corro; Gemulla, 2013; Fader; Soderland; Etzioni, 2011; Xavier; Lima; Souza, 2015), mas, como observado por Glauber; Claro (2018), os principais avanços na área se concentraram principalmente no idioma inglês.\n",
            "\n",
            "A EIA para a língua portuguesa tem uma história bastante recente. A partir dos trabalhos de Souza; Claro (2014), Pereira; Pinheiro (2015) e de (Barbosa; Glauber; Claro, 2016), têm crescido o número de estudos sobre a tarefa assim como os resultados obtidos por esses estudos, com recentes desenvolvimentos de métodos (Oliveira; Claro; Souza, 2022; Sena; Claro, 2019, 2020; Sena; Glauber; Claro, 2017; Souza; Claro; Glauber, 2018), construção do corpus (Glauber et al., 2018) e avaliação dos sistemas disponíveis (Glauber; Claro; Oliveira, 2019; Glauber; Claro; Sena, 2019; Malenchini et al., 2019).\n",
            "\n",
            "Embora a área tenha visto um crescimento recente para o desenvolvimento de métodos para línguas como o inglês, principalmente com a aplicação de métodos supervisionados e redes neurais, esses avanços ainda não foram incorporados na literatura sobre EIA para a língua portuguesa. A razão para isso é principalmente a falta de recursos linguísticos disponíveis para orientar o desenvolvimento de pesquisas para a língua. Embora o foco no idioma inglês possa ser devido ao seu uso generalizado em todo o mundo, foi reconhecido pela comunidade científica que esse foco no inglês com suas características particulares pode introduzir algum viés na área (Bender, 2009).\n",
            "\n",
            "Assim, esta seção aborda EIA para a língua portuguesa, incluindo uma formalização e a evolução das abordagens da área.\n",
            "\n",
            "A tarefa de EIA pode ser formalmente definida sendo \\(X = \\langle x_{1}, x_{2}, \\cdots, x_{n}\\rangle\\) uma sentença composta de tokens \\(x_i\\). Um extrator EIA é uma função que mapeia \\(X\\) em um conjunto \\(Y = \\langle y_{1}, y_{2}, \\cdots, y_{j} \\rangle\\) como um conjunto de tuplas \\(y \\_i = \\langle rel_i, arg1_i, arg2_i, \\cdots, argn_i\\rangle\\), que descrevem as informações expressas na sentença X. Neste capítulo, consideramos que as tuplas estão sempre no formato \\(y = (arg_{1 }, rel, arg_{2})\\), onde \\(arg1\\) e \\(arg2\\) são sintagmas nominais, não necessariamente formados por tokens presentes em X, e \\(rel\\) é um descritor de um relacionamento entre \\(arg_{1}\\) e \\(arg_{2}\\). Não consideraremos extrações formadas por mais de dois argumentos neste capítulo.\n",
            "\n",
            "Os primeiros métodos de EIA empregavam padrões de inspiração linguística para extração, como ArgOE (Gamallo; Garcia, 2015), ou adaptação de métodos para a língua inglesa, como SGS (Souza; Claro; Glauber, 2018), InferReVerbPT Sena; Glauber; Claro (2017) e RePort Pereira; Pinheiro (2015). Os trabalhos são principalmente influenciados por métodos baseados no inglês da chamada segunda geração de EIA (Fader; Soderland; Etzioni, 2011).\n",
            "\n",
            "O primeiro sistema de EIA para o português de que temos conhecimento foi o DepOE (Gamallo; Garcia; Fernández-Lanza, 2012). Ele executa a extração aberta multilíngue de triplas (inglês, espanhol, português e galego) usando o analisador sintático de dependências baseado em regras DepPattern. No entanto, nenhuma avaliação ou resultados são relatados para a língua portuguesa. Os autores apresentam somente uma comparação dos seus resultados com Reverb na língua inglesa.\n",
            "\n",
            "Souza; Claro (2014) se propuseram a analisar o conjunto de características mais representativas da língua portuguesa para a identificação de extrações válidas no contexto de EIA, tal qual empregado na língua inglesa com o sistema ReVerb (Fader; Soderland; Etzioni, 2011).\n",
            "\n",
            "parte do cap 9\n",
            "\n",
            "Algumas dificuldades com a análise do exemplo, à luz da OWN-PT, foram:\n",
            "\n",
            "A partir da associação de uma palavra a um synset, um parser semântico pode, por exemplo, expandir o texto com tais informações semânticas, servindo como entrada para sistemas de entendimento de linguagem natural.\n",
            "\n",
            "Como dito anteriormente, as bases não são sempre corretas e, definitivamente, não são completas. A língua muda, evolue o tempo todo e os significados das palavras seguem essa evolução. Nesse sentido, outros recursos léxico-semânticos são propostos e visam preencher lacunas na semântica das linguagens naturais. Na próxima subseção, detalharemos o recurso léxico-semântico FrameNet. Essa base se tornou relevante para a tarefa de Anotação de Papéis Semânticos (Semantic Role Labeling – SRL) pela abrangência e por incluir os papéis semânticos associados a substantivos e adjetivos.\n",
            "\n",
            "FrameNet (Baker; Fillmore; Lowe, 1998), da Universidade de Berkeley17, é um recurso com conhecimento léxico e semântico baseado na semântica de frames (Fillmore et al., 1976) e na teoria de frames de (Minsky, 1975). Um frame é uma estrutura hierárquica conceitual que define uma situação, objeto ou evento por meio de seus participantes e relacionamentos. FrameNet faz parte da classe de recursos léxico-semânticos que suportam a tarefa de Anotação de Papéis Semânticos (Semantic Role Labeling - SRL), pois provê uma base de relações semânticas entre predicados e argumentos. Por exemplo, no evento de cometimento de crime, definido pelo frame Commiting_crime, são definidas as seguintes relações entre os verbos “cometer” ou “perpetrar” e os argumentos “criminoso”, “crime”, “explicação”, “frequência”, “instrumento”, “maneira”, dentre outros. Essas relações são denominadas de papéis semânticos, pois expressam funções que os diferentes constituintes de uma sentença desempenham em relação ao verbo ou predicado da sentença. FrameNet difere-se de outros recursos para SRL, como PropBank (Palmer; Gildea; Kingsbury, 2005) e VerbNet (Kipper; Dang; Palmer, 2000), na medida em que associa papéis semânticos não somente a verbos, mas também a substantivos, a adjetivos, a advérbios, e até a proposições.\n",
            "\n",
            "A Figura 9.4 apresenta um recorte da definição e componentes do frame Commiting_crime18.\n",
            "\n",
            "Como se pode observar na Figura 9.4, o frame é formado por vários componentes, descritos a seguir:\n",
            "\n",
            "Além da definição individual de cada frame, a FrameNet possui relações semânticas entre frames, denominadas relações frame-to-frame. Alguns exemplos são: Inherits_from (herda de), Is_Inherited_by (é herdado por), Is_Used_by` (é usado por). Em (Ruppenhofer et al., 2006, pp. 104-111), tem-se a descrição das relações frame-to-frame* suportadas pela FrameNet.\n",
            "\n",
            "Atualmente, a FrameNet contém 1224 frames, 10.478 elementos de frames (papéis semânticos), e 13.687 unidades lexicais20.\n",
            "\n",
            "FrameNet fornece uma nova perspectiva para um recurso léxico-semântico. O significado de palavras ou unidades lexicais é dado no contexto das situações em que podem participar (frames), por meio dos papéis que podem assumir. FrameNet não poderia substituir completamente a WordNet porque falta à primeira muitas das relações semânticas úteis como meronímia e hiperonímia. Embora haja uma interseção entre essas bases, elas se distinguem em boa parte. Enquanto a WordNet foca em relações entre synsets organizando uma hierarquia e taxonomia do mundo, a FrameNet foca nas relações que ocorrem em eventos.\n",
            "\n",
            "Alguns projetos visam relacionar as entradas lexicais dessas duas bases. É o caso do projeto SemLink21, cujo objetivo é vincular diferentes recursos léxico-semânticos por meio de um conjunto de mapeamentos. Estes mapeamentos permitirão combinar as diferentes informações fornecidas por esses diferentes recursos lexicais para tarefas como inferência em linguagem natural (Natural Language Inference – NLI). Os recursos mapeados pelo SemLink são WordNet, FrameNet, VerbNet e PropBank.\n",
            "\n",
            "FrameNet Brasil (FN-Br)22 (Salomão, 2009), iniciativa de pesquisa lexicográfica, em desenvolvimento na Universidade Federal de Juiz de Fora (UFJF) desde 2008, tem o objetivo de construir e evoluir, para o português, a contraparte linguística da rede semântica original FrameNet. Atualmente, a base da FN-Br é a base mais robusta e representativa do paradigma da Semântica de Frames para o português. Foi construída através da tradução automática dos frames existentes na FrameNet original, e posterior adaptação para o português brasileiro. Este processo de adaptação envolveu traduzir e ajustar a descrição e os elementos dos frames para garantir que eles sejam relevantes e aplicáveis ao contexto brasileiro. Além da adaptação dos frames originais da FrameNet, no âmbito de alguns projetos, como o COPA 2014 (Torrent et al., 2014) e FLAME23, relativos aos domínios de esporte e turismo, respectivamente, foram criados novos frames para representar conceitos e situações específicos da cultura e do português brasileiro. O corpus FN-Br é constituído pela combinação de mais de 16 corpora, todos caracterizados por permitir acesso público e que representam usos do português europeu e do português brasileiro. Em 2009, de acordo com (Salomão, 2009), os corpora totalizavam pouco mais de 280 milhões de palavras.\n",
            "\n",
            "A Figura 9.5 apresenta um recorte da definição e componentes do frame Cometer_crime da FN-Br24, adaptado do frame Commiting_crime da FrameNet de Berkeley (vide Figura 9.4).\n",
            "\n",
            "parte do cap 17\n",
            "\n",
            "O sistema RePort (Pereira; Pinheiro, 2015), por outro lado, é uma adaptação do ReVerb para a língua portuguesa baseada em análise sintática rasa com regras sintáticas e lexicais. Os autores relatam que suas extrações apresentam grande similaridade com suas correlatas extraídas pelo ReVerb (dos textos traduzidos para o inglês).\n",
            "\n",
            "O RELP, proposto por Abreu; Vieira (2017), é um sistema aberto de extração de relações que extrai relações entre entidades nomeadas em um domínio de organização aplicando classificação sequencial com CRF (Conditional Random Fields). O sistema RelP extrai qualquer descritor de relação que expressa um relacionamento entre pares de entidades nomeadas (Organização, Pessoa ou Lugar), caracterizando-o como uma abordagem híbrida da REN com a EIA.\n",
            "\n",
            "O InferReVerbPT desenvolvido por Sena; Glauber; Claro (2017) baseia-se numa adaptação do sistema ReVerb para a língua portuguesa, expandindo-o com a extração de relacionamentos implícitos obtidos por inferência por propriedades de simetria e transitividade das relações com inferência transitiva e simétrica. Um classificador SVM foi empregado para realizar a inferência baseado nas propriedades semânticas do verbo central no descritor de relação.\n",
            "\n",
            "Souza; Claro; Glauber (2018) analisaram que a maior desvantagem dos estudos baseados em recursos linguísticos, como dados anotados, reside na escassez de tais recursos na maioria dos idiomas além do inglês. Assim, para mitigar esse problema, eles propõem um método de classificação de fatos baseado na similaridade de estruturas gramaticais (SGS). Sua abordagem modela estruturas morfosintáticas dos fatos (triplas descrevendo relacionamentos) para identificar padrões de semelhanças que podem ser usados para distinguir entre fatos válidos e inválidos. Eles aplicaram algoritmos de isomorfismo de grafos para detectar subgrafos descrevendo tais padrões.\n",
            "\n",
            "Um novo sistema de EIA baseado em análise de dependência foi proposto por Gamallo; Garcia (2015), chamado ArgOE. Tal sistema é multilíngue, baseado em heurísticas e utiliza a informação de dependência sintáticas do texto para analisar a estrutura de dependência do verbo, bem como um conjunto de regras para gerar os relacionamentos. A introdução de um Analisador de Dependência em sistemas de EIA focados inteiramente na língua portuguesa foi feita pelos autores Oliveira; Claro; Souza (2022). O DptOIE é baseado em análise de dependência e regras elaboradas manualmente. As sentenças são pré-processadas por meio de um tokenizador, um PoS Tagger e um analisador de dependências. Os autores propõem um acoplamento de três módulos para tratar casos particulares: conjunções coordenadas, orações subordinadas e aposto.\n",
            "\n",
            "Com a evolução dos métodos de EIA para a língua inglesa utilizando os modelos neurais, novas abordagens foram propostas também para a língua portuguesa.\n",
            "\n",
            "O primeiro trabalho que utilizou aprendizado supervisionado com rede neural profunda para o português foi o de Ro; Lee; Kang (2020) que descreve o sistema Multi2OIE. Os autores utilizaram o modelo de linguagem BERT multilíngue (Devlin et al., 2019) para obter representações vetoriais das palavras e reduzem a tarefa de EIA à classificação sequencial, identificado os fragmentos do texto que determinam os argumentos (\\(arg_1, arg_2\\)) e o descritor de relação (\\(rel\\)). Seu sistema foi capaz de produzir extrações para vários idiomas (inglês, português e espanhol), treinados, entretanto, sobre dados traduzidos do inglês.\n",
            "\n",
            "Stanovsky et al. (2018) propuseram uma abordagem de EIA para a língua inglesa baseada em triplas. Os mesmos fazem uso de uma classificação sequencial cuja limitação define uma tripla extraída para cada sentença. Este método utiliza uma arquitetura de Redes Neurais Recursivas (RNN) para realizar EIA. A EIA é formulada como uma tarefa de rotulagem de sequências, utilizando estratégias semelhantes às que foram aplicadas anteriormente a tarefas como o Reconhecimento de Entidades Nomeadas. Já os autores em Cui; Wei; Zhou (2018) e Zhang; Duh; Van Durme (2017) propõem modelar o problema da EIA como um problema de aprendizado sequência a sequência (seq2seq). Eles definem uma estrutura encoder-decoder para aprender argumentos e tuplas de relação inicializadas a partir de um sistema de EIA.\n",
            "\n",
            "Seguindo o trabalho de (Stanovsky et al., 2018), em 2022, Cabral; Souza; Claro (2022) propuseram PortNOIE, uma arquitetura neural para EIA em português que combina representações contextuais de palavras com codificadores neurais para extrair relacionamentos baseado em classificação sequencial iterativa. Diferente de outros métodos de classificação sequencial para EIA, os autores focam na extração de múltiplas triplas de uma mesma sentença.\n",
            "\n",
            "A avaliação sistemática de sistemas de EI foi estabelecida primeiramente nas conferências MUC, em particular na sua segunda edição, com o estabelecimento de gabaritos-padrão que deveriam ser utilizados por todos os sistemas participantes e a adoção de métricas de qualidade, baseadas naquelas usadas na área de recuperação de informação, que foram abordadas no Capítulo 16. Para avaliar a tarefa de extração de relações, a MUC-2 estabeleceu como métricas de qualidade do sistema as medidas de precisão e cobertura, também denominada de Recall ou Revocação.\n",
            "\n",
            "A precisão de um sistema reflete a qualidade de suas extrações, i.e., quantas das extrações realizadas estão corretas, dado um corpus de teste. A medida de precisão pode ser calculada como:\n",
            "\n",
            "P = \\frac{\\#(\\mbox{relacionamentos corretamente extraídos})}{\\#(\\mbox{relacionamentos extraídos pelo sistema})}\n",
            "\n",
            "A cobertura também conhecida como revocação, reflete quão abrangente um sistema é em suas extrações, i.e., quantas das extrações a serem realizadas em um corpus de teste, o sistema é capaz de realizar. A medida de cobertura pode ser calculada como:\n",
            "\n",
            "R = \\frac{\\#(\\mbox{relacionamentos extraídos})}{\\#(\\mbox{relacionamentos no \\textit{corpus}})}\n",
            "\n",
            "Enquanto a MUC-3 adicionou duas novas métricas de avaliação, a saber sobre-geração (overgeneration) e sub-geração (fallout), tais métricas receberam pouco interesse na literatura. De fato, Lehnert; Sundheim (1991) argumentam que tais métricas foram pouco informativas ou difíceis de calcular para a tarefa de EI e, portanto, abandonadas. Foi também empregado nessa conferência um sistema automático de avaliação disponibilizado às equipes participantes que permitiu uma maior compreensão do modelo de avaliação e, como discutem Lehnert; Sundheim (1991), um avanço qualitativo nos sistemas gerados.\n",
            "\n",
            "parte do cap 9\n",
            "\n",
            "Algumas dificuldades com a análise do exemplo, à luz da OWN-PT, foram:\n",
            "\n",
            "A partir da associação de uma palavra a um synset, um parser semântico pode, por exemplo, expandir o texto com tais informações semânticas, servindo como entrada para sistemas de entendimento de linguagem natural.\n",
            "\n",
            "Como dito anteriormente, as bases não são sempre corretas e, definitivamente, não são completas. A língua muda, evolue o tempo todo e os significados das palavras seguem essa evolução. Nesse sentido, outros recursos léxico-semânticos são propostos e visam preencher lacunas na semântica das linguagens naturais. Na próxima subseção, detalharemos o recurso léxico-semântico FrameNet. Essa base se tornou relevante para a tarefa de Anotação de Papéis Semânticos (Semantic Role Labeling – SRL) pela abrangência e por incluir os papéis semânticos associados a substantivos e adjetivos.\n",
            "\n",
            "FrameNet (Baker; Fillmore; Lowe, 1998), da Universidade de Berkeley17, é um recurso com conhecimento léxico e semântico baseado na semântica de frames (Fillmore et al., 1976) e na teoria de frames de (Minsky, 1975). Um frame é uma estrutura hierárquica conceitual que define uma situação, objeto ou evento por meio de seus participantes e relacionamentos. FrameNet faz parte da classe de recursos léxico-semânticos que suportam a tarefa de Anotação de Papéis Semânticos (Semantic Role Labeling - SRL), pois provê uma base de relações semânticas entre predicados e argumentos. Por exemplo, no evento de cometimento de crime, definido pelo frame Commiting_crime, são definidas as seguintes relações entre os verbos “cometer” ou “perpetrar” e os argumentos “criminoso”, “crime”, “explicação”, “frequência”, “instrumento”, “maneira”, dentre outros. Essas relações são denominadas de papéis semânticos, pois expressam funções que os diferentes constituintes de uma sentença desempenham em relação ao verbo ou predicado da sentença. FrameNet difere-se de outros recursos para SRL, como PropBank (Palmer; Gildea; Kingsbury, 2005) e VerbNet (Kipper; Dang; Palmer, 2000), na medida em que associa papéis semânticos não somente a verbos, mas também a substantivos, a adjetivos, a advérbios, e até a proposições.\n",
            "\n",
            "A Figura 9.4 apresenta um recorte da definição e componentes do frame Commiting_crime18.\n",
            "\n",
            "Como se pode observar na Figura 9.4, o frame é formado por vários componentes, descritos a seguir:\n",
            "\n",
            "Além da definição individual de cada frame, a FrameNet possui relações semânticas entre frames, denominadas relações frame-to-frame. Alguns exemplos são: Inherits_from (herda de), Is_Inherited_by (é herdado por), Is_Used_by` (é usado por). Em (Ruppenhofer et al., 2006, pp. 104-111), tem-se a descrição das relações frame-to-frame* suportadas pela FrameNet.\n",
            "\n",
            "Atualmente, a FrameNet contém 1224 frames, 10.478 elementos de frames (papéis semânticos), e 13.687 unidades lexicais20.\n",
            "\n",
            "FrameNet fornece uma nova perspectiva para um recurso léxico-semântico. O significado de palavras ou unidades lexicais é dado no contexto das situações em que podem participar (frames), por meio dos papéis que podem assumir. FrameNet não poderia substituir completamente a WordNet porque falta à primeira muitas das relações semânticas úteis como meronímia e hiperonímia. Embora haja uma interseção entre essas bases, elas se distinguem em boa parte. Enquanto a WordNet foca em relações entre synsets organizando uma hierarquia e taxonomia do mundo, a FrameNet foca nas relações que ocorrem em eventos.\n",
            "\n",
            "Alguns projetos visam relacionar as entradas lexicais dessas duas bases. É o caso do projeto SemLink21, cujo objetivo é vincular diferentes recursos léxico-semânticos por meio de um conjunto de mapeamentos. Estes mapeamentos permitirão combinar as diferentes informações fornecidas por esses diferentes recursos lexicais para tarefas como inferência em linguagem natural (Natural Language Inference – NLI). Os recursos mapeados pelo SemLink são WordNet, FrameNet, VerbNet e PropBank.\n",
            "\n",
            "FrameNet Brasil (FN-Br)22 (Salomão, 2009), iniciativa de pesquisa lexicográfica, em desenvolvimento na Universidade Federal de Juiz de Fora (UFJF) desde 2008, tem o objetivo de construir e evoluir, para o português, a contraparte linguística da rede semântica original FrameNet. Atualmente, a base da FN-Br é a base mais robusta e representativa do paradigma da Semântica de Frames para o português. Foi construída através da tradução automática dos frames existentes na FrameNet original, e posterior adaptação para o português brasileiro. Este processo de adaptação envolveu traduzir e ajustar a descrição e os elementos dos frames para garantir que eles sejam relevantes e aplicáveis ao contexto brasileiro. Além da adaptação dos frames originais da FrameNet, no âmbito de alguns projetos, como o COPA 2014 (Torrent et al., 2014) e FLAME23, relativos aos domínios de esporte e turismo, respectivamente, foram criados novos frames para representar conceitos e situações específicos da cultura e do português brasileiro. O corpus FN-Br é constituído pela combinação de mais de 16 corpora, todos caracterizados por permitir acesso público e que representam usos do português europeu e do português brasileiro. Em 2009, de acordo com (Salomão, 2009), os corpora totalizavam pouco mais de 280 milhões de palavras.\n",
            "\n",
            "A Figura 9.5 apresenta um recorte da definição e componentes do frame Cometer_crime da FN-Br24, adaptado do frame Commiting_crime da FrameNet de Berkeley (vide Figura 9.4).\n",
            "\n",
            "parte do cap 17\n",
            "\n",
            "Além das medidas de precisão e cobertura, assim como em tarefas de classificação de texto e recuperação de informação, utilizamos a média harmônica entre essas medidas, chamada medida F1, a fim de condensar a informação contida nas duas. A medida F1 pode ser calculada como:\n",
            "\n",
            "F1 = \\frac{2*P*R}{P+R}\n",
            "\n",
            "A avaliação da tarefa de REN segue padrões semelhantes aos aplicados à tarefa de ER. De fato, desde a MUC-6 (Grishman; Sundheim, 1996), as medidas de precisão, cobertura e F1 tem sido usada consistentemente como métricas de avaliação da tarefa de REN em diversos esforços de avaliação, como a CoNNL (Sang; De Meulder, 2003), para a língua inglesa, e das duas edições do HAREM (Gonçalo Oliveira et al., 2008; Santos; Cardoso; Seco, 2007), com excessão à ACE (Doddington et al., 2004) que apresenta uma combinação da tarefa de REN com reconhecimento de co-referência entre entidades e utiliza um sistema de pontuação próprio.\n",
            "\n",
            "A avaliação de sistemas de EIA, por sua vez, possui algumas peculiaridades que precisam ser discutidas. Uma vez que a tarefa é postulada por Banko et al. (2007) como a extração de todas as relações identificadas em um dado fragmento textual, sem limitação de domínio de interesse, tal tarefa impõe imensa dificuldade aos esforços de avaliação.\n",
            "\n",
            "De fato, Glauber et al. (2018) relatam um esforço de anotação de dados para a tarefa em língua portuguesa em que foram identificados por anotadores humanos mais de 400 relacionamentos em um corpus de 25 sentenças retiradas de textos jornalísticos e de enciclopédia. Assim, a avaliação de EIA deu-se, em grande parte de seu desenvolvimento e maturação, em conjuntos de dados não anotados, recorrendo a avaliações qualitativas das saídas dos sistemas e comparação direta por humanos das extrações obtidas.\n",
            "\n",
            "Nesses esforços de avaliação, a precisão do sistema pode ser mensurada a partir da avaliação humana das saídas. Não é possível, entretanto, avaliar medidas como cobertura e F1, dada a inexistência de uma referência do conjunto total de relacionamentos a serem identificados. Assim, os autores da área propuseram diferentes métricas a fim de estimar tais valores, como a métrica rendimento (yield) (Fader; Soderland; Etzioni, 2011; Schmitz et al., 2012).\n",
            "\n",
            "A métrica de rendimento consiste no núemro de extrações válidas, i.e. corretas, de um dado sistema. Como calcular tal medida é, na maioria dos casos, impraticável dada a grande quantidade de extrações realizadas pelos sistemas, ela pode ser estimada a partir da precisão do sistema calculada sobre uma amostra aleatória das extrações realizadas (\\(P'\\)). Assim, podemos estimar o rendimento como:\n",
            "\n",
            "Y = P'\\cdot \\#(\\mbox{extrações realizadas})\n",
            "\n",
            "Foi também explorada a estratégia de criação (semi-)automática de conjuntos de dados usando vários sistemas (Del Corro; Gemulla, 2013), estratégias de supervisão fraca (Smirnova; Cudré-Mauroux, 2018), ou a geração de corpora para a tarefa a partir da transformação de anotações de tarefas próximas, como identificação de papéis temáticos (Semantic Role Labeling) por (Stanovsky et al., 2018). Corpora gerados de forma semi-automática vêm ganhando atenção na literatura recente, particularmente para a língua inglesa, devido a necessidade de dados anotados para se utilizar técnicas de aprendizado de máquina e redes neurais em EIA. Corpora como o OIE2016 (Stanovsky et al., 2018), Wire57 (Léchelle; Gotti; Langlais, 2018) e CARB (Bhardwaj; Aggarwal; Mausam, 2019) vêm se tornando corpora de referência em língua inglesa para o problema, apesar dos problemas existentes na construção de tais recursos – a não exaustividade das relações anotadas.\n",
            "\n",
            "Para a língua portuguesa, foram propostas algumas iniciativas para avaliar os sistemas da OIE. Uma avaliação conjunta foi promovida durante o Fórum Ibérico de Avaliação de Línguas (IberLEF) em 2019 (Collovini et al., 2019). A avaliação foi feita usando o corpus proposto por Glauber et al. (2018), que é composto por 442 relacionamentos extraídos de 25 frases de fontes como a seção em português da Wikipédia, o corpus CETENFolha, resenhas de filmes do portal Adoro Cinema2 e o corpus Europarl. Apesar desta tarefa ter contemplado quatro cenários de avaliação, a avaliação geral dos sistemas permaneceu consistente nos diferentes cenários, indicando robustez nos resultados da avaliação. No geral, os sistemas DPTOIE (Oliveira; Claro; Souza, 2022) e Linguakit (Gamallo; Garcia, 2015) tiveram o melhor desempenho, com o Linguakit2 dominando as avaliações de correspondência exata e o DPTOIE as avaliações de correspondências parciais (Collovini et al., 2019).\n",
            "\n",
            "Outra abordagem de avaliação foi idealizada por (Malenchini et al., 2019). Seu foco foi a avaliação extrínseca dos sistemas de EIA através de sua contribuição na tarefa de respostas automáticas a perguntas. Os autores apresentaram um conjunto de dados de referência (benchmark) para avaliação extrínseca de sistemas de EIA em textos de língua portuguesa. Os sistemas que alcançaram os melhores valores na avaliação realizada pelos autores foram os sistemas ArgOE (Gamallo; Garcia, 2015), DependentIE (Glauber; Claro; Oliveira, 2019) e DptOIE (Oliveira; Claro; Souza, 2022).\n",
            "\n",
            "Este capítulo descreveu uma visão geral da área de Extração de Informação, apresentando a Extração de Informação Tradicional e a Extração de Informação Aberta. Transversalmente, apresentamos as formalizações necessárias e os conceitos fundamentais para a compreensão da EIA, assim como a avaliação da área e as heranças de outras áreas afins, tais como RI.\n",
            "\n",
            "Nessa primeira versão, este capítulo descreveu de maneira bem sucinta as abordagens propostas para EI e EIA durante seu desenvolvimento histórico e as abordagens atuais da literatura, como as utilizando modelos de linguagens. Especificamente, a utilização da arquitetura Transformers, descritas no Capítulo 15 para as tarefas de EI e EIA tem sido bastante difundida para a língua inglesa e tem atuado em diversas áreas da PLN.\n",
            "\n",
            "Agradecemos as colaborações dos autores deste Capítulo e suas indicações, assim como agradecemos a Adriana Pagano e Aline Macohin pela revisão e comentários.\n",
            "\n",
            "Em nossa terminologia, por um relacionamento.↩︎\n",
            "\n",
            "parte do cap 9\n",
            "\n",
            "Outras iniciativas culminaram na geração de bases de frames em português, todas de menor tamanho que a FN-Br e para domínios ainda mais específicos.\n",
            "\n",
            "A base FrameFOR (Barreira; Pinheiro; Furtado, 2017) é uma base com 113 frames em português brasileiro, adaptados da FrameNet original, contendo os papéis semânticos, unidades e entradas lexicais relacionados aos tipos de crimes mais investigados na Perícia Forense do Estado do Ceará, no Brasil (PEFOCE) – formação de quadrilha, tráfico de drogas, sequestro, corrupção, receptação, contrabando, pedofilia, estupro, agressão, tortura, falsificação, ameaça, porte ilegal de arma, estelionato, e extorsão.\n",
            "\n",
            "O estudo de (Bertoldi, 2011) analisou os limites da criação automática de léxicos computacionais segundo o paradigma FrameNet, comparando as unidades lexicais evocadoras, os papéis semânticos e a estrutura do frame Criminal_process, em inglês e português. Esse estudo contrastivo mostrou que os frames do domínio jurídico são socialmente orientados e que a criação automática de léxicos em áreas cultural e socialmente orientadas tende a apresentar divergências. Em (Bick, 2009) tem-se a proposta de PFN-PT, um sistema para a anotação semântica automática do português, consistindo numa nova framenet contendo cerca de 13.000 padrões sintáticos, cobrindo 7.300 lemas verbais com 10.700 sentidos.\n",
            "\n",
            "Todos estes projetos, ainda que de menor porte, possuem relatos de sucesso em aplicações de PLN como extração de informação, anotação de papéis semânticos, reconhecimento de entidades nomeadas, evidenciando a importância de abordar as peculiaridades linguísticas com perspectivas contextualizadas e culturalmente relevantes.\n",
            "\n",
            "Nesta seção, usaremos a FrameNet de Berkeley para analisar o exemplo motivador definido no início da Seção 9.1. No Exemplo 9.3 são destacados o frame associado, as unidades lexicais (elemento evocador) que evocaram o frame e os papéis semânticos identificados no texto.\n",
            "\n",
            "Exemplo 9.3  \n",
            "\n",
            "Um assalto do tipo saidinha bancária, ocorrido na tarde desta terça-feira, terminou com uma mulher de 42 anos baleada pelos assaltantes. O roubo ocorreu na rua Professor Costa Mendes.\n",
            "\n",
            "Uma dificuldade com a análise desse exemplo, à luz da FrameNet, foi na identificação do papel semântico “vítima” (“uma mulher de 42 anos”), pois o complemento da sentença que a contém “…com uma mulher de 42 anos baleada …” possui a estrutura sintática Prep.Det.N (preposição + determinante + substantivo) e não é compatível com nenhuma realização sintática do elemento de frame victim.\n",
            "\n",
            "ConceptNet25 (Speer; Chin; Havasi, 2016) é uma base de conhecimento de senso comum que expressa relações rotuladas e ponderadas entre palavras ou fragmentos de textos em linguagem natural, através de um Grafo de Conhecimento (Knowledge Graph) contendo edges ou afirmações. Alguns exemplos de afirmações expressas na ConceptNet são:\n",
            "\n",
            "Sua versão original (Havasi; Speer; Alonso, 2007; Liu; Singh, 2004) foi criada pela equipe do MediaLab do Massachusetts Institute of Technology (MIT) em 1999, a partir de conhecimentos extraídos do projeto de construção coletiva (crowdsourcing) Open Mind Common Sense (OMCS) (Singh et al., 2002). O OMCS surgiu com o objetivo de coletar, pela Internet e de colaboradores voluntários, sentenças que expressavam fatos da vida comum. Por exemplo, a sentença “The Effect of [falling off a bike] is [you get hurt]” foi coletada de voluntários, quando solicitados a preencher os espaços do template “The Effect of [.….] is [.….]”. A alternativa adotada pela equipe da ConceptNet foi construir a rede semântica (nós conceituais interligados pelas relações semânticas), a partir de um processo automático sobre o corpus OMCS, o qual extraiu as relações semânticas e seus argumentos.\n",
            "\n",
            "A motivação do projeto que mantém a ConceptNet é expressar os fatos que as pessoas sabem comumente sobre o mundo ― conhecimento de senso comum ― através de afirmações que relacionam conceitos. Este tipo de conhecimento é importante porque, quando as pessoas se comunicam, seus proferimentos acontecem sobre suposições implícitas e básicas, as quais suportam e explicam boa parte dos raciocínios necessários para um bom nível de entendimento e, consequentemente, uma boa comunicação. Por exemplo, quando alguém fala “Eu comprei doces”, está implícito que usou dinheiro, ou quando fala “Fui a um casamento”, provavelmente tinha uma noiva, um noivo, uma festa com bolo e champagne, e o interlocutor está autorizado a perguntar “A noiva estava bonita?” etc.\n",
            "\n",
            "Atualmente, a ConceptNet26 evoluiu como um projeto colaborativo com diversas fontes:\n",
            "\n",
            "parte do cap 17\n",
            "\n",
            "Daniela Barreiro Claro \n",
            "\n",
            "Joaquim Santos \n",
            "\n",
            "Marlo Souza \n",
            "\n",
            "Renata Vieira \n",
            "\n",
            "Vládia Pinheiro \n",
            "\n",
            "PDF\n",
            "\n",
            "A Extração de Informação (EI) é desenvolvida com o objetivo de se obter informação estruturada de dados não-estruturados (Jurafsky; Martin, 2023; Konstantinova, 2014).\n",
            "\n",
            "Os primeiros trabalhos a debruçarem-se sobre o problema remontam à década de 1970, com a aplicação de gramáticas formais e parsers sintáticos para a estruturação de informação em domínios como prontuários médicos (Sager, 1978; Sager; Friedman; Lyman, 1987) e textos jornalísticos (DeJong, 1979). A comunidade científica demonstrou grande interesse pela área nas décadas posteriores devido à sua utilidade prática, seu foco no processamento de dados reais, suas tarefas bem-definidas e a facilidade de mensurar a qualidade dos resultados em comparação com o desempenho humano na mesma tarefa (Cowie; Lehnert, 1996).\n",
            "\n",
            "Para autores como Eisenstein (2019) e Jurafsky; Martin (2023), a EI é normalmente dividida em diversas tarefas de interesse, com foco no tipo de informação a ser extraída do texto. Entre as mais comumente citadas na literatura estão o Reconhecimento de Entidades Nomeadas (REN), a Extração de Relações (ER) e a Extração de Eventos (EE).\n",
            "\n",
            "O Reconhecimento de Entidades Nomeadas (REN) consiste em identificar e classificar entidades mencionadas em textos através de designadores rígidos como nomes próprios, expressões temporais e espécies biológicas (Nadeau, 2007). Esse é considerado por alguns como um primeiro passo na análise semântica de um texto (Santos; Cardoso, 2007a), pois permite identificar as entidades às quais se faz referência nele.\n",
            "\n",
            "A Extração de Relações (ER), também chamada de extração de informação tradicional ou somente extração de informação, por sua vez, diz respeito à identificação de relacionamentos semânticos entre duas ou mais entidades, ou seja, identificar “quem fez o que para quem e quando”. Ananiadou; Mcnaught (2005) a definem como o processo de extrair fatos (em nossa terminologia, relacionamentos) a partir de uma fonte textual e representá-los a partir de um gabarito (em inglês, template). As relações são elementos essenciais para o entendimento da informação relatada no texto e sua identificação é passo essencial para a estruturação da mesma. Assim, identificar relações entre entidades é tarefa essencial para construção de bases de conhecimento e de grande utilidade na construção de soluções para a resposta automática a perguntas (em inglês, query answering), sumarização, recuperação de informação e mais (Nasar; Jaffry; Malik, 2021).\n",
            "\n",
            "A extração de eventos consiste na tarefa de identificação de uma menção a um evento em uma sentença e, se existirem, extração de outras informações sobre o evento. Um evento pode, por sua vez, ser entendido como uma ocorrência específica envolvendo participantes (Consortium, 2005), i.e., algo que acontece e que pode ser descrito como uma mudança de estado da qual participam entidades como agentes. Devido a intrínseca natureza temporal dos eventos, tal problema possui uma natureza mais complexa e costuma possuir tratamento específico.\n",
            "\n",
            "Assim, nesse capítulo, iniciaremos com um pouco de história da Extração de Informação (EI) e sua evolução para Extração de Informação Aberta, e destacaremos as tarefas de Reconhecimeno de Entidades Nomeadas (REN) e Extração de Relação (ER).\n",
            "\n",
            "Os primeiros trabalhos que abordaram o problema de EI dos quais temos conhecimento surgiram no final da década de 1970. Esses primeiros trabalhos da década de 1970 e 1980 tinham como modelo geral a aplicação de regras para a identificação de informações especificadas em um gabarito. Tais sistemas empregavam analisadores sintáticos (parsers) e regras definidas especificamente para o domínio e gênero textual estudado.\n",
            "\n",
            "Entre esses primeiros trabalhos, estão aqueles de Sager (1978), Sager; Friedman; Lyman (1987), de DeJong (1979) e de Cowie (1983). Sager et al. exploraram como identificar informações do estado de saúde de pacientes através dos textos de prontuários médicos. DeJong (1979), por sua vez, descrevem o sistema FRUMP que, a partir de um parser e regras de análise conceitual baseadas em uma arquitetura cognitiva proposta pelos autores e no conceito de dependência conceitual de Schank et al. (1973), processavam textos de notícias e realizavam tarefas como sumarização e identificação de papéis semânticos associados aos constituintes da sentença. Cowie (1983), por fim, descreve um sistema que emprega regras simples de segmentação e análise sintática rasa para identificar propriedades de plantas a partir de textos descritivos no campo da botânica. Diferente dos métodos anteriores, o trabalho dos autores se baseia em grande parte no estudo de padrões de descrição das informações a serem identificadas, em detrimento do emprego de parsers robustos da língua.\n",
            "\n",
            "A década de 1990 traz um grande interesse na área de EI com a implementação das conferências MUC (do inglês, Message Understanding Conference, ou Conferência de Compreensão de Mensagem), promovidas pela Agência de Projetos de Pesquisa Avançada de Defesa (DARPA, do inglês Defense Advanced Research Projects Agency). As conferências MUC, realizadas e financiadas pelo exército americano, representaram um esforço em avançar a tecnologia de EI e consistiam de tarefas de avaliação conjunta de métodos desenvolvidos por pesquisadores para problemas propostos pelos organizadores. As sete conferências realizadas de 1987 a 1997, foram cruciais para definir aspectos centrais da área, como estruturar a tarefa de ER, definindo suas métricas de avaliação, e propor a tarefa de REN (Grishman; Sundheim, 1996).\n",
            "\n",
            "parte do cap 9\n",
            "\n",
            "Outras iniciativas culminaram na geração de bases de frames em português, todas de menor tamanho que a FN-Br e para domínios ainda mais específicos.\n",
            "\n",
            "A base FrameFOR (Barreira; Pinheiro; Furtado, 2017) é uma base com 113 frames em português brasileiro, adaptados da FrameNet original, contendo os papéis semânticos, unidades e entradas lexicais relacionados aos tipos de crimes mais investigados na Perícia Forense do Estado do Ceará, no Brasil (PEFOCE) – formação de quadrilha, tráfico de drogas, sequestro, corrupção, receptação, contrabando, pedofilia, estupro, agressão, tortura, falsificação, ameaça, porte ilegal de arma, estelionato, e extorsão.\n",
            "\n",
            "O estudo de (Bertoldi, 2011) analisou os limites da criação automática de léxicos computacionais segundo o paradigma FrameNet, comparando as unidades lexicais evocadoras, os papéis semânticos e a estrutura do frame Criminal_process, em inglês e português. Esse estudo contrastivo mostrou que os frames do domínio jurídico são socialmente orientados e que a criação automática de léxicos em áreas cultural e socialmente orientadas tende a apresentar divergências. Em (Bick, 2009) tem-se a proposta de PFN-PT, um sistema para a anotação semântica automática do português, consistindo numa nova framenet contendo cerca de 13.000 padrões sintáticos, cobrindo 7.300 lemas verbais com 10.700 sentidos.\n",
            "\n",
            "Todos estes projetos, ainda que de menor porte, possuem relatos de sucesso em aplicações de PLN como extração de informação, anotação de papéis semânticos, reconhecimento de entidades nomeadas, evidenciando a importância de abordar as peculiaridades linguísticas com perspectivas contextualizadas e culturalmente relevantes.\n",
            "\n",
            "Nesta seção, usaremos a FrameNet de Berkeley para analisar o exemplo motivador definido no início da Seção 9.1. No Exemplo 9.3 são destacados o frame associado, as unidades lexicais (elemento evocador) que evocaram o frame e os papéis semânticos identificados no texto.\n",
            "\n",
            "Exemplo 9.3  \n",
            "\n",
            "Um assalto do tipo saidinha bancária, ocorrido na tarde desta terça-feira, terminou com uma mulher de 42 anos baleada pelos assaltantes. O roubo ocorreu na rua Professor Costa Mendes.\n",
            "\n",
            "Uma dificuldade com a análise desse exemplo, à luz da FrameNet, foi na identificação do papel semântico “vítima” (“uma mulher de 42 anos”), pois o complemento da sentença que a contém “…com uma mulher de 42 anos baleada …” possui a estrutura sintática Prep.Det.N (preposição + determinante + substantivo) e não é compatível com nenhuma realização sintática do elemento de frame victim.\n",
            "\n",
            "ConceptNet25 (Speer; Chin; Havasi, 2016) é uma base de conhecimento de senso comum que expressa relações rotuladas e ponderadas entre palavras ou fragmentos de textos em linguagem natural, através de um Grafo de Conhecimento (Knowledge Graph) contendo edges ou afirmações. Alguns exemplos de afirmações expressas na ConceptNet são:\n",
            "\n",
            "Sua versão original (Havasi; Speer; Alonso, 2007; Liu; Singh, 2004) foi criada pela equipe do MediaLab do Massachusetts Institute of Technology (MIT) em 1999, a partir de conhecimentos extraídos do projeto de construção coletiva (crowdsourcing) Open Mind Common Sense (OMCS) (Singh et al., 2002). O OMCS surgiu com o objetivo de coletar, pela Internet e de colaboradores voluntários, sentenças que expressavam fatos da vida comum. Por exemplo, a sentença “The Effect of [falling off a bike] is [you get hurt]” foi coletada de voluntários, quando solicitados a preencher os espaços do template “The Effect of [.….] is [.….]”. A alternativa adotada pela equipe da ConceptNet foi construir a rede semântica (nós conceituais interligados pelas relações semânticas), a partir de um processo automático sobre o corpus OMCS, o qual extraiu as relações semânticas e seus argumentos.\n",
            "\n",
            "A motivação do projeto que mantém a ConceptNet é expressar os fatos que as pessoas sabem comumente sobre o mundo ― conhecimento de senso comum ― através de afirmações que relacionam conceitos. Este tipo de conhecimento é importante porque, quando as pessoas se comunicam, seus proferimentos acontecem sobre suposições implícitas e básicas, as quais suportam e explicam boa parte dos raciocínios necessários para um bom nível de entendimento e, consequentemente, uma boa comunicação. Por exemplo, quando alguém fala “Eu comprei doces”, está implícito que usou dinheiro, ou quando fala “Fui a um casamento”, provavelmente tinha uma noiva, um noivo, uma festa com bolo e champagne, e o interlocutor está autorizado a perguntar “A noiva estava bonita?” etc.\n",
            "\n",
            "Atualmente, a ConceptNet26 evoluiu como um projeto colaborativo com diversas fontes:\n",
            "\n",
            "parte do cap 17\n",
            "\n",
            "A partir da MUC-3, em 1991, a conferência passa a ter foco no processamento de textos jornalísticos em detrimento dos relatórios militares utilizados anteriormente (DARPA, 1991). Com a disponibilidade de dados e o incentivo no desenvolvimento de soluções para a tarefa, vemos na década de 1990 o surgimento das primeiras aplicações comerciais de EI, como o JASPER (Andersen et al., 1992)., construído para a agência de notícias Reuters.\n",
            "\n",
            "A MUC-6, ocorrida em 1995, introduz a tarefa de REN com o intuito de ser uma tarefa de uso prático, independente de domínio e que poderia ser realizada automaticamente em um futuro próximo (Grishman; Sundheim, 1996). Enquanto os trabalhos em REN se avolumaram a partir de sua proposição na MUC-6, trabalhos anteriores como Rau (1991) e Wolinski; Vichot; Dillet (1995) já se debruçavam sobre o problema de identificação e classificação de nomes próprios. Desde então, o interesse na tarefa cresceu significativamente e outras conferências de avaliação conjunta têm sido dedicadas a essa tarefa, como a Automatic Content Extraction (ACE) e a conferência Avaliação de Sistemas de Reconhecimento de Entidades Mencionadas (HAREM), dedicada exclusivamente à língua portuguesa, com sua primeira edição em 2005 (Santos; Cardoso, 2007a).\n",
            "\n",
            "Por outro lado, houve um crescimento de abordagens baseadas em dados nesta década, a partir da análise de corpora. Tais esforços são impulsionados pelos resultados positivos na área, como o trabalho de Hearst (1992). Logo, métodos baseados em dados passaram também a explorar o emprego de análise estatística e aprendizado de máquina na construção de padrões para a extração de relações (Riloff et al., 1993; Riloff; Jones; et al., 1999; Roark; Charniak, 2000; Soderland et al., 1995)\n",
            "\n",
            "Não foi somente na extração de padrões que métodos de aprendizado de máquina, em particular aprendizado supervisionado, foram aplicados. A década de 2000 viu a proliferação de métodos supervisionados aplicados à ER (Culotta; McCallum; Betz, 2006; Kambhatla, 2004; Zelenko; Aone; Richardella, 2003; Zhao; Grishman, 2005) e ao REN (Asahara; Matsumoto, 2003; McCallum; Li, 2003; Sekine, 1998).\n",
            "\n",
            "Devido à dificuldade de construção de dados para treinamento e padrões para extração, além da pouca adaptabilidade dos sistemas construídos para outros escopos e domínios, nos anos 2000, sistemas baseados em métodos de aprendizado semi-supervisionado, como o DIPRE (Brin, 1998) e Snowball (Agichtein; Gravano, 2000) começaram a aparecer, juntamente com os estudos sobre expansão automatizada de anotações (bootstrapping) (Riloff; Jones; et al., 1999). Também para entidades nomeadas, estudos investigaram como utilizar recursos da Web (Etzioni et al., 2005; Nadeau, 2007) ou corpora (Cucchiarelli; Velardi, 2001) para aprender entidades com pouco ou nenhum esforço de anotação.\n",
            "\n",
            "Buscando superar as dificuldades da limitação de escopo, i.e. das relações-alvo a serem extraídas e categorias de entidades a serem identificadas, ainda restritas à definição de padrões desde a criação dessas tarefas, Banko et al. (2007) propõe a tarefa de extração de informação aberta (EIA), também conhecida como Open Information Extraction, OpenIE ou OIE, a qual busca extrair todas as relações possíveis expressas em um texto, sem necessidade de pré-definição de relações e entidades.\n",
            "\n",
            "Devido ao recente sucesso da aplicação de métodos baseados em redes neurais, em particular deep learning e grandes modelos de linguagem, às tarefas de Processamento de Linguagem Natural, uma tendência atual da área se delineou como o estudo de arquiteturas neurais para os problemas de EI e a geração de grandes conjuntos de dados por supervisão fraca. Surveys recentes, como (Cui; Wei; Zhou, 2018; Konstantinova, 2014; Nasar; Jaffry; Malik, 2021), nos mostram a evolução da área em direção à aplicação de métodos neurais. Na vertente de geração de dados, vemos o emprego da Wikipédia e Freebase como fontes mais usadas para obter anotações de entidades e relações em textos (Nguyen; Theobald; Weikum, 2016; Smirnova; Cudré-Mauroux, 2018; Takamatsu; Sato; Nakagawa, 2012).\n",
            "\n",
            "Porém, toda a tarefa de EI necessita de uma concordância entre as definições de Entidade e Relação. Neste sentido, a próxima seção discute a conceituação de relação adotada neste capítulo, assim como o conceito de entidade.\n",
            "\n",
            "A natureza das relações estudadas na área de Extração de Informação e os critérios para reconhecer sua ocorrência em um texto têm recebido pouca atenção na literatura. Este é um passo importante para estabelecer metodologias adequadas para avaliar os sistemas, bem como para criar conjuntos de dados que possam apoiar a criação de sistemas futuros.\n",
            "\n",
            "Enquanto as noções de Relação e Entidade são de grande importância e já bem estudadas nas áreas de Computação, Linguística, Ciência da Informação e Filosofia da Linguagem, esses conceitos não são empregados de forma consistente entre as áreas, ou mesmo entre suas subáreas.\n",
            "\n",
            "Para Chen (1976), uma entidade é um objeto que pode ser concreto, tal como pessoa, livro, casa ou ainda abstrato, tal como um emprego, um sentimento, uma disciplina. As entidades podem estabelecer relações entre si. Duas ou mais entidades são vinculadas, ou seja conectadas por uma relação1.\n",
            "\n",
            "Tradicionalmente em reconhecimento de entidades nomeadas, as entidades consideradas são aquelas referenciadas por um nome próprio, acrescidas das referências temporais e valores que são expressões numéricas. Essas expressões, portanto, geralmente não constituem uma entrada em uma base lexical. Porém a tarefa se expandiu para domínios especializados, onde as entidades de interesse são mais conceituais. No domínio bio-médico por exemplo, podemos ter como exemplo de entidades de interesse, sintomas e tratamento que não são referenciadas por nomes próprios.\n",
            "\n",
            "Os conceitos de relação e relacionamento são noções fundamentais que vêm sendo estudadas em áreas como Ciência da Computação, Linguística e Filosofia.\n",
            "\n",
            "No campo de bancos de dados e modelagem conceitual, Chen (1976) define um relacionamento, no contexto da modelagem de Entidade-Relacionamento, como uma associação entre entidades. Guarino; Guizzardi (2015), por sua vez, estudando a natureza ontológica dos relacionamentos com base na semântica de veridadores (truthmaker semantics) (Fine, 2017), postulam relacionamentos como entidades que atuam como veridadores (thruthmakers) de alguma proposição relacionando duas ou mais entidades, ou seja, uma relação mantida entre essas entidades. Um veridador é um elemento cuja existência torna verdadeira uma proposição particular. Por exemplo, considerando a sentença (1) “a é uma maçã”, a existência de um objeto denotado pelo nome a que por acaso é uma maçã é uma condição suficiente para a verdade da frase (1). Como tal, dizemos que esse objeto é o veridador de (1). Tal definição nos permite adotar critérios ontológicos para validar a existência de relacionamentos a partir da informação relatada em um texto e, por isso, adotaremos tal definição de relacionamento neste capítulo.\n",
            "\n",
            "O conceito de relações é muito menos consistente na literatura. Ainda na área de modelagem conceitual, Guarino; Guizzardi (2015) definem as relações como proposições para as quais os relacionamentos são veridadores e, portanto, possuem conteúdo proposicional. Assim, podemos entender uma relação como um tipo para entidades como relacionamentos. Ou seja, relações são universais ontológicos que descrevem a natureza dos relacionamentos.\n",
            "\n",
            "Xavier; Lima; Souza (2015), no entanto, argumentam que a noção de relacionamento adotada na área de Extração de Informação é mais geral do que isso, não se limitando àquelas entre objetos e propriedades, mas também àquelas que descrevem ou implicam propriedades de classes gerais como descrito pela sentença (2) “Filósofos são autores de Livros”. Assim, para o contexto de EI consideramos relações como tipos de relacionamentos de primeira ou segunda ordem. Isso significa que uma relação é um tipo de relacionamento que existe entre objetos, suas propriedades e classes de objetos ou suas propriedades.\n",
            "\n",
            "parte do cap 9\n",
            "\n",
            "Outras iniciativas culminaram na geração de bases de frames em português, todas de menor tamanho que a FN-Br e para domínios ainda mais específicos.\n",
            "\n",
            "A base FrameFOR (Barreira; Pinheiro; Furtado, 2017) é uma base com 113 frames em português brasileiro, adaptados da FrameNet original, contendo os papéis semânticos, unidades e entradas lexicais relacionados aos tipos de crimes mais investigados na Perícia Forense do Estado do Ceará, no Brasil (PEFOCE) – formação de quadrilha, tráfico de drogas, sequestro, corrupção, receptação, contrabando, pedofilia, estupro, agressão, tortura, falsificação, ameaça, porte ilegal de arma, estelionato, e extorsão.\n",
            "\n",
            "O estudo de (Bertoldi, 2011) analisou os limites da criação automática de léxicos computacionais segundo o paradigma FrameNet, comparando as unidades lexicais evocadoras, os papéis semânticos e a estrutura do frame Criminal_process, em inglês e português. Esse estudo contrastivo mostrou que os frames do domínio jurídico são socialmente orientados e que a criação automática de léxicos em áreas cultural e socialmente orientadas tende a apresentar divergências. Em (Bick, 2009) tem-se a proposta de PFN-PT, um sistema para a anotação semântica automática do português, consistindo numa nova framenet contendo cerca de 13.000 padrões sintáticos, cobrindo 7.300 lemas verbais com 10.700 sentidos.\n",
            "\n",
            "Todos estes projetos, ainda que de menor porte, possuem relatos de sucesso em aplicações de PLN como extração de informação, anotação de papéis semânticos, reconhecimento de entidades nomeadas, evidenciando a importância de abordar as peculiaridades linguísticas com perspectivas contextualizadas e culturalmente relevantes.\n",
            "\n",
            "Nesta seção, usaremos a FrameNet de Berkeley para analisar o exemplo motivador definido no início da Seção 9.1. No Exemplo 9.3 são destacados o frame associado, as unidades lexicais (elemento evocador) que evocaram o frame e os papéis semânticos identificados no texto.\n",
            "\n",
            "Exemplo 9.3  \n",
            "\n",
            "Um assalto do tipo saidinha bancária, ocorrido na tarde desta terça-feira, terminou com uma mulher de 42 anos baleada pelos assaltantes. O roubo ocorreu na rua Professor Costa Mendes.\n",
            "\n",
            "Uma dificuldade com a análise desse exemplo, à luz da FrameNet, foi na identificação do papel semântico “vítima” (“uma mulher de 42 anos”), pois o complemento da sentença que a contém “…com uma mulher de 42 anos baleada …” possui a estrutura sintática Prep.Det.N (preposição + determinante + substantivo) e não é compatível com nenhuma realização sintática do elemento de frame victim.\n",
            "\n",
            "ConceptNet25 (Speer; Chin; Havasi, 2016) é uma base de conhecimento de senso comum que expressa relações rotuladas e ponderadas entre palavras ou fragmentos de textos em linguagem natural, através de um Grafo de Conhecimento (Knowledge Graph) contendo edges ou afirmações. Alguns exemplos de afirmações expressas na ConceptNet são:\n",
            "\n",
            "Sua versão original (Havasi; Speer; Alonso, 2007; Liu; Singh, 2004) foi criada pela equipe do MediaLab do Massachusetts Institute of Technology (MIT) em 1999, a partir de conhecimentos extraídos do projeto de construção coletiva (crowdsourcing) Open Mind Common Sense (OMCS) (Singh et al., 2002). O OMCS surgiu com o objetivo de coletar, pela Internet e de colaboradores voluntários, sentenças que expressavam fatos da vida comum. Por exemplo, a sentença “The Effect of [falling off a bike] is [you get hurt]” foi coletada de voluntários, quando solicitados a preencher os espaços do template “The Effect of [.….] is [.….]”. A alternativa adotada pela equipe da ConceptNet foi construir a rede semântica (nós conceituais interligados pelas relações semânticas), a partir de um processo automático sobre o corpus OMCS, o qual extraiu as relações semânticas e seus argumentos.\n",
            "\n",
            "A motivação do projeto que mantém a ConceptNet é expressar os fatos que as pessoas sabem comumente sobre o mundo ― conhecimento de senso comum ― através de afirmações que relacionam conceitos. Este tipo de conhecimento é importante porque, quando as pessoas se comunicam, seus proferimentos acontecem sobre suposições implícitas e básicas, as quais suportam e explicam boa parte dos raciocínios necessários para um bom nível de entendimento e, consequentemente, uma boa comunicação. Por exemplo, quando alguém fala “Eu comprei doces”, está implícito que usou dinheiro, ou quando fala “Fui a um casamento”, provavelmente tinha uma noiva, um noivo, uma festa com bolo e champagne, e o interlocutor está autorizado a perguntar “A noiva estava bonita?” etc.\n",
            "\n",
            "Atualmente, a ConceptNet26 evoluiu como um projeto colaborativo com diversas fontes:\n",
            "\n",
            "parte do cap 17\n",
            "\n",
            "Enquanto os métodos tradicionais de Extração de Informação dependem de um conjunto pré-existente de relações semânticas bem definidas que são relevantes para um domínio específico, a noção de “relação” e “entidade” na literatura da área mais recente, tais como a Extração de Informação Aberta, requer mais aprofundamento por demandar um significado diferente, principalmente com diferente visões de autores. Esta indeterminação terminológica pode trazer problemas para comparar os resultados dos métodos propostos ou para reutilizar os conjuntos de dados criados na área.\n",
            "\n",
            "As seções seguintes exploram essas duas áreas: Extração de Informação e Extração de Informação Aberta.\n",
            "\n",
            "A Extração de Informação é caracterizada por obter informação estruturada a partir de textos, sendo entidades ou fatos, i.e. relacionamentos entre entidades, de tipos previamente definidos, conforme exemplo na Quadro 17.1. Métodos com limitação de escopo possuem como uma de suas principais desvantagens a necessidade de intervenção humana para especificar novos fatos a serem extraídos. Esta limitação impede que sistemas de Extração de Informação, doravante denominados de EI tradicional extraiam fatos fora do escopo pré-definido.\n",
            "\n",
            "Quadro 17.1 Exemplos de relações específicas na EI tradicional\n",
            "\n",
            "Fonte: (Souza; Claro, 2014)\n",
            "\n",
            "O Reconhecimento de Entidades Nomeadas (REN) consiste na tarefa de identificar e classificar expressões linguísticas, denominadas entidades nomeadas (EN), que referenciam entidades específicas num domínio de discurso, como nomes próprios, expressões temporais e espécies biológicas (Mota; Santos; Ranchhod, 2007; Nadeau, 2007). De uma forma geral, o REN pode ser dividido em duas etapas: a identificação (ou delimitação) da expressão, na qual as palavras que formam a EN são selecionadas; a classificação, em que é atribuída uma categoria semântica à EN.\n",
            "\n",
            "A classificação das ENs determina os tipos de entidades a serem consideradas e são especificadas a partir do escopo definido previamente para a tarefa. Algumas das categorias mais comumente utilizadas incluem as entidades que referenciam Pessoas Singulares (antropônimos); Coletivas (empresas e organizações) e Lugares (topônimos) (Mota; Santos; Ranchhod, 2007). Para exemplificar tomemos a sentença: “Renata Silva e Maria Costa palestraram na Universidade Federal da Bahia”. No exemplo temos três ENs: “Renata Silva”, “Maria Costa”, “Universidade Federal da Bahia”, sendo as duas primeiras correspondentes à categoria semântica Pessoa e a última, à categoria semântica Organização. Entretanto, existem outras categorias de ENs, como as menções a Obras (por exemplo, “Código Da Vinci”); Acontecimentos (por exemplo, “Festa de Santo Antônio”), Tempo (por exemplo, “meio-dia”); Coisa (por exemplo, “barco”), entre outras.\n",
            "\n",
            "O REN é uma tarefa com grande importância para o Processamento de Linguagem Natural, pois consiste numa primeira tarefa de análise semântica de um texto, com potencial aplicações a diversas tarefas. Por exemplo, em sistemas de perguntas e respostas, as perguntas frequentemente se referem a informações sobre entidades. Também, métodos de identificação de estruturas mais complexas, como eventos ou relações, dependem do bom desempenho do REN como uma etapa de pré-processamento (Socher et al., 2012; Zelenko; Aone; Richardella, 2003).\n",
            "\n",
            "A tarefa de extração de relações (ou de relacionamentos) (ER) refere-se a identificar relacionamentos entre entidades de um determinado escopo mencionadas em um texto (Jurafsky; Martin, 2023). O escopo, no contexto da ER, refere-se a um conjunto de relações-alvo de um determinado domínio de conhecimento ou aplicação a ser investigado. Por exemplo, o Quadro 17.2 apresenta alguns exemplos de relações no domínio de geografia brasileira. Na descrição das relações, os elementos em negrito referem-se às entidades em um dado relacionamento descrito pelo termo em itálico.\n",
            "\n",
            "Quadro 17.2 Exemplos de relações no domínio da geografia brasileira.\n",
            "\n",
            "Nesse contexto, a delimitação de um escopo ou domínio de interesse, concentra-se na determinação das relações a serem processadas, i.e. nos tipos de relacionamentos de interesse, assim como da natureza das entidades associadas por tais relações.\n",
            "\n",
            "As tarefas de reconhecimento de entidades nomeadas e extração de relações são interdependentes, no sentido de que a definição do escopo a ser estudado delimita tanto as categorias e natureza das entidades a serem extraídas, como também as relações entre essas entidades. Também, note-se que, pelo fato de as relações serem comumente definidas entre entidades de tipo especificado, como o caso da relação Tem_Prefeito no Quadro 17.2 que ocorre entre entidades das classes Cidade e Pessoa, tanto as informações das entidades mencionadas no texto são úteis para a extração de relações, quanto a informação das relações identificadas pode ser útil ao processo de identificação de entidades.\n",
            "\n",
            "De fato, na literatura recente, existem vários trabalhos que consideram a tarefa de extração conjunta de entidades e relações (ERE, do inglês Entity and Relation Joint Extraction), composta das tarefas de REN e ER (Agichtein; Gravano, 2000; Shaowei et al., 2022; Yuan et al., 2021). Enquanto normalmente abordagens estruturam suas soluções de forma sequencial, usualmente realizando REN inicialmente e, posteriormente, realizando ER, como nos trabalhos de (Hasegawa; Sekine; Grishman, 2004) e de (Socher et al., 2012), a literatura recente aponta para as vantagens da identificação conjunta ao permitir um melhor aprendizado de restrições para identificação de entidades e relações, c.f. o recente survey realizado por (Shaowei et al., 2022) sobre métodos para tal tarefa.\n",
            "\n",
            "Várias abordagens foram adotadas para o problema de EI durante seu desenvolvimento histórico. Enquanto abordagens iniciais privilegiavam métodos ricos em conhecimento, como regras e recursos linguísticos e de conhecimento de mundo, a literatura recente na área privilegia métodos baseados em dados, como o aprendizado de máquina, com o recente emprego de arquiteturas neurais aos problemas.\n",
            "\n",
            "A seguir faremos uma breve apresentação das abordagens descritas na literatura para os problemas de EI.\n",
            "\n",
            "parte do cap 9\n",
            "\n",
            "Outras iniciativas culminaram na geração de bases de frames em português, todas de menor tamanho que a FN-Br e para domínios ainda mais específicos.\n",
            "\n",
            "A base FrameFOR (Barreira; Pinheiro; Furtado, 2017) é uma base com 113 frames em português brasileiro, adaptados da FrameNet original, contendo os papéis semânticos, unidades e entradas lexicais relacionados aos tipos de crimes mais investigados na Perícia Forense do Estado do Ceará, no Brasil (PEFOCE) – formação de quadrilha, tráfico de drogas, sequestro, corrupção, receptação, contrabando, pedofilia, estupro, agressão, tortura, falsificação, ameaça, porte ilegal de arma, estelionato, e extorsão.\n",
            "\n",
            "O estudo de (Bertoldi, 2011) analisou os limites da criação automática de léxicos computacionais segundo o paradigma FrameNet, comparando as unidades lexicais evocadoras, os papéis semânticos e a estrutura do frame Criminal_process, em inglês e português. Esse estudo contrastivo mostrou que os frames do domínio jurídico são socialmente orientados e que a criação automática de léxicos em áreas cultural e socialmente orientadas tende a apresentar divergências. Em (Bick, 2009) tem-se a proposta de PFN-PT, um sistema para a anotação semântica automática do português, consistindo numa nova framenet contendo cerca de 13.000 padrões sintáticos, cobrindo 7.300 lemas verbais com 10.700 sentidos.\n",
            "\n",
            "Todos estes projetos, ainda que de menor porte, possuem relatos de sucesso em aplicações de PLN como extração de informação, anotação de papéis semânticos, reconhecimento de entidades nomeadas, evidenciando a importância de abordar as peculiaridades linguísticas com perspectivas contextualizadas e culturalmente relevantes.\n",
            "\n",
            "Nesta seção, usaremos a FrameNet de Berkeley para analisar o exemplo motivador definido no início da Seção 9.1. No Exemplo 9.3 são destacados o frame associado, as unidades lexicais (elemento evocador) que evocaram o frame e os papéis semânticos identificados no texto.\n",
            "\n",
            "Exemplo 9.3  \n",
            "\n",
            "Um assalto do tipo saidinha bancária, ocorrido na tarde desta terça-feira, terminou com uma mulher de 42 anos baleada pelos assaltantes. O roubo ocorreu na rua Professor Costa Mendes.\n",
            "\n",
            "Uma dificuldade com a análise desse exemplo, à luz da FrameNet, foi na identificação do papel semântico “vítima” (“uma mulher de 42 anos”), pois o complemento da sentença que a contém “…com uma mulher de 42 anos baleada …” possui a estrutura sintática Prep.Det.N (preposição + determinante + substantivo) e não é compatível com nenhuma realização sintática do elemento de frame victim.\n",
            "\n",
            "ConceptNet25 (Speer; Chin; Havasi, 2016) é uma base de conhecimento de senso comum que expressa relações rotuladas e ponderadas entre palavras ou fragmentos de textos em linguagem natural, através de um Grafo de Conhecimento (Knowledge Graph) contendo edges ou afirmações. Alguns exemplos de afirmações expressas na ConceptNet são:\n",
            "\n",
            "Sua versão original (Havasi; Speer; Alonso, 2007; Liu; Singh, 2004) foi criada pela equipe do MediaLab do Massachusetts Institute of Technology (MIT) em 1999, a partir de conhecimentos extraídos do projeto de construção coletiva (crowdsourcing) Open Mind Common Sense (OMCS) (Singh et al., 2002). O OMCS surgiu com o objetivo de coletar, pela Internet e de colaboradores voluntários, sentenças que expressavam fatos da vida comum. Por exemplo, a sentença “The Effect of [falling off a bike] is [you get hurt]” foi coletada de voluntários, quando solicitados a preencher os espaços do template “The Effect of [.….] is [.….]”. A alternativa adotada pela equipe da ConceptNet foi construir a rede semântica (nós conceituais interligados pelas relações semânticas), a partir de um processo automático sobre o corpus OMCS, o qual extraiu as relações semânticas e seus argumentos.\n",
            "\n",
            "A motivação do projeto que mantém a ConceptNet é expressar os fatos que as pessoas sabem comumente sobre o mundo ― conhecimento de senso comum ― através de afirmações que relacionam conceitos. Este tipo de conhecimento é importante porque, quando as pessoas se comunicam, seus proferimentos acontecem sobre suposições implícitas e básicas, as quais suportam e explicam boa parte dos raciocínios necessários para um bom nível de entendimento e, consequentemente, uma boa comunicação. Por exemplo, quando alguém fala “Eu comprei doces”, está implícito que usou dinheiro, ou quando fala “Fui a um casamento”, provavelmente tinha uma noiva, um noivo, uma festa com bolo e champagne, e o interlocutor está autorizado a perguntar “A noiva estava bonita?” etc.\n",
            "\n",
            "Atualmente, a ConceptNet26 evoluiu como um projeto colaborativo com diversas fontes:\n",
            "\n",
            "parte do cap 17\n",
            "\n",
            "As abordagens iniciais para REN baseavam-se, majoritariamente, no emprego de regras lexico-sintáticas e consulta a almanaques (gazeeers). Tais abordagens dependem da construção de listas de nomes próprios como antropônimos, topônimos etc., e outras palavras, como “Ltda.”, “Jr.” etc., que auxiliam no processo de identificação e classificação de ENs complexas ou desconhecidas. Essa é, por exemplo, a abordagem empregada por Wolinski; Vichot; Dillet (1995) que combina almanaques e regras para a identificação e classificação de ENs. Posteriormente, almanaques foram também empregados em conjunção com métodos baseados em dados, como o trabalho de Florian et al. (2003) que os emprega aliados aos classificadores, enquanto Liu; Yao; Lin (2019) os utilizam durante o treinamento de uma rede neural, como um sinal de treinamento (parte da função de perda, ou loss em inglês).\n",
            "\n",
            "Muitos trabalhos debruçaram-se também sobre o problema de construção automática ou semi-automática de almanaques, dos quais os trabalhos de Nadeau (2007), de Riloff; Jones; et al. (1999) e de Etzioni et al. (2005) são alguns dos mais importantes.\n",
            "\n",
            "Enquanto as abordagens iniciais para o problema baseavam-se em regras, com a disponibilidade de dados anotados para a tarefa, tais métodos foram rapidamente suplantados por métodos baseados em dados, tais como: os métodos baseados em classificação (Asahara; Matsumoto, 2003; Sekine, 1998) e classificação sequencial (Bikel; Schwartz; Weischedel, 1999; McCallum; Li, 2003).\n",
            "\n",
            "A redução de REN à tarefa de classificação sequencial merece destaque pelos bons resultados obtidos. Tal redução se dá através de um esquema de codificação do problema que nos permite representar fragmentos textuais e sua classificação como um problema de rotulação ou etiquetação.\n",
            "\n",
            "Partindo-se do pressuposto de que os fragmentos textuais descrevendo entidades nomeadas são contíguos, podemos codificar a tarefa de delimitação de entidades como classificação sequencial empregando rótulos que descrevem os limites de uma EN, e.g. o esquema BIO com os rótulos B (do inglês, begin) para designar a palavra inicial de uma EN, I (do inglês, inside) para designar palavras que fazem parte da EN mas não a iniciam e O (do inglês, outside) para designar palavras que não pertencem a uma entidade. Da mesma forma, podemos estender nosso esquema de codificação para incluir as classes de interesse. Assim, seguindo o esquema BIO, teremos os rótulos B-PER e I-PER para descrever entidades da classe Pessoa.\n",
            "\n",
            "A redução do problema de REN à classificação sequencial está ilustrada no Exemplo 17.1.\n",
            "\n",
            "Exemplo 17.1  \n",
            "\n",
            "Renata/B-PER Silva/I-PER e/O Maria/B-PER Costa/I-PER palestraram/O na/O Universidade/B-ORG Federal/I-ORG da/I-ORG Bahia/I-ORG.\n",
            "\n",
            "Recentemente, destacam-se na literatura abordagens baseadas em redes neurais profundas, com uma grande concentração nos últimos anos em modelos gerativos de linguagem, devido aos resultados positivos obtidos por tais arquiteturas em diversas tarefas.\n",
            "\n",
            "Na literatura são de grande destaque os modelos recentes BART (Lewis et al., 2020), RoBERTa (Liu et al., 2019), T5 (Raffel et al., 2020), BERT (Devlin et al., 2019) e GPT-3 (Brown et al., 2020), conforme descritos no Capítulo 15.\n",
            "\n",
            "Similarmente, na língua portuguesa, nas duas edições do HAREM (Mota; Santos, 2008; Santos; Cardoso, 2007b), o primeiro esforço sistemático de desenvolvimento de soluções para a tarefa na língua, a maioria dos sistemas participantes baseava-se em métodos ricos em conhecimento, como regras e almanaques. De fato, nas duas avaliações, somente os sistemas MALINCHE (Solorio, 2007), NEURA (Ferrández et al., 2007) e R3M (Mota, 2008) não se baseavam em regras. Métodos baseados em classificação sequencial se seguiram para a língua portuguesa, como o RELP-CRF (Amaral; Vieira, 2014) baseado em um classificador sequencial. Mais recentemente, abordagens baseadas em redes neurais e modelos de linguagem foram desenvolvidas tornando-se o estado da arte da tarefa na língua. A Tabela 17.1 apresenta o atual estado da arte em português, com base no corpus HAREM. A métrica de avaliação apresentada, medida F1, será discutida na Seção 17.6.\n",
            "\n",
            "Souza; Nogueira; Lotufo (2020) desenvolveram um modelo BERT para o Português com 2,68 bilhões de tokens e aplicaram o modelo em um classificador CRF. Santos et al., avaliaram o impacto do modelo contextualizado Flair Embeddings aplicado a tarefa de REN junto com uma rede neural BiLSTM-CRF. Os autores também desenvolveram um modelo Flair Embeddings para o português, o FlairBBP, treinado com 4,9 bilhões de tokens (Santos et al., 2019). Castro; Silva; Soares (2018) utilizou uma rede LSTM e um classificador CRF junto com modelos Word Embeddings pré-treinados. Santos; Guimarães (2015) desenvolveram uma rede neural convolucional capaz de capturar características a nível de caracteres e também de incorporar word embeddings pré-treinados.\n",
            "\n",
            "O reconhecimento de entidades tem sido aplicado em muitas áreas específicas, como direito, saúde e geologia. Nesses casos há uma demanda de adaptação dos modelos preditivos de acordo com a nova linguagem especializada do domínio e um novo conjunto de rótulos que devem ser aprendidos. Da mesma forma, são necessários novos conjuntos de dados para o processo de aprendizado, uma vez que abordagens de aprendizado de máquina necessitam de exemplos anotados para se chegar a um modelo preditivo eficaz.\n",
            "\n",
            "Muitos trabalhos endereçam domínios específicos, citamos exemplos em diversas línguas. Para o inglês, uma rede neural BiLSTM-CRF para o domínio biomédico é proposta em (Habibi et al., 2017).\n",
            "\n",
            "Um conjunto de dados do domínio jurídico em língua alemã é apresentado por Leitner; Rehm; Schneider (2019), que empregam redes neurais BiLSTM para a rotulação dos textos. Em (Qiu et al., 2019), uma rede neural BiLSTM-CRF com mecanismo de atenção é aplicada para reconhecer entidades geológicas para a língua chinesa.\n",
            "\n",
            "parte do cap 9\n",
            "\n",
            "Outras iniciativas culminaram na geração de bases de frames em português, todas de menor tamanho que a FN-Br e para domínios ainda mais específicos.\n",
            "\n",
            "A base FrameFOR (Barreira; Pinheiro; Furtado, 2017) é uma base com 113 frames em português brasileiro, adaptados da FrameNet original, contendo os papéis semânticos, unidades e entradas lexicais relacionados aos tipos de crimes mais investigados na Perícia Forense do Estado do Ceará, no Brasil (PEFOCE) – formação de quadrilha, tráfico de drogas, sequestro, corrupção, receptação, contrabando, pedofilia, estupro, agressão, tortura, falsificação, ameaça, porte ilegal de arma, estelionato, e extorsão.\n",
            "\n",
            "O estudo de (Bertoldi, 2011) analisou os limites da criação automática de léxicos computacionais segundo o paradigma FrameNet, comparando as unidades lexicais evocadoras, os papéis semânticos e a estrutura do frame Criminal_process, em inglês e português. Esse estudo contrastivo mostrou que os frames do domínio jurídico são socialmente orientados e que a criação automática de léxicos em áreas cultural e socialmente orientadas tende a apresentar divergências. Em (Bick, 2009) tem-se a proposta de PFN-PT, um sistema para a anotação semântica automática do português, consistindo numa nova framenet contendo cerca de 13.000 padrões sintáticos, cobrindo 7.300 lemas verbais com 10.700 sentidos.\n",
            "\n",
            "Todos estes projetos, ainda que de menor porte, possuem relatos de sucesso em aplicações de PLN como extração de informação, anotação de papéis semânticos, reconhecimento de entidades nomeadas, evidenciando a importância de abordar as peculiaridades linguísticas com perspectivas contextualizadas e culturalmente relevantes.\n",
            "\n",
            "Nesta seção, usaremos a FrameNet de Berkeley para analisar o exemplo motivador definido no início da Seção 9.1. No Exemplo 9.3 são destacados o frame associado, as unidades lexicais (elemento evocador) que evocaram o frame e os papéis semânticos identificados no texto.\n",
            "\n",
            "Exemplo 9.3  \n",
            "\n",
            "Um assalto do tipo saidinha bancária, ocorrido na tarde desta terça-feira, terminou com uma mulher de 42 anos baleada pelos assaltantes. O roubo ocorreu na rua Professor Costa Mendes.\n",
            "\n",
            "Uma dificuldade com a análise desse exemplo, à luz da FrameNet, foi na identificação do papel semântico “vítima” (“uma mulher de 42 anos”), pois o complemento da sentença que a contém “…com uma mulher de 42 anos baleada …” possui a estrutura sintática Prep.Det.N (preposição + determinante + substantivo) e não é compatível com nenhuma realização sintática do elemento de frame victim.\n",
            "\n",
            "ConceptNet25 (Speer; Chin; Havasi, 2016) é uma base de conhecimento de senso comum que expressa relações rotuladas e ponderadas entre palavras ou fragmentos de textos em linguagem natural, através de um Grafo de Conhecimento (Knowledge Graph) contendo edges ou afirmações. Alguns exemplos de afirmações expressas na ConceptNet são:\n",
            "\n",
            "Sua versão original (Havasi; Speer; Alonso, 2007; Liu; Singh, 2004) foi criada pela equipe do MediaLab do Massachusetts Institute of Technology (MIT) em 1999, a partir de conhecimentos extraídos do projeto de construção coletiva (crowdsourcing) Open Mind Common Sense (OMCS) (Singh et al., 2002). O OMCS surgiu com o objetivo de coletar, pela Internet e de colaboradores voluntários, sentenças que expressavam fatos da vida comum. Por exemplo, a sentença “The Effect of [falling off a bike] is [you get hurt]” foi coletada de voluntários, quando solicitados a preencher os espaços do template “The Effect of [.….] is [.….]”. A alternativa adotada pela equipe da ConceptNet foi construir a rede semântica (nós conceituais interligados pelas relações semânticas), a partir de um processo automático sobre o corpus OMCS, o qual extraiu as relações semânticas e seus argumentos.\n",
            "\n",
            "A motivação do projeto que mantém a ConceptNet é expressar os fatos que as pessoas sabem comumente sobre o mundo ― conhecimento de senso comum ― através de afirmações que relacionam conceitos. Este tipo de conhecimento é importante porque, quando as pessoas se comunicam, seus proferimentos acontecem sobre suposições implícitas e básicas, as quais suportam e explicam boa parte dos raciocínios necessários para um bom nível de entendimento e, consequentemente, uma boa comunicação. Por exemplo, quando alguém fala “Eu comprei doces”, está implícito que usou dinheiro, ou quando fala “Fui a um casamento”, provavelmente tinha uma noiva, um noivo, uma festa com bolo e champagne, e o interlocutor está autorizado a perguntar “A noiva estava bonita?” etc.\n",
            "\n",
            "Atualmente, a ConceptNet26 evoluiu como um projeto colaborativo com diversas fontes:\n",
            "\n",
            "parte do cap 17\n",
            "\n",
            "Para o português, um corpus para detecção de eventos de quedas de pacientes em prontuários eletrônicos é descrito em (Santos; Santos; Vieira, 2020). Os autores usaram uma rede neural BiLSTM-CRF+Flair para gerar um modelo classificador de tokens. Um corpus no domínio jurídico, tendo categorias específicas como legislação e jurisprudência é proposto por  Araujo et al. (2018), que usaram uma rede neural BiLSTM-CRF para criar um primeiro baseline para esse corpus. Ademais, Consoli et al. (2020) analisam um corpus no domínio de geologia usando uma rede neural BiLSTM-CRF com um modelo contextualizado Flair Embeddings.\n",
            "\n",
            "As abordagens iniciais para o problema de ER baseavam-se na definição de gabaritos e regras de extração, com base em informação sintática obtida de analisadores sintáticos rasos ou profundos (Cowie, 1983; Sager, 1978). Tais métodos foram rapidamente suplantados por métodos baseados em dados e padrões obtidos de corpora, como os famosos padrões de Hearst (1992) para identificação de relações de hiponímia.\n",
            "\n",
            "O trabalho de Hearst (1992) se baseou na definição de padrões lexico-sintáticos para expressão de relações de hiponímia e hiperonímia a partir de uma análise de corpus. Ao escolher a relação de hiponímia, que ocorre em todo domínio, e padrões gerais baseados em aspectos da língua, como os representados no Quadro 17.3, o autor garante generalizabilidade dos padrões obtidos para diversos domínios e aplicações.\n",
            "\n",
            "Quadro 17.3 Exemplos de Padrões de Hearst para hiponímia\n",
            "\n",
            "Devido à dificuldade de construção manual das regras, os métodos de Riloff et al. (1993), empregam heurísticas para geração de padrões baseadas em informação gramatical, e de Soderland et al. (1995), que se baseia numa semântica de quadros (frames) empregando um analisador semântico e medidas de qualidade de identificação de exemplos, baseado no percentual de acerto sobre relacionamentos previamente conhecidos, para identificação de quadros relevantes.\n",
            "\n",
            "As abordagens baseadas em aprendizado de máquina, hoje as mais comuns e com melhor desempenho na literatura (Konstantinova, 2014; Nasar; Jaffry; Malik, 2021) dividem-se em abordagens que realizam reconhecimento de entidades e extração de relações de forma conjunta e separada.\n",
            "\n",
            "Abordagens baseadas na realização de REN e ER de forma separada baseiam-se em um fluxo de processamento em que, em geral, as entidades são identificadas primeiro e a tarefa de ER se reduz a identificar quando uma sentença ou fragmento textual denota uma relação semântica entre duas entidades. Consideremos o Exemplo 17.2, retirado de (Socher et al., 2012):\n",
            "\n",
            "Exemplo 17.2  \n",
            "\n",
            "Gripe aviária]\\(_{e1}\\) é uma doença infecciosa causada pelo vírus da [influenza tipo a]\\(_{e2}\\)\n",
            "\n",
            "Podemos, então, reduzir o problema de identificar a relação Causa-Efeito(\\(e1\\),\\(e2\\)) a um problema de classificação textual, identificando se a sentença acima fornece indícios para a expressão da relação de interesse. As soluções propostas na literatura para o problema são variadas e baseadas em diferentes métodos.\n",
            "\n",
            "Zelenko; Aone; Richardella (2003), por exemplo, propõem funções de kernel para árvores sintáticas rasas, i.e. funções que descrevem medidas de similaridade entre tais árvores. Eles empregam tais medidas para treinar um classificador de perceptron com votação (voted perceptron) sobre relações no domínio de organizações extraídas de um corpus de textos jornalísticos. De forma similar, Zhao; Grishman (2005) empregam diferentes funções de kernel sobre informações sintáticas relevantes para a identificação de relação e argumentos visando treinar um classificador SVM sobre o corpus de ER da conferência ACE.\n",
            "\n",
            "Culotta; McCallum; Betz (2006), por outro lado, empregam um classificador sequencial baseado em modelos escondidos de Markov para identificação de relações em um texto. Ao restringir sua análise a textos biográficos, os autores reduzem o processo de identificar instâncias de relações à identificação de fragmento textual que delimita o argumento e sua classificação, tarefa para a qual a classificação sequencial já é comumente utilizada. Consideremos o Exemplo 17.3 sobre George W. Bush, retirado de (Culotta; McCallum; Betz, 2006):\n",
            "\n",
            "Exemplo 17.3  \n",
            "\n",
            "George é filho de \\(\\underbrace{\\mbox{George H. W. Bush}}_{\\mbox{pai}}\\) e \\(\\underbrace{\\mbox{Barbara Bush}}_{\\mbox{mãe}}\\).\n",
            "\n",
            "Ao identificar o papel de pai e mãe, os autores conseguem construir a relação Pai(George H. W. Bush, George W. Bush) e Mãe(Barbara Bush, George W. Bush).\n",
            "\n",
            "parte do cap 9\n",
            "\n",
            "Outras iniciativas culminaram na geração de bases de frames em português, todas de menor tamanho que a FN-Br e para domínios ainda mais específicos.\n",
            "\n",
            "A base FrameFOR (Barreira; Pinheiro; Furtado, 2017) é uma base com 113 frames em português brasileiro, adaptados da FrameNet original, contendo os papéis semânticos, unidades e entradas lexicais relacionados aos tipos de crimes mais investigados na Perícia Forense do Estado do Ceará, no Brasil (PEFOCE) – formação de quadrilha, tráfico de drogas, sequestro, corrupção, receptação, contrabando, pedofilia, estupro, agressão, tortura, falsificação, ameaça, porte ilegal de arma, estelionato, e extorsão.\n",
            "\n",
            "O estudo de (Bertoldi, 2011) analisou os limites da criação automática de léxicos computacionais segundo o paradigma FrameNet, comparando as unidades lexicais evocadoras, os papéis semânticos e a estrutura do frame Criminal_process, em inglês e português. Esse estudo contrastivo mostrou que os frames do domínio jurídico são socialmente orientados e que a criação automática de léxicos em áreas cultural e socialmente orientadas tende a apresentar divergências. Em (Bick, 2009) tem-se a proposta de PFN-PT, um sistema para a anotação semântica automática do português, consistindo numa nova framenet contendo cerca de 13.000 padrões sintáticos, cobrindo 7.300 lemas verbais com 10.700 sentidos.\n",
            "\n",
            "Todos estes projetos, ainda que de menor porte, possuem relatos de sucesso em aplicações de PLN como extração de informação, anotação de papéis semânticos, reconhecimento de entidades nomeadas, evidenciando a importância de abordar as peculiaridades linguísticas com perspectivas contextualizadas e culturalmente relevantes.\n",
            "\n",
            "Nesta seção, usaremos a FrameNet de Berkeley para analisar o exemplo motivador definido no início da Seção 9.1. No Exemplo 9.3 são destacados o frame associado, as unidades lexicais (elemento evocador) que evocaram o frame e os papéis semânticos identificados no texto.\n",
            "\n",
            "Exemplo 9.3  \n",
            "\n",
            "Um assalto do tipo saidinha bancária, ocorrido na tarde desta terça-feira, terminou com uma mulher de 42 anos baleada pelos assaltantes. O roubo ocorreu na rua Professor Costa Mendes.\n",
            "\n",
            "Uma dificuldade com a análise desse exemplo, à luz da FrameNet, foi na identificação do papel semântico “vítima” (“uma mulher de 42 anos”), pois o complemento da sentença que a contém “…com uma mulher de 42 anos baleada …” possui a estrutura sintática Prep.Det.N (preposição + determinante + substantivo) e não é compatível com nenhuma realização sintática do elemento de frame victim.\n",
            "\n",
            "ConceptNet25 (Speer; Chin; Havasi, 2016) é uma base de conhecimento de senso comum que expressa relações rotuladas e ponderadas entre palavras ou fragmentos de textos em linguagem natural, através de um Grafo de Conhecimento (Knowledge Graph) contendo edges ou afirmações. Alguns exemplos de afirmações expressas na ConceptNet são:\n",
            "\n",
            "Sua versão original (Havasi; Speer; Alonso, 2007; Liu; Singh, 2004) foi criada pela equipe do MediaLab do Massachusetts Institute of Technology (MIT) em 1999, a partir de conhecimentos extraídos do projeto de construção coletiva (crowdsourcing) Open Mind Common Sense (OMCS) (Singh et al., 2002). O OMCS surgiu com o objetivo de coletar, pela Internet e de colaboradores voluntários, sentenças que expressavam fatos da vida comum. Por exemplo, a sentença “The Effect of [falling off a bike] is [you get hurt]” foi coletada de voluntários, quando solicitados a preencher os espaços do template “The Effect of [.….] is [.….]”. A alternativa adotada pela equipe da ConceptNet foi construir a rede semântica (nós conceituais interligados pelas relações semânticas), a partir de um processo automático sobre o corpus OMCS, o qual extraiu as relações semânticas e seus argumentos.\n",
            "\n",
            "A motivação do projeto que mantém a ConceptNet é expressar os fatos que as pessoas sabem comumente sobre o mundo ― conhecimento de senso comum ― através de afirmações que relacionam conceitos. Este tipo de conhecimento é importante porque, quando as pessoas se comunicam, seus proferimentos acontecem sobre suposições implícitas e básicas, as quais suportam e explicam boa parte dos raciocínios necessários para um bom nível de entendimento e, consequentemente, uma boa comunicação. Por exemplo, quando alguém fala “Eu comprei doces”, está implícito que usou dinheiro, ou quando fala “Fui a um casamento”, provavelmente tinha uma noiva, um noivo, uma festa com bolo e champagne, e o interlocutor está autorizado a perguntar “A noiva estava bonita?” etc.\n",
            "\n",
            "Atualmente, a ConceptNet26 evoluiu como um projeto colaborativo com diversas fontes:\n",
            "\n",
            "parte do cap 17\n",
            "\n",
            "Métodos baseados em redes neurais, de forma geral, costumam empregar técnicas de aprendizado de representação (Bengio; Courville; Vincent, 2013) para aprender representações do conteúdo semântico dos fragmentos textuais e reduzem o problema de ER à classificação textual. É o caso de Socher et al. (2012), que propõem a MV-RNN, uma rede neural que constrói um espaço de representação baseado em matrizes e vetores com o objetivo de capturar a composicionalidade de sentido de sintagmas e sentenças e os aplica para ER. Similarmente, Zeng et al. (2014) e Wang et al. (2016) empregam redes neurais convolucionais para obter representações vetoriais de sentenças que serão empregadas no processo de classificação quanto à relação expressa pela mesma.\n",
            "\n",
            "Abordagens baseadas em identificação sequencial de entidades e relações possuem desvantagens observadas na literatura. Primeiramente, como a ER é guiada pelas entidades identificadas no processo de REN, a propagação de erros da primeira tarefa pode ter impacto considerável na performance dos sistemas desenvolvidos. Segundo, uma vez que o contexto determinado limita tanto as tarefas de REN, quanto as de ER, existe uma interdependência entre as tarefas. Assim, propostas visando realizar a extração de entidades e relações de forma conjunta começaram a surgir na literatura recente, ganhando certo interesse da comunidade.\n",
            "\n",
            "As abordagens empregadas para tal tarefa são diversificadas, incluindo desde métodos de aprendizado relacional a redes neurais\n",
            "\n",
            "Roth; Yih (2007) propõem a utilização de métodos de programação inteira ao problema, baseados na teoria estatística de aprendizado relacional. Os autores utilizam classificadores locais para a identificação de entidades e relações e um classificador global que combina as informações dos classificadores locais em uma predição que maximiza a qualidade da extração, codificada por meio de restrições em programação inteira. Também baseados em modelos estatísticos, Yu; Lam (2010) propõem o uso de modelos gráficos globais para identificação de um descritor de relação e uma segmentação do texto para identificação dos argumentos.\n",
            "\n",
            "Li; Ji (2014) e Miwa; Bansal (2016), por sua vez, reduzem a tarefa de ERE à classificação sequencial, utilizando redes neurais recorrentes bidirecionais sequenciais e estruturadas com base na estrutura superficial e na árvore de dependências sintáticas da entrada para identificação conjunta de entidades e relações.\n",
            "\n",
            "A Extração de Informação Aberta (EIA), também conhecida como Open Information Extraction, Open IE ou OIE em inglês, é a tarefa de extrair informações estruturadas de documentos sem necessitar da pré-definição do contexto da tarefa, i.e. das relações e tipos de entidade de interesse. A tarefa foi inicialmente proposta pelo trabalho de (Banko et al., 2007) e ganhou popularidade nas últimas décadas devido à sua aplicabilidade para processar e estruturar o conhecimento a partir de grandes volumes de dados disponíveis na Web, seguindo o paradigma da Web como um Corpus (WaC) (Meyer et al., 2003).\n",
            "\n",
            "A EIA surge visando generalizar a tarefa de Extração de Relações. A principal diferença entre as duas abordagens, porém, reside na dependência da ER de uma especificação prévia do domínio de aplicação, bem como das relações alvo a serem identificadas, que a EIA visa eliminar.\n",
            "\n",
            "Seguindo o trabalho original de Banko et al. (2007), que propôs o sistema TextRunner, vários métodos e sistemas para EIA foram propostos na literatura (Del Corro; Gemulla, 2013; Fader; Soderland; Etzioni, 2011; Xavier; Lima; Souza, 2015), mas, como observado por Glauber; Claro (2018), os principais avanços na área se concentraram principalmente no idioma inglês.\n",
            "\n",
            "A EIA para a língua portuguesa tem uma história bastante recente. A partir dos trabalhos de Souza; Claro (2014), Pereira; Pinheiro (2015) e de (Barbosa; Glauber; Claro, 2016), têm crescido o número de estudos sobre a tarefa assim como os resultados obtidos por esses estudos, com recentes desenvolvimentos de métodos (Oliveira; Claro; Souza, 2022; Sena; Claro, 2019, 2020; Sena; Glauber; Claro, 2017; Souza; Claro; Glauber, 2018), construção do corpus (Glauber et al., 2018) e avaliação dos sistemas disponíveis (Glauber; Claro; Oliveira, 2019; Glauber; Claro; Sena, 2019; Malenchini et al., 2019).\n",
            "\n",
            "Embora a área tenha visto um crescimento recente para o desenvolvimento de métodos para línguas como o inglês, principalmente com a aplicação de métodos supervisionados e redes neurais, esses avanços ainda não foram incorporados na literatura sobre EIA para a língua portuguesa. A razão para isso é principalmente a falta de recursos linguísticos disponíveis para orientar o desenvolvimento de pesquisas para a língua. Embora o foco no idioma inglês possa ser devido ao seu uso generalizado em todo o mundo, foi reconhecido pela comunidade científica que esse foco no inglês com suas características particulares pode introduzir algum viés na área (Bender, 2009).\n",
            "\n",
            "Assim, esta seção aborda EIA para a língua portuguesa, incluindo uma formalização e a evolução das abordagens da área.\n",
            "\n",
            "A tarefa de EIA pode ser formalmente definida sendo \\(X = \\langle x_{1}, x_{2}, \\cdots, x_{n}\\rangle\\) uma sentença composta de tokens \\(x_i\\). Um extrator EIA é uma função que mapeia \\(X\\) em um conjunto \\(Y = \\langle y_{1}, y_{2}, \\cdots, y_{j} \\rangle\\) como um conjunto de tuplas \\(y \\_i = \\langle rel_i, arg1_i, arg2_i, \\cdots, argn_i\\rangle\\), que descrevem as informações expressas na sentença X. Neste capítulo, consideramos que as tuplas estão sempre no formato \\(y = (arg_{1 }, rel, arg_{2})\\), onde \\(arg1\\) e \\(arg2\\) são sintagmas nominais, não necessariamente formados por tokens presentes em X, e \\(rel\\) é um descritor de um relacionamento entre \\(arg_{1}\\) e \\(arg_{2}\\). Não consideraremos extrações formadas por mais de dois argumentos neste capítulo.\n",
            "\n",
            "Os primeiros métodos de EIA empregavam padrões de inspiração linguística para extração, como ArgOE (Gamallo; Garcia, 2015), ou adaptação de métodos para a língua inglesa, como SGS (Souza; Claro; Glauber, 2018), InferReVerbPT Sena; Glauber; Claro (2017) e RePort Pereira; Pinheiro (2015). Os trabalhos são principalmente influenciados por métodos baseados no inglês da chamada segunda geração de EIA (Fader; Soderland; Etzioni, 2011).\n",
            "\n",
            "O primeiro sistema de EIA para o português de que temos conhecimento foi o DepOE (Gamallo; Garcia; Fernández-Lanza, 2012). Ele executa a extração aberta multilíngue de triplas (inglês, espanhol, português e galego) usando o analisador sintático de dependências baseado em regras DepPattern. No entanto, nenhuma avaliação ou resultados são relatados para a língua portuguesa. Os autores apresentam somente uma comparação dos seus resultados com Reverb na língua inglesa.\n",
            "\n",
            "Souza; Claro (2014) se propuseram a analisar o conjunto de características mais representativas da língua portuguesa para a identificação de extrações válidas no contexto de EIA, tal qual empregado na língua inglesa com o sistema ReVerb (Fader; Soderland; Etzioni, 2011).\n",
            "\n",
            "parte do cap 9\n",
            "\n",
            "Outras iniciativas culminaram na geração de bases de frames em português, todas de menor tamanho que a FN-Br e para domínios ainda mais específicos.\n",
            "\n",
            "A base FrameFOR (Barreira; Pinheiro; Furtado, 2017) é uma base com 113 frames em português brasileiro, adaptados da FrameNet original, contendo os papéis semânticos, unidades e entradas lexicais relacionados aos tipos de crimes mais investigados na Perícia Forense do Estado do Ceará, no Brasil (PEFOCE) – formação de quadrilha, tráfico de drogas, sequestro, corrupção, receptação, contrabando, pedofilia, estupro, agressão, tortura, falsificação, ameaça, porte ilegal de arma, estelionato, e extorsão.\n",
            "\n",
            "O estudo de (Bertoldi, 2011) analisou os limites da criação automática de léxicos computacionais segundo o paradigma FrameNet, comparando as unidades lexicais evocadoras, os papéis semânticos e a estrutura do frame Criminal_process, em inglês e português. Esse estudo contrastivo mostrou que os frames do domínio jurídico são socialmente orientados e que a criação automática de léxicos em áreas cultural e socialmente orientadas tende a apresentar divergências. Em (Bick, 2009) tem-se a proposta de PFN-PT, um sistema para a anotação semântica automática do português, consistindo numa nova framenet contendo cerca de 13.000 padrões sintáticos, cobrindo 7.300 lemas verbais com 10.700 sentidos.\n",
            "\n",
            "Todos estes projetos, ainda que de menor porte, possuem relatos de sucesso em aplicações de PLN como extração de informação, anotação de papéis semânticos, reconhecimento de entidades nomeadas, evidenciando a importância de abordar as peculiaridades linguísticas com perspectivas contextualizadas e culturalmente relevantes.\n",
            "\n",
            "Nesta seção, usaremos a FrameNet de Berkeley para analisar o exemplo motivador definido no início da Seção 9.1. No Exemplo 9.3 são destacados o frame associado, as unidades lexicais (elemento evocador) que evocaram o frame e os papéis semânticos identificados no texto.\n",
            "\n",
            "Exemplo 9.3  \n",
            "\n",
            "Um assalto do tipo saidinha bancária, ocorrido na tarde desta terça-feira, terminou com uma mulher de 42 anos baleada pelos assaltantes. O roubo ocorreu na rua Professor Costa Mendes.\n",
            "\n",
            "Uma dificuldade com a análise desse exemplo, à luz da FrameNet, foi na identificação do papel semântico “vítima” (“uma mulher de 42 anos”), pois o complemento da sentença que a contém “…com uma mulher de 42 anos baleada …” possui a estrutura sintática Prep.Det.N (preposição + determinante + substantivo) e não é compatível com nenhuma realização sintática do elemento de frame victim.\n",
            "\n",
            "ConceptNet25 (Speer; Chin; Havasi, 2016) é uma base de conhecimento de senso comum que expressa relações rotuladas e ponderadas entre palavras ou fragmentos de textos em linguagem natural, através de um Grafo de Conhecimento (Knowledge Graph) contendo edges ou afirmações. Alguns exemplos de afirmações expressas na ConceptNet são:\n",
            "\n",
            "Sua versão original (Havasi; Speer; Alonso, 2007; Liu; Singh, 2004) foi criada pela equipe do MediaLab do Massachusetts Institute of Technology (MIT) em 1999, a partir de conhecimentos extraídos do projeto de construção coletiva (crowdsourcing) Open Mind Common Sense (OMCS) (Singh et al., 2002). O OMCS surgiu com o objetivo de coletar, pela Internet e de colaboradores voluntários, sentenças que expressavam fatos da vida comum. Por exemplo, a sentença “The Effect of [falling off a bike] is [you get hurt]” foi coletada de voluntários, quando solicitados a preencher os espaços do template “The Effect of [.….] is [.….]”. A alternativa adotada pela equipe da ConceptNet foi construir a rede semântica (nós conceituais interligados pelas relações semânticas), a partir de um processo automático sobre o corpus OMCS, o qual extraiu as relações semânticas e seus argumentos.\n",
            "\n",
            "A motivação do projeto que mantém a ConceptNet é expressar os fatos que as pessoas sabem comumente sobre o mundo ― conhecimento de senso comum ― através de afirmações que relacionam conceitos. Este tipo de conhecimento é importante porque, quando as pessoas se comunicam, seus proferimentos acontecem sobre suposições implícitas e básicas, as quais suportam e explicam boa parte dos raciocínios necessários para um bom nível de entendimento e, consequentemente, uma boa comunicação. Por exemplo, quando alguém fala “Eu comprei doces”, está implícito que usou dinheiro, ou quando fala “Fui a um casamento”, provavelmente tinha uma noiva, um noivo, uma festa com bolo e champagne, e o interlocutor está autorizado a perguntar “A noiva estava bonita?” etc.\n",
            "\n",
            "Atualmente, a ConceptNet26 evoluiu como um projeto colaborativo com diversas fontes:\n",
            "\n",
            "parte do cap 17\n",
            "\n",
            "O sistema RePort (Pereira; Pinheiro, 2015), por outro lado, é uma adaptação do ReVerb para a língua portuguesa baseada em análise sintática rasa com regras sintáticas e lexicais. Os autores relatam que suas extrações apresentam grande similaridade com suas correlatas extraídas pelo ReVerb (dos textos traduzidos para o inglês).\n",
            "\n",
            "O RELP, proposto por Abreu; Vieira (2017), é um sistema aberto de extração de relações que extrai relações entre entidades nomeadas em um domínio de organização aplicando classificação sequencial com CRF (Conditional Random Fields). O sistema RelP extrai qualquer descritor de relação que expressa um relacionamento entre pares de entidades nomeadas (Organização, Pessoa ou Lugar), caracterizando-o como uma abordagem híbrida da REN com a EIA.\n",
            "\n",
            "O InferReVerbPT desenvolvido por Sena; Glauber; Claro (2017) baseia-se numa adaptação do sistema ReVerb para a língua portuguesa, expandindo-o com a extração de relacionamentos implícitos obtidos por inferência por propriedades de simetria e transitividade das relações com inferência transitiva e simétrica. Um classificador SVM foi empregado para realizar a inferência baseado nas propriedades semânticas do verbo central no descritor de relação.\n",
            "\n",
            "Souza; Claro; Glauber (2018) analisaram que a maior desvantagem dos estudos baseados em recursos linguísticos, como dados anotados, reside na escassez de tais recursos na maioria dos idiomas além do inglês. Assim, para mitigar esse problema, eles propõem um método de classificação de fatos baseado na similaridade de estruturas gramaticais (SGS). Sua abordagem modela estruturas morfosintáticas dos fatos (triplas descrevendo relacionamentos) para identificar padrões de semelhanças que podem ser usados para distinguir entre fatos válidos e inválidos. Eles aplicaram algoritmos de isomorfismo de grafos para detectar subgrafos descrevendo tais padrões.\n",
            "\n",
            "Um novo sistema de EIA baseado em análise de dependência foi proposto por Gamallo; Garcia (2015), chamado ArgOE. Tal sistema é multilíngue, baseado em heurísticas e utiliza a informação de dependência sintáticas do texto para analisar a estrutura de dependência do verbo, bem como um conjunto de regras para gerar os relacionamentos. A introdução de um Analisador de Dependência em sistemas de EIA focados inteiramente na língua portuguesa foi feita pelos autores Oliveira; Claro; Souza (2022). O DptOIE é baseado em análise de dependência e regras elaboradas manualmente. As sentenças são pré-processadas por meio de um tokenizador, um PoS Tagger e um analisador de dependências. Os autores propõem um acoplamento de três módulos para tratar casos particulares: conjunções coordenadas, orações subordinadas e aposto.\n",
            "\n",
            "Com a evolução dos métodos de EIA para a língua inglesa utilizando os modelos neurais, novas abordagens foram propostas também para a língua portuguesa.\n",
            "\n",
            "O primeiro trabalho que utilizou aprendizado supervisionado com rede neural profunda para o português foi o de Ro; Lee; Kang (2020) que descreve o sistema Multi2OIE. Os autores utilizaram o modelo de linguagem BERT multilíngue (Devlin et al., 2019) para obter representações vetoriais das palavras e reduzem a tarefa de EIA à classificação sequencial, identificado os fragmentos do texto que determinam os argumentos (\\(arg_1, arg_2\\)) e o descritor de relação (\\(rel\\)). Seu sistema foi capaz de produzir extrações para vários idiomas (inglês, português e espanhol), treinados, entretanto, sobre dados traduzidos do inglês.\n",
            "\n",
            "Stanovsky et al. (2018) propuseram uma abordagem de EIA para a língua inglesa baseada em triplas. Os mesmos fazem uso de uma classificação sequencial cuja limitação define uma tripla extraída para cada sentença. Este método utiliza uma arquitetura de Redes Neurais Recursivas (RNN) para realizar EIA. A EIA é formulada como uma tarefa de rotulagem de sequências, utilizando estratégias semelhantes às que foram aplicadas anteriormente a tarefas como o Reconhecimento de Entidades Nomeadas. Já os autores em Cui; Wei; Zhou (2018) e Zhang; Duh; Van Durme (2017) propõem modelar o problema da EIA como um problema de aprendizado sequência a sequência (seq2seq). Eles definem uma estrutura encoder-decoder para aprender argumentos e tuplas de relação inicializadas a partir de um sistema de EIA.\n",
            "\n",
            "Seguindo o trabalho de (Stanovsky et al., 2018), em 2022, Cabral; Souza; Claro (2022) propuseram PortNOIE, uma arquitetura neural para EIA em português que combina representações contextuais de palavras com codificadores neurais para extrair relacionamentos baseado em classificação sequencial iterativa. Diferente de outros métodos de classificação sequencial para EIA, os autores focam na extração de múltiplas triplas de uma mesma sentença.\n",
            "\n",
            "A avaliação sistemática de sistemas de EI foi estabelecida primeiramente nas conferências MUC, em particular na sua segunda edição, com o estabelecimento de gabaritos-padrão que deveriam ser utilizados por todos os sistemas participantes e a adoção de métricas de qualidade, baseadas naquelas usadas na área de recuperação de informação, que foram abordadas no Capítulo 16. Para avaliar a tarefa de extração de relações, a MUC-2 estabeleceu como métricas de qualidade do sistema as medidas de precisão e cobertura, também denominada de Recall ou Revocação.\n",
            "\n",
            "A precisão de um sistema reflete a qualidade de suas extrações, i.e., quantas das extrações realizadas estão corretas, dado um corpus de teste. A medida de precisão pode ser calculada como:\n",
            "\n",
            "P = \\frac{\\#(\\mbox{relacionamentos corretamente extraídos})}{\\#(\\mbox{relacionamentos extraídos pelo sistema})}\n",
            "\n",
            "A cobertura também conhecida como revocação, reflete quão abrangente um sistema é em suas extrações, i.e., quantas das extrações a serem realizadas em um corpus de teste, o sistema é capaz de realizar. A medida de cobertura pode ser calculada como:\n",
            "\n",
            "R = \\frac{\\#(\\mbox{relacionamentos extraídos})}{\\#(\\mbox{relacionamentos no \\textit{corpus}})}\n",
            "\n",
            "Enquanto a MUC-3 adicionou duas novas métricas de avaliação, a saber sobre-geração (overgeneration) e sub-geração (fallout), tais métricas receberam pouco interesse na literatura. De fato, Lehnert; Sundheim (1991) argumentam que tais métricas foram pouco informativas ou difíceis de calcular para a tarefa de EI e, portanto, abandonadas. Foi também empregado nessa conferência um sistema automático de avaliação disponibilizado às equipes participantes que permitiu uma maior compreensão do modelo de avaliação e, como discutem Lehnert; Sundheim (1991), um avanço qualitativo nos sistemas gerados.\n",
            "\n",
            "parte do cap 9\n",
            "\n",
            "Outras iniciativas culminaram na geração de bases de frames em português, todas de menor tamanho que a FN-Br e para domínios ainda mais específicos.\n",
            "\n",
            "A base FrameFOR (Barreira; Pinheiro; Furtado, 2017) é uma base com 113 frames em português brasileiro, adaptados da FrameNet original, contendo os papéis semânticos, unidades e entradas lexicais relacionados aos tipos de crimes mais investigados na Perícia Forense do Estado do Ceará, no Brasil (PEFOCE) – formação de quadrilha, tráfico de drogas, sequestro, corrupção, receptação, contrabando, pedofilia, estupro, agressão, tortura, falsificação, ameaça, porte ilegal de arma, estelionato, e extorsão.\n",
            "\n",
            "O estudo de (Bertoldi, 2011) analisou os limites da criação automática de léxicos computacionais segundo o paradigma FrameNet, comparando as unidades lexicais evocadoras, os papéis semânticos e a estrutura do frame Criminal_process, em inglês e português. Esse estudo contrastivo mostrou que os frames do domínio jurídico são socialmente orientados e que a criação automática de léxicos em áreas cultural e socialmente orientadas tende a apresentar divergências. Em (Bick, 2009) tem-se a proposta de PFN-PT, um sistema para a anotação semântica automática do português, consistindo numa nova framenet contendo cerca de 13.000 padrões sintáticos, cobrindo 7.300 lemas verbais com 10.700 sentidos.\n",
            "\n",
            "Todos estes projetos, ainda que de menor porte, possuem relatos de sucesso em aplicações de PLN como extração de informação, anotação de papéis semânticos, reconhecimento de entidades nomeadas, evidenciando a importância de abordar as peculiaridades linguísticas com perspectivas contextualizadas e culturalmente relevantes.\n",
            "\n",
            "Nesta seção, usaremos a FrameNet de Berkeley para analisar o exemplo motivador definido no início da Seção 9.1. No Exemplo 9.3 são destacados o frame associado, as unidades lexicais (elemento evocador) que evocaram o frame e os papéis semânticos identificados no texto.\n",
            "\n",
            "Exemplo 9.3  \n",
            "\n",
            "Um assalto do tipo saidinha bancária, ocorrido na tarde desta terça-feira, terminou com uma mulher de 42 anos baleada pelos assaltantes. O roubo ocorreu na rua Professor Costa Mendes.\n",
            "\n",
            "Uma dificuldade com a análise desse exemplo, à luz da FrameNet, foi na identificação do papel semântico “vítima” (“uma mulher de 42 anos”), pois o complemento da sentença que a contém “…com uma mulher de 42 anos baleada …” possui a estrutura sintática Prep.Det.N (preposição + determinante + substantivo) e não é compatível com nenhuma realização sintática do elemento de frame victim.\n",
            "\n",
            "ConceptNet25 (Speer; Chin; Havasi, 2016) é uma base de conhecimento de senso comum que expressa relações rotuladas e ponderadas entre palavras ou fragmentos de textos em linguagem natural, através de um Grafo de Conhecimento (Knowledge Graph) contendo edges ou afirmações. Alguns exemplos de afirmações expressas na ConceptNet são:\n",
            "\n",
            "Sua versão original (Havasi; Speer; Alonso, 2007; Liu; Singh, 2004) foi criada pela equipe do MediaLab do Massachusetts Institute of Technology (MIT) em 1999, a partir de conhecimentos extraídos do projeto de construção coletiva (crowdsourcing) Open Mind Common Sense (OMCS) (Singh et al., 2002). O OMCS surgiu com o objetivo de coletar, pela Internet e de colaboradores voluntários, sentenças que expressavam fatos da vida comum. Por exemplo, a sentença “The Effect of [falling off a bike] is [you get hurt]” foi coletada de voluntários, quando solicitados a preencher os espaços do template “The Effect of [.….] is [.….]”. A alternativa adotada pela equipe da ConceptNet foi construir a rede semântica (nós conceituais interligados pelas relações semânticas), a partir de um processo automático sobre o corpus OMCS, o qual extraiu as relações semânticas e seus argumentos.\n",
            "\n",
            "A motivação do projeto que mantém a ConceptNet é expressar os fatos que as pessoas sabem comumente sobre o mundo ― conhecimento de senso comum ― através de afirmações que relacionam conceitos. Este tipo de conhecimento é importante porque, quando as pessoas se comunicam, seus proferimentos acontecem sobre suposições implícitas e básicas, as quais suportam e explicam boa parte dos raciocínios necessários para um bom nível de entendimento e, consequentemente, uma boa comunicação. Por exemplo, quando alguém fala “Eu comprei doces”, está implícito que usou dinheiro, ou quando fala “Fui a um casamento”, provavelmente tinha uma noiva, um noivo, uma festa com bolo e champagne, e o interlocutor está autorizado a perguntar “A noiva estava bonita?” etc.\n",
            "\n",
            "Atualmente, a ConceptNet26 evoluiu como um projeto colaborativo com diversas fontes:\n",
            "\n",
            "parte do cap 17\n",
            "\n",
            "Além das medidas de precisão e cobertura, assim como em tarefas de classificação de texto e recuperação de informação, utilizamos a média harmônica entre essas medidas, chamada medida F1, a fim de condensar a informação contida nas duas. A medida F1 pode ser calculada como:\n",
            "\n",
            "F1 = \\frac{2*P*R}{P+R}\n",
            "\n",
            "A avaliação da tarefa de REN segue padrões semelhantes aos aplicados à tarefa de ER. De fato, desde a MUC-6 (Grishman; Sundheim, 1996), as medidas de precisão, cobertura e F1 tem sido usada consistentemente como métricas de avaliação da tarefa de REN em diversos esforços de avaliação, como a CoNNL (Sang; De Meulder, 2003), para a língua inglesa, e das duas edições do HAREM (Gonçalo Oliveira et al., 2008; Santos; Cardoso; Seco, 2007), com excessão à ACE (Doddington et al., 2004) que apresenta uma combinação da tarefa de REN com reconhecimento de co-referência entre entidades e utiliza um sistema de pontuação próprio.\n",
            "\n",
            "A avaliação de sistemas de EIA, por sua vez, possui algumas peculiaridades que precisam ser discutidas. Uma vez que a tarefa é postulada por Banko et al. (2007) como a extração de todas as relações identificadas em um dado fragmento textual, sem limitação de domínio de interesse, tal tarefa impõe imensa dificuldade aos esforços de avaliação.\n",
            "\n",
            "De fato, Glauber et al. (2018) relatam um esforço de anotação de dados para a tarefa em língua portuguesa em que foram identificados por anotadores humanos mais de 400 relacionamentos em um corpus de 25 sentenças retiradas de textos jornalísticos e de enciclopédia. Assim, a avaliação de EIA deu-se, em grande parte de seu desenvolvimento e maturação, em conjuntos de dados não anotados, recorrendo a avaliações qualitativas das saídas dos sistemas e comparação direta por humanos das extrações obtidas.\n",
            "\n",
            "Nesses esforços de avaliação, a precisão do sistema pode ser mensurada a partir da avaliação humana das saídas. Não é possível, entretanto, avaliar medidas como cobertura e F1, dada a inexistência de uma referência do conjunto total de relacionamentos a serem identificados. Assim, os autores da área propuseram diferentes métricas a fim de estimar tais valores, como a métrica rendimento (yield) (Fader; Soderland; Etzioni, 2011; Schmitz et al., 2012).\n",
            "\n",
            "A métrica de rendimento consiste no núemro de extrações válidas, i.e. corretas, de um dado sistema. Como calcular tal medida é, na maioria dos casos, impraticável dada a grande quantidade de extrações realizadas pelos sistemas, ela pode ser estimada a partir da precisão do sistema calculada sobre uma amostra aleatória das extrações realizadas (\\(P'\\)). Assim, podemos estimar o rendimento como:\n",
            "\n",
            "Y = P'\\cdot \\#(\\mbox{extrações realizadas})\n",
            "\n",
            "Foi também explorada a estratégia de criação (semi-)automática de conjuntos de dados usando vários sistemas (Del Corro; Gemulla, 2013), estratégias de supervisão fraca (Smirnova; Cudré-Mauroux, 2018), ou a geração de corpora para a tarefa a partir da transformação de anotações de tarefas próximas, como identificação de papéis temáticos (Semantic Role Labeling) por (Stanovsky et al., 2018). Corpora gerados de forma semi-automática vêm ganhando atenção na literatura recente, particularmente para a língua inglesa, devido a necessidade de dados anotados para se utilizar técnicas de aprendizado de máquina e redes neurais em EIA. Corpora como o OIE2016 (Stanovsky et al., 2018), Wire57 (Léchelle; Gotti; Langlais, 2018) e CARB (Bhardwaj; Aggarwal; Mausam, 2019) vêm se tornando corpora de referência em língua inglesa para o problema, apesar dos problemas existentes na construção de tais recursos – a não exaustividade das relações anotadas.\n",
            "\n",
            "Para a língua portuguesa, foram propostas algumas iniciativas para avaliar os sistemas da OIE. Uma avaliação conjunta foi promovida durante o Fórum Ibérico de Avaliação de Línguas (IberLEF) em 2019 (Collovini et al., 2019). A avaliação foi feita usando o corpus proposto por Glauber et al. (2018), que é composto por 442 relacionamentos extraídos de 25 frases de fontes como a seção em português da Wikipédia, o corpus CETENFolha, resenhas de filmes do portal Adoro Cinema2 e o corpus Europarl. Apesar desta tarefa ter contemplado quatro cenários de avaliação, a avaliação geral dos sistemas permaneceu consistente nos diferentes cenários, indicando robustez nos resultados da avaliação. No geral, os sistemas DPTOIE (Oliveira; Claro; Souza, 2022) e Linguakit (Gamallo; Garcia, 2015) tiveram o melhor desempenho, com o Linguakit2 dominando as avaliações de correspondência exata e o DPTOIE as avaliações de correspondências parciais (Collovini et al., 2019).\n",
            "\n",
            "Outra abordagem de avaliação foi idealizada por (Malenchini et al., 2019). Seu foco foi a avaliação extrínseca dos sistemas de EIA através de sua contribuição na tarefa de respostas automáticas a perguntas. Os autores apresentaram um conjunto de dados de referência (benchmark) para avaliação extrínseca de sistemas de EIA em textos de língua portuguesa. Os sistemas que alcançaram os melhores valores na avaliação realizada pelos autores foram os sistemas ArgOE (Gamallo; Garcia, 2015), DependentIE (Glauber; Claro; Oliveira, 2019) e DptOIE (Oliveira; Claro; Souza, 2022).\n",
            "\n",
            "Este capítulo descreveu uma visão geral da área de Extração de Informação, apresentando a Extração de Informação Tradicional e a Extração de Informação Aberta. Transversalmente, apresentamos as formalizações necessárias e os conceitos fundamentais para a compreensão da EIA, assim como a avaliação da área e as heranças de outras áreas afins, tais como RI.\n",
            "\n",
            "Nessa primeira versão, este capítulo descreveu de maneira bem sucinta as abordagens propostas para EI e EIA durante seu desenvolvimento histórico e as abordagens atuais da literatura, como as utilizando modelos de linguagens. Especificamente, a utilização da arquitetura Transformers, descritas no Capítulo 15 para as tarefas de EI e EIA tem sido bastante difundida para a língua inglesa e tem atuado em diversas áreas da PLN.\n",
            "\n",
            "Agradecemos as colaborações dos autores deste Capítulo e suas indicações, assim como agradecemos a Adriana Pagano e Aline Macohin pela revisão e comentários.\n",
            "\n",
            "Em nossa terminologia, por um relacionamento.↩︎\n",
            "\n",
            "parte do cap 9\n",
            "\n",
            "A unidade de conhecimento da ConceptNet é uma afirmação ou edge28 que é uma relação particular entre termos ou frases em uma linguagem natural, de uma fonte específica. Sucintamente, cada edge é uma tripla com um primeiro argumento (nó inicial), um rótulo da relação e um segundo argumento (nó final). Por exemplo, a afirmação “Bicycle is used to get somewhere fast” pode ser expressa como (Bicycle, is used to, get somewhere fast). Cada edge é representada em uma estrutura de dados com os seguintes atributos:\n",
            "\n",
            "A ConceptNet contém mais de 21 milhões de edges e quase 10 milhões de nós com palavras ou fragmentos de textos. A base cobre em torno de 78 linguagens naturais31 com pelo menos 10.000 entradas no vocabulário. As 10 (dez) principais linguagens são: inglês, francês, italiano, alemão, espanhol, russo, português, japonês, holandês e chinês. A base de afirmações na linguagem inglesa possui um vocabulário com 1,8 milhão de nós, e no português contém um vocabulário com 473 mil nós.\n",
            "\n",
            "O framework computacional da ConceptNet contém uma hierarquia de URIs que identificam os principais componentes dessa base de conhecimento: afirmações (ou edges), termos (palavras ou frases em uma linguagem particular), relações (por exemplo, IsA), datasets, fontes de dados. Também possui uma API REST32 pela qual você pode obter os componentes no formato JSON. Cada edge, termo, relação, dataset e fonte da ConceptNet possui uma URI que os identificam e sua definição completa em JSON pode ser acessada via API. A Figura 9.6 apresenta um recorte da definição do termo “murder”, contendo a lista de edges a partir desse termo.\n",
            "\n",
            "Ao acessar, via API, a definição deste termo, tem-se acesso à sua definição em JSON, conforme ilustrado na Figura 9.7, com a URI deste conceito (“/c/en/murder”) e a lista de edges.\n",
            "\n",
            "ConceptNet se tornou um hub de conteúdo semântico, pois provê link para outras bases de dados, com um toolkit e uma API que suportam inferências práticas de senso comum sobre textos, tais como descoberta de contexto (que habilita a extração da vizinhança contextual de um conceito, e.g., “tirar a roupa”, “ir dormir”, e “deitar-se” são vizinhos do conceito “ir para a cama”), cadeia de inferências (que habilita encontrar caminhos na rede semântica a partir de um conceito, e.g., “comprar comida” - “ter comida” - “comer comida” - “sentir-se cheio” - “sentir-se com sono”) e analogia conceitual (que envolve encontrar conceitos que são estruturalmente similares, e.g., “funeral” e “casamento”, “sofá” e “cama”). Todos esses exemplos foram extraídos de (Ovchinnikova, 2012).\n",
            "\n",
            "Como visto, a Conceptnet 5.8 possui uma cobertura de 473 mil termos ou frases no português, representando assim a mais extensa base de conhecimento de senso comum para essa língua.\n",
            "\n",
            "O projeto Open Mind Common Sense – Brasil (OMCS-Br) foi um projeto do Laboratório de Interação Avançada (LIA) da Universidade Federal de São Carlos – UFSCar, em colaboração com o MediaLab do MIT, para a coleta de conhecimento de senso comum em português (Anacleto et al., 2006). Este projeto em 2010 contava com 160.000 afirmações de senso comum de seus colaboradores. O projeto foi descontinuado, mas diversas aplicações e estudos foram desenvolvidos a partir desta base. Dentre eles, podemos citar, uma ferramenta que utiliza a base de conhecimento de senso comum para auxiliar a interação humana (de alunos e professores) com ferramentas educacionais (Anacleto et al., 2007).\n",
            "\n",
            "A base InferenceNet-BR (Pinheiro et al., 2010) adapta a ConceptNet (Liu; Singh, 2004) adicionando uma camada que define o papel da afirmação em uma inferência – se como premissa (ou pré-condição) ou como conclusão (ou pós-condição). Além da tradução dos termos e suas afirmações (relações com outros conceitos), o projeto da InferenceNet-BR evoluiu a base com novo conhecimento semântico específico para o domínio de segurança pública em português.\n",
            "\n",
            "A InferenceNet-BR compõe-se de duas bases de conhecimento:\n",
            "\n",
            "A Figura 9.8 ilustra uma parte da rede de relacionamento inferencial da palavra “crime” na base InferenceNet-BR, com as seguintes relações:\n",
            "\n",
            "Nesta seção, usaremos a base da ConceptNet para o português e para o inglês para analisar o Exemplo 9.1. No Exemplo 9.4 são destacadas algumas afirmações de senso comum associadas aos termos mencionados no texto (termos sublinhados).\n",
            "\n",
            "Exemplo 9.4  \n",
            "\n",
            "parte do cap 17\n",
            "\n",
            "Daniela Barreiro Claro \n",
            "\n",
            "Joaquim Santos \n",
            "\n",
            "Marlo Souza \n",
            "\n",
            "Renata Vieira \n",
            "\n",
            "Vládia Pinheiro \n",
            "\n",
            "PDF\n",
            "\n",
            "A Extração de Informação (EI) é desenvolvida com o objetivo de se obter informação estruturada de dados não-estruturados (Jurafsky; Martin, 2023; Konstantinova, 2014).\n",
            "\n",
            "Os primeiros trabalhos a debruçarem-se sobre o problema remontam à década de 1970, com a aplicação de gramáticas formais e parsers sintáticos para a estruturação de informação em domínios como prontuários médicos (Sager, 1978; Sager; Friedman; Lyman, 1987) e textos jornalísticos (DeJong, 1979). A comunidade científica demonstrou grande interesse pela área nas décadas posteriores devido à sua utilidade prática, seu foco no processamento de dados reais, suas tarefas bem-definidas e a facilidade de mensurar a qualidade dos resultados em comparação com o desempenho humano na mesma tarefa (Cowie; Lehnert, 1996).\n",
            "\n",
            "Para autores como Eisenstein (2019) e Jurafsky; Martin (2023), a EI é normalmente dividida em diversas tarefas de interesse, com foco no tipo de informação a ser extraída do texto. Entre as mais comumente citadas na literatura estão o Reconhecimento de Entidades Nomeadas (REN), a Extração de Relações (ER) e a Extração de Eventos (EE).\n",
            "\n",
            "O Reconhecimento de Entidades Nomeadas (REN) consiste em identificar e classificar entidades mencionadas em textos através de designadores rígidos como nomes próprios, expressões temporais e espécies biológicas (Nadeau, 2007). Esse é considerado por alguns como um primeiro passo na análise semântica de um texto (Santos; Cardoso, 2007a), pois permite identificar as entidades às quais se faz referência nele.\n",
            "\n",
            "A Extração de Relações (ER), também chamada de extração de informação tradicional ou somente extração de informação, por sua vez, diz respeito à identificação de relacionamentos semânticos entre duas ou mais entidades, ou seja, identificar “quem fez o que para quem e quando”. Ananiadou; Mcnaught (2005) a definem como o processo de extrair fatos (em nossa terminologia, relacionamentos) a partir de uma fonte textual e representá-los a partir de um gabarito (em inglês, template). As relações são elementos essenciais para o entendimento da informação relatada no texto e sua identificação é passo essencial para a estruturação da mesma. Assim, identificar relações entre entidades é tarefa essencial para construção de bases de conhecimento e de grande utilidade na construção de soluções para a resposta automática a perguntas (em inglês, query answering), sumarização, recuperação de informação e mais (Nasar; Jaffry; Malik, 2021).\n",
            "\n",
            "A extração de eventos consiste na tarefa de identificação de uma menção a um evento em uma sentença e, se existirem, extração de outras informações sobre o evento. Um evento pode, por sua vez, ser entendido como uma ocorrência específica envolvendo participantes (Consortium, 2005), i.e., algo que acontece e que pode ser descrito como uma mudança de estado da qual participam entidades como agentes. Devido a intrínseca natureza temporal dos eventos, tal problema possui uma natureza mais complexa e costuma possuir tratamento específico.\n",
            "\n",
            "Assim, nesse capítulo, iniciaremos com um pouco de história da Extração de Informação (EI) e sua evolução para Extração de Informação Aberta, e destacaremos as tarefas de Reconhecimeno de Entidades Nomeadas (REN) e Extração de Relação (ER).\n",
            "\n",
            "Os primeiros trabalhos que abordaram o problema de EI dos quais temos conhecimento surgiram no final da década de 1970. Esses primeiros trabalhos da década de 1970 e 1980 tinham como modelo geral a aplicação de regras para a identificação de informações especificadas em um gabarito. Tais sistemas empregavam analisadores sintáticos (parsers) e regras definidas especificamente para o domínio e gênero textual estudado.\n",
            "\n",
            "Entre esses primeiros trabalhos, estão aqueles de Sager (1978), Sager; Friedman; Lyman (1987), de DeJong (1979) e de Cowie (1983). Sager et al. exploraram como identificar informações do estado de saúde de pacientes através dos textos de prontuários médicos. DeJong (1979), por sua vez, descrevem o sistema FRUMP que, a partir de um parser e regras de análise conceitual baseadas em uma arquitetura cognitiva proposta pelos autores e no conceito de dependência conceitual de Schank et al. (1973), processavam textos de notícias e realizavam tarefas como sumarização e identificação de papéis semânticos associados aos constituintes da sentença. Cowie (1983), por fim, descreve um sistema que emprega regras simples de segmentação e análise sintática rasa para identificar propriedades de plantas a partir de textos descritivos no campo da botânica. Diferente dos métodos anteriores, o trabalho dos autores se baseia em grande parte no estudo de padrões de descrição das informações a serem identificadas, em detrimento do emprego de parsers robustos da língua.\n",
            "\n",
            "A década de 1990 traz um grande interesse na área de EI com a implementação das conferências MUC (do inglês, Message Understanding Conference, ou Conferência de Compreensão de Mensagem), promovidas pela Agência de Projetos de Pesquisa Avançada de Defesa (DARPA, do inglês Defense Advanced Research Projects Agency). As conferências MUC, realizadas e financiadas pelo exército americano, representaram um esforço em avançar a tecnologia de EI e consistiam de tarefas de avaliação conjunta de métodos desenvolvidos por pesquisadores para problemas propostos pelos organizadores. As sete conferências realizadas de 1987 a 1997, foram cruciais para definir aspectos centrais da área, como estruturar a tarefa de ER, definindo suas métricas de avaliação, e propor a tarefa de REN (Grishman; Sundheim, 1996).\n",
            "\n",
            "parte do cap 9\n",
            "\n",
            "A unidade de conhecimento da ConceptNet é uma afirmação ou edge28 que é uma relação particular entre termos ou frases em uma linguagem natural, de uma fonte específica. Sucintamente, cada edge é uma tripla com um primeiro argumento (nó inicial), um rótulo da relação e um segundo argumento (nó final). Por exemplo, a afirmação “Bicycle is used to get somewhere fast” pode ser expressa como (Bicycle, is used to, get somewhere fast). Cada edge é representada em uma estrutura de dados com os seguintes atributos:\n",
            "\n",
            "A ConceptNet contém mais de 21 milhões de edges e quase 10 milhões de nós com palavras ou fragmentos de textos. A base cobre em torno de 78 linguagens naturais31 com pelo menos 10.000 entradas no vocabulário. As 10 (dez) principais linguagens são: inglês, francês, italiano, alemão, espanhol, russo, português, japonês, holandês e chinês. A base de afirmações na linguagem inglesa possui um vocabulário com 1,8 milhão de nós, e no português contém um vocabulário com 473 mil nós.\n",
            "\n",
            "O framework computacional da ConceptNet contém uma hierarquia de URIs que identificam os principais componentes dessa base de conhecimento: afirmações (ou edges), termos (palavras ou frases em uma linguagem particular), relações (por exemplo, IsA), datasets, fontes de dados. Também possui uma API REST32 pela qual você pode obter os componentes no formato JSON. Cada edge, termo, relação, dataset e fonte da ConceptNet possui uma URI que os identificam e sua definição completa em JSON pode ser acessada via API. A Figura 9.6 apresenta um recorte da definição do termo “murder”, contendo a lista de edges a partir desse termo.\n",
            "\n",
            "Ao acessar, via API, a definição deste termo, tem-se acesso à sua definição em JSON, conforme ilustrado na Figura 9.7, com a URI deste conceito (“/c/en/murder”) e a lista de edges.\n",
            "\n",
            "ConceptNet se tornou um hub de conteúdo semântico, pois provê link para outras bases de dados, com um toolkit e uma API que suportam inferências práticas de senso comum sobre textos, tais como descoberta de contexto (que habilita a extração da vizinhança contextual de um conceito, e.g., “tirar a roupa”, “ir dormir”, e “deitar-se” são vizinhos do conceito “ir para a cama”), cadeia de inferências (que habilita encontrar caminhos na rede semântica a partir de um conceito, e.g., “comprar comida” - “ter comida” - “comer comida” - “sentir-se cheio” - “sentir-se com sono”) e analogia conceitual (que envolve encontrar conceitos que são estruturalmente similares, e.g., “funeral” e “casamento”, “sofá” e “cama”). Todos esses exemplos foram extraídos de (Ovchinnikova, 2012).\n",
            "\n",
            "Como visto, a Conceptnet 5.8 possui uma cobertura de 473 mil termos ou frases no português, representando assim a mais extensa base de conhecimento de senso comum para essa língua.\n",
            "\n",
            "O projeto Open Mind Common Sense – Brasil (OMCS-Br) foi um projeto do Laboratório de Interação Avançada (LIA) da Universidade Federal de São Carlos – UFSCar, em colaboração com o MediaLab do MIT, para a coleta de conhecimento de senso comum em português (Anacleto et al., 2006). Este projeto em 2010 contava com 160.000 afirmações de senso comum de seus colaboradores. O projeto foi descontinuado, mas diversas aplicações e estudos foram desenvolvidos a partir desta base. Dentre eles, podemos citar, uma ferramenta que utiliza a base de conhecimento de senso comum para auxiliar a interação humana (de alunos e professores) com ferramentas educacionais (Anacleto et al., 2007).\n",
            "\n",
            "A base InferenceNet-BR (Pinheiro et al., 2010) adapta a ConceptNet (Liu; Singh, 2004) adicionando uma camada que define o papel da afirmação em uma inferência – se como premissa (ou pré-condição) ou como conclusão (ou pós-condição). Além da tradução dos termos e suas afirmações (relações com outros conceitos), o projeto da InferenceNet-BR evoluiu a base com novo conhecimento semântico específico para o domínio de segurança pública em português.\n",
            "\n",
            "A InferenceNet-BR compõe-se de duas bases de conhecimento:\n",
            "\n",
            "A Figura 9.8 ilustra uma parte da rede de relacionamento inferencial da palavra “crime” na base InferenceNet-BR, com as seguintes relações:\n",
            "\n",
            "Nesta seção, usaremos a base da ConceptNet para o português e para o inglês para analisar o Exemplo 9.1. No Exemplo 9.4 são destacadas algumas afirmações de senso comum associadas aos termos mencionados no texto (termos sublinhados).\n",
            "\n",
            "Exemplo 9.4  \n",
            "\n",
            "parte do cap 17\n",
            "\n",
            "A partir da MUC-3, em 1991, a conferência passa a ter foco no processamento de textos jornalísticos em detrimento dos relatórios militares utilizados anteriormente (DARPA, 1991). Com a disponibilidade de dados e o incentivo no desenvolvimento de soluções para a tarefa, vemos na década de 1990 o surgimento das primeiras aplicações comerciais de EI, como o JASPER (Andersen et al., 1992)., construído para a agência de notícias Reuters.\n",
            "\n",
            "A MUC-6, ocorrida em 1995, introduz a tarefa de REN com o intuito de ser uma tarefa de uso prático, independente de domínio e que poderia ser realizada automaticamente em um futuro próximo (Grishman; Sundheim, 1996). Enquanto os trabalhos em REN se avolumaram a partir de sua proposição na MUC-6, trabalhos anteriores como Rau (1991) e Wolinski; Vichot; Dillet (1995) já se debruçavam sobre o problema de identificação e classificação de nomes próprios. Desde então, o interesse na tarefa cresceu significativamente e outras conferências de avaliação conjunta têm sido dedicadas a essa tarefa, como a Automatic Content Extraction (ACE) e a conferência Avaliação de Sistemas de Reconhecimento de Entidades Mencionadas (HAREM), dedicada exclusivamente à língua portuguesa, com sua primeira edição em 2005 (Santos; Cardoso, 2007a).\n",
            "\n",
            "Por outro lado, houve um crescimento de abordagens baseadas em dados nesta década, a partir da análise de corpora. Tais esforços são impulsionados pelos resultados positivos na área, como o trabalho de Hearst (1992). Logo, métodos baseados em dados passaram também a explorar o emprego de análise estatística e aprendizado de máquina na construção de padrões para a extração de relações (Riloff et al., 1993; Riloff; Jones; et al., 1999; Roark; Charniak, 2000; Soderland et al., 1995)\n",
            "\n",
            "Não foi somente na extração de padrões que métodos de aprendizado de máquina, em particular aprendizado supervisionado, foram aplicados. A década de 2000 viu a proliferação de métodos supervisionados aplicados à ER (Culotta; McCallum; Betz, 2006; Kambhatla, 2004; Zelenko; Aone; Richardella, 2003; Zhao; Grishman, 2005) e ao REN (Asahara; Matsumoto, 2003; McCallum; Li, 2003; Sekine, 1998).\n",
            "\n",
            "Devido à dificuldade de construção de dados para treinamento e padrões para extração, além da pouca adaptabilidade dos sistemas construídos para outros escopos e domínios, nos anos 2000, sistemas baseados em métodos de aprendizado semi-supervisionado, como o DIPRE (Brin, 1998) e Snowball (Agichtein; Gravano, 2000) começaram a aparecer, juntamente com os estudos sobre expansão automatizada de anotações (bootstrapping) (Riloff; Jones; et al., 1999). Também para entidades nomeadas, estudos investigaram como utilizar recursos da Web (Etzioni et al., 2005; Nadeau, 2007) ou corpora (Cucchiarelli; Velardi, 2001) para aprender entidades com pouco ou nenhum esforço de anotação.\n",
            "\n",
            "Buscando superar as dificuldades da limitação de escopo, i.e. das relações-alvo a serem extraídas e categorias de entidades a serem identificadas, ainda restritas à definição de padrões desde a criação dessas tarefas, Banko et al. (2007) propõe a tarefa de extração de informação aberta (EIA), também conhecida como Open Information Extraction, OpenIE ou OIE, a qual busca extrair todas as relações possíveis expressas em um texto, sem necessidade de pré-definição de relações e entidades.\n",
            "\n",
            "Devido ao recente sucesso da aplicação de métodos baseados em redes neurais, em particular deep learning e grandes modelos de linguagem, às tarefas de Processamento de Linguagem Natural, uma tendência atual da área se delineou como o estudo de arquiteturas neurais para os problemas de EI e a geração de grandes conjuntos de dados por supervisão fraca. Surveys recentes, como (Cui; Wei; Zhou, 2018; Konstantinova, 2014; Nasar; Jaffry; Malik, 2021), nos mostram a evolução da área em direção à aplicação de métodos neurais. Na vertente de geração de dados, vemos o emprego da Wikipédia e Freebase como fontes mais usadas para obter anotações de entidades e relações em textos (Nguyen; Theobald; Weikum, 2016; Smirnova; Cudré-Mauroux, 2018; Takamatsu; Sato; Nakagawa, 2012).\n",
            "\n",
            "Porém, toda a tarefa de EI necessita de uma concordância entre as definições de Entidade e Relação. Neste sentido, a próxima seção discute a conceituação de relação adotada neste capítulo, assim como o conceito de entidade.\n",
            "\n",
            "A natureza das relações estudadas na área de Extração de Informação e os critérios para reconhecer sua ocorrência em um texto têm recebido pouca atenção na literatura. Este é um passo importante para estabelecer metodologias adequadas para avaliar os sistemas, bem como para criar conjuntos de dados que possam apoiar a criação de sistemas futuros.\n",
            "\n",
            "Enquanto as noções de Relação e Entidade são de grande importância e já bem estudadas nas áreas de Computação, Linguística, Ciência da Informação e Filosofia da Linguagem, esses conceitos não são empregados de forma consistente entre as áreas, ou mesmo entre suas subáreas.\n",
            "\n",
            "Para Chen (1976), uma entidade é um objeto que pode ser concreto, tal como pessoa, livro, casa ou ainda abstrato, tal como um emprego, um sentimento, uma disciplina. As entidades podem estabelecer relações entre si. Duas ou mais entidades são vinculadas, ou seja conectadas por uma relação1.\n",
            "\n",
            "Tradicionalmente em reconhecimento de entidades nomeadas, as entidades consideradas são aquelas referenciadas por um nome próprio, acrescidas das referências temporais e valores que são expressões numéricas. Essas expressões, portanto, geralmente não constituem uma entrada em uma base lexical. Porém a tarefa se expandiu para domínios especializados, onde as entidades de interesse são mais conceituais. No domínio bio-médico por exemplo, podemos ter como exemplo de entidades de interesse, sintomas e tratamento que não são referenciadas por nomes próprios.\n",
            "\n",
            "Os conceitos de relação e relacionamento são noções fundamentais que vêm sendo estudadas em áreas como Ciência da Computação, Linguística e Filosofia.\n",
            "\n",
            "No campo de bancos de dados e modelagem conceitual, Chen (1976) define um relacionamento, no contexto da modelagem de Entidade-Relacionamento, como uma associação entre entidades. Guarino; Guizzardi (2015), por sua vez, estudando a natureza ontológica dos relacionamentos com base na semântica de veridadores (truthmaker semantics) (Fine, 2017), postulam relacionamentos como entidades que atuam como veridadores (thruthmakers) de alguma proposição relacionando duas ou mais entidades, ou seja, uma relação mantida entre essas entidades. Um veridador é um elemento cuja existência torna verdadeira uma proposição particular. Por exemplo, considerando a sentença (1) “a é uma maçã”, a existência de um objeto denotado pelo nome a que por acaso é uma maçã é uma condição suficiente para a verdade da frase (1). Como tal, dizemos que esse objeto é o veridador de (1). Tal definição nos permite adotar critérios ontológicos para validar a existência de relacionamentos a partir da informação relatada em um texto e, por isso, adotaremos tal definição de relacionamento neste capítulo.\n",
            "\n",
            "O conceito de relações é muito menos consistente na literatura. Ainda na área de modelagem conceitual, Guarino; Guizzardi (2015) definem as relações como proposições para as quais os relacionamentos são veridadores e, portanto, possuem conteúdo proposicional. Assim, podemos entender uma relação como um tipo para entidades como relacionamentos. Ou seja, relações são universais ontológicos que descrevem a natureza dos relacionamentos.\n",
            "\n",
            "Xavier; Lima; Souza (2015), no entanto, argumentam que a noção de relacionamento adotada na área de Extração de Informação é mais geral do que isso, não se limitando àquelas entre objetos e propriedades, mas também àquelas que descrevem ou implicam propriedades de classes gerais como descrito pela sentença (2) “Filósofos são autores de Livros”. Assim, para o contexto de EI consideramos relações como tipos de relacionamentos de primeira ou segunda ordem. Isso significa que uma relação é um tipo de relacionamento que existe entre objetos, suas propriedades e classes de objetos ou suas propriedades.\n",
            "\n",
            "parte do cap 9\n",
            "\n",
            "A unidade de conhecimento da ConceptNet é uma afirmação ou edge28 que é uma relação particular entre termos ou frases em uma linguagem natural, de uma fonte específica. Sucintamente, cada edge é uma tripla com um primeiro argumento (nó inicial), um rótulo da relação e um segundo argumento (nó final). Por exemplo, a afirmação “Bicycle is used to get somewhere fast” pode ser expressa como (Bicycle, is used to, get somewhere fast). Cada edge é representada em uma estrutura de dados com os seguintes atributos:\n",
            "\n",
            "A ConceptNet contém mais de 21 milhões de edges e quase 10 milhões de nós com palavras ou fragmentos de textos. A base cobre em torno de 78 linguagens naturais31 com pelo menos 10.000 entradas no vocabulário. As 10 (dez) principais linguagens são: inglês, francês, italiano, alemão, espanhol, russo, português, japonês, holandês e chinês. A base de afirmações na linguagem inglesa possui um vocabulário com 1,8 milhão de nós, e no português contém um vocabulário com 473 mil nós.\n",
            "\n",
            "O framework computacional da ConceptNet contém uma hierarquia de URIs que identificam os principais componentes dessa base de conhecimento: afirmações (ou edges), termos (palavras ou frases em uma linguagem particular), relações (por exemplo, IsA), datasets, fontes de dados. Também possui uma API REST32 pela qual você pode obter os componentes no formato JSON. Cada edge, termo, relação, dataset e fonte da ConceptNet possui uma URI que os identificam e sua definição completa em JSON pode ser acessada via API. A Figura 9.6 apresenta um recorte da definição do termo “murder”, contendo a lista de edges a partir desse termo.\n",
            "\n",
            "Ao acessar, via API, a definição deste termo, tem-se acesso à sua definição em JSON, conforme ilustrado na Figura 9.7, com a URI deste conceito (“/c/en/murder”) e a lista de edges.\n",
            "\n",
            "ConceptNet se tornou um hub de conteúdo semântico, pois provê link para outras bases de dados, com um toolkit e uma API que suportam inferências práticas de senso comum sobre textos, tais como descoberta de contexto (que habilita a extração da vizinhança contextual de um conceito, e.g., “tirar a roupa”, “ir dormir”, e “deitar-se” são vizinhos do conceito “ir para a cama”), cadeia de inferências (que habilita encontrar caminhos na rede semântica a partir de um conceito, e.g., “comprar comida” - “ter comida” - “comer comida” - “sentir-se cheio” - “sentir-se com sono”) e analogia conceitual (que envolve encontrar conceitos que são estruturalmente similares, e.g., “funeral” e “casamento”, “sofá” e “cama”). Todos esses exemplos foram extraídos de (Ovchinnikova, 2012).\n",
            "\n",
            "Como visto, a Conceptnet 5.8 possui uma cobertura de 473 mil termos ou frases no português, representando assim a mais extensa base de conhecimento de senso comum para essa língua.\n",
            "\n",
            "O projeto Open Mind Common Sense – Brasil (OMCS-Br) foi um projeto do Laboratório de Interação Avançada (LIA) da Universidade Federal de São Carlos – UFSCar, em colaboração com o MediaLab do MIT, para a coleta de conhecimento de senso comum em português (Anacleto et al., 2006). Este projeto em 2010 contava com 160.000 afirmações de senso comum de seus colaboradores. O projeto foi descontinuado, mas diversas aplicações e estudos foram desenvolvidos a partir desta base. Dentre eles, podemos citar, uma ferramenta que utiliza a base de conhecimento de senso comum para auxiliar a interação humana (de alunos e professores) com ferramentas educacionais (Anacleto et al., 2007).\n",
            "\n",
            "A base InferenceNet-BR (Pinheiro et al., 2010) adapta a ConceptNet (Liu; Singh, 2004) adicionando uma camada que define o papel da afirmação em uma inferência – se como premissa (ou pré-condição) ou como conclusão (ou pós-condição). Além da tradução dos termos e suas afirmações (relações com outros conceitos), o projeto da InferenceNet-BR evoluiu a base com novo conhecimento semântico específico para o domínio de segurança pública em português.\n",
            "\n",
            "A InferenceNet-BR compõe-se de duas bases de conhecimento:\n",
            "\n",
            "A Figura 9.8 ilustra uma parte da rede de relacionamento inferencial da palavra “crime” na base InferenceNet-BR, com as seguintes relações:\n",
            "\n",
            "Nesta seção, usaremos a base da ConceptNet para o português e para o inglês para analisar o Exemplo 9.1. No Exemplo 9.4 são destacadas algumas afirmações de senso comum associadas aos termos mencionados no texto (termos sublinhados).\n",
            "\n",
            "Exemplo 9.4  \n",
            "\n",
            "parte do cap 17\n",
            "\n",
            "Enquanto os métodos tradicionais de Extração de Informação dependem de um conjunto pré-existente de relações semânticas bem definidas que são relevantes para um domínio específico, a noção de “relação” e “entidade” na literatura da área mais recente, tais como a Extração de Informação Aberta, requer mais aprofundamento por demandar um significado diferente, principalmente com diferente visões de autores. Esta indeterminação terminológica pode trazer problemas para comparar os resultados dos métodos propostos ou para reutilizar os conjuntos de dados criados na área.\n",
            "\n",
            "As seções seguintes exploram essas duas áreas: Extração de Informação e Extração de Informação Aberta.\n",
            "\n",
            "A Extração de Informação é caracterizada por obter informação estruturada a partir de textos, sendo entidades ou fatos, i.e. relacionamentos entre entidades, de tipos previamente definidos, conforme exemplo na Quadro 17.1. Métodos com limitação de escopo possuem como uma de suas principais desvantagens a necessidade de intervenção humana para especificar novos fatos a serem extraídos. Esta limitação impede que sistemas de Extração de Informação, doravante denominados de EI tradicional extraiam fatos fora do escopo pré-definido.\n",
            "\n",
            "Quadro 17.1 Exemplos de relações específicas na EI tradicional\n",
            "\n",
            "Fonte: (Souza; Claro, 2014)\n",
            "\n",
            "O Reconhecimento de Entidades Nomeadas (REN) consiste na tarefa de identificar e classificar expressões linguísticas, denominadas entidades nomeadas (EN), que referenciam entidades específicas num domínio de discurso, como nomes próprios, expressões temporais e espécies biológicas (Mota; Santos; Ranchhod, 2007; Nadeau, 2007). De uma forma geral, o REN pode ser dividido em duas etapas: a identificação (ou delimitação) da expressão, na qual as palavras que formam a EN são selecionadas; a classificação, em que é atribuída uma categoria semântica à EN.\n",
            "\n",
            "A classificação das ENs determina os tipos de entidades a serem consideradas e são especificadas a partir do escopo definido previamente para a tarefa. Algumas das categorias mais comumente utilizadas incluem as entidades que referenciam Pessoas Singulares (antropônimos); Coletivas (empresas e organizações) e Lugares (topônimos) (Mota; Santos; Ranchhod, 2007). Para exemplificar tomemos a sentença: “Renata Silva e Maria Costa palestraram na Universidade Federal da Bahia”. No exemplo temos três ENs: “Renata Silva”, “Maria Costa”, “Universidade Federal da Bahia”, sendo as duas primeiras correspondentes à categoria semântica Pessoa e a última, à categoria semântica Organização. Entretanto, existem outras categorias de ENs, como as menções a Obras (por exemplo, “Código Da Vinci”); Acontecimentos (por exemplo, “Festa de Santo Antônio”), Tempo (por exemplo, “meio-dia”); Coisa (por exemplo, “barco”), entre outras.\n",
            "\n",
            "O REN é uma tarefa com grande importância para o Processamento de Linguagem Natural, pois consiste numa primeira tarefa de análise semântica de um texto, com potencial aplicações a diversas tarefas. Por exemplo, em sistemas de perguntas e respostas, as perguntas frequentemente se referem a informações sobre entidades. Também, métodos de identificação de estruturas mais complexas, como eventos ou relações, dependem do bom desempenho do REN como uma etapa de pré-processamento (Socher et al., 2012; Zelenko; Aone; Richardella, 2003).\n",
            "\n",
            "A tarefa de extração de relações (ou de relacionamentos) (ER) refere-se a identificar relacionamentos entre entidades de um determinado escopo mencionadas em um texto (Jurafsky; Martin, 2023). O escopo, no contexto da ER, refere-se a um conjunto de relações-alvo de um determinado domínio de conhecimento ou aplicação a ser investigado. Por exemplo, o Quadro 17.2 apresenta alguns exemplos de relações no domínio de geografia brasileira. Na descrição das relações, os elementos em negrito referem-se às entidades em um dado relacionamento descrito pelo termo em itálico.\n",
            "\n",
            "Quadro 17.2 Exemplos de relações no domínio da geografia brasileira.\n",
            "\n",
            "Nesse contexto, a delimitação de um escopo ou domínio de interesse, concentra-se na determinação das relações a serem processadas, i.e. nos tipos de relacionamentos de interesse, assim como da natureza das entidades associadas por tais relações.\n",
            "\n",
            "As tarefas de reconhecimento de entidades nomeadas e extração de relações são interdependentes, no sentido de que a definição do escopo a ser estudado delimita tanto as categorias e natureza das entidades a serem extraídas, como também as relações entre essas entidades. Também, note-se que, pelo fato de as relações serem comumente definidas entre entidades de tipo especificado, como o caso da relação Tem_Prefeito no Quadro 17.2 que ocorre entre entidades das classes Cidade e Pessoa, tanto as informações das entidades mencionadas no texto são úteis para a extração de relações, quanto a informação das relações identificadas pode ser útil ao processo de identificação de entidades.\n",
            "\n",
            "De fato, na literatura recente, existem vários trabalhos que consideram a tarefa de extração conjunta de entidades e relações (ERE, do inglês Entity and Relation Joint Extraction), composta das tarefas de REN e ER (Agichtein; Gravano, 2000; Shaowei et al., 2022; Yuan et al., 2021). Enquanto normalmente abordagens estruturam suas soluções de forma sequencial, usualmente realizando REN inicialmente e, posteriormente, realizando ER, como nos trabalhos de (Hasegawa; Sekine; Grishman, 2004) e de (Socher et al., 2012), a literatura recente aponta para as vantagens da identificação conjunta ao permitir um melhor aprendizado de restrições para identificação de entidades e relações, c.f. o recente survey realizado por (Shaowei et al., 2022) sobre métodos para tal tarefa.\n",
            "\n",
            "Várias abordagens foram adotadas para o problema de EI durante seu desenvolvimento histórico. Enquanto abordagens iniciais privilegiavam métodos ricos em conhecimento, como regras e recursos linguísticos e de conhecimento de mundo, a literatura recente na área privilegia métodos baseados em dados, como o aprendizado de máquina, com o recente emprego de arquiteturas neurais aos problemas.\n",
            "\n",
            "A seguir faremos uma breve apresentação das abordagens descritas na literatura para os problemas de EI.\n",
            "\n",
            "parte do cap 9\n",
            "\n",
            "A unidade de conhecimento da ConceptNet é uma afirmação ou edge28 que é uma relação particular entre termos ou frases em uma linguagem natural, de uma fonte específica. Sucintamente, cada edge é uma tripla com um primeiro argumento (nó inicial), um rótulo da relação e um segundo argumento (nó final). Por exemplo, a afirmação “Bicycle is used to get somewhere fast” pode ser expressa como (Bicycle, is used to, get somewhere fast). Cada edge é representada em uma estrutura de dados com os seguintes atributos:\n",
            "\n",
            "A ConceptNet contém mais de 21 milhões de edges e quase 10 milhões de nós com palavras ou fragmentos de textos. A base cobre em torno de 78 linguagens naturais31 com pelo menos 10.000 entradas no vocabulário. As 10 (dez) principais linguagens são: inglês, francês, italiano, alemão, espanhol, russo, português, japonês, holandês e chinês. A base de afirmações na linguagem inglesa possui um vocabulário com 1,8 milhão de nós, e no português contém um vocabulário com 473 mil nós.\n",
            "\n",
            "O framework computacional da ConceptNet contém uma hierarquia de URIs que identificam os principais componentes dessa base de conhecimento: afirmações (ou edges), termos (palavras ou frases em uma linguagem particular), relações (por exemplo, IsA), datasets, fontes de dados. Também possui uma API REST32 pela qual você pode obter os componentes no formato JSON. Cada edge, termo, relação, dataset e fonte da ConceptNet possui uma URI que os identificam e sua definição completa em JSON pode ser acessada via API. A Figura 9.6 apresenta um recorte da definição do termo “murder”, contendo a lista de edges a partir desse termo.\n",
            "\n",
            "Ao acessar, via API, a definição deste termo, tem-se acesso à sua definição em JSON, conforme ilustrado na Figura 9.7, com a URI deste conceito (“/c/en/murder”) e a lista de edges.\n",
            "\n",
            "ConceptNet se tornou um hub de conteúdo semântico, pois provê link para outras bases de dados, com um toolkit e uma API que suportam inferências práticas de senso comum sobre textos, tais como descoberta de contexto (que habilita a extração da vizinhança contextual de um conceito, e.g., “tirar a roupa”, “ir dormir”, e “deitar-se” são vizinhos do conceito “ir para a cama”), cadeia de inferências (que habilita encontrar caminhos na rede semântica a partir de um conceito, e.g., “comprar comida” - “ter comida” - “comer comida” - “sentir-se cheio” - “sentir-se com sono”) e analogia conceitual (que envolve encontrar conceitos que são estruturalmente similares, e.g., “funeral” e “casamento”, “sofá” e “cama”). Todos esses exemplos foram extraídos de (Ovchinnikova, 2012).\n",
            "\n",
            "Como visto, a Conceptnet 5.8 possui uma cobertura de 473 mil termos ou frases no português, representando assim a mais extensa base de conhecimento de senso comum para essa língua.\n",
            "\n",
            "O projeto Open Mind Common Sense – Brasil (OMCS-Br) foi um projeto do Laboratório de Interação Avançada (LIA) da Universidade Federal de São Carlos – UFSCar, em colaboração com o MediaLab do MIT, para a coleta de conhecimento de senso comum em português (Anacleto et al., 2006). Este projeto em 2010 contava com 160.000 afirmações de senso comum de seus colaboradores. O projeto foi descontinuado, mas diversas aplicações e estudos foram desenvolvidos a partir desta base. Dentre eles, podemos citar, uma ferramenta que utiliza a base de conhecimento de senso comum para auxiliar a interação humana (de alunos e professores) com ferramentas educacionais (Anacleto et al., 2007).\n",
            "\n",
            "A base InferenceNet-BR (Pinheiro et al., 2010) adapta a ConceptNet (Liu; Singh, 2004) adicionando uma camada que define o papel da afirmação em uma inferência – se como premissa (ou pré-condição) ou como conclusão (ou pós-condição). Além da tradução dos termos e suas afirmações (relações com outros conceitos), o projeto da InferenceNet-BR evoluiu a base com novo conhecimento semântico específico para o domínio de segurança pública em português.\n",
            "\n",
            "A InferenceNet-BR compõe-se de duas bases de conhecimento:\n",
            "\n",
            "A Figura 9.8 ilustra uma parte da rede de relacionamento inferencial da palavra “crime” na base InferenceNet-BR, com as seguintes relações:\n",
            "\n",
            "Nesta seção, usaremos a base da ConceptNet para o português e para o inglês para analisar o Exemplo 9.1. No Exemplo 9.4 são destacadas algumas afirmações de senso comum associadas aos termos mencionados no texto (termos sublinhados).\n",
            "\n",
            "Exemplo 9.4  \n",
            "\n",
            "parte do cap 17\n",
            "\n",
            "As abordagens iniciais para REN baseavam-se, majoritariamente, no emprego de regras lexico-sintáticas e consulta a almanaques (gazeeers). Tais abordagens dependem da construção de listas de nomes próprios como antropônimos, topônimos etc., e outras palavras, como “Ltda.”, “Jr.” etc., que auxiliam no processo de identificação e classificação de ENs complexas ou desconhecidas. Essa é, por exemplo, a abordagem empregada por Wolinski; Vichot; Dillet (1995) que combina almanaques e regras para a identificação e classificação de ENs. Posteriormente, almanaques foram também empregados em conjunção com métodos baseados em dados, como o trabalho de Florian et al. (2003) que os emprega aliados aos classificadores, enquanto Liu; Yao; Lin (2019) os utilizam durante o treinamento de uma rede neural, como um sinal de treinamento (parte da função de perda, ou loss em inglês).\n",
            "\n",
            "Muitos trabalhos debruçaram-se também sobre o problema de construção automática ou semi-automática de almanaques, dos quais os trabalhos de Nadeau (2007), de Riloff; Jones; et al. (1999) e de Etzioni et al. (2005) são alguns dos mais importantes.\n",
            "\n",
            "Enquanto as abordagens iniciais para o problema baseavam-se em regras, com a disponibilidade de dados anotados para a tarefa, tais métodos foram rapidamente suplantados por métodos baseados em dados, tais como: os métodos baseados em classificação (Asahara; Matsumoto, 2003; Sekine, 1998) e classificação sequencial (Bikel; Schwartz; Weischedel, 1999; McCallum; Li, 2003).\n",
            "\n",
            "A redução de REN à tarefa de classificação sequencial merece destaque pelos bons resultados obtidos. Tal redução se dá através de um esquema de codificação do problema que nos permite representar fragmentos textuais e sua classificação como um problema de rotulação ou etiquetação.\n",
            "\n",
            "Partindo-se do pressuposto de que os fragmentos textuais descrevendo entidades nomeadas são contíguos, podemos codificar a tarefa de delimitação de entidades como classificação sequencial empregando rótulos que descrevem os limites de uma EN, e.g. o esquema BIO com os rótulos B (do inglês, begin) para designar a palavra inicial de uma EN, I (do inglês, inside) para designar palavras que fazem parte da EN mas não a iniciam e O (do inglês, outside) para designar palavras que não pertencem a uma entidade. Da mesma forma, podemos estender nosso esquema de codificação para incluir as classes de interesse. Assim, seguindo o esquema BIO, teremos os rótulos B-PER e I-PER para descrever entidades da classe Pessoa.\n",
            "\n",
            "A redução do problema de REN à classificação sequencial está ilustrada no Exemplo 17.1.\n",
            "\n",
            "Exemplo 17.1  \n",
            "\n",
            "Renata/B-PER Silva/I-PER e/O Maria/B-PER Costa/I-PER palestraram/O na/O Universidade/B-ORG Federal/I-ORG da/I-ORG Bahia/I-ORG.\n",
            "\n",
            "Recentemente, destacam-se na literatura abordagens baseadas em redes neurais profundas, com uma grande concentração nos últimos anos em modelos gerativos de linguagem, devido aos resultados positivos obtidos por tais arquiteturas em diversas tarefas.\n",
            "\n",
            "Na literatura são de grande destaque os modelos recentes BART (Lewis et al., 2020), RoBERTa (Liu et al., 2019), T5 (Raffel et al., 2020), BERT (Devlin et al., 2019) e GPT-3 (Brown et al., 2020), conforme descritos no Capítulo 15.\n",
            "\n",
            "Similarmente, na língua portuguesa, nas duas edições do HAREM (Mota; Santos, 2008; Santos; Cardoso, 2007b), o primeiro esforço sistemático de desenvolvimento de soluções para a tarefa na língua, a maioria dos sistemas participantes baseava-se em métodos ricos em conhecimento, como regras e almanaques. De fato, nas duas avaliações, somente os sistemas MALINCHE (Solorio, 2007), NEURA (Ferrández et al., 2007) e R3M (Mota, 2008) não se baseavam em regras. Métodos baseados em classificação sequencial se seguiram para a língua portuguesa, como o RELP-CRF (Amaral; Vieira, 2014) baseado em um classificador sequencial. Mais recentemente, abordagens baseadas em redes neurais e modelos de linguagem foram desenvolvidas tornando-se o estado da arte da tarefa na língua. A Tabela 17.1 apresenta o atual estado da arte em português, com base no corpus HAREM. A métrica de avaliação apresentada, medida F1, será discutida na Seção 17.6.\n",
            "\n",
            "Souza; Nogueira; Lotufo (2020) desenvolveram um modelo BERT para o Português com 2,68 bilhões de tokens e aplicaram o modelo em um classificador CRF. Santos et al., avaliaram o impacto do modelo contextualizado Flair Embeddings aplicado a tarefa de REN junto com uma rede neural BiLSTM-CRF. Os autores também desenvolveram um modelo Flair Embeddings para o português, o FlairBBP, treinado com 4,9 bilhões de tokens (Santos et al., 2019). Castro; Silva; Soares (2018) utilizou uma rede LSTM e um classificador CRF junto com modelos Word Embeddings pré-treinados. Santos; Guimarães (2015) desenvolveram uma rede neural convolucional capaz de capturar características a nível de caracteres e também de incorporar word embeddings pré-treinados.\n",
            "\n",
            "O reconhecimento de entidades tem sido aplicado em muitas áreas específicas, como direito, saúde e geologia. Nesses casos há uma demanda de adaptação dos modelos preditivos de acordo com a nova linguagem especializada do domínio e um novo conjunto de rótulos que devem ser aprendidos. Da mesma forma, são necessários novos conjuntos de dados para o processo de aprendizado, uma vez que abordagens de aprendizado de máquina necessitam de exemplos anotados para se chegar a um modelo preditivo eficaz.\n",
            "\n",
            "Muitos trabalhos endereçam domínios específicos, citamos exemplos em diversas línguas. Para o inglês, uma rede neural BiLSTM-CRF para o domínio biomédico é proposta em (Habibi et al., 2017).\n",
            "\n",
            "Um conjunto de dados do domínio jurídico em língua alemã é apresentado por Leitner; Rehm; Schneider (2019), que empregam redes neurais BiLSTM para a rotulação dos textos. Em (Qiu et al., 2019), uma rede neural BiLSTM-CRF com mecanismo de atenção é aplicada para reconhecer entidades geológicas para a língua chinesa.\n",
            "\n",
            "parte do cap 9\n",
            "\n",
            "A unidade de conhecimento da ConceptNet é uma afirmação ou edge28 que é uma relação particular entre termos ou frases em uma linguagem natural, de uma fonte específica. Sucintamente, cada edge é uma tripla com um primeiro argumento (nó inicial), um rótulo da relação e um segundo argumento (nó final). Por exemplo, a afirmação “Bicycle is used to get somewhere fast” pode ser expressa como (Bicycle, is used to, get somewhere fast). Cada edge é representada em uma estrutura de dados com os seguintes atributos:\n",
            "\n",
            "A ConceptNet contém mais de 21 milhões de edges e quase 10 milhões de nós com palavras ou fragmentos de textos. A base cobre em torno de 78 linguagens naturais31 com pelo menos 10.000 entradas no vocabulário. As 10 (dez) principais linguagens são: inglês, francês, italiano, alemão, espanhol, russo, português, japonês, holandês e chinês. A base de afirmações na linguagem inglesa possui um vocabulário com 1,8 milhão de nós, e no português contém um vocabulário com 473 mil nós.\n",
            "\n",
            "O framework computacional da ConceptNet contém uma hierarquia de URIs que identificam os principais componentes dessa base de conhecimento: afirmações (ou edges), termos (palavras ou frases em uma linguagem particular), relações (por exemplo, IsA), datasets, fontes de dados. Também possui uma API REST32 pela qual você pode obter os componentes no formato JSON. Cada edge, termo, relação, dataset e fonte da ConceptNet possui uma URI que os identificam e sua definição completa em JSON pode ser acessada via API. A Figura 9.6 apresenta um recorte da definição do termo “murder”, contendo a lista de edges a partir desse termo.\n",
            "\n",
            "Ao acessar, via API, a definição deste termo, tem-se acesso à sua definição em JSON, conforme ilustrado na Figura 9.7, com a URI deste conceito (“/c/en/murder”) e a lista de edges.\n",
            "\n",
            "ConceptNet se tornou um hub de conteúdo semântico, pois provê link para outras bases de dados, com um toolkit e uma API que suportam inferências práticas de senso comum sobre textos, tais como descoberta de contexto (que habilita a extração da vizinhança contextual de um conceito, e.g., “tirar a roupa”, “ir dormir”, e “deitar-se” são vizinhos do conceito “ir para a cama”), cadeia de inferências (que habilita encontrar caminhos na rede semântica a partir de um conceito, e.g., “comprar comida” - “ter comida” - “comer comida” - “sentir-se cheio” - “sentir-se com sono”) e analogia conceitual (que envolve encontrar conceitos que são estruturalmente similares, e.g., “funeral” e “casamento”, “sofá” e “cama”). Todos esses exemplos foram extraídos de (Ovchinnikova, 2012).\n",
            "\n",
            "Como visto, a Conceptnet 5.8 possui uma cobertura de 473 mil termos ou frases no português, representando assim a mais extensa base de conhecimento de senso comum para essa língua.\n",
            "\n",
            "O projeto Open Mind Common Sense – Brasil (OMCS-Br) foi um projeto do Laboratório de Interação Avançada (LIA) da Universidade Federal de São Carlos – UFSCar, em colaboração com o MediaLab do MIT, para a coleta de conhecimento de senso comum em português (Anacleto et al., 2006). Este projeto em 2010 contava com 160.000 afirmações de senso comum de seus colaboradores. O projeto foi descontinuado, mas diversas aplicações e estudos foram desenvolvidos a partir desta base. Dentre eles, podemos citar, uma ferramenta que utiliza a base de conhecimento de senso comum para auxiliar a interação humana (de alunos e professores) com ferramentas educacionais (Anacleto et al., 2007).\n",
            "\n",
            "A base InferenceNet-BR (Pinheiro et al., 2010) adapta a ConceptNet (Liu; Singh, 2004) adicionando uma camada que define o papel da afirmação em uma inferência – se como premissa (ou pré-condição) ou como conclusão (ou pós-condição). Além da tradução dos termos e suas afirmações (relações com outros conceitos), o projeto da InferenceNet-BR evoluiu a base com novo conhecimento semântico específico para o domínio de segurança pública em português.\n",
            "\n",
            "A InferenceNet-BR compõe-se de duas bases de conhecimento:\n",
            "\n",
            "A Figura 9.8 ilustra uma parte da rede de relacionamento inferencial da palavra “crime” na base InferenceNet-BR, com as seguintes relações:\n",
            "\n",
            "Nesta seção, usaremos a base da ConceptNet para o português e para o inglês para analisar o Exemplo 9.1. No Exemplo 9.4 são destacadas algumas afirmações de senso comum associadas aos termos mencionados no texto (termos sublinhados).\n",
            "\n",
            "Exemplo 9.4  \n",
            "\n",
            "parte do cap 17\n",
            "\n",
            "Para o português, um corpus para detecção de eventos de quedas de pacientes em prontuários eletrônicos é descrito em (Santos; Santos; Vieira, 2020). Os autores usaram uma rede neural BiLSTM-CRF+Flair para gerar um modelo classificador de tokens. Um corpus no domínio jurídico, tendo categorias específicas como legislação e jurisprudência é proposto por  Araujo et al. (2018), que usaram uma rede neural BiLSTM-CRF para criar um primeiro baseline para esse corpus. Ademais, Consoli et al. (2020) analisam um corpus no domínio de geologia usando uma rede neural BiLSTM-CRF com um modelo contextualizado Flair Embeddings.\n",
            "\n",
            "As abordagens iniciais para o problema de ER baseavam-se na definição de gabaritos e regras de extração, com base em informação sintática obtida de analisadores sintáticos rasos ou profundos (Cowie, 1983; Sager, 1978). Tais métodos foram rapidamente suplantados por métodos baseados em dados e padrões obtidos de corpora, como os famosos padrões de Hearst (1992) para identificação de relações de hiponímia.\n",
            "\n",
            "O trabalho de Hearst (1992) se baseou na definição de padrões lexico-sintáticos para expressão de relações de hiponímia e hiperonímia a partir de uma análise de corpus. Ao escolher a relação de hiponímia, que ocorre em todo domínio, e padrões gerais baseados em aspectos da língua, como os representados no Quadro 17.3, o autor garante generalizabilidade dos padrões obtidos para diversos domínios e aplicações.\n",
            "\n",
            "Quadro 17.3 Exemplos de Padrões de Hearst para hiponímia\n",
            "\n",
            "Devido à dificuldade de construção manual das regras, os métodos de Riloff et al. (1993), empregam heurísticas para geração de padrões baseadas em informação gramatical, e de Soderland et al. (1995), que se baseia numa semântica de quadros (frames) empregando um analisador semântico e medidas de qualidade de identificação de exemplos, baseado no percentual de acerto sobre relacionamentos previamente conhecidos, para identificação de quadros relevantes.\n",
            "\n",
            "As abordagens baseadas em aprendizado de máquina, hoje as mais comuns e com melhor desempenho na literatura (Konstantinova, 2014; Nasar; Jaffry; Malik, 2021) dividem-se em abordagens que realizam reconhecimento de entidades e extração de relações de forma conjunta e separada.\n",
            "\n",
            "Abordagens baseadas na realização de REN e ER de forma separada baseiam-se em um fluxo de processamento em que, em geral, as entidades são identificadas primeiro e a tarefa de ER se reduz a identificar quando uma sentença ou fragmento textual denota uma relação semântica entre duas entidades. Consideremos o Exemplo 17.2, retirado de (Socher et al., 2012):\n",
            "\n",
            "Exemplo 17.2  \n",
            "\n",
            "Gripe aviária]\\(_{e1}\\) é uma doença infecciosa causada pelo vírus da [influenza tipo a]\\(_{e2}\\)\n",
            "\n",
            "Podemos, então, reduzir o problema de identificar a relação Causa-Efeito(\\(e1\\),\\(e2\\)) a um problema de classificação textual, identificando se a sentença acima fornece indícios para a expressão da relação de interesse. As soluções propostas na literatura para o problema são variadas e baseadas em diferentes métodos.\n",
            "\n",
            "Zelenko; Aone; Richardella (2003), por exemplo, propõem funções de kernel para árvores sintáticas rasas, i.e. funções que descrevem medidas de similaridade entre tais árvores. Eles empregam tais medidas para treinar um classificador de perceptron com votação (voted perceptron) sobre relações no domínio de organizações extraídas de um corpus de textos jornalísticos. De forma similar, Zhao; Grishman (2005) empregam diferentes funções de kernel sobre informações sintáticas relevantes para a identificação de relação e argumentos visando treinar um classificador SVM sobre o corpus de ER da conferência ACE.\n",
            "\n",
            "Culotta; McCallum; Betz (2006), por outro lado, empregam um classificador sequencial baseado em modelos escondidos de Markov para identificação de relações em um texto. Ao restringir sua análise a textos biográficos, os autores reduzem o processo de identificar instâncias de relações à identificação de fragmento textual que delimita o argumento e sua classificação, tarefa para a qual a classificação sequencial já é comumente utilizada. Consideremos o Exemplo 17.3 sobre George W. Bush, retirado de (Culotta; McCallum; Betz, 2006):\n",
            "\n",
            "Exemplo 17.3  \n",
            "\n",
            "George é filho de \\(\\underbrace{\\mbox{George H. W. Bush}}_{\\mbox{pai}}\\) e \\(\\underbrace{\\mbox{Barbara Bush}}_{\\mbox{mãe}}\\).\n",
            "\n",
            "Ao identificar o papel de pai e mãe, os autores conseguem construir a relação Pai(George H. W. Bush, George W. Bush) e Mãe(Barbara Bush, George W. Bush).\n",
            "\n",
            "parte do cap 9\n",
            "\n",
            "A unidade de conhecimento da ConceptNet é uma afirmação ou edge28 que é uma relação particular entre termos ou frases em uma linguagem natural, de uma fonte específica. Sucintamente, cada edge é uma tripla com um primeiro argumento (nó inicial), um rótulo da relação e um segundo argumento (nó final). Por exemplo, a afirmação “Bicycle is used to get somewhere fast” pode ser expressa como (Bicycle, is used to, get somewhere fast). Cada edge é representada em uma estrutura de dados com os seguintes atributos:\n",
            "\n",
            "A ConceptNet contém mais de 21 milhões de edges e quase 10 milhões de nós com palavras ou fragmentos de textos. A base cobre em torno de 78 linguagens naturais31 com pelo menos 10.000 entradas no vocabulário. As 10 (dez) principais linguagens são: inglês, francês, italiano, alemão, espanhol, russo, português, japonês, holandês e chinês. A base de afirmações na linguagem inglesa possui um vocabulário com 1,8 milhão de nós, e no português contém um vocabulário com 473 mil nós.\n",
            "\n",
            "O framework computacional da ConceptNet contém uma hierarquia de URIs que identificam os principais componentes dessa base de conhecimento: afirmações (ou edges), termos (palavras ou frases em uma linguagem particular), relações (por exemplo, IsA), datasets, fontes de dados. Também possui uma API REST32 pela qual você pode obter os componentes no formato JSON. Cada edge, termo, relação, dataset e fonte da ConceptNet possui uma URI que os identificam e sua definição completa em JSON pode ser acessada via API. A Figura 9.6 apresenta um recorte da definição do termo “murder”, contendo a lista de edges a partir desse termo.\n",
            "\n",
            "Ao acessar, via API, a definição deste termo, tem-se acesso à sua definição em JSON, conforme ilustrado na Figura 9.7, com a URI deste conceito (“/c/en/murder”) e a lista de edges.\n",
            "\n",
            "ConceptNet se tornou um hub de conteúdo semântico, pois provê link para outras bases de dados, com um toolkit e uma API que suportam inferências práticas de senso comum sobre textos, tais como descoberta de contexto (que habilita a extração da vizinhança contextual de um conceito, e.g., “tirar a roupa”, “ir dormir”, e “deitar-se” são vizinhos do conceito “ir para a cama”), cadeia de inferências (que habilita encontrar caminhos na rede semântica a partir de um conceito, e.g., “comprar comida” - “ter comida” - “comer comida” - “sentir-se cheio” - “sentir-se com sono”) e analogia conceitual (que envolve encontrar conceitos que são estruturalmente similares, e.g., “funeral” e “casamento”, “sofá” e “cama”). Todos esses exemplos foram extraídos de (Ovchinnikova, 2012).\n",
            "\n",
            "Como visto, a Conceptnet 5.8 possui uma cobertura de 473 mil termos ou frases no português, representando assim a mais extensa base de conhecimento de senso comum para essa língua.\n",
            "\n",
            "O projeto Open Mind Common Sense – Brasil (OMCS-Br) foi um projeto do Laboratório de Interação Avançada (LIA) da Universidade Federal de São Carlos – UFSCar, em colaboração com o MediaLab do MIT, para a coleta de conhecimento de senso comum em português (Anacleto et al., 2006). Este projeto em 2010 contava com 160.000 afirmações de senso comum de seus colaboradores. O projeto foi descontinuado, mas diversas aplicações e estudos foram desenvolvidos a partir desta base. Dentre eles, podemos citar, uma ferramenta que utiliza a base de conhecimento de senso comum para auxiliar a interação humana (de alunos e professores) com ferramentas educacionais (Anacleto et al., 2007).\n",
            "\n",
            "A base InferenceNet-BR (Pinheiro et al., 2010) adapta a ConceptNet (Liu; Singh, 2004) adicionando uma camada que define o papel da afirmação em uma inferência – se como premissa (ou pré-condição) ou como conclusão (ou pós-condição). Além da tradução dos termos e suas afirmações (relações com outros conceitos), o projeto da InferenceNet-BR evoluiu a base com novo conhecimento semântico específico para o domínio de segurança pública em português.\n",
            "\n",
            "A InferenceNet-BR compõe-se de duas bases de conhecimento:\n",
            "\n",
            "A Figura 9.8 ilustra uma parte da rede de relacionamento inferencial da palavra “crime” na base InferenceNet-BR, com as seguintes relações:\n",
            "\n",
            "Nesta seção, usaremos a base da ConceptNet para o português e para o inglês para analisar o Exemplo 9.1. No Exemplo 9.4 são destacadas algumas afirmações de senso comum associadas aos termos mencionados no texto (termos sublinhados).\n",
            "\n",
            "Exemplo 9.4  \n",
            "\n",
            "parte do cap 17\n",
            "\n",
            "Métodos baseados em redes neurais, de forma geral, costumam empregar técnicas de aprendizado de representação (Bengio; Courville; Vincent, 2013) para aprender representações do conteúdo semântico dos fragmentos textuais e reduzem o problema de ER à classificação textual. É o caso de Socher et al. (2012), que propõem a MV-RNN, uma rede neural que constrói um espaço de representação baseado em matrizes e vetores com o objetivo de capturar a composicionalidade de sentido de sintagmas e sentenças e os aplica para ER. Similarmente, Zeng et al. (2014) e Wang et al. (2016) empregam redes neurais convolucionais para obter representações vetoriais de sentenças que serão empregadas no processo de classificação quanto à relação expressa pela mesma.\n",
            "\n",
            "Abordagens baseadas em identificação sequencial de entidades e relações possuem desvantagens observadas na literatura. Primeiramente, como a ER é guiada pelas entidades identificadas no processo de REN, a propagação de erros da primeira tarefa pode ter impacto considerável na performance dos sistemas desenvolvidos. Segundo, uma vez que o contexto determinado limita tanto as tarefas de REN, quanto as de ER, existe uma interdependência entre as tarefas. Assim, propostas visando realizar a extração de entidades e relações de forma conjunta começaram a surgir na literatura recente, ganhando certo interesse da comunidade.\n",
            "\n",
            "As abordagens empregadas para tal tarefa são diversificadas, incluindo desde métodos de aprendizado relacional a redes neurais\n",
            "\n",
            "Roth; Yih (2007) propõem a utilização de métodos de programação inteira ao problema, baseados na teoria estatística de aprendizado relacional. Os autores utilizam classificadores locais para a identificação de entidades e relações e um classificador global que combina as informações dos classificadores locais em uma predição que maximiza a qualidade da extração, codificada por meio de restrições em programação inteira. Também baseados em modelos estatísticos, Yu; Lam (2010) propõem o uso de modelos gráficos globais para identificação de um descritor de relação e uma segmentação do texto para identificação dos argumentos.\n",
            "\n",
            "Li; Ji (2014) e Miwa; Bansal (2016), por sua vez, reduzem a tarefa de ERE à classificação sequencial, utilizando redes neurais recorrentes bidirecionais sequenciais e estruturadas com base na estrutura superficial e na árvore de dependências sintáticas da entrada para identificação conjunta de entidades e relações.\n",
            "\n",
            "A Extração de Informação Aberta (EIA), também conhecida como Open Information Extraction, Open IE ou OIE em inglês, é a tarefa de extrair informações estruturadas de documentos sem necessitar da pré-definição do contexto da tarefa, i.e. das relações e tipos de entidade de interesse. A tarefa foi inicialmente proposta pelo trabalho de (Banko et al., 2007) e ganhou popularidade nas últimas décadas devido à sua aplicabilidade para processar e estruturar o conhecimento a partir de grandes volumes de dados disponíveis na Web, seguindo o paradigma da Web como um Corpus (WaC) (Meyer et al., 2003).\n",
            "\n",
            "A EIA surge visando generalizar a tarefa de Extração de Relações. A principal diferença entre as duas abordagens, porém, reside na dependência da ER de uma especificação prévia do domínio de aplicação, bem como das relações alvo a serem identificadas, que a EIA visa eliminar.\n",
            "\n",
            "Seguindo o trabalho original de Banko et al. (2007), que propôs o sistema TextRunner, vários métodos e sistemas para EIA foram propostos na literatura (Del Corro; Gemulla, 2013; Fader; Soderland; Etzioni, 2011; Xavier; Lima; Souza, 2015), mas, como observado por Glauber; Claro (2018), os principais avanços na área se concentraram principalmente no idioma inglês.\n",
            "\n",
            "A EIA para a língua portuguesa tem uma história bastante recente. A partir dos trabalhos de Souza; Claro (2014), Pereira; Pinheiro (2015) e de (Barbosa; Glauber; Claro, 2016), têm crescido o número de estudos sobre a tarefa assim como os resultados obtidos por esses estudos, com recentes desenvolvimentos de métodos (Oliveira; Claro; Souza, 2022; Sena; Claro, 2019, 2020; Sena; Glauber; Claro, 2017; Souza; Claro; Glauber, 2018), construção do corpus (Glauber et al., 2018) e avaliação dos sistemas disponíveis (Glauber; Claro; Oliveira, 2019; Glauber; Claro; Sena, 2019; Malenchini et al., 2019).\n",
            "\n",
            "Embora a área tenha visto um crescimento recente para o desenvolvimento de métodos para línguas como o inglês, principalmente com a aplicação de métodos supervisionados e redes neurais, esses avanços ainda não foram incorporados na literatura sobre EIA para a língua portuguesa. A razão para isso é principalmente a falta de recursos linguísticos disponíveis para orientar o desenvolvimento de pesquisas para a língua. Embora o foco no idioma inglês possa ser devido ao seu uso generalizado em todo o mundo, foi reconhecido pela comunidade científica que esse foco no inglês com suas características particulares pode introduzir algum viés na área (Bender, 2009).\n",
            "\n",
            "Assim, esta seção aborda EIA para a língua portuguesa, incluindo uma formalização e a evolução das abordagens da área.\n",
            "\n",
            "A tarefa de EIA pode ser formalmente definida sendo \\(X = \\langle x_{1}, x_{2}, \\cdots, x_{n}\\rangle\\) uma sentença composta de tokens \\(x_i\\). Um extrator EIA é uma função que mapeia \\(X\\) em um conjunto \\(Y = \\langle y_{1}, y_{2}, \\cdots, y_{j} \\rangle\\) como um conjunto de tuplas \\(y \\_i = \\langle rel_i, arg1_i, arg2_i, \\cdots, argn_i\\rangle\\), que descrevem as informações expressas na sentença X. Neste capítulo, consideramos que as tuplas estão sempre no formato \\(y = (arg_{1 }, rel, arg_{2})\\), onde \\(arg1\\) e \\(arg2\\) são sintagmas nominais, não necessariamente formados por tokens presentes em X, e \\(rel\\) é um descritor de um relacionamento entre \\(arg_{1}\\) e \\(arg_{2}\\). Não consideraremos extrações formadas por mais de dois argumentos neste capítulo.\n",
            "\n",
            "Os primeiros métodos de EIA empregavam padrões de inspiração linguística para extração, como ArgOE (Gamallo; Garcia, 2015), ou adaptação de métodos para a língua inglesa, como SGS (Souza; Claro; Glauber, 2018), InferReVerbPT Sena; Glauber; Claro (2017) e RePort Pereira; Pinheiro (2015). Os trabalhos são principalmente influenciados por métodos baseados no inglês da chamada segunda geração de EIA (Fader; Soderland; Etzioni, 2011).\n",
            "\n",
            "O primeiro sistema de EIA para o português de que temos conhecimento foi o DepOE (Gamallo; Garcia; Fernández-Lanza, 2012). Ele executa a extração aberta multilíngue de triplas (inglês, espanhol, português e galego) usando o analisador sintático de dependências baseado em regras DepPattern. No entanto, nenhuma avaliação ou resultados são relatados para a língua portuguesa. Os autores apresentam somente uma comparação dos seus resultados com Reverb na língua inglesa.\n",
            "\n",
            "Souza; Claro (2014) se propuseram a analisar o conjunto de características mais representativas da língua portuguesa para a identificação de extrações válidas no contexto de EIA, tal qual empregado na língua inglesa com o sistema ReVerb (Fader; Soderland; Etzioni, 2011).\n",
            "\n",
            "parte do cap 9\n",
            "\n",
            "A unidade de conhecimento da ConceptNet é uma afirmação ou edge28 que é uma relação particular entre termos ou frases em uma linguagem natural, de uma fonte específica. Sucintamente, cada edge é uma tripla com um primeiro argumento (nó inicial), um rótulo da relação e um segundo argumento (nó final). Por exemplo, a afirmação “Bicycle is used to get somewhere fast” pode ser expressa como (Bicycle, is used to, get somewhere fast). Cada edge é representada em uma estrutura de dados com os seguintes atributos:\n",
            "\n",
            "A ConceptNet contém mais de 21 milhões de edges e quase 10 milhões de nós com palavras ou fragmentos de textos. A base cobre em torno de 78 linguagens naturais31 com pelo menos 10.000 entradas no vocabulário. As 10 (dez) principais linguagens são: inglês, francês, italiano, alemão, espanhol, russo, português, japonês, holandês e chinês. A base de afirmações na linguagem inglesa possui um vocabulário com 1,8 milhão de nós, e no português contém um vocabulário com 473 mil nós.\n",
            "\n",
            "O framework computacional da ConceptNet contém uma hierarquia de URIs que identificam os principais componentes dessa base de conhecimento: afirmações (ou edges), termos (palavras ou frases em uma linguagem particular), relações (por exemplo, IsA), datasets, fontes de dados. Também possui uma API REST32 pela qual você pode obter os componentes no formato JSON. Cada edge, termo, relação, dataset e fonte da ConceptNet possui uma URI que os identificam e sua definição completa em JSON pode ser acessada via API. A Figura 9.6 apresenta um recorte da definição do termo “murder”, contendo a lista de edges a partir desse termo.\n",
            "\n",
            "Ao acessar, via API, a definição deste termo, tem-se acesso à sua definição em JSON, conforme ilustrado na Figura 9.7, com a URI deste conceito (“/c/en/murder”) e a lista de edges.\n",
            "\n",
            "ConceptNet se tornou um hub de conteúdo semântico, pois provê link para outras bases de dados, com um toolkit e uma API que suportam inferências práticas de senso comum sobre textos, tais como descoberta de contexto (que habilita a extração da vizinhança contextual de um conceito, e.g., “tirar a roupa”, “ir dormir”, e “deitar-se” são vizinhos do conceito “ir para a cama”), cadeia de inferências (que habilita encontrar caminhos na rede semântica a partir de um conceito, e.g., “comprar comida” - “ter comida” - “comer comida” - “sentir-se cheio” - “sentir-se com sono”) e analogia conceitual (que envolve encontrar conceitos que são estruturalmente similares, e.g., “funeral” e “casamento”, “sofá” e “cama”). Todos esses exemplos foram extraídos de (Ovchinnikova, 2012).\n",
            "\n",
            "Como visto, a Conceptnet 5.8 possui uma cobertura de 473 mil termos ou frases no português, representando assim a mais extensa base de conhecimento de senso comum para essa língua.\n",
            "\n",
            "O projeto Open Mind Common Sense – Brasil (OMCS-Br) foi um projeto do Laboratório de Interação Avançada (LIA) da Universidade Federal de São Carlos – UFSCar, em colaboração com o MediaLab do MIT, para a coleta de conhecimento de senso comum em português (Anacleto et al., 2006). Este projeto em 2010 contava com 160.000 afirmações de senso comum de seus colaboradores. O projeto foi descontinuado, mas diversas aplicações e estudos foram desenvolvidos a partir desta base. Dentre eles, podemos citar, uma ferramenta que utiliza a base de conhecimento de senso comum para auxiliar a interação humana (de alunos e professores) com ferramentas educacionais (Anacleto et al., 2007).\n",
            "\n",
            "A base InferenceNet-BR (Pinheiro et al., 2010) adapta a ConceptNet (Liu; Singh, 2004) adicionando uma camada que define o papel da afirmação em uma inferência – se como premissa (ou pré-condição) ou como conclusão (ou pós-condição). Além da tradução dos termos e suas afirmações (relações com outros conceitos), o projeto da InferenceNet-BR evoluiu a base com novo conhecimento semântico específico para o domínio de segurança pública em português.\n",
            "\n",
            "A InferenceNet-BR compõe-se de duas bases de conhecimento:\n",
            "\n",
            "A Figura 9.8 ilustra uma parte da rede de relacionamento inferencial da palavra “crime” na base InferenceNet-BR, com as seguintes relações:\n",
            "\n",
            "Nesta seção, usaremos a base da ConceptNet para o português e para o inglês para analisar o Exemplo 9.1. No Exemplo 9.4 são destacadas algumas afirmações de senso comum associadas aos termos mencionados no texto (termos sublinhados).\n",
            "\n",
            "Exemplo 9.4  \n",
            "\n",
            "parte do cap 17\n",
            "\n",
            "O sistema RePort (Pereira; Pinheiro, 2015), por outro lado, é uma adaptação do ReVerb para a língua portuguesa baseada em análise sintática rasa com regras sintáticas e lexicais. Os autores relatam que suas extrações apresentam grande similaridade com suas correlatas extraídas pelo ReVerb (dos textos traduzidos para o inglês).\n",
            "\n",
            "O RELP, proposto por Abreu; Vieira (2017), é um sistema aberto de extração de relações que extrai relações entre entidades nomeadas em um domínio de organização aplicando classificação sequencial com CRF (Conditional Random Fields). O sistema RelP extrai qualquer descritor de relação que expressa um relacionamento entre pares de entidades nomeadas (Organização, Pessoa ou Lugar), caracterizando-o como uma abordagem híbrida da REN com a EIA.\n",
            "\n",
            "O InferReVerbPT desenvolvido por Sena; Glauber; Claro (2017) baseia-se numa adaptação do sistema ReVerb para a língua portuguesa, expandindo-o com a extração de relacionamentos implícitos obtidos por inferência por propriedades de simetria e transitividade das relações com inferência transitiva e simétrica. Um classificador SVM foi empregado para realizar a inferência baseado nas propriedades semânticas do verbo central no descritor de relação.\n",
            "\n",
            "Souza; Claro; Glauber (2018) analisaram que a maior desvantagem dos estudos baseados em recursos linguísticos, como dados anotados, reside na escassez de tais recursos na maioria dos idiomas além do inglês. Assim, para mitigar esse problema, eles propõem um método de classificação de fatos baseado na similaridade de estruturas gramaticais (SGS). Sua abordagem modela estruturas morfosintáticas dos fatos (triplas descrevendo relacionamentos) para identificar padrões de semelhanças que podem ser usados para distinguir entre fatos válidos e inválidos. Eles aplicaram algoritmos de isomorfismo de grafos para detectar subgrafos descrevendo tais padrões.\n",
            "\n",
            "Um novo sistema de EIA baseado em análise de dependência foi proposto por Gamallo; Garcia (2015), chamado ArgOE. Tal sistema é multilíngue, baseado em heurísticas e utiliza a informação de dependência sintáticas do texto para analisar a estrutura de dependência do verbo, bem como um conjunto de regras para gerar os relacionamentos. A introdução de um Analisador de Dependência em sistemas de EIA focados inteiramente na língua portuguesa foi feita pelos autores Oliveira; Claro; Souza (2022). O DptOIE é baseado em análise de dependência e regras elaboradas manualmente. As sentenças são pré-processadas por meio de um tokenizador, um PoS Tagger e um analisador de dependências. Os autores propõem um acoplamento de três módulos para tratar casos particulares: conjunções coordenadas, orações subordinadas e aposto.\n",
            "\n",
            "Com a evolução dos métodos de EIA para a língua inglesa utilizando os modelos neurais, novas abordagens foram propostas também para a língua portuguesa.\n",
            "\n",
            "O primeiro trabalho que utilizou aprendizado supervisionado com rede neural profunda para o português foi o de Ro; Lee; Kang (2020) que descreve o sistema Multi2OIE. Os autores utilizaram o modelo de linguagem BERT multilíngue (Devlin et al., 2019) para obter representações vetoriais das palavras e reduzem a tarefa de EIA à classificação sequencial, identificado os fragmentos do texto que determinam os argumentos (\\(arg_1, arg_2\\)) e o descritor de relação (\\(rel\\)). Seu sistema foi capaz de produzir extrações para vários idiomas (inglês, português e espanhol), treinados, entretanto, sobre dados traduzidos do inglês.\n",
            "\n",
            "Stanovsky et al. (2018) propuseram uma abordagem de EIA para a língua inglesa baseada em triplas. Os mesmos fazem uso de uma classificação sequencial cuja limitação define uma tripla extraída para cada sentença. Este método utiliza uma arquitetura de Redes Neurais Recursivas (RNN) para realizar EIA. A EIA é formulada como uma tarefa de rotulagem de sequências, utilizando estratégias semelhantes às que foram aplicadas anteriormente a tarefas como o Reconhecimento de Entidades Nomeadas. Já os autores em Cui; Wei; Zhou (2018) e Zhang; Duh; Van Durme (2017) propõem modelar o problema da EIA como um problema de aprendizado sequência a sequência (seq2seq). Eles definem uma estrutura encoder-decoder para aprender argumentos e tuplas de relação inicializadas a partir de um sistema de EIA.\n",
            "\n",
            "Seguindo o trabalho de (Stanovsky et al., 2018), em 2022, Cabral; Souza; Claro (2022) propuseram PortNOIE, uma arquitetura neural para EIA em português que combina representações contextuais de palavras com codificadores neurais para extrair relacionamentos baseado em classificação sequencial iterativa. Diferente de outros métodos de classificação sequencial para EIA, os autores focam na extração de múltiplas triplas de uma mesma sentença.\n",
            "\n",
            "A avaliação sistemática de sistemas de EI foi estabelecida primeiramente nas conferências MUC, em particular na sua segunda edição, com o estabelecimento de gabaritos-padrão que deveriam ser utilizados por todos os sistemas participantes e a adoção de métricas de qualidade, baseadas naquelas usadas na área de recuperação de informação, que foram abordadas no Capítulo 16. Para avaliar a tarefa de extração de relações, a MUC-2 estabeleceu como métricas de qualidade do sistema as medidas de precisão e cobertura, também denominada de Recall ou Revocação.\n",
            "\n",
            "A precisão de um sistema reflete a qualidade de suas extrações, i.e., quantas das extrações realizadas estão corretas, dado um corpus de teste. A medida de precisão pode ser calculada como:\n",
            "\n",
            "P = \\frac{\\#(\\mbox{relacionamentos corretamente extraídos})}{\\#(\\mbox{relacionamentos extraídos pelo sistema})}\n",
            "\n",
            "A cobertura também conhecida como revocação, reflete quão abrangente um sistema é em suas extrações, i.e., quantas das extrações a serem realizadas em um corpus de teste, o sistema é capaz de realizar. A medida de cobertura pode ser calculada como:\n",
            "\n",
            "R = \\frac{\\#(\\mbox{relacionamentos extraídos})}{\\#(\\mbox{relacionamentos no \\textit{corpus}})}\n",
            "\n",
            "Enquanto a MUC-3 adicionou duas novas métricas de avaliação, a saber sobre-geração (overgeneration) e sub-geração (fallout), tais métricas receberam pouco interesse na literatura. De fato, Lehnert; Sundheim (1991) argumentam que tais métricas foram pouco informativas ou difíceis de calcular para a tarefa de EI e, portanto, abandonadas. Foi também empregado nessa conferência um sistema automático de avaliação disponibilizado às equipes participantes que permitiu uma maior compreensão do modelo de avaliação e, como discutem Lehnert; Sundheim (1991), um avanço qualitativo nos sistemas gerados.\n",
            "\n",
            "parte do cap 9\n",
            "\n",
            "A unidade de conhecimento da ConceptNet é uma afirmação ou edge28 que é uma relação particular entre termos ou frases em uma linguagem natural, de uma fonte específica. Sucintamente, cada edge é uma tripla com um primeiro argumento (nó inicial), um rótulo da relação e um segundo argumento (nó final). Por exemplo, a afirmação “Bicycle is used to get somewhere fast” pode ser expressa como (Bicycle, is used to, get somewhere fast). Cada edge é representada em uma estrutura de dados com os seguintes atributos:\n",
            "\n",
            "A ConceptNet contém mais de 21 milhões de edges e quase 10 milhões de nós com palavras ou fragmentos de textos. A base cobre em torno de 78 linguagens naturais31 com pelo menos 10.000 entradas no vocabulário. As 10 (dez) principais linguagens são: inglês, francês, italiano, alemão, espanhol, russo, português, japonês, holandês e chinês. A base de afirmações na linguagem inglesa possui um vocabulário com 1,8 milhão de nós, e no português contém um vocabulário com 473 mil nós.\n",
            "\n",
            "O framework computacional da ConceptNet contém uma hierarquia de URIs que identificam os principais componentes dessa base de conhecimento: afirmações (ou edges), termos (palavras ou frases em uma linguagem particular), relações (por exemplo, IsA), datasets, fontes de dados. Também possui uma API REST32 pela qual você pode obter os componentes no formato JSON. Cada edge, termo, relação, dataset e fonte da ConceptNet possui uma URI que os identificam e sua definição completa em JSON pode ser acessada via API. A Figura 9.6 apresenta um recorte da definição do termo “murder”, contendo a lista de edges a partir desse termo.\n",
            "\n",
            "Ao acessar, via API, a definição deste termo, tem-se acesso à sua definição em JSON, conforme ilustrado na Figura 9.7, com a URI deste conceito (“/c/en/murder”) e a lista de edges.\n",
            "\n",
            "ConceptNet se tornou um hub de conteúdo semântico, pois provê link para outras bases de dados, com um toolkit e uma API que suportam inferências práticas de senso comum sobre textos, tais como descoberta de contexto (que habilita a extração da vizinhança contextual de um conceito, e.g., “tirar a roupa”, “ir dormir”, e “deitar-se” são vizinhos do conceito “ir para a cama”), cadeia de inferências (que habilita encontrar caminhos na rede semântica a partir de um conceito, e.g., “comprar comida” - “ter comida” - “comer comida” - “sentir-se cheio” - “sentir-se com sono”) e analogia conceitual (que envolve encontrar conceitos que são estruturalmente similares, e.g., “funeral” e “casamento”, “sofá” e “cama”). Todos esses exemplos foram extraídos de (Ovchinnikova, 2012).\n",
            "\n",
            "Como visto, a Conceptnet 5.8 possui uma cobertura de 473 mil termos ou frases no português, representando assim a mais extensa base de conhecimento de senso comum para essa língua.\n",
            "\n",
            "O projeto Open Mind Common Sense – Brasil (OMCS-Br) foi um projeto do Laboratório de Interação Avançada (LIA) da Universidade Federal de São Carlos – UFSCar, em colaboração com o MediaLab do MIT, para a coleta de conhecimento de senso comum em português (Anacleto et al., 2006). Este projeto em 2010 contava com 160.000 afirmações de senso comum de seus colaboradores. O projeto foi descontinuado, mas diversas aplicações e estudos foram desenvolvidos a partir desta base. Dentre eles, podemos citar, uma ferramenta que utiliza a base de conhecimento de senso comum para auxiliar a interação humana (de alunos e professores) com ferramentas educacionais (Anacleto et al., 2007).\n",
            "\n",
            "A base InferenceNet-BR (Pinheiro et al., 2010) adapta a ConceptNet (Liu; Singh, 2004) adicionando uma camada que define o papel da afirmação em uma inferência – se como premissa (ou pré-condição) ou como conclusão (ou pós-condição). Além da tradução dos termos e suas afirmações (relações com outros conceitos), o projeto da InferenceNet-BR evoluiu a base com novo conhecimento semântico específico para o domínio de segurança pública em português.\n",
            "\n",
            "A InferenceNet-BR compõe-se de duas bases de conhecimento:\n",
            "\n",
            "A Figura 9.8 ilustra uma parte da rede de relacionamento inferencial da palavra “crime” na base InferenceNet-BR, com as seguintes relações:\n",
            "\n",
            "Nesta seção, usaremos a base da ConceptNet para o português e para o inglês para analisar o Exemplo 9.1. No Exemplo 9.4 são destacadas algumas afirmações de senso comum associadas aos termos mencionados no texto (termos sublinhados).\n",
            "\n",
            "Exemplo 9.4  \n",
            "\n",
            "parte do cap 17\n",
            "\n",
            "Além das medidas de precisão e cobertura, assim como em tarefas de classificação de texto e recuperação de informação, utilizamos a média harmônica entre essas medidas, chamada medida F1, a fim de condensar a informação contida nas duas. A medida F1 pode ser calculada como:\n",
            "\n",
            "F1 = \\frac{2*P*R}{P+R}\n",
            "\n",
            "A avaliação da tarefa de REN segue padrões semelhantes aos aplicados à tarefa de ER. De fato, desde a MUC-6 (Grishman; Sundheim, 1996), as medidas de precisão, cobertura e F1 tem sido usada consistentemente como métricas de avaliação da tarefa de REN em diversos esforços de avaliação, como a CoNNL (Sang; De Meulder, 2003), para a língua inglesa, e das duas edições do HAREM (Gonçalo Oliveira et al., 2008; Santos; Cardoso; Seco, 2007), com excessão à ACE (Doddington et al., 2004) que apresenta uma combinação da tarefa de REN com reconhecimento de co-referência entre entidades e utiliza um sistema de pontuação próprio.\n",
            "\n",
            "A avaliação de sistemas de EIA, por sua vez, possui algumas peculiaridades que precisam ser discutidas. Uma vez que a tarefa é postulada por Banko et al. (2007) como a extração de todas as relações identificadas em um dado fragmento textual, sem limitação de domínio de interesse, tal tarefa impõe imensa dificuldade aos esforços de avaliação.\n",
            "\n",
            "De fato, Glauber et al. (2018) relatam um esforço de anotação de dados para a tarefa em língua portuguesa em que foram identificados por anotadores humanos mais de 400 relacionamentos em um corpus de 25 sentenças retiradas de textos jornalísticos e de enciclopédia. Assim, a avaliação de EIA deu-se, em grande parte de seu desenvolvimento e maturação, em conjuntos de dados não anotados, recorrendo a avaliações qualitativas das saídas dos sistemas e comparação direta por humanos das extrações obtidas.\n",
            "\n",
            "Nesses esforços de avaliação, a precisão do sistema pode ser mensurada a partir da avaliação humana das saídas. Não é possível, entretanto, avaliar medidas como cobertura e F1, dada a inexistência de uma referência do conjunto total de relacionamentos a serem identificados. Assim, os autores da área propuseram diferentes métricas a fim de estimar tais valores, como a métrica rendimento (yield) (Fader; Soderland; Etzioni, 2011; Schmitz et al., 2012).\n",
            "\n",
            "A métrica de rendimento consiste no núemro de extrações válidas, i.e. corretas, de um dado sistema. Como calcular tal medida é, na maioria dos casos, impraticável dada a grande quantidade de extrações realizadas pelos sistemas, ela pode ser estimada a partir da precisão do sistema calculada sobre uma amostra aleatória das extrações realizadas (\\(P'\\)). Assim, podemos estimar o rendimento como:\n",
            "\n",
            "Y = P'\\cdot \\#(\\mbox{extrações realizadas})\n",
            "\n",
            "Foi também explorada a estratégia de criação (semi-)automática de conjuntos de dados usando vários sistemas (Del Corro; Gemulla, 2013), estratégias de supervisão fraca (Smirnova; Cudré-Mauroux, 2018), ou a geração de corpora para a tarefa a partir da transformação de anotações de tarefas próximas, como identificação de papéis temáticos (Semantic Role Labeling) por (Stanovsky et al., 2018). Corpora gerados de forma semi-automática vêm ganhando atenção na literatura recente, particularmente para a língua inglesa, devido a necessidade de dados anotados para se utilizar técnicas de aprendizado de máquina e redes neurais em EIA. Corpora como o OIE2016 (Stanovsky et al., 2018), Wire57 (Léchelle; Gotti; Langlais, 2018) e CARB (Bhardwaj; Aggarwal; Mausam, 2019) vêm se tornando corpora de referência em língua inglesa para o problema, apesar dos problemas existentes na construção de tais recursos – a não exaustividade das relações anotadas.\n",
            "\n",
            "Para a língua portuguesa, foram propostas algumas iniciativas para avaliar os sistemas da OIE. Uma avaliação conjunta foi promovida durante o Fórum Ibérico de Avaliação de Línguas (IberLEF) em 2019 (Collovini et al., 2019). A avaliação foi feita usando o corpus proposto por Glauber et al. (2018), que é composto por 442 relacionamentos extraídos de 25 frases de fontes como a seção em português da Wikipédia, o corpus CETENFolha, resenhas de filmes do portal Adoro Cinema2 e o corpus Europarl. Apesar desta tarefa ter contemplado quatro cenários de avaliação, a avaliação geral dos sistemas permaneceu consistente nos diferentes cenários, indicando robustez nos resultados da avaliação. No geral, os sistemas DPTOIE (Oliveira; Claro; Souza, 2022) e Linguakit (Gamallo; Garcia, 2015) tiveram o melhor desempenho, com o Linguakit2 dominando as avaliações de correspondência exata e o DPTOIE as avaliações de correspondências parciais (Collovini et al., 2019).\n",
            "\n",
            "Outra abordagem de avaliação foi idealizada por (Malenchini et al., 2019). Seu foco foi a avaliação extrínseca dos sistemas de EIA através de sua contribuição na tarefa de respostas automáticas a perguntas. Os autores apresentaram um conjunto de dados de referência (benchmark) para avaliação extrínseca de sistemas de EIA em textos de língua portuguesa. Os sistemas que alcançaram os melhores valores na avaliação realizada pelos autores foram os sistemas ArgOE (Gamallo; Garcia, 2015), DependentIE (Glauber; Claro; Oliveira, 2019) e DptOIE (Oliveira; Claro; Souza, 2022).\n",
            "\n",
            "Este capítulo descreveu uma visão geral da área de Extração de Informação, apresentando a Extração de Informação Tradicional e a Extração de Informação Aberta. Transversalmente, apresentamos as formalizações necessárias e os conceitos fundamentais para a compreensão da EIA, assim como a avaliação da área e as heranças de outras áreas afins, tais como RI.\n",
            "\n",
            "Nessa primeira versão, este capítulo descreveu de maneira bem sucinta as abordagens propostas para EI e EIA durante seu desenvolvimento histórico e as abordagens atuais da literatura, como as utilizando modelos de linguagens. Especificamente, a utilização da arquitetura Transformers, descritas no Capítulo 15 para as tarefas de EI e EIA tem sido bastante difundida para a língua inglesa e tem atuado em diversas áreas da PLN.\n",
            "\n",
            "Agradecemos as colaborações dos autores deste Capítulo e suas indicações, assim como agradecemos a Adriana Pagano e Aline Macohin pela revisão e comentários.\n",
            "\n",
            "Em nossa terminologia, por um relacionamento.↩︎\n",
            "\n",
            "parte do cap 9\n",
            "\n",
            "Um assalto do tipo saidinha bancária, ocorrido na tarde desta terça-feira, terminou com uma mulher de 42 anos baleada pelos assaltantes. O roubo ocorreu na rua Professor Costa Mendes.\n",
            "\n",
            "Afirmações (edges) do termo assalto:\n",
            "\n",
            "Afirmações (edges) do termo balear (“shoot”, em inglês):\n",
            "\n",
            "Algumas dificuldades com a análise do exemplo, à luz da ConceptNet, foram:\n",
            "\n",
            "Ao longo deste capítulo exploramos três bases de conhecimento comuns na área de PLN: WordNet, FrameNet e ConceptNet. WordNet, com sua rica estrutura hierárquica, destaca-se por mapear relações semânticas entre conjuntos de sinônimos (synsets), fornecendo uma compreensão sobre sinônimos, antônimos, hiperônimos e muito mais. Esse recurso se tornou uma das ferramentas mais utilizadas em aplicações de PLN, desde a análise de sentimentos até a desambiguação de sentidos.\n",
            "\n",
            "FrameNet, por sua vez, adota uma abordagem baseada em frames para capturar significados em dados contextos ou situações, fazendo a ponte entre elementos lexicais e seus respectivos papéis semânticos. Através dessa base, podemos entender mais profundamente como as palavras interagem dentro de estruturas semânticas e pragmáticas mais amplas. Esta abordagem, focada nos papéis semânticos, permite uma análise mais rica do texto, tornando-a particularmente útil para tarefas de anotação de papéis semânticos e análise de discurso. Em contrapartida, ela não possui um critério claro de completamento, ou seja, não sabemos quando vamos ter (ou se já temos) todos os frames necessários.\n",
            "\n",
            "Por fim, a base ConceptNet destaca-se pelo seu caráter colaborativo e multidimensional. Integra conhecimentos de senso comum e conhecimento léxico-semântico de várias fontes e idiomas, oferecendo uma visão ampla das relações entre conceitos e contextos. Seu formato de rede semântica ajuda a capturar a complexidade e interconexão do conhecimento humano de uma maneira holística. ConceptNet tem sido usada em aplicações de extração de informação e reconhecimento de implicação textual. Em contrapartida, problemas de consistência da base parecem importantes. E tal como no caso de FrameNet, não temos um critério explícito de quando teremos uma cobertura suficiente.\n",
            "\n",
            "Em resumo, cada uma destas bases de conhecimento representa um recurso para o PLN com perspectivas únicas, mas qual delas se aplica melhor e em quais casos? Recursos léxicos-semânticos parecem não serem suficientes para expressar conhecimento de mundo. De outro lado, bases de conhecimento de senso comum são mais flexíveis e expressivas, porém menos formais. Acreditamos que uma abordagem híbrida, em que tais bases de conhecimento sejam usadas de forma combinada, é mais promissora para o PLN. Nas próximas versões deste capítulo introduziremos os parsers semânticos que, em conjunto com as bases de conhecimento, constituem poderoso framework para sistemas de entendimento de linguagem natural.\n",
            "\n",
            "OWL/↩︎\n",
            "\n",
            "Esse texto foi adaptado de notícia publicada em jornal digital, disponível em https://diariodonordeste.verdesmares.com.br/seguranca/mulher-e-baleada-em-saidinha-bancaria-no-montese-1.933137?page=10.↩︎\n",
            "\n",
            "O alinhamento entre wordnets refere-se ao processo de mapeamento ou ligação de synsets entre diferentes wordnets de línguas distintas. Por exemplo, o alinhamento entre PWN e OWN-PT seria o processo de identificar que o synset em inglês para “car” é equivalente ao synset em português para “carro”.↩︎\n",
            "\n",
            "parte do cap 17\n",
            "\n",
            "Daniela Barreiro Claro \n",
            "\n",
            "Joaquim Santos \n",
            "\n",
            "Marlo Souza \n",
            "\n",
            "Renata Vieira \n",
            "\n",
            "Vládia Pinheiro \n",
            "\n",
            "PDF\n",
            "\n",
            "A Extração de Informação (EI) é desenvolvida com o objetivo de se obter informação estruturada de dados não-estruturados (Jurafsky; Martin, 2023; Konstantinova, 2014).\n",
            "\n",
            "Os primeiros trabalhos a debruçarem-se sobre o problema remontam à década de 1970, com a aplicação de gramáticas formais e parsers sintáticos para a estruturação de informação em domínios como prontuários médicos (Sager, 1978; Sager; Friedman; Lyman, 1987) e textos jornalísticos (DeJong, 1979). A comunidade científica demonstrou grande interesse pela área nas décadas posteriores devido à sua utilidade prática, seu foco no processamento de dados reais, suas tarefas bem-definidas e a facilidade de mensurar a qualidade dos resultados em comparação com o desempenho humano na mesma tarefa (Cowie; Lehnert, 1996).\n",
            "\n",
            "Para autores como Eisenstein (2019) e Jurafsky; Martin (2023), a EI é normalmente dividida em diversas tarefas de interesse, com foco no tipo de informação a ser extraída do texto. Entre as mais comumente citadas na literatura estão o Reconhecimento de Entidades Nomeadas (REN), a Extração de Relações (ER) e a Extração de Eventos (EE).\n",
            "\n",
            "O Reconhecimento de Entidades Nomeadas (REN) consiste em identificar e classificar entidades mencionadas em textos através de designadores rígidos como nomes próprios, expressões temporais e espécies biológicas (Nadeau, 2007). Esse é considerado por alguns como um primeiro passo na análise semântica de um texto (Santos; Cardoso, 2007a), pois permite identificar as entidades às quais se faz referência nele.\n",
            "\n",
            "A Extração de Relações (ER), também chamada de extração de informação tradicional ou somente extração de informação, por sua vez, diz respeito à identificação de relacionamentos semânticos entre duas ou mais entidades, ou seja, identificar “quem fez o que para quem e quando”. Ananiadou; Mcnaught (2005) a definem como o processo de extrair fatos (em nossa terminologia, relacionamentos) a partir de uma fonte textual e representá-los a partir de um gabarito (em inglês, template). As relações são elementos essenciais para o entendimento da informação relatada no texto e sua identificação é passo essencial para a estruturação da mesma. Assim, identificar relações entre entidades é tarefa essencial para construção de bases de conhecimento e de grande utilidade na construção de soluções para a resposta automática a perguntas (em inglês, query answering), sumarização, recuperação de informação e mais (Nasar; Jaffry; Malik, 2021).\n",
            "\n",
            "A extração de eventos consiste na tarefa de identificação de uma menção a um evento em uma sentença e, se existirem, extração de outras informações sobre o evento. Um evento pode, por sua vez, ser entendido como uma ocorrência específica envolvendo participantes (Consortium, 2005), i.e., algo que acontece e que pode ser descrito como uma mudança de estado da qual participam entidades como agentes. Devido a intrínseca natureza temporal dos eventos, tal problema possui uma natureza mais complexa e costuma possuir tratamento específico.\n",
            "\n",
            "Assim, nesse capítulo, iniciaremos com um pouco de história da Extração de Informação (EI) e sua evolução para Extração de Informação Aberta, e destacaremos as tarefas de Reconhecimeno de Entidades Nomeadas (REN) e Extração de Relação (ER).\n",
            "\n",
            "Os primeiros trabalhos que abordaram o problema de EI dos quais temos conhecimento surgiram no final da década de 1970. Esses primeiros trabalhos da década de 1970 e 1980 tinham como modelo geral a aplicação de regras para a identificação de informações especificadas em um gabarito. Tais sistemas empregavam analisadores sintáticos (parsers) e regras definidas especificamente para o domínio e gênero textual estudado.\n",
            "\n",
            "Entre esses primeiros trabalhos, estão aqueles de Sager (1978), Sager; Friedman; Lyman (1987), de DeJong (1979) e de Cowie (1983). Sager et al. exploraram como identificar informações do estado de saúde de pacientes através dos textos de prontuários médicos. DeJong (1979), por sua vez, descrevem o sistema FRUMP que, a partir de um parser e regras de análise conceitual baseadas em uma arquitetura cognitiva proposta pelos autores e no conceito de dependência conceitual de Schank et al. (1973), processavam textos de notícias e realizavam tarefas como sumarização e identificação de papéis semânticos associados aos constituintes da sentença. Cowie (1983), por fim, descreve um sistema que emprega regras simples de segmentação e análise sintática rasa para identificar propriedades de plantas a partir de textos descritivos no campo da botânica. Diferente dos métodos anteriores, o trabalho dos autores se baseia em grande parte no estudo de padrões de descrição das informações a serem identificadas, em detrimento do emprego de parsers robustos da língua.\n",
            "\n",
            "A década de 1990 traz um grande interesse na área de EI com a implementação das conferências MUC (do inglês, Message Understanding Conference, ou Conferência de Compreensão de Mensagem), promovidas pela Agência de Projetos de Pesquisa Avançada de Defesa (DARPA, do inglês Defense Advanced Research Projects Agency). As conferências MUC, realizadas e financiadas pelo exército americano, representaram um esforço em avançar a tecnologia de EI e consistiam de tarefas de avaliação conjunta de métodos desenvolvidos por pesquisadores para problemas propostos pelos organizadores. As sete conferências realizadas de 1987 a 1997, foram cruciais para definir aspectos centrais da área, como estruturar a tarefa de ER, definindo suas métricas de avaliação, e propor a tarefa de REN (Grishman; Sundheim, 1996).\n",
            "\n",
            "parte do cap 9\n",
            "\n",
            "Um assalto do tipo saidinha bancária, ocorrido na tarde desta terça-feira, terminou com uma mulher de 42 anos baleada pelos assaltantes. O roubo ocorreu na rua Professor Costa Mendes.\n",
            "\n",
            "Afirmações (edges) do termo assalto:\n",
            "\n",
            "Afirmações (edges) do termo balear (“shoot”, em inglês):\n",
            "\n",
            "Algumas dificuldades com a análise do exemplo, à luz da ConceptNet, foram:\n",
            "\n",
            "Ao longo deste capítulo exploramos três bases de conhecimento comuns na área de PLN: WordNet, FrameNet e ConceptNet. WordNet, com sua rica estrutura hierárquica, destaca-se por mapear relações semânticas entre conjuntos de sinônimos (synsets), fornecendo uma compreensão sobre sinônimos, antônimos, hiperônimos e muito mais. Esse recurso se tornou uma das ferramentas mais utilizadas em aplicações de PLN, desde a análise de sentimentos até a desambiguação de sentidos.\n",
            "\n",
            "FrameNet, por sua vez, adota uma abordagem baseada em frames para capturar significados em dados contextos ou situações, fazendo a ponte entre elementos lexicais e seus respectivos papéis semânticos. Através dessa base, podemos entender mais profundamente como as palavras interagem dentro de estruturas semânticas e pragmáticas mais amplas. Esta abordagem, focada nos papéis semânticos, permite uma análise mais rica do texto, tornando-a particularmente útil para tarefas de anotação de papéis semânticos e análise de discurso. Em contrapartida, ela não possui um critério claro de completamento, ou seja, não sabemos quando vamos ter (ou se já temos) todos os frames necessários.\n",
            "\n",
            "Por fim, a base ConceptNet destaca-se pelo seu caráter colaborativo e multidimensional. Integra conhecimentos de senso comum e conhecimento léxico-semântico de várias fontes e idiomas, oferecendo uma visão ampla das relações entre conceitos e contextos. Seu formato de rede semântica ajuda a capturar a complexidade e interconexão do conhecimento humano de uma maneira holística. ConceptNet tem sido usada em aplicações de extração de informação e reconhecimento de implicação textual. Em contrapartida, problemas de consistência da base parecem importantes. E tal como no caso de FrameNet, não temos um critério explícito de quando teremos uma cobertura suficiente.\n",
            "\n",
            "Em resumo, cada uma destas bases de conhecimento representa um recurso para o PLN com perspectivas únicas, mas qual delas se aplica melhor e em quais casos? Recursos léxicos-semânticos parecem não serem suficientes para expressar conhecimento de mundo. De outro lado, bases de conhecimento de senso comum são mais flexíveis e expressivas, porém menos formais. Acreditamos que uma abordagem híbrida, em que tais bases de conhecimento sejam usadas de forma combinada, é mais promissora para o PLN. Nas próximas versões deste capítulo introduziremos os parsers semânticos que, em conjunto com as bases de conhecimento, constituem poderoso framework para sistemas de entendimento de linguagem natural.\n",
            "\n",
            "OWL/↩︎\n",
            "\n",
            "Esse texto foi adaptado de notícia publicada em jornal digital, disponível em https://diariodonordeste.verdesmares.com.br/seguranca/mulher-e-baleada-em-saidinha-bancaria-no-montese-1.933137?page=10.↩︎\n",
            "\n",
            "O alinhamento entre wordnets refere-se ao processo de mapeamento ou ligação de synsets entre diferentes wordnets de línguas distintas. Por exemplo, o alinhamento entre PWN e OWN-PT seria o processo de identificar que o synset em inglês para “car” é equivalente ao synset em português para “carro”.↩︎\n",
            "\n",
            "parte do cap 17\n",
            "\n",
            "A partir da MUC-3, em 1991, a conferência passa a ter foco no processamento de textos jornalísticos em detrimento dos relatórios militares utilizados anteriormente (DARPA, 1991). Com a disponibilidade de dados e o incentivo no desenvolvimento de soluções para a tarefa, vemos na década de 1990 o surgimento das primeiras aplicações comerciais de EI, como o JASPER (Andersen et al., 1992)., construído para a agência de notícias Reuters.\n",
            "\n",
            "A MUC-6, ocorrida em 1995, introduz a tarefa de REN com o intuito de ser uma tarefa de uso prático, independente de domínio e que poderia ser realizada automaticamente em um futuro próximo (Grishman; Sundheim, 1996). Enquanto os trabalhos em REN se avolumaram a partir de sua proposição na MUC-6, trabalhos anteriores como Rau (1991) e Wolinski; Vichot; Dillet (1995) já se debruçavam sobre o problema de identificação e classificação de nomes próprios. Desde então, o interesse na tarefa cresceu significativamente e outras conferências de avaliação conjunta têm sido dedicadas a essa tarefa, como a Automatic Content Extraction (ACE) e a conferência Avaliação de Sistemas de Reconhecimento de Entidades Mencionadas (HAREM), dedicada exclusivamente à língua portuguesa, com sua primeira edição em 2005 (Santos; Cardoso, 2007a).\n",
            "\n",
            "Por outro lado, houve um crescimento de abordagens baseadas em dados nesta década, a partir da análise de corpora. Tais esforços são impulsionados pelos resultados positivos na área, como o trabalho de Hearst (1992). Logo, métodos baseados em dados passaram também a explorar o emprego de análise estatística e aprendizado de máquina na construção de padrões para a extração de relações (Riloff et al., 1993; Riloff; Jones; et al., 1999; Roark; Charniak, 2000; Soderland et al., 1995)\n",
            "\n",
            "Não foi somente na extração de padrões que métodos de aprendizado de máquina, em particular aprendizado supervisionado, foram aplicados. A década de 2000 viu a proliferação de métodos supervisionados aplicados à ER (Culotta; McCallum; Betz, 2006; Kambhatla, 2004; Zelenko; Aone; Richardella, 2003; Zhao; Grishman, 2005) e ao REN (Asahara; Matsumoto, 2003; McCallum; Li, 2003; Sekine, 1998).\n",
            "\n",
            "Devido à dificuldade de construção de dados para treinamento e padrões para extração, além da pouca adaptabilidade dos sistemas construídos para outros escopos e domínios, nos anos 2000, sistemas baseados em métodos de aprendizado semi-supervisionado, como o DIPRE (Brin, 1998) e Snowball (Agichtein; Gravano, 2000) começaram a aparecer, juntamente com os estudos sobre expansão automatizada de anotações (bootstrapping) (Riloff; Jones; et al., 1999). Também para entidades nomeadas, estudos investigaram como utilizar recursos da Web (Etzioni et al., 2005; Nadeau, 2007) ou corpora (Cucchiarelli; Velardi, 2001) para aprender entidades com pouco ou nenhum esforço de anotação.\n",
            "\n",
            "Buscando superar as dificuldades da limitação de escopo, i.e. das relações-alvo a serem extraídas e categorias de entidades a serem identificadas, ainda restritas à definição de padrões desde a criação dessas tarefas, Banko et al. (2007) propõe a tarefa de extração de informação aberta (EIA), também conhecida como Open Information Extraction, OpenIE ou OIE, a qual busca extrair todas as relações possíveis expressas em um texto, sem necessidade de pré-definição de relações e entidades.\n",
            "\n",
            "Devido ao recente sucesso da aplicação de métodos baseados em redes neurais, em particular deep learning e grandes modelos de linguagem, às tarefas de Processamento de Linguagem Natural, uma tendência atual da área se delineou como o estudo de arquiteturas neurais para os problemas de EI e a geração de grandes conjuntos de dados por supervisão fraca. Surveys recentes, como (Cui; Wei; Zhou, 2018; Konstantinova, 2014; Nasar; Jaffry; Malik, 2021), nos mostram a evolução da área em direção à aplicação de métodos neurais. Na vertente de geração de dados, vemos o emprego da Wikipédia e Freebase como fontes mais usadas para obter anotações de entidades e relações em textos (Nguyen; Theobald; Weikum, 2016; Smirnova; Cudré-Mauroux, 2018; Takamatsu; Sato; Nakagawa, 2012).\n",
            "\n",
            "Porém, toda a tarefa de EI necessita de uma concordância entre as definições de Entidade e Relação. Neste sentido, a próxima seção discute a conceituação de relação adotada neste capítulo, assim como o conceito de entidade.\n",
            "\n",
            "A natureza das relações estudadas na área de Extração de Informação e os critérios para reconhecer sua ocorrência em um texto têm recebido pouca atenção na literatura. Este é um passo importante para estabelecer metodologias adequadas para avaliar os sistemas, bem como para criar conjuntos de dados que possam apoiar a criação de sistemas futuros.\n",
            "\n",
            "Enquanto as noções de Relação e Entidade são de grande importância e já bem estudadas nas áreas de Computação, Linguística, Ciência da Informação e Filosofia da Linguagem, esses conceitos não são empregados de forma consistente entre as áreas, ou mesmo entre suas subáreas.\n",
            "\n",
            "Para Chen (1976), uma entidade é um objeto que pode ser concreto, tal como pessoa, livro, casa ou ainda abstrato, tal como um emprego, um sentimento, uma disciplina. As entidades podem estabelecer relações entre si. Duas ou mais entidades são vinculadas, ou seja conectadas por uma relação1.\n",
            "\n",
            "Tradicionalmente em reconhecimento de entidades nomeadas, as entidades consideradas são aquelas referenciadas por um nome próprio, acrescidas das referências temporais e valores que são expressões numéricas. Essas expressões, portanto, geralmente não constituem uma entrada em uma base lexical. Porém a tarefa se expandiu para domínios especializados, onde as entidades de interesse são mais conceituais. No domínio bio-médico por exemplo, podemos ter como exemplo de entidades de interesse, sintomas e tratamento que não são referenciadas por nomes próprios.\n",
            "\n",
            "Os conceitos de relação e relacionamento são noções fundamentais que vêm sendo estudadas em áreas como Ciência da Computação, Linguística e Filosofia.\n",
            "\n",
            "No campo de bancos de dados e modelagem conceitual, Chen (1976) define um relacionamento, no contexto da modelagem de Entidade-Relacionamento, como uma associação entre entidades. Guarino; Guizzardi (2015), por sua vez, estudando a natureza ontológica dos relacionamentos com base na semântica de veridadores (truthmaker semantics) (Fine, 2017), postulam relacionamentos como entidades que atuam como veridadores (thruthmakers) de alguma proposição relacionando duas ou mais entidades, ou seja, uma relação mantida entre essas entidades. Um veridador é um elemento cuja existência torna verdadeira uma proposição particular. Por exemplo, considerando a sentença (1) “a é uma maçã”, a existência de um objeto denotado pelo nome a que por acaso é uma maçã é uma condição suficiente para a verdade da frase (1). Como tal, dizemos que esse objeto é o veridador de (1). Tal definição nos permite adotar critérios ontológicos para validar a existência de relacionamentos a partir da informação relatada em um texto e, por isso, adotaremos tal definição de relacionamento neste capítulo.\n",
            "\n",
            "O conceito de relações é muito menos consistente na literatura. Ainda na área de modelagem conceitual, Guarino; Guizzardi (2015) definem as relações como proposições para as quais os relacionamentos são veridadores e, portanto, possuem conteúdo proposicional. Assim, podemos entender uma relação como um tipo para entidades como relacionamentos. Ou seja, relações são universais ontológicos que descrevem a natureza dos relacionamentos.\n",
            "\n",
            "Xavier; Lima; Souza (2015), no entanto, argumentam que a noção de relacionamento adotada na área de Extração de Informação é mais geral do que isso, não se limitando àquelas entre objetos e propriedades, mas também àquelas que descrevem ou implicam propriedades de classes gerais como descrito pela sentença (2) “Filósofos são autores de Livros”. Assim, para o contexto de EI consideramos relações como tipos de relacionamentos de primeira ou segunda ordem. Isso significa que uma relação é um tipo de relacionamento que existe entre objetos, suas propriedades e classes de objetos ou suas propriedades.\n",
            "\n",
            "parte do cap 9\n",
            "\n",
            "Um assalto do tipo saidinha bancária, ocorrido na tarde desta terça-feira, terminou com uma mulher de 42 anos baleada pelos assaltantes. O roubo ocorreu na rua Professor Costa Mendes.\n",
            "\n",
            "Afirmações (edges) do termo assalto:\n",
            "\n",
            "Afirmações (edges) do termo balear (“shoot”, em inglês):\n",
            "\n",
            "Algumas dificuldades com a análise do exemplo, à luz da ConceptNet, foram:\n",
            "\n",
            "Ao longo deste capítulo exploramos três bases de conhecimento comuns na área de PLN: WordNet, FrameNet e ConceptNet. WordNet, com sua rica estrutura hierárquica, destaca-se por mapear relações semânticas entre conjuntos de sinônimos (synsets), fornecendo uma compreensão sobre sinônimos, antônimos, hiperônimos e muito mais. Esse recurso se tornou uma das ferramentas mais utilizadas em aplicações de PLN, desde a análise de sentimentos até a desambiguação de sentidos.\n",
            "\n",
            "FrameNet, por sua vez, adota uma abordagem baseada em frames para capturar significados em dados contextos ou situações, fazendo a ponte entre elementos lexicais e seus respectivos papéis semânticos. Através dessa base, podemos entender mais profundamente como as palavras interagem dentro de estruturas semânticas e pragmáticas mais amplas. Esta abordagem, focada nos papéis semânticos, permite uma análise mais rica do texto, tornando-a particularmente útil para tarefas de anotação de papéis semânticos e análise de discurso. Em contrapartida, ela não possui um critério claro de completamento, ou seja, não sabemos quando vamos ter (ou se já temos) todos os frames necessários.\n",
            "\n",
            "Por fim, a base ConceptNet destaca-se pelo seu caráter colaborativo e multidimensional. Integra conhecimentos de senso comum e conhecimento léxico-semântico de várias fontes e idiomas, oferecendo uma visão ampla das relações entre conceitos e contextos. Seu formato de rede semântica ajuda a capturar a complexidade e interconexão do conhecimento humano de uma maneira holística. ConceptNet tem sido usada em aplicações de extração de informação e reconhecimento de implicação textual. Em contrapartida, problemas de consistência da base parecem importantes. E tal como no caso de FrameNet, não temos um critério explícito de quando teremos uma cobertura suficiente.\n",
            "\n",
            "Em resumo, cada uma destas bases de conhecimento representa um recurso para o PLN com perspectivas únicas, mas qual delas se aplica melhor e em quais casos? Recursos léxicos-semânticos parecem não serem suficientes para expressar conhecimento de mundo. De outro lado, bases de conhecimento de senso comum são mais flexíveis e expressivas, porém menos formais. Acreditamos que uma abordagem híbrida, em que tais bases de conhecimento sejam usadas de forma combinada, é mais promissora para o PLN. Nas próximas versões deste capítulo introduziremos os parsers semânticos que, em conjunto com as bases de conhecimento, constituem poderoso framework para sistemas de entendimento de linguagem natural.\n",
            "\n",
            "OWL/↩︎\n",
            "\n",
            "Esse texto foi adaptado de notícia publicada em jornal digital, disponível em https://diariodonordeste.verdesmares.com.br/seguranca/mulher-e-baleada-em-saidinha-bancaria-no-montese-1.933137?page=10.↩︎\n",
            "\n",
            "O alinhamento entre wordnets refere-se ao processo de mapeamento ou ligação de synsets entre diferentes wordnets de línguas distintas. Por exemplo, o alinhamento entre PWN e OWN-PT seria o processo de identificar que o synset em inglês para “car” é equivalente ao synset em português para “carro”.↩︎\n",
            "\n",
            "parte do cap 17\n",
            "\n",
            "Enquanto os métodos tradicionais de Extração de Informação dependem de um conjunto pré-existente de relações semânticas bem definidas que são relevantes para um domínio específico, a noção de “relação” e “entidade” na literatura da área mais recente, tais como a Extração de Informação Aberta, requer mais aprofundamento por demandar um significado diferente, principalmente com diferente visões de autores. Esta indeterminação terminológica pode trazer problemas para comparar os resultados dos métodos propostos ou para reutilizar os conjuntos de dados criados na área.\n",
            "\n",
            "As seções seguintes exploram essas duas áreas: Extração de Informação e Extração de Informação Aberta.\n",
            "\n",
            "A Extração de Informação é caracterizada por obter informação estruturada a partir de textos, sendo entidades ou fatos, i.e. relacionamentos entre entidades, de tipos previamente definidos, conforme exemplo na Quadro 17.1. Métodos com limitação de escopo possuem como uma de suas principais desvantagens a necessidade de intervenção humana para especificar novos fatos a serem extraídos. Esta limitação impede que sistemas de Extração de Informação, doravante denominados de EI tradicional extraiam fatos fora do escopo pré-definido.\n",
            "\n",
            "Quadro 17.1 Exemplos de relações específicas na EI tradicional\n",
            "\n",
            "Fonte: (Souza; Claro, 2014)\n",
            "\n",
            "O Reconhecimento de Entidades Nomeadas (REN) consiste na tarefa de identificar e classificar expressões linguísticas, denominadas entidades nomeadas (EN), que referenciam entidades específicas num domínio de discurso, como nomes próprios, expressões temporais e espécies biológicas (Mota; Santos; Ranchhod, 2007; Nadeau, 2007). De uma forma geral, o REN pode ser dividido em duas etapas: a identificação (ou delimitação) da expressão, na qual as palavras que formam a EN são selecionadas; a classificação, em que é atribuída uma categoria semântica à EN.\n",
            "\n",
            "A classificação das ENs determina os tipos de entidades a serem consideradas e são especificadas a partir do escopo definido previamente para a tarefa. Algumas das categorias mais comumente utilizadas incluem as entidades que referenciam Pessoas Singulares (antropônimos); Coletivas (empresas e organizações) e Lugares (topônimos) (Mota; Santos; Ranchhod, 2007). Para exemplificar tomemos a sentença: “Renata Silva e Maria Costa palestraram na Universidade Federal da Bahia”. No exemplo temos três ENs: “Renata Silva”, “Maria Costa”, “Universidade Federal da Bahia”, sendo as duas primeiras correspondentes à categoria semântica Pessoa e a última, à categoria semântica Organização. Entretanto, existem outras categorias de ENs, como as menções a Obras (por exemplo, “Código Da Vinci”); Acontecimentos (por exemplo, “Festa de Santo Antônio”), Tempo (por exemplo, “meio-dia”); Coisa (por exemplo, “barco”), entre outras.\n",
            "\n",
            "O REN é uma tarefa com grande importância para o Processamento de Linguagem Natural, pois consiste numa primeira tarefa de análise semântica de um texto, com potencial aplicações a diversas tarefas. Por exemplo, em sistemas de perguntas e respostas, as perguntas frequentemente se referem a informações sobre entidades. Também, métodos de identificação de estruturas mais complexas, como eventos ou relações, dependem do bom desempenho do REN como uma etapa de pré-processamento (Socher et al., 2012; Zelenko; Aone; Richardella, 2003).\n",
            "\n",
            "A tarefa de extração de relações (ou de relacionamentos) (ER) refere-se a identificar relacionamentos entre entidades de um determinado escopo mencionadas em um texto (Jurafsky; Martin, 2023). O escopo, no contexto da ER, refere-se a um conjunto de relações-alvo de um determinado domínio de conhecimento ou aplicação a ser investigado. Por exemplo, o Quadro 17.2 apresenta alguns exemplos de relações no domínio de geografia brasileira. Na descrição das relações, os elementos em negrito referem-se às entidades em um dado relacionamento descrito pelo termo em itálico.\n",
            "\n",
            "Quadro 17.2 Exemplos de relações no domínio da geografia brasileira.\n",
            "\n",
            "Nesse contexto, a delimitação de um escopo ou domínio de interesse, concentra-se na determinação das relações a serem processadas, i.e. nos tipos de relacionamentos de interesse, assim como da natureza das entidades associadas por tais relações.\n",
            "\n",
            "As tarefas de reconhecimento de entidades nomeadas e extração de relações são interdependentes, no sentido de que a definição do escopo a ser estudado delimita tanto as categorias e natureza das entidades a serem extraídas, como também as relações entre essas entidades. Também, note-se que, pelo fato de as relações serem comumente definidas entre entidades de tipo especificado, como o caso da relação Tem_Prefeito no Quadro 17.2 que ocorre entre entidades das classes Cidade e Pessoa, tanto as informações das entidades mencionadas no texto são úteis para a extração de relações, quanto a informação das relações identificadas pode ser útil ao processo de identificação de entidades.\n",
            "\n",
            "De fato, na literatura recente, existem vários trabalhos que consideram a tarefa de extração conjunta de entidades e relações (ERE, do inglês Entity and Relation Joint Extraction), composta das tarefas de REN e ER (Agichtein; Gravano, 2000; Shaowei et al., 2022; Yuan et al., 2021). Enquanto normalmente abordagens estruturam suas soluções de forma sequencial, usualmente realizando REN inicialmente e, posteriormente, realizando ER, como nos trabalhos de (Hasegawa; Sekine; Grishman, 2004) e de (Socher et al., 2012), a literatura recente aponta para as vantagens da identificação conjunta ao permitir um melhor aprendizado de restrições para identificação de entidades e relações, c.f. o recente survey realizado por (Shaowei et al., 2022) sobre métodos para tal tarefa.\n",
            "\n",
            "Várias abordagens foram adotadas para o problema de EI durante seu desenvolvimento histórico. Enquanto abordagens iniciais privilegiavam métodos ricos em conhecimento, como regras e recursos linguísticos e de conhecimento de mundo, a literatura recente na área privilegia métodos baseados em dados, como o aprendizado de máquina, com o recente emprego de arquiteturas neurais aos problemas.\n",
            "\n",
            "A seguir faremos uma breve apresentação das abordagens descritas na literatura para os problemas de EI.\n",
            "\n",
            "parte do cap 9\n",
            "\n",
            "Um assalto do tipo saidinha bancária, ocorrido na tarde desta terça-feira, terminou com uma mulher de 42 anos baleada pelos assaltantes. O roubo ocorreu na rua Professor Costa Mendes.\n",
            "\n",
            "Afirmações (edges) do termo assalto:\n",
            "\n",
            "Afirmações (edges) do termo balear (“shoot”, em inglês):\n",
            "\n",
            "Algumas dificuldades com a análise do exemplo, à luz da ConceptNet, foram:\n",
            "\n",
            "Ao longo deste capítulo exploramos três bases de conhecimento comuns na área de PLN: WordNet, FrameNet e ConceptNet. WordNet, com sua rica estrutura hierárquica, destaca-se por mapear relações semânticas entre conjuntos de sinônimos (synsets), fornecendo uma compreensão sobre sinônimos, antônimos, hiperônimos e muito mais. Esse recurso se tornou uma das ferramentas mais utilizadas em aplicações de PLN, desde a análise de sentimentos até a desambiguação de sentidos.\n",
            "\n",
            "FrameNet, por sua vez, adota uma abordagem baseada em frames para capturar significados em dados contextos ou situações, fazendo a ponte entre elementos lexicais e seus respectivos papéis semânticos. Através dessa base, podemos entender mais profundamente como as palavras interagem dentro de estruturas semânticas e pragmáticas mais amplas. Esta abordagem, focada nos papéis semânticos, permite uma análise mais rica do texto, tornando-a particularmente útil para tarefas de anotação de papéis semânticos e análise de discurso. Em contrapartida, ela não possui um critério claro de completamento, ou seja, não sabemos quando vamos ter (ou se já temos) todos os frames necessários.\n",
            "\n",
            "Por fim, a base ConceptNet destaca-se pelo seu caráter colaborativo e multidimensional. Integra conhecimentos de senso comum e conhecimento léxico-semântico de várias fontes e idiomas, oferecendo uma visão ampla das relações entre conceitos e contextos. Seu formato de rede semântica ajuda a capturar a complexidade e interconexão do conhecimento humano de uma maneira holística. ConceptNet tem sido usada em aplicações de extração de informação e reconhecimento de implicação textual. Em contrapartida, problemas de consistência da base parecem importantes. E tal como no caso de FrameNet, não temos um critério explícito de quando teremos uma cobertura suficiente.\n",
            "\n",
            "Em resumo, cada uma destas bases de conhecimento representa um recurso para o PLN com perspectivas únicas, mas qual delas se aplica melhor e em quais casos? Recursos léxicos-semânticos parecem não serem suficientes para expressar conhecimento de mundo. De outro lado, bases de conhecimento de senso comum são mais flexíveis e expressivas, porém menos formais. Acreditamos que uma abordagem híbrida, em que tais bases de conhecimento sejam usadas de forma combinada, é mais promissora para o PLN. Nas próximas versões deste capítulo introduziremos os parsers semânticos que, em conjunto com as bases de conhecimento, constituem poderoso framework para sistemas de entendimento de linguagem natural.\n",
            "\n",
            "OWL/↩︎\n",
            "\n",
            "Esse texto foi adaptado de notícia publicada em jornal digital, disponível em https://diariodonordeste.verdesmares.com.br/seguranca/mulher-e-baleada-em-saidinha-bancaria-no-montese-1.933137?page=10.↩︎\n",
            "\n",
            "O alinhamento entre wordnets refere-se ao processo de mapeamento ou ligação de synsets entre diferentes wordnets de línguas distintas. Por exemplo, o alinhamento entre PWN e OWN-PT seria o processo de identificar que o synset em inglês para “car” é equivalente ao synset em português para “carro”.↩︎\n",
            "\n",
            "parte do cap 17\n",
            "\n",
            "As abordagens iniciais para REN baseavam-se, majoritariamente, no emprego de regras lexico-sintáticas e consulta a almanaques (gazeeers). Tais abordagens dependem da construção de listas de nomes próprios como antropônimos, topônimos etc., e outras palavras, como “Ltda.”, “Jr.” etc., que auxiliam no processo de identificação e classificação de ENs complexas ou desconhecidas. Essa é, por exemplo, a abordagem empregada por Wolinski; Vichot; Dillet (1995) que combina almanaques e regras para a identificação e classificação de ENs. Posteriormente, almanaques foram também empregados em conjunção com métodos baseados em dados, como o trabalho de Florian et al. (2003) que os emprega aliados aos classificadores, enquanto Liu; Yao; Lin (2019) os utilizam durante o treinamento de uma rede neural, como um sinal de treinamento (parte da função de perda, ou loss em inglês).\n",
            "\n",
            "Muitos trabalhos debruçaram-se também sobre o problema de construção automática ou semi-automática de almanaques, dos quais os trabalhos de Nadeau (2007), de Riloff; Jones; et al. (1999) e de Etzioni et al. (2005) são alguns dos mais importantes.\n",
            "\n",
            "Enquanto as abordagens iniciais para o problema baseavam-se em regras, com a disponibilidade de dados anotados para a tarefa, tais métodos foram rapidamente suplantados por métodos baseados em dados, tais como: os métodos baseados em classificação (Asahara; Matsumoto, 2003; Sekine, 1998) e classificação sequencial (Bikel; Schwartz; Weischedel, 1999; McCallum; Li, 2003).\n",
            "\n",
            "A redução de REN à tarefa de classificação sequencial merece destaque pelos bons resultados obtidos. Tal redução se dá através de um esquema de codificação do problema que nos permite representar fragmentos textuais e sua classificação como um problema de rotulação ou etiquetação.\n",
            "\n",
            "Partindo-se do pressuposto de que os fragmentos textuais descrevendo entidades nomeadas são contíguos, podemos codificar a tarefa de delimitação de entidades como classificação sequencial empregando rótulos que descrevem os limites de uma EN, e.g. o esquema BIO com os rótulos B (do inglês, begin) para designar a palavra inicial de uma EN, I (do inglês, inside) para designar palavras que fazem parte da EN mas não a iniciam e O (do inglês, outside) para designar palavras que não pertencem a uma entidade. Da mesma forma, podemos estender nosso esquema de codificação para incluir as classes de interesse. Assim, seguindo o esquema BIO, teremos os rótulos B-PER e I-PER para descrever entidades da classe Pessoa.\n",
            "\n",
            "A redução do problema de REN à classificação sequencial está ilustrada no Exemplo 17.1.\n",
            "\n",
            "Exemplo 17.1  \n",
            "\n",
            "Renata/B-PER Silva/I-PER e/O Maria/B-PER Costa/I-PER palestraram/O na/O Universidade/B-ORG Federal/I-ORG da/I-ORG Bahia/I-ORG.\n",
            "\n",
            "Recentemente, destacam-se na literatura abordagens baseadas em redes neurais profundas, com uma grande concentração nos últimos anos em modelos gerativos de linguagem, devido aos resultados positivos obtidos por tais arquiteturas em diversas tarefas.\n",
            "\n",
            "Na literatura são de grande destaque os modelos recentes BART (Lewis et al., 2020), RoBERTa (Liu et al., 2019), T5 (Raffel et al., 2020), BERT (Devlin et al., 2019) e GPT-3 (Brown et al., 2020), conforme descritos no Capítulo 15.\n",
            "\n",
            "Similarmente, na língua portuguesa, nas duas edições do HAREM (Mota; Santos, 2008; Santos; Cardoso, 2007b), o primeiro esforço sistemático de desenvolvimento de soluções para a tarefa na língua, a maioria dos sistemas participantes baseava-se em métodos ricos em conhecimento, como regras e almanaques. De fato, nas duas avaliações, somente os sistemas MALINCHE (Solorio, 2007), NEURA (Ferrández et al., 2007) e R3M (Mota, 2008) não se baseavam em regras. Métodos baseados em classificação sequencial se seguiram para a língua portuguesa, como o RELP-CRF (Amaral; Vieira, 2014) baseado em um classificador sequencial. Mais recentemente, abordagens baseadas em redes neurais e modelos de linguagem foram desenvolvidas tornando-se o estado da arte da tarefa na língua. A Tabela 17.1 apresenta o atual estado da arte em português, com base no corpus HAREM. A métrica de avaliação apresentada, medida F1, será discutida na Seção 17.6.\n",
            "\n",
            "Souza; Nogueira; Lotufo (2020) desenvolveram um modelo BERT para o Português com 2,68 bilhões de tokens e aplicaram o modelo em um classificador CRF. Santos et al., avaliaram o impacto do modelo contextualizado Flair Embeddings aplicado a tarefa de REN junto com uma rede neural BiLSTM-CRF. Os autores também desenvolveram um modelo Flair Embeddings para o português, o FlairBBP, treinado com 4,9 bilhões de tokens (Santos et al., 2019). Castro; Silva; Soares (2018) utilizou uma rede LSTM e um classificador CRF junto com modelos Word Embeddings pré-treinados. Santos; Guimarães (2015) desenvolveram uma rede neural convolucional capaz de capturar características a nível de caracteres e também de incorporar word embeddings pré-treinados.\n",
            "\n",
            "O reconhecimento de entidades tem sido aplicado em muitas áreas específicas, como direito, saúde e geologia. Nesses casos há uma demanda de adaptação dos modelos preditivos de acordo com a nova linguagem especializada do domínio e um novo conjunto de rótulos que devem ser aprendidos. Da mesma forma, são necessários novos conjuntos de dados para o processo de aprendizado, uma vez que abordagens de aprendizado de máquina necessitam de exemplos anotados para se chegar a um modelo preditivo eficaz.\n",
            "\n",
            "Muitos trabalhos endereçam domínios específicos, citamos exemplos em diversas línguas. Para o inglês, uma rede neural BiLSTM-CRF para o domínio biomédico é proposta em (Habibi et al., 2017).\n",
            "\n",
            "Um conjunto de dados do domínio jurídico em língua alemã é apresentado por Leitner; Rehm; Schneider (2019), que empregam redes neurais BiLSTM para a rotulação dos textos. Em (Qiu et al., 2019), uma rede neural BiLSTM-CRF com mecanismo de atenção é aplicada para reconhecer entidades geológicas para a língua chinesa.\n",
            "\n",
            "parte do cap 9\n",
            "\n",
            "Um assalto do tipo saidinha bancária, ocorrido na tarde desta terça-feira, terminou com uma mulher de 42 anos baleada pelos assaltantes. O roubo ocorreu na rua Professor Costa Mendes.\n",
            "\n",
            "Afirmações (edges) do termo assalto:\n",
            "\n",
            "Afirmações (edges) do termo balear (“shoot”, em inglês):\n",
            "\n",
            "Algumas dificuldades com a análise do exemplo, à luz da ConceptNet, foram:\n",
            "\n",
            "Ao longo deste capítulo exploramos três bases de conhecimento comuns na área de PLN: WordNet, FrameNet e ConceptNet. WordNet, com sua rica estrutura hierárquica, destaca-se por mapear relações semânticas entre conjuntos de sinônimos (synsets), fornecendo uma compreensão sobre sinônimos, antônimos, hiperônimos e muito mais. Esse recurso se tornou uma das ferramentas mais utilizadas em aplicações de PLN, desde a análise de sentimentos até a desambiguação de sentidos.\n",
            "\n",
            "FrameNet, por sua vez, adota uma abordagem baseada em frames para capturar significados em dados contextos ou situações, fazendo a ponte entre elementos lexicais e seus respectivos papéis semânticos. Através dessa base, podemos entender mais profundamente como as palavras interagem dentro de estruturas semânticas e pragmáticas mais amplas. Esta abordagem, focada nos papéis semânticos, permite uma análise mais rica do texto, tornando-a particularmente útil para tarefas de anotação de papéis semânticos e análise de discurso. Em contrapartida, ela não possui um critério claro de completamento, ou seja, não sabemos quando vamos ter (ou se já temos) todos os frames necessários.\n",
            "\n",
            "Por fim, a base ConceptNet destaca-se pelo seu caráter colaborativo e multidimensional. Integra conhecimentos de senso comum e conhecimento léxico-semântico de várias fontes e idiomas, oferecendo uma visão ampla das relações entre conceitos e contextos. Seu formato de rede semântica ajuda a capturar a complexidade e interconexão do conhecimento humano de uma maneira holística. ConceptNet tem sido usada em aplicações de extração de informação e reconhecimento de implicação textual. Em contrapartida, problemas de consistência da base parecem importantes. E tal como no caso de FrameNet, não temos um critério explícito de quando teremos uma cobertura suficiente.\n",
            "\n",
            "Em resumo, cada uma destas bases de conhecimento representa um recurso para o PLN com perspectivas únicas, mas qual delas se aplica melhor e em quais casos? Recursos léxicos-semânticos parecem não serem suficientes para expressar conhecimento de mundo. De outro lado, bases de conhecimento de senso comum são mais flexíveis e expressivas, porém menos formais. Acreditamos que uma abordagem híbrida, em que tais bases de conhecimento sejam usadas de forma combinada, é mais promissora para o PLN. Nas próximas versões deste capítulo introduziremos os parsers semânticos que, em conjunto com as bases de conhecimento, constituem poderoso framework para sistemas de entendimento de linguagem natural.\n",
            "\n",
            "OWL/↩︎\n",
            "\n",
            "Esse texto foi adaptado de notícia publicada em jornal digital, disponível em https://diariodonordeste.verdesmares.com.br/seguranca/mulher-e-baleada-em-saidinha-bancaria-no-montese-1.933137?page=10.↩︎\n",
            "\n",
            "O alinhamento entre wordnets refere-se ao processo de mapeamento ou ligação de synsets entre diferentes wordnets de línguas distintas. Por exemplo, o alinhamento entre PWN e OWN-PT seria o processo de identificar que o synset em inglês para “car” é equivalente ao synset em português para “carro”.↩︎\n",
            "\n",
            "parte do cap 17\n",
            "\n",
            "Para o português, um corpus para detecção de eventos de quedas de pacientes em prontuários eletrônicos é descrito em (Santos; Santos; Vieira, 2020). Os autores usaram uma rede neural BiLSTM-CRF+Flair para gerar um modelo classificador de tokens. Um corpus no domínio jurídico, tendo categorias específicas como legislação e jurisprudência é proposto por  Araujo et al. (2018), que usaram uma rede neural BiLSTM-CRF para criar um primeiro baseline para esse corpus. Ademais, Consoli et al. (2020) analisam um corpus no domínio de geologia usando uma rede neural BiLSTM-CRF com um modelo contextualizado Flair Embeddings.\n",
            "\n",
            "As abordagens iniciais para o problema de ER baseavam-se na definição de gabaritos e regras de extração, com base em informação sintática obtida de analisadores sintáticos rasos ou profundos (Cowie, 1983; Sager, 1978). Tais métodos foram rapidamente suplantados por métodos baseados em dados e padrões obtidos de corpora, como os famosos padrões de Hearst (1992) para identificação de relações de hiponímia.\n",
            "\n",
            "O trabalho de Hearst (1992) se baseou na definição de padrões lexico-sintáticos para expressão de relações de hiponímia e hiperonímia a partir de uma análise de corpus. Ao escolher a relação de hiponímia, que ocorre em todo domínio, e padrões gerais baseados em aspectos da língua, como os representados no Quadro 17.3, o autor garante generalizabilidade dos padrões obtidos para diversos domínios e aplicações.\n",
            "\n",
            "Quadro 17.3 Exemplos de Padrões de Hearst para hiponímia\n",
            "\n",
            "Devido à dificuldade de construção manual das regras, os métodos de Riloff et al. (1993), empregam heurísticas para geração de padrões baseadas em informação gramatical, e de Soderland et al. (1995), que se baseia numa semântica de quadros (frames) empregando um analisador semântico e medidas de qualidade de identificação de exemplos, baseado no percentual de acerto sobre relacionamentos previamente conhecidos, para identificação de quadros relevantes.\n",
            "\n",
            "As abordagens baseadas em aprendizado de máquina, hoje as mais comuns e com melhor desempenho na literatura (Konstantinova, 2014; Nasar; Jaffry; Malik, 2021) dividem-se em abordagens que realizam reconhecimento de entidades e extração de relações de forma conjunta e separada.\n",
            "\n",
            "Abordagens baseadas na realização de REN e ER de forma separada baseiam-se em um fluxo de processamento em que, em geral, as entidades são identificadas primeiro e a tarefa de ER se reduz a identificar quando uma sentença ou fragmento textual denota uma relação semântica entre duas entidades. Consideremos o Exemplo 17.2, retirado de (Socher et al., 2012):\n",
            "\n",
            "Exemplo 17.2  \n",
            "\n",
            "Gripe aviária]\\(_{e1}\\) é uma doença infecciosa causada pelo vírus da [influenza tipo a]\\(_{e2}\\)\n",
            "\n",
            "Podemos, então, reduzir o problema de identificar a relação Causa-Efeito(\\(e1\\),\\(e2\\)) a um problema de classificação textual, identificando se a sentença acima fornece indícios para a expressão da relação de interesse. As soluções propostas na literatura para o problema são variadas e baseadas em diferentes métodos.\n",
            "\n",
            "Zelenko; Aone; Richardella (2003), por exemplo, propõem funções de kernel para árvores sintáticas rasas, i.e. funções que descrevem medidas de similaridade entre tais árvores. Eles empregam tais medidas para treinar um classificador de perceptron com votação (voted perceptron) sobre relações no domínio de organizações extraídas de um corpus de textos jornalísticos. De forma similar, Zhao; Grishman (2005) empregam diferentes funções de kernel sobre informações sintáticas relevantes para a identificação de relação e argumentos visando treinar um classificador SVM sobre o corpus de ER da conferência ACE.\n",
            "\n",
            "Culotta; McCallum; Betz (2006), por outro lado, empregam um classificador sequencial baseado em modelos escondidos de Markov para identificação de relações em um texto. Ao restringir sua análise a textos biográficos, os autores reduzem o processo de identificar instâncias de relações à identificação de fragmento textual que delimita o argumento e sua classificação, tarefa para a qual a classificação sequencial já é comumente utilizada. Consideremos o Exemplo 17.3 sobre George W. Bush, retirado de (Culotta; McCallum; Betz, 2006):\n",
            "\n",
            "Exemplo 17.3  \n",
            "\n",
            "George é filho de \\(\\underbrace{\\mbox{George H. W. Bush}}_{\\mbox{pai}}\\) e \\(\\underbrace{\\mbox{Barbara Bush}}_{\\mbox{mãe}}\\).\n",
            "\n",
            "Ao identificar o papel de pai e mãe, os autores conseguem construir a relação Pai(George H. W. Bush, George W. Bush) e Mãe(Barbara Bush, George W. Bush).\n",
            "\n",
            "parte do cap 9\n",
            "\n",
            "Um assalto do tipo saidinha bancária, ocorrido na tarde desta terça-feira, terminou com uma mulher de 42 anos baleada pelos assaltantes. O roubo ocorreu na rua Professor Costa Mendes.\n",
            "\n",
            "Afirmações (edges) do termo assalto:\n",
            "\n",
            "Afirmações (edges) do termo balear (“shoot”, em inglês):\n",
            "\n",
            "Algumas dificuldades com a análise do exemplo, à luz da ConceptNet, foram:\n",
            "\n",
            "Ao longo deste capítulo exploramos três bases de conhecimento comuns na área de PLN: WordNet, FrameNet e ConceptNet. WordNet, com sua rica estrutura hierárquica, destaca-se por mapear relações semânticas entre conjuntos de sinônimos (synsets), fornecendo uma compreensão sobre sinônimos, antônimos, hiperônimos e muito mais. Esse recurso se tornou uma das ferramentas mais utilizadas em aplicações de PLN, desde a análise de sentimentos até a desambiguação de sentidos.\n",
            "\n",
            "FrameNet, por sua vez, adota uma abordagem baseada em frames para capturar significados em dados contextos ou situações, fazendo a ponte entre elementos lexicais e seus respectivos papéis semânticos. Através dessa base, podemos entender mais profundamente como as palavras interagem dentro de estruturas semânticas e pragmáticas mais amplas. Esta abordagem, focada nos papéis semânticos, permite uma análise mais rica do texto, tornando-a particularmente útil para tarefas de anotação de papéis semânticos e análise de discurso. Em contrapartida, ela não possui um critério claro de completamento, ou seja, não sabemos quando vamos ter (ou se já temos) todos os frames necessários.\n",
            "\n",
            "Por fim, a base ConceptNet destaca-se pelo seu caráter colaborativo e multidimensional. Integra conhecimentos de senso comum e conhecimento léxico-semântico de várias fontes e idiomas, oferecendo uma visão ampla das relações entre conceitos e contextos. Seu formato de rede semântica ajuda a capturar a complexidade e interconexão do conhecimento humano de uma maneira holística. ConceptNet tem sido usada em aplicações de extração de informação e reconhecimento de implicação textual. Em contrapartida, problemas de consistência da base parecem importantes. E tal como no caso de FrameNet, não temos um critério explícito de quando teremos uma cobertura suficiente.\n",
            "\n",
            "Em resumo, cada uma destas bases de conhecimento representa um recurso para o PLN com perspectivas únicas, mas qual delas se aplica melhor e em quais casos? Recursos léxicos-semânticos parecem não serem suficientes para expressar conhecimento de mundo. De outro lado, bases de conhecimento de senso comum são mais flexíveis e expressivas, porém menos formais. Acreditamos que uma abordagem híbrida, em que tais bases de conhecimento sejam usadas de forma combinada, é mais promissora para o PLN. Nas próximas versões deste capítulo introduziremos os parsers semânticos que, em conjunto com as bases de conhecimento, constituem poderoso framework para sistemas de entendimento de linguagem natural.\n",
            "\n",
            "OWL/↩︎\n",
            "\n",
            "Esse texto foi adaptado de notícia publicada em jornal digital, disponível em https://diariodonordeste.verdesmares.com.br/seguranca/mulher-e-baleada-em-saidinha-bancaria-no-montese-1.933137?page=10.↩︎\n",
            "\n",
            "O alinhamento entre wordnets refere-se ao processo de mapeamento ou ligação de synsets entre diferentes wordnets de línguas distintas. Por exemplo, o alinhamento entre PWN e OWN-PT seria o processo de identificar que o synset em inglês para “car” é equivalente ao synset em português para “carro”.↩︎\n",
            "\n",
            "parte do cap 17\n",
            "\n",
            "Métodos baseados em redes neurais, de forma geral, costumam empregar técnicas de aprendizado de representação (Bengio; Courville; Vincent, 2013) para aprender representações do conteúdo semântico dos fragmentos textuais e reduzem o problema de ER à classificação textual. É o caso de Socher et al. (2012), que propõem a MV-RNN, uma rede neural que constrói um espaço de representação baseado em matrizes e vetores com o objetivo de capturar a composicionalidade de sentido de sintagmas e sentenças e os aplica para ER. Similarmente, Zeng et al. (2014) e Wang et al. (2016) empregam redes neurais convolucionais para obter representações vetoriais de sentenças que serão empregadas no processo de classificação quanto à relação expressa pela mesma.\n",
            "\n",
            "Abordagens baseadas em identificação sequencial de entidades e relações possuem desvantagens observadas na literatura. Primeiramente, como a ER é guiada pelas entidades identificadas no processo de REN, a propagação de erros da primeira tarefa pode ter impacto considerável na performance dos sistemas desenvolvidos. Segundo, uma vez que o contexto determinado limita tanto as tarefas de REN, quanto as de ER, existe uma interdependência entre as tarefas. Assim, propostas visando realizar a extração de entidades e relações de forma conjunta começaram a surgir na literatura recente, ganhando certo interesse da comunidade.\n",
            "\n",
            "As abordagens empregadas para tal tarefa são diversificadas, incluindo desde métodos de aprendizado relacional a redes neurais\n",
            "\n",
            "Roth; Yih (2007) propõem a utilização de métodos de programação inteira ao problema, baseados na teoria estatística de aprendizado relacional. Os autores utilizam classificadores locais para a identificação de entidades e relações e um classificador global que combina as informações dos classificadores locais em uma predição que maximiza a qualidade da extração, codificada por meio de restrições em programação inteira. Também baseados em modelos estatísticos, Yu; Lam (2010) propõem o uso de modelos gráficos globais para identificação de um descritor de relação e uma segmentação do texto para identificação dos argumentos.\n",
            "\n",
            "Li; Ji (2014) e Miwa; Bansal (2016), por sua vez, reduzem a tarefa de ERE à classificação sequencial, utilizando redes neurais recorrentes bidirecionais sequenciais e estruturadas com base na estrutura superficial e na árvore de dependências sintáticas da entrada para identificação conjunta de entidades e relações.\n",
            "\n",
            "A Extração de Informação Aberta (EIA), também conhecida como Open Information Extraction, Open IE ou OIE em inglês, é a tarefa de extrair informações estruturadas de documentos sem necessitar da pré-definição do contexto da tarefa, i.e. das relações e tipos de entidade de interesse. A tarefa foi inicialmente proposta pelo trabalho de (Banko et al., 2007) e ganhou popularidade nas últimas décadas devido à sua aplicabilidade para processar e estruturar o conhecimento a partir de grandes volumes de dados disponíveis na Web, seguindo o paradigma da Web como um Corpus (WaC) (Meyer et al., 2003).\n",
            "\n",
            "A EIA surge visando generalizar a tarefa de Extração de Relações. A principal diferença entre as duas abordagens, porém, reside na dependência da ER de uma especificação prévia do domínio de aplicação, bem como das relações alvo a serem identificadas, que a EIA visa eliminar.\n",
            "\n",
            "Seguindo o trabalho original de Banko et al. (2007), que propôs o sistema TextRunner, vários métodos e sistemas para EIA foram propostos na literatura (Del Corro; Gemulla, 2013; Fader; Soderland; Etzioni, 2011; Xavier; Lima; Souza, 2015), mas, como observado por Glauber; Claro (2018), os principais avanços na área se concentraram principalmente no idioma inglês.\n",
            "\n",
            "A EIA para a língua portuguesa tem uma história bastante recente. A partir dos trabalhos de Souza; Claro (2014), Pereira; Pinheiro (2015) e de (Barbosa; Glauber; Claro, 2016), têm crescido o número de estudos sobre a tarefa assim como os resultados obtidos por esses estudos, com recentes desenvolvimentos de métodos (Oliveira; Claro; Souza, 2022; Sena; Claro, 2019, 2020; Sena; Glauber; Claro, 2017; Souza; Claro; Glauber, 2018), construção do corpus (Glauber et al., 2018) e avaliação dos sistemas disponíveis (Glauber; Claro; Oliveira, 2019; Glauber; Claro; Sena, 2019; Malenchini et al., 2019).\n",
            "\n",
            "Embora a área tenha visto um crescimento recente para o desenvolvimento de métodos para línguas como o inglês, principalmente com a aplicação de métodos supervisionados e redes neurais, esses avanços ainda não foram incorporados na literatura sobre EIA para a língua portuguesa. A razão para isso é principalmente a falta de recursos linguísticos disponíveis para orientar o desenvolvimento de pesquisas para a língua. Embora o foco no idioma inglês possa ser devido ao seu uso generalizado em todo o mundo, foi reconhecido pela comunidade científica que esse foco no inglês com suas características particulares pode introduzir algum viés na área (Bender, 2009).\n",
            "\n",
            "Assim, esta seção aborda EIA para a língua portuguesa, incluindo uma formalização e a evolução das abordagens da área.\n",
            "\n",
            "A tarefa de EIA pode ser formalmente definida sendo \\(X = \\langle x_{1}, x_{2}, \\cdots, x_{n}\\rangle\\) uma sentença composta de tokens \\(x_i\\). Um extrator EIA é uma função que mapeia \\(X\\) em um conjunto \\(Y = \\langle y_{1}, y_{2}, \\cdots, y_{j} \\rangle\\) como um conjunto de tuplas \\(y \\_i = \\langle rel_i, arg1_i, arg2_i, \\cdots, argn_i\\rangle\\), que descrevem as informações expressas na sentença X. Neste capítulo, consideramos que as tuplas estão sempre no formato \\(y = (arg_{1 }, rel, arg_{2})\\), onde \\(arg1\\) e \\(arg2\\) são sintagmas nominais, não necessariamente formados por tokens presentes em X, e \\(rel\\) é um descritor de um relacionamento entre \\(arg_{1}\\) e \\(arg_{2}\\). Não consideraremos extrações formadas por mais de dois argumentos neste capítulo.\n",
            "\n",
            "Os primeiros métodos de EIA empregavam padrões de inspiração linguística para extração, como ArgOE (Gamallo; Garcia, 2015), ou adaptação de métodos para a língua inglesa, como SGS (Souza; Claro; Glauber, 2018), InferReVerbPT Sena; Glauber; Claro (2017) e RePort Pereira; Pinheiro (2015). Os trabalhos são principalmente influenciados por métodos baseados no inglês da chamada segunda geração de EIA (Fader; Soderland; Etzioni, 2011).\n",
            "\n",
            "O primeiro sistema de EIA para o português de que temos conhecimento foi o DepOE (Gamallo; Garcia; Fernández-Lanza, 2012). Ele executa a extração aberta multilíngue de triplas (inglês, espanhol, português e galego) usando o analisador sintático de dependências baseado em regras DepPattern. No entanto, nenhuma avaliação ou resultados são relatados para a língua portuguesa. Os autores apresentam somente uma comparação dos seus resultados com Reverb na língua inglesa.\n",
            "\n",
            "Souza; Claro (2014) se propuseram a analisar o conjunto de características mais representativas da língua portuguesa para a identificação de extrações válidas no contexto de EIA, tal qual empregado na língua inglesa com o sistema ReVerb (Fader; Soderland; Etzioni, 2011).\n",
            "\n",
            "parte do cap 9\n",
            "\n",
            "Um assalto do tipo saidinha bancária, ocorrido na tarde desta terça-feira, terminou com uma mulher de 42 anos baleada pelos assaltantes. O roubo ocorreu na rua Professor Costa Mendes.\n",
            "\n",
            "Afirmações (edges) do termo assalto:\n",
            "\n",
            "Afirmações (edges) do termo balear (“shoot”, em inglês):\n",
            "\n",
            "Algumas dificuldades com a análise do exemplo, à luz da ConceptNet, foram:\n",
            "\n",
            "Ao longo deste capítulo exploramos três bases de conhecimento comuns na área de PLN: WordNet, FrameNet e ConceptNet. WordNet, com sua rica estrutura hierárquica, destaca-se por mapear relações semânticas entre conjuntos de sinônimos (synsets), fornecendo uma compreensão sobre sinônimos, antônimos, hiperônimos e muito mais. Esse recurso se tornou uma das ferramentas mais utilizadas em aplicações de PLN, desde a análise de sentimentos até a desambiguação de sentidos.\n",
            "\n",
            "FrameNet, por sua vez, adota uma abordagem baseada em frames para capturar significados em dados contextos ou situações, fazendo a ponte entre elementos lexicais e seus respectivos papéis semânticos. Através dessa base, podemos entender mais profundamente como as palavras interagem dentro de estruturas semânticas e pragmáticas mais amplas. Esta abordagem, focada nos papéis semânticos, permite uma análise mais rica do texto, tornando-a particularmente útil para tarefas de anotação de papéis semânticos e análise de discurso. Em contrapartida, ela não possui um critério claro de completamento, ou seja, não sabemos quando vamos ter (ou se já temos) todos os frames necessários.\n",
            "\n",
            "Por fim, a base ConceptNet destaca-se pelo seu caráter colaborativo e multidimensional. Integra conhecimentos de senso comum e conhecimento léxico-semântico de várias fontes e idiomas, oferecendo uma visão ampla das relações entre conceitos e contextos. Seu formato de rede semântica ajuda a capturar a complexidade e interconexão do conhecimento humano de uma maneira holística. ConceptNet tem sido usada em aplicações de extração de informação e reconhecimento de implicação textual. Em contrapartida, problemas de consistência da base parecem importantes. E tal como no caso de FrameNet, não temos um critério explícito de quando teremos uma cobertura suficiente.\n",
            "\n",
            "Em resumo, cada uma destas bases de conhecimento representa um recurso para o PLN com perspectivas únicas, mas qual delas se aplica melhor e em quais casos? Recursos léxicos-semânticos parecem não serem suficientes para expressar conhecimento de mundo. De outro lado, bases de conhecimento de senso comum são mais flexíveis e expressivas, porém menos formais. Acreditamos que uma abordagem híbrida, em que tais bases de conhecimento sejam usadas de forma combinada, é mais promissora para o PLN. Nas próximas versões deste capítulo introduziremos os parsers semânticos que, em conjunto com as bases de conhecimento, constituem poderoso framework para sistemas de entendimento de linguagem natural.\n",
            "\n",
            "OWL/↩︎\n",
            "\n",
            "Esse texto foi adaptado de notícia publicada em jornal digital, disponível em https://diariodonordeste.verdesmares.com.br/seguranca/mulher-e-baleada-em-saidinha-bancaria-no-montese-1.933137?page=10.↩︎\n",
            "\n",
            "O alinhamento entre wordnets refere-se ao processo de mapeamento ou ligação de synsets entre diferentes wordnets de línguas distintas. Por exemplo, o alinhamento entre PWN e OWN-PT seria o processo de identificar que o synset em inglês para “car” é equivalente ao synset em português para “carro”.↩︎\n",
            "\n",
            "parte do cap 17\n",
            "\n",
            "O sistema RePort (Pereira; Pinheiro, 2015), por outro lado, é uma adaptação do ReVerb para a língua portuguesa baseada em análise sintática rasa com regras sintáticas e lexicais. Os autores relatam que suas extrações apresentam grande similaridade com suas correlatas extraídas pelo ReVerb (dos textos traduzidos para o inglês).\n",
            "\n",
            "O RELP, proposto por Abreu; Vieira (2017), é um sistema aberto de extração de relações que extrai relações entre entidades nomeadas em um domínio de organização aplicando classificação sequencial com CRF (Conditional Random Fields). O sistema RelP extrai qualquer descritor de relação que expressa um relacionamento entre pares de entidades nomeadas (Organização, Pessoa ou Lugar), caracterizando-o como uma abordagem híbrida da REN com a EIA.\n",
            "\n",
            "O InferReVerbPT desenvolvido por Sena; Glauber; Claro (2017) baseia-se numa adaptação do sistema ReVerb para a língua portuguesa, expandindo-o com a extração de relacionamentos implícitos obtidos por inferência por propriedades de simetria e transitividade das relações com inferência transitiva e simétrica. Um classificador SVM foi empregado para realizar a inferência baseado nas propriedades semânticas do verbo central no descritor de relação.\n",
            "\n",
            "Souza; Claro; Glauber (2018) analisaram que a maior desvantagem dos estudos baseados em recursos linguísticos, como dados anotados, reside na escassez de tais recursos na maioria dos idiomas além do inglês. Assim, para mitigar esse problema, eles propõem um método de classificação de fatos baseado na similaridade de estruturas gramaticais (SGS). Sua abordagem modela estruturas morfosintáticas dos fatos (triplas descrevendo relacionamentos) para identificar padrões de semelhanças que podem ser usados para distinguir entre fatos válidos e inválidos. Eles aplicaram algoritmos de isomorfismo de grafos para detectar subgrafos descrevendo tais padrões.\n",
            "\n",
            "Um novo sistema de EIA baseado em análise de dependência foi proposto por Gamallo; Garcia (2015), chamado ArgOE. Tal sistema é multilíngue, baseado em heurísticas e utiliza a informação de dependência sintáticas do texto para analisar a estrutura de dependência do verbo, bem como um conjunto de regras para gerar os relacionamentos. A introdução de um Analisador de Dependência em sistemas de EIA focados inteiramente na língua portuguesa foi feita pelos autores Oliveira; Claro; Souza (2022). O DptOIE é baseado em análise de dependência e regras elaboradas manualmente. As sentenças são pré-processadas por meio de um tokenizador, um PoS Tagger e um analisador de dependências. Os autores propõem um acoplamento de três módulos para tratar casos particulares: conjunções coordenadas, orações subordinadas e aposto.\n",
            "\n",
            "Com a evolução dos métodos de EIA para a língua inglesa utilizando os modelos neurais, novas abordagens foram propostas também para a língua portuguesa.\n",
            "\n",
            "O primeiro trabalho que utilizou aprendizado supervisionado com rede neural profunda para o português foi o de Ro; Lee; Kang (2020) que descreve o sistema Multi2OIE. Os autores utilizaram o modelo de linguagem BERT multilíngue (Devlin et al., 2019) para obter representações vetoriais das palavras e reduzem a tarefa de EIA à classificação sequencial, identificado os fragmentos do texto que determinam os argumentos (\\(arg_1, arg_2\\)) e o descritor de relação (\\(rel\\)). Seu sistema foi capaz de produzir extrações para vários idiomas (inglês, português e espanhol), treinados, entretanto, sobre dados traduzidos do inglês.\n",
            "\n",
            "Stanovsky et al. (2018) propuseram uma abordagem de EIA para a língua inglesa baseada em triplas. Os mesmos fazem uso de uma classificação sequencial cuja limitação define uma tripla extraída para cada sentença. Este método utiliza uma arquitetura de Redes Neurais Recursivas (RNN) para realizar EIA. A EIA é formulada como uma tarefa de rotulagem de sequências, utilizando estratégias semelhantes às que foram aplicadas anteriormente a tarefas como o Reconhecimento de Entidades Nomeadas. Já os autores em Cui; Wei; Zhou (2018) e Zhang; Duh; Van Durme (2017) propõem modelar o problema da EIA como um problema de aprendizado sequência a sequência (seq2seq). Eles definem uma estrutura encoder-decoder para aprender argumentos e tuplas de relação inicializadas a partir de um sistema de EIA.\n",
            "\n",
            "Seguindo o trabalho de (Stanovsky et al., 2018), em 2022, Cabral; Souza; Claro (2022) propuseram PortNOIE, uma arquitetura neural para EIA em português que combina representações contextuais de palavras com codificadores neurais para extrair relacionamentos baseado em classificação sequencial iterativa. Diferente de outros métodos de classificação sequencial para EIA, os autores focam na extração de múltiplas triplas de uma mesma sentença.\n",
            "\n",
            "A avaliação sistemática de sistemas de EI foi estabelecida primeiramente nas conferências MUC, em particular na sua segunda edição, com o estabelecimento de gabaritos-padrão que deveriam ser utilizados por todos os sistemas participantes e a adoção de métricas de qualidade, baseadas naquelas usadas na área de recuperação de informação, que foram abordadas no Capítulo 16. Para avaliar a tarefa de extração de relações, a MUC-2 estabeleceu como métricas de qualidade do sistema as medidas de precisão e cobertura, também denominada de Recall ou Revocação.\n",
            "\n",
            "A precisão de um sistema reflete a qualidade de suas extrações, i.e., quantas das extrações realizadas estão corretas, dado um corpus de teste. A medida de precisão pode ser calculada como:\n",
            "\n",
            "P = \\frac{\\#(\\mbox{relacionamentos corretamente extraídos})}{\\#(\\mbox{relacionamentos extraídos pelo sistema})}\n",
            "\n",
            "A cobertura também conhecida como revocação, reflete quão abrangente um sistema é em suas extrações, i.e., quantas das extrações a serem realizadas em um corpus de teste, o sistema é capaz de realizar. A medida de cobertura pode ser calculada como:\n",
            "\n",
            "R = \\frac{\\#(\\mbox{relacionamentos extraídos})}{\\#(\\mbox{relacionamentos no \\textit{corpus}})}\n",
            "\n",
            "Enquanto a MUC-3 adicionou duas novas métricas de avaliação, a saber sobre-geração (overgeneration) e sub-geração (fallout), tais métricas receberam pouco interesse na literatura. De fato, Lehnert; Sundheim (1991) argumentam que tais métricas foram pouco informativas ou difíceis de calcular para a tarefa de EI e, portanto, abandonadas. Foi também empregado nessa conferência um sistema automático de avaliação disponibilizado às equipes participantes que permitiu uma maior compreensão do modelo de avaliação e, como discutem Lehnert; Sundheim (1991), um avanço qualitativo nos sistemas gerados.\n",
            "\n",
            "parte do cap 9\n",
            "\n",
            "Um assalto do tipo saidinha bancária, ocorrido na tarde desta terça-feira, terminou com uma mulher de 42 anos baleada pelos assaltantes. O roubo ocorreu na rua Professor Costa Mendes.\n",
            "\n",
            "Afirmações (edges) do termo assalto:\n",
            "\n",
            "Afirmações (edges) do termo balear (“shoot”, em inglês):\n",
            "\n",
            "Algumas dificuldades com a análise do exemplo, à luz da ConceptNet, foram:\n",
            "\n",
            "Ao longo deste capítulo exploramos três bases de conhecimento comuns na área de PLN: WordNet, FrameNet e ConceptNet. WordNet, com sua rica estrutura hierárquica, destaca-se por mapear relações semânticas entre conjuntos de sinônimos (synsets), fornecendo uma compreensão sobre sinônimos, antônimos, hiperônimos e muito mais. Esse recurso se tornou uma das ferramentas mais utilizadas em aplicações de PLN, desde a análise de sentimentos até a desambiguação de sentidos.\n",
            "\n",
            "FrameNet, por sua vez, adota uma abordagem baseada em frames para capturar significados em dados contextos ou situações, fazendo a ponte entre elementos lexicais e seus respectivos papéis semânticos. Através dessa base, podemos entender mais profundamente como as palavras interagem dentro de estruturas semânticas e pragmáticas mais amplas. Esta abordagem, focada nos papéis semânticos, permite uma análise mais rica do texto, tornando-a particularmente útil para tarefas de anotação de papéis semânticos e análise de discurso. Em contrapartida, ela não possui um critério claro de completamento, ou seja, não sabemos quando vamos ter (ou se já temos) todos os frames necessários.\n",
            "\n",
            "Por fim, a base ConceptNet destaca-se pelo seu caráter colaborativo e multidimensional. Integra conhecimentos de senso comum e conhecimento léxico-semântico de várias fontes e idiomas, oferecendo uma visão ampla das relações entre conceitos e contextos. Seu formato de rede semântica ajuda a capturar a complexidade e interconexão do conhecimento humano de uma maneira holística. ConceptNet tem sido usada em aplicações de extração de informação e reconhecimento de implicação textual. Em contrapartida, problemas de consistência da base parecem importantes. E tal como no caso de FrameNet, não temos um critério explícito de quando teremos uma cobertura suficiente.\n",
            "\n",
            "Em resumo, cada uma destas bases de conhecimento representa um recurso para o PLN com perspectivas únicas, mas qual delas se aplica melhor e em quais casos? Recursos léxicos-semânticos parecem não serem suficientes para expressar conhecimento de mundo. De outro lado, bases de conhecimento de senso comum são mais flexíveis e expressivas, porém menos formais. Acreditamos que uma abordagem híbrida, em que tais bases de conhecimento sejam usadas de forma combinada, é mais promissora para o PLN. Nas próximas versões deste capítulo introduziremos os parsers semânticos que, em conjunto com as bases de conhecimento, constituem poderoso framework para sistemas de entendimento de linguagem natural.\n",
            "\n",
            "OWL/↩︎\n",
            "\n",
            "Esse texto foi adaptado de notícia publicada em jornal digital, disponível em https://diariodonordeste.verdesmares.com.br/seguranca/mulher-e-baleada-em-saidinha-bancaria-no-montese-1.933137?page=10.↩︎\n",
            "\n",
            "O alinhamento entre wordnets refere-se ao processo de mapeamento ou ligação de synsets entre diferentes wordnets de línguas distintas. Por exemplo, o alinhamento entre PWN e OWN-PT seria o processo de identificar que o synset em inglês para “car” é equivalente ao synset em português para “carro”.↩︎\n",
            "\n",
            "parte do cap 17\n",
            "\n",
            "Além das medidas de precisão e cobertura, assim como em tarefas de classificação de texto e recuperação de informação, utilizamos a média harmônica entre essas medidas, chamada medida F1, a fim de condensar a informação contida nas duas. A medida F1 pode ser calculada como:\n",
            "\n",
            "F1 = \\frac{2*P*R}{P+R}\n",
            "\n",
            "A avaliação da tarefa de REN segue padrões semelhantes aos aplicados à tarefa de ER. De fato, desde a MUC-6 (Grishman; Sundheim, 1996), as medidas de precisão, cobertura e F1 tem sido usada consistentemente como métricas de avaliação da tarefa de REN em diversos esforços de avaliação, como a CoNNL (Sang; De Meulder, 2003), para a língua inglesa, e das duas edições do HAREM (Gonçalo Oliveira et al., 2008; Santos; Cardoso; Seco, 2007), com excessão à ACE (Doddington et al., 2004) que apresenta uma combinação da tarefa de REN com reconhecimento de co-referência entre entidades e utiliza um sistema de pontuação próprio.\n",
            "\n",
            "A avaliação de sistemas de EIA, por sua vez, possui algumas peculiaridades que precisam ser discutidas. Uma vez que a tarefa é postulada por Banko et al. (2007) como a extração de todas as relações identificadas em um dado fragmento textual, sem limitação de domínio de interesse, tal tarefa impõe imensa dificuldade aos esforços de avaliação.\n",
            "\n",
            "De fato, Glauber et al. (2018) relatam um esforço de anotação de dados para a tarefa em língua portuguesa em que foram identificados por anotadores humanos mais de 400 relacionamentos em um corpus de 25 sentenças retiradas de textos jornalísticos e de enciclopédia. Assim, a avaliação de EIA deu-se, em grande parte de seu desenvolvimento e maturação, em conjuntos de dados não anotados, recorrendo a avaliações qualitativas das saídas dos sistemas e comparação direta por humanos das extrações obtidas.\n",
            "\n",
            "Nesses esforços de avaliação, a precisão do sistema pode ser mensurada a partir da avaliação humana das saídas. Não é possível, entretanto, avaliar medidas como cobertura e F1, dada a inexistência de uma referência do conjunto total de relacionamentos a serem identificados. Assim, os autores da área propuseram diferentes métricas a fim de estimar tais valores, como a métrica rendimento (yield) (Fader; Soderland; Etzioni, 2011; Schmitz et al., 2012).\n",
            "\n",
            "A métrica de rendimento consiste no núemro de extrações válidas, i.e. corretas, de um dado sistema. Como calcular tal medida é, na maioria dos casos, impraticável dada a grande quantidade de extrações realizadas pelos sistemas, ela pode ser estimada a partir da precisão do sistema calculada sobre uma amostra aleatória das extrações realizadas (\\(P'\\)). Assim, podemos estimar o rendimento como:\n",
            "\n",
            "Y = P'\\cdot \\#(\\mbox{extrações realizadas})\n",
            "\n",
            "Foi também explorada a estratégia de criação (semi-)automática de conjuntos de dados usando vários sistemas (Del Corro; Gemulla, 2013), estratégias de supervisão fraca (Smirnova; Cudré-Mauroux, 2018), ou a geração de corpora para a tarefa a partir da transformação de anotações de tarefas próximas, como identificação de papéis temáticos (Semantic Role Labeling) por (Stanovsky et al., 2018). Corpora gerados de forma semi-automática vêm ganhando atenção na literatura recente, particularmente para a língua inglesa, devido a necessidade de dados anotados para se utilizar técnicas de aprendizado de máquina e redes neurais em EIA. Corpora como o OIE2016 (Stanovsky et al., 2018), Wire57 (Léchelle; Gotti; Langlais, 2018) e CARB (Bhardwaj; Aggarwal; Mausam, 2019) vêm se tornando corpora de referência em língua inglesa para o problema, apesar dos problemas existentes na construção de tais recursos – a não exaustividade das relações anotadas.\n",
            "\n",
            "Para a língua portuguesa, foram propostas algumas iniciativas para avaliar os sistemas da OIE. Uma avaliação conjunta foi promovida durante o Fórum Ibérico de Avaliação de Línguas (IberLEF) em 2019 (Collovini et al., 2019). A avaliação foi feita usando o corpus proposto por Glauber et al. (2018), que é composto por 442 relacionamentos extraídos de 25 frases de fontes como a seção em português da Wikipédia, o corpus CETENFolha, resenhas de filmes do portal Adoro Cinema2 e o corpus Europarl. Apesar desta tarefa ter contemplado quatro cenários de avaliação, a avaliação geral dos sistemas permaneceu consistente nos diferentes cenários, indicando robustez nos resultados da avaliação. No geral, os sistemas DPTOIE (Oliveira; Claro; Souza, 2022) e Linguakit (Gamallo; Garcia, 2015) tiveram o melhor desempenho, com o Linguakit2 dominando as avaliações de correspondência exata e o DPTOIE as avaliações de correspondências parciais (Collovini et al., 2019).\n",
            "\n",
            "Outra abordagem de avaliação foi idealizada por (Malenchini et al., 2019). Seu foco foi a avaliação extrínseca dos sistemas de EIA através de sua contribuição na tarefa de respostas automáticas a perguntas. Os autores apresentaram um conjunto de dados de referência (benchmark) para avaliação extrínseca de sistemas de EIA em textos de língua portuguesa. Os sistemas que alcançaram os melhores valores na avaliação realizada pelos autores foram os sistemas ArgOE (Gamallo; Garcia, 2015), DependentIE (Glauber; Claro; Oliveira, 2019) e DptOIE (Oliveira; Claro; Souza, 2022).\n",
            "\n",
            "Este capítulo descreveu uma visão geral da área de Extração de Informação, apresentando a Extração de Informação Tradicional e a Extração de Informação Aberta. Transversalmente, apresentamos as formalizações necessárias e os conceitos fundamentais para a compreensão da EIA, assim como a avaliação da área e as heranças de outras áreas afins, tais como RI.\n",
            "\n",
            "Nessa primeira versão, este capítulo descreveu de maneira bem sucinta as abordagens propostas para EI e EIA durante seu desenvolvimento histórico e as abordagens atuais da literatura, como as utilizando modelos de linguagens. Especificamente, a utilização da arquitetura Transformers, descritas no Capítulo 15 para as tarefas de EI e EIA tem sido bastante difundida para a língua inglesa e tem atuado em diversas áreas da PLN.\n",
            "\n",
            "Agradecemos as colaborações dos autores deste Capítulo e suas indicações, assim como agradecemos a Adriana Pagano e Aline Macohin pela revisão e comentários.\n",
            "\n",
            "Em nossa terminologia, por um relacionamento.↩︎\n",
            "\n",
            "parte do cap 9\n",
            "\n",
            "A descrição completa do frame está disponível em https://framenet.icsi.berkeley.edu/frameIndex.↩︎\n",
            "\n",
            "Uma palavra polissêmica é uma palavra que possui vários significados ou sentidos relacionados entre si, dependendo do contexto em que é usada. Por exemplo, a palavra “banco” pode se referir a uma instituição financeira, um local para sentar, ou a uma elevação de areia no mar.↩︎\n",
            "\n",
            "Mais detalhes sobre os números atuais da FrameNet podem ser acessados em https://framenet.icsi.berkeley.edu/current_status.↩︎\n",
            "\n",
            "A versão atual do SemLink é a versão 2.0 e pode ser acessada pelo GitHub https://github.com/cu-clear/semlink.↩︎\n",
            "\n",
            "Ver descrição completa em https://webtool.framenetbr.ufjf.br/index.php/webtool/report/frame/main↩︎\n",
            "\n",
            "Sua última versão é a ConceptNet 5.8 e a documentação completa está disponível em https://github.com/commonsense/conceptnet5/wiki↩︎\n",
            "\n",
            "Disponível em https://pt.wiktionary.org/wiki/Wikcion%C3%A1rio:P%C3%A1gina_principal↩︎\n",
            "\n",
            "Edges↩︎\n",
            "\n",
            "A lista completa das relações expressas na ConceptNet está disponível em https://github.com/commonsense/conceptnet5/wiki/Relations↩︎\n",
            "\n",
            "Pode ser nulo porque nem todas as afirmações foram derivadas de entrada em linguagem natural↩︎\n",
            "\n",
            "As bases de afirmações da ConceptNet para todas as linguagens naturais suportadas pode ser consultada em https://github.com/commonsense/conceptnet5/wiki/Languages↩︎\n",
            "\n",
            "parte do cap 17\n",
            "\n",
            "Daniela Barreiro Claro \n",
            "\n",
            "Joaquim Santos \n",
            "\n",
            "Marlo Souza \n",
            "\n",
            "Renata Vieira \n",
            "\n",
            "Vládia Pinheiro \n",
            "\n",
            "PDF\n",
            "\n",
            "A Extração de Informação (EI) é desenvolvida com o objetivo de se obter informação estruturada de dados não-estruturados (Jurafsky; Martin, 2023; Konstantinova, 2014).\n",
            "\n",
            "Os primeiros trabalhos a debruçarem-se sobre o problema remontam à década de 1970, com a aplicação de gramáticas formais e parsers sintáticos para a estruturação de informação em domínios como prontuários médicos (Sager, 1978; Sager; Friedman; Lyman, 1987) e textos jornalísticos (DeJong, 1979). A comunidade científica demonstrou grande interesse pela área nas décadas posteriores devido à sua utilidade prática, seu foco no processamento de dados reais, suas tarefas bem-definidas e a facilidade de mensurar a qualidade dos resultados em comparação com o desempenho humano na mesma tarefa (Cowie; Lehnert, 1996).\n",
            "\n",
            "Para autores como Eisenstein (2019) e Jurafsky; Martin (2023), a EI é normalmente dividida em diversas tarefas de interesse, com foco no tipo de informação a ser extraída do texto. Entre as mais comumente citadas na literatura estão o Reconhecimento de Entidades Nomeadas (REN), a Extração de Relações (ER) e a Extração de Eventos (EE).\n",
            "\n",
            "O Reconhecimento de Entidades Nomeadas (REN) consiste em identificar e classificar entidades mencionadas em textos através de designadores rígidos como nomes próprios, expressões temporais e espécies biológicas (Nadeau, 2007). Esse é considerado por alguns como um primeiro passo na análise semântica de um texto (Santos; Cardoso, 2007a), pois permite identificar as entidades às quais se faz referência nele.\n",
            "\n",
            "A Extração de Relações (ER), também chamada de extração de informação tradicional ou somente extração de informação, por sua vez, diz respeito à identificação de relacionamentos semânticos entre duas ou mais entidades, ou seja, identificar “quem fez o que para quem e quando”. Ananiadou; Mcnaught (2005) a definem como o processo de extrair fatos (em nossa terminologia, relacionamentos) a partir de uma fonte textual e representá-los a partir de um gabarito (em inglês, template). As relações são elementos essenciais para o entendimento da informação relatada no texto e sua identificação é passo essencial para a estruturação da mesma. Assim, identificar relações entre entidades é tarefa essencial para construção de bases de conhecimento e de grande utilidade na construção de soluções para a resposta automática a perguntas (em inglês, query answering), sumarização, recuperação de informação e mais (Nasar; Jaffry; Malik, 2021).\n",
            "\n",
            "A extração de eventos consiste na tarefa de identificação de uma menção a um evento em uma sentença e, se existirem, extração de outras informações sobre o evento. Um evento pode, por sua vez, ser entendido como uma ocorrência específica envolvendo participantes (Consortium, 2005), i.e., algo que acontece e que pode ser descrito como uma mudança de estado da qual participam entidades como agentes. Devido a intrínseca natureza temporal dos eventos, tal problema possui uma natureza mais complexa e costuma possuir tratamento específico.\n",
            "\n",
            "Assim, nesse capítulo, iniciaremos com um pouco de história da Extração de Informação (EI) e sua evolução para Extração de Informação Aberta, e destacaremos as tarefas de Reconhecimeno de Entidades Nomeadas (REN) e Extração de Relação (ER).\n",
            "\n",
            "Os primeiros trabalhos que abordaram o problema de EI dos quais temos conhecimento surgiram no final da década de 1970. Esses primeiros trabalhos da década de 1970 e 1980 tinham como modelo geral a aplicação de regras para a identificação de informações especificadas em um gabarito. Tais sistemas empregavam analisadores sintáticos (parsers) e regras definidas especificamente para o domínio e gênero textual estudado.\n",
            "\n",
            "Entre esses primeiros trabalhos, estão aqueles de Sager (1978), Sager; Friedman; Lyman (1987), de DeJong (1979) e de Cowie (1983). Sager et al. exploraram como identificar informações do estado de saúde de pacientes através dos textos de prontuários médicos. DeJong (1979), por sua vez, descrevem o sistema FRUMP que, a partir de um parser e regras de análise conceitual baseadas em uma arquitetura cognitiva proposta pelos autores e no conceito de dependência conceitual de Schank et al. (1973), processavam textos de notícias e realizavam tarefas como sumarização e identificação de papéis semânticos associados aos constituintes da sentença. Cowie (1983), por fim, descreve um sistema que emprega regras simples de segmentação e análise sintática rasa para identificar propriedades de plantas a partir de textos descritivos no campo da botânica. Diferente dos métodos anteriores, o trabalho dos autores se baseia em grande parte no estudo de padrões de descrição das informações a serem identificadas, em detrimento do emprego de parsers robustos da língua.\n",
            "\n",
            "A década de 1990 traz um grande interesse na área de EI com a implementação das conferências MUC (do inglês, Message Understanding Conference, ou Conferência de Compreensão de Mensagem), promovidas pela Agência de Projetos de Pesquisa Avançada de Defesa (DARPA, do inglês Defense Advanced Research Projects Agency). As conferências MUC, realizadas e financiadas pelo exército americano, representaram um esforço em avançar a tecnologia de EI e consistiam de tarefas de avaliação conjunta de métodos desenvolvidos por pesquisadores para problemas propostos pelos organizadores. As sete conferências realizadas de 1987 a 1997, foram cruciais para definir aspectos centrais da área, como estruturar a tarefa de ER, definindo suas métricas de avaliação, e propor a tarefa de REN (Grishman; Sundheim, 1996).\n",
            "\n",
            "parte do cap 9\n",
            "\n",
            "A descrição completa do frame está disponível em https://framenet.icsi.berkeley.edu/frameIndex.↩︎\n",
            "\n",
            "Uma palavra polissêmica é uma palavra que possui vários significados ou sentidos relacionados entre si, dependendo do contexto em que é usada. Por exemplo, a palavra “banco” pode se referir a uma instituição financeira, um local para sentar, ou a uma elevação de areia no mar.↩︎\n",
            "\n",
            "Mais detalhes sobre os números atuais da FrameNet podem ser acessados em https://framenet.icsi.berkeley.edu/current_status.↩︎\n",
            "\n",
            "A versão atual do SemLink é a versão 2.0 e pode ser acessada pelo GitHub https://github.com/cu-clear/semlink.↩︎\n",
            "\n",
            "Ver descrição completa em https://webtool.framenetbr.ufjf.br/index.php/webtool/report/frame/main↩︎\n",
            "\n",
            "Sua última versão é a ConceptNet 5.8 e a documentação completa está disponível em https://github.com/commonsense/conceptnet5/wiki↩︎\n",
            "\n",
            "Disponível em https://pt.wiktionary.org/wiki/Wikcion%C3%A1rio:P%C3%A1gina_principal↩︎\n",
            "\n",
            "Edges↩︎\n",
            "\n",
            "A lista completa das relações expressas na ConceptNet está disponível em https://github.com/commonsense/conceptnet5/wiki/Relations↩︎\n",
            "\n",
            "Pode ser nulo porque nem todas as afirmações foram derivadas de entrada em linguagem natural↩︎\n",
            "\n",
            "As bases de afirmações da ConceptNet para todas as linguagens naturais suportadas pode ser consultada em https://github.com/commonsense/conceptnet5/wiki/Languages↩︎\n",
            "\n",
            "parte do cap 17\n",
            "\n",
            "A partir da MUC-3, em 1991, a conferência passa a ter foco no processamento de textos jornalísticos em detrimento dos relatórios militares utilizados anteriormente (DARPA, 1991). Com a disponibilidade de dados e o incentivo no desenvolvimento de soluções para a tarefa, vemos na década de 1990 o surgimento das primeiras aplicações comerciais de EI, como o JASPER (Andersen et al., 1992)., construído para a agência de notícias Reuters.\n",
            "\n",
            "A MUC-6, ocorrida em 1995, introduz a tarefa de REN com o intuito de ser uma tarefa de uso prático, independente de domínio e que poderia ser realizada automaticamente em um futuro próximo (Grishman; Sundheim, 1996). Enquanto os trabalhos em REN se avolumaram a partir de sua proposição na MUC-6, trabalhos anteriores como Rau (1991) e Wolinski; Vichot; Dillet (1995) já se debruçavam sobre o problema de identificação e classificação de nomes próprios. Desde então, o interesse na tarefa cresceu significativamente e outras conferências de avaliação conjunta têm sido dedicadas a essa tarefa, como a Automatic Content Extraction (ACE) e a conferência Avaliação de Sistemas de Reconhecimento de Entidades Mencionadas (HAREM), dedicada exclusivamente à língua portuguesa, com sua primeira edição em 2005 (Santos; Cardoso, 2007a).\n",
            "\n",
            "Por outro lado, houve um crescimento de abordagens baseadas em dados nesta década, a partir da análise de corpora. Tais esforços são impulsionados pelos resultados positivos na área, como o trabalho de Hearst (1992). Logo, métodos baseados em dados passaram também a explorar o emprego de análise estatística e aprendizado de máquina na construção de padrões para a extração de relações (Riloff et al., 1993; Riloff; Jones; et al., 1999; Roark; Charniak, 2000; Soderland et al., 1995)\n",
            "\n",
            "Não foi somente na extração de padrões que métodos de aprendizado de máquina, em particular aprendizado supervisionado, foram aplicados. A década de 2000 viu a proliferação de métodos supervisionados aplicados à ER (Culotta; McCallum; Betz, 2006; Kambhatla, 2004; Zelenko; Aone; Richardella, 2003; Zhao; Grishman, 2005) e ao REN (Asahara; Matsumoto, 2003; McCallum; Li, 2003; Sekine, 1998).\n",
            "\n",
            "Devido à dificuldade de construção de dados para treinamento e padrões para extração, além da pouca adaptabilidade dos sistemas construídos para outros escopos e domínios, nos anos 2000, sistemas baseados em métodos de aprendizado semi-supervisionado, como o DIPRE (Brin, 1998) e Snowball (Agichtein; Gravano, 2000) começaram a aparecer, juntamente com os estudos sobre expansão automatizada de anotações (bootstrapping) (Riloff; Jones; et al., 1999). Também para entidades nomeadas, estudos investigaram como utilizar recursos da Web (Etzioni et al., 2005; Nadeau, 2007) ou corpora (Cucchiarelli; Velardi, 2001) para aprender entidades com pouco ou nenhum esforço de anotação.\n",
            "\n",
            "Buscando superar as dificuldades da limitação de escopo, i.e. das relações-alvo a serem extraídas e categorias de entidades a serem identificadas, ainda restritas à definição de padrões desde a criação dessas tarefas, Banko et al. (2007) propõe a tarefa de extração de informação aberta (EIA), também conhecida como Open Information Extraction, OpenIE ou OIE, a qual busca extrair todas as relações possíveis expressas em um texto, sem necessidade de pré-definição de relações e entidades.\n",
            "\n",
            "Devido ao recente sucesso da aplicação de métodos baseados em redes neurais, em particular deep learning e grandes modelos de linguagem, às tarefas de Processamento de Linguagem Natural, uma tendência atual da área se delineou como o estudo de arquiteturas neurais para os problemas de EI e a geração de grandes conjuntos de dados por supervisão fraca. Surveys recentes, como (Cui; Wei; Zhou, 2018; Konstantinova, 2014; Nasar; Jaffry; Malik, 2021), nos mostram a evolução da área em direção à aplicação de métodos neurais. Na vertente de geração de dados, vemos o emprego da Wikipédia e Freebase como fontes mais usadas para obter anotações de entidades e relações em textos (Nguyen; Theobald; Weikum, 2016; Smirnova; Cudré-Mauroux, 2018; Takamatsu; Sato; Nakagawa, 2012).\n",
            "\n",
            "Porém, toda a tarefa de EI necessita de uma concordância entre as definições de Entidade e Relação. Neste sentido, a próxima seção discute a conceituação de relação adotada neste capítulo, assim como o conceito de entidade.\n",
            "\n",
            "A natureza das relações estudadas na área de Extração de Informação e os critérios para reconhecer sua ocorrência em um texto têm recebido pouca atenção na literatura. Este é um passo importante para estabelecer metodologias adequadas para avaliar os sistemas, bem como para criar conjuntos de dados que possam apoiar a criação de sistemas futuros.\n",
            "\n",
            "Enquanto as noções de Relação e Entidade são de grande importância e já bem estudadas nas áreas de Computação, Linguística, Ciência da Informação e Filosofia da Linguagem, esses conceitos não são empregados de forma consistente entre as áreas, ou mesmo entre suas subáreas.\n",
            "\n",
            "Para Chen (1976), uma entidade é um objeto que pode ser concreto, tal como pessoa, livro, casa ou ainda abstrato, tal como um emprego, um sentimento, uma disciplina. As entidades podem estabelecer relações entre si. Duas ou mais entidades são vinculadas, ou seja conectadas por uma relação1.\n",
            "\n",
            "Tradicionalmente em reconhecimento de entidades nomeadas, as entidades consideradas são aquelas referenciadas por um nome próprio, acrescidas das referências temporais e valores que são expressões numéricas. Essas expressões, portanto, geralmente não constituem uma entrada em uma base lexical. Porém a tarefa se expandiu para domínios especializados, onde as entidades de interesse são mais conceituais. No domínio bio-médico por exemplo, podemos ter como exemplo de entidades de interesse, sintomas e tratamento que não são referenciadas por nomes próprios.\n",
            "\n",
            "Os conceitos de relação e relacionamento são noções fundamentais que vêm sendo estudadas em áreas como Ciência da Computação, Linguística e Filosofia.\n",
            "\n",
            "No campo de bancos de dados e modelagem conceitual, Chen (1976) define um relacionamento, no contexto da modelagem de Entidade-Relacionamento, como uma associação entre entidades. Guarino; Guizzardi (2015), por sua vez, estudando a natureza ontológica dos relacionamentos com base na semântica de veridadores (truthmaker semantics) (Fine, 2017), postulam relacionamentos como entidades que atuam como veridadores (thruthmakers) de alguma proposição relacionando duas ou mais entidades, ou seja, uma relação mantida entre essas entidades. Um veridador é um elemento cuja existência torna verdadeira uma proposição particular. Por exemplo, considerando a sentença (1) “a é uma maçã”, a existência de um objeto denotado pelo nome a que por acaso é uma maçã é uma condição suficiente para a verdade da frase (1). Como tal, dizemos que esse objeto é o veridador de (1). Tal definição nos permite adotar critérios ontológicos para validar a existência de relacionamentos a partir da informação relatada em um texto e, por isso, adotaremos tal definição de relacionamento neste capítulo.\n",
            "\n",
            "O conceito de relações é muito menos consistente na literatura. Ainda na área de modelagem conceitual, Guarino; Guizzardi (2015) definem as relações como proposições para as quais os relacionamentos são veridadores e, portanto, possuem conteúdo proposicional. Assim, podemos entender uma relação como um tipo para entidades como relacionamentos. Ou seja, relações são universais ontológicos que descrevem a natureza dos relacionamentos.\n",
            "\n",
            "Xavier; Lima; Souza (2015), no entanto, argumentam que a noção de relacionamento adotada na área de Extração de Informação é mais geral do que isso, não se limitando àquelas entre objetos e propriedades, mas também àquelas que descrevem ou implicam propriedades de classes gerais como descrito pela sentença (2) “Filósofos são autores de Livros”. Assim, para o contexto de EI consideramos relações como tipos de relacionamentos de primeira ou segunda ordem. Isso significa que uma relação é um tipo de relacionamento que existe entre objetos, suas propriedades e classes de objetos ou suas propriedades.\n",
            "\n",
            "parte do cap 9\n",
            "\n",
            "A descrição completa do frame está disponível em https://framenet.icsi.berkeley.edu/frameIndex.↩︎\n",
            "\n",
            "Uma palavra polissêmica é uma palavra que possui vários significados ou sentidos relacionados entre si, dependendo do contexto em que é usada. Por exemplo, a palavra “banco” pode se referir a uma instituição financeira, um local para sentar, ou a uma elevação de areia no mar.↩︎\n",
            "\n",
            "Mais detalhes sobre os números atuais da FrameNet podem ser acessados em https://framenet.icsi.berkeley.edu/current_status.↩︎\n",
            "\n",
            "A versão atual do SemLink é a versão 2.0 e pode ser acessada pelo GitHub https://github.com/cu-clear/semlink.↩︎\n",
            "\n",
            "Ver descrição completa em https://webtool.framenetbr.ufjf.br/index.php/webtool/report/frame/main↩︎\n",
            "\n",
            "Sua última versão é a ConceptNet 5.8 e a documentação completa está disponível em https://github.com/commonsense/conceptnet5/wiki↩︎\n",
            "\n",
            "Disponível em https://pt.wiktionary.org/wiki/Wikcion%C3%A1rio:P%C3%A1gina_principal↩︎\n",
            "\n",
            "Edges↩︎\n",
            "\n",
            "A lista completa das relações expressas na ConceptNet está disponível em https://github.com/commonsense/conceptnet5/wiki/Relations↩︎\n",
            "\n",
            "Pode ser nulo porque nem todas as afirmações foram derivadas de entrada em linguagem natural↩︎\n",
            "\n",
            "As bases de afirmações da ConceptNet para todas as linguagens naturais suportadas pode ser consultada em https://github.com/commonsense/conceptnet5/wiki/Languages↩︎\n",
            "\n",
            "parte do cap 17\n",
            "\n",
            "Enquanto os métodos tradicionais de Extração de Informação dependem de um conjunto pré-existente de relações semânticas bem definidas que são relevantes para um domínio específico, a noção de “relação” e “entidade” na literatura da área mais recente, tais como a Extração de Informação Aberta, requer mais aprofundamento por demandar um significado diferente, principalmente com diferente visões de autores. Esta indeterminação terminológica pode trazer problemas para comparar os resultados dos métodos propostos ou para reutilizar os conjuntos de dados criados na área.\n",
            "\n",
            "As seções seguintes exploram essas duas áreas: Extração de Informação e Extração de Informação Aberta.\n",
            "\n",
            "A Extração de Informação é caracterizada por obter informação estruturada a partir de textos, sendo entidades ou fatos, i.e. relacionamentos entre entidades, de tipos previamente definidos, conforme exemplo na Quadro 17.1. Métodos com limitação de escopo possuem como uma de suas principais desvantagens a necessidade de intervenção humana para especificar novos fatos a serem extraídos. Esta limitação impede que sistemas de Extração de Informação, doravante denominados de EI tradicional extraiam fatos fora do escopo pré-definido.\n",
            "\n",
            "Quadro 17.1 Exemplos de relações específicas na EI tradicional\n",
            "\n",
            "Fonte: (Souza; Claro, 2014)\n",
            "\n",
            "O Reconhecimento de Entidades Nomeadas (REN) consiste na tarefa de identificar e classificar expressões linguísticas, denominadas entidades nomeadas (EN), que referenciam entidades específicas num domínio de discurso, como nomes próprios, expressões temporais e espécies biológicas (Mota; Santos; Ranchhod, 2007; Nadeau, 2007). De uma forma geral, o REN pode ser dividido em duas etapas: a identificação (ou delimitação) da expressão, na qual as palavras que formam a EN são selecionadas; a classificação, em que é atribuída uma categoria semântica à EN.\n",
            "\n",
            "A classificação das ENs determina os tipos de entidades a serem consideradas e são especificadas a partir do escopo definido previamente para a tarefa. Algumas das categorias mais comumente utilizadas incluem as entidades que referenciam Pessoas Singulares (antropônimos); Coletivas (empresas e organizações) e Lugares (topônimos) (Mota; Santos; Ranchhod, 2007). Para exemplificar tomemos a sentença: “Renata Silva e Maria Costa palestraram na Universidade Federal da Bahia”. No exemplo temos três ENs: “Renata Silva”, “Maria Costa”, “Universidade Federal da Bahia”, sendo as duas primeiras correspondentes à categoria semântica Pessoa e a última, à categoria semântica Organização. Entretanto, existem outras categorias de ENs, como as menções a Obras (por exemplo, “Código Da Vinci”); Acontecimentos (por exemplo, “Festa de Santo Antônio”), Tempo (por exemplo, “meio-dia”); Coisa (por exemplo, “barco”), entre outras.\n",
            "\n",
            "O REN é uma tarefa com grande importância para o Processamento de Linguagem Natural, pois consiste numa primeira tarefa de análise semântica de um texto, com potencial aplicações a diversas tarefas. Por exemplo, em sistemas de perguntas e respostas, as perguntas frequentemente se referem a informações sobre entidades. Também, métodos de identificação de estruturas mais complexas, como eventos ou relações, dependem do bom desempenho do REN como uma etapa de pré-processamento (Socher et al., 2012; Zelenko; Aone; Richardella, 2003).\n",
            "\n",
            "A tarefa de extração de relações (ou de relacionamentos) (ER) refere-se a identificar relacionamentos entre entidades de um determinado escopo mencionadas em um texto (Jurafsky; Martin, 2023). O escopo, no contexto da ER, refere-se a um conjunto de relações-alvo de um determinado domínio de conhecimento ou aplicação a ser investigado. Por exemplo, o Quadro 17.2 apresenta alguns exemplos de relações no domínio de geografia brasileira. Na descrição das relações, os elementos em negrito referem-se às entidades em um dado relacionamento descrito pelo termo em itálico.\n",
            "\n",
            "Quadro 17.2 Exemplos de relações no domínio da geografia brasileira.\n",
            "\n",
            "Nesse contexto, a delimitação de um escopo ou domínio de interesse, concentra-se na determinação das relações a serem processadas, i.e. nos tipos de relacionamentos de interesse, assim como da natureza das entidades associadas por tais relações.\n",
            "\n",
            "As tarefas de reconhecimento de entidades nomeadas e extração de relações são interdependentes, no sentido de que a definição do escopo a ser estudado delimita tanto as categorias e natureza das entidades a serem extraídas, como também as relações entre essas entidades. Também, note-se que, pelo fato de as relações serem comumente definidas entre entidades de tipo especificado, como o caso da relação Tem_Prefeito no Quadro 17.2 que ocorre entre entidades das classes Cidade e Pessoa, tanto as informações das entidades mencionadas no texto são úteis para a extração de relações, quanto a informação das relações identificadas pode ser útil ao processo de identificação de entidades.\n",
            "\n",
            "De fato, na literatura recente, existem vários trabalhos que consideram a tarefa de extração conjunta de entidades e relações (ERE, do inglês Entity and Relation Joint Extraction), composta das tarefas de REN e ER (Agichtein; Gravano, 2000; Shaowei et al., 2022; Yuan et al., 2021). Enquanto normalmente abordagens estruturam suas soluções de forma sequencial, usualmente realizando REN inicialmente e, posteriormente, realizando ER, como nos trabalhos de (Hasegawa; Sekine; Grishman, 2004) e de (Socher et al., 2012), a literatura recente aponta para as vantagens da identificação conjunta ao permitir um melhor aprendizado de restrições para identificação de entidades e relações, c.f. o recente survey realizado por (Shaowei et al., 2022) sobre métodos para tal tarefa.\n",
            "\n",
            "Várias abordagens foram adotadas para o problema de EI durante seu desenvolvimento histórico. Enquanto abordagens iniciais privilegiavam métodos ricos em conhecimento, como regras e recursos linguísticos e de conhecimento de mundo, a literatura recente na área privilegia métodos baseados em dados, como o aprendizado de máquina, com o recente emprego de arquiteturas neurais aos problemas.\n",
            "\n",
            "A seguir faremos uma breve apresentação das abordagens descritas na literatura para os problemas de EI.\n",
            "\n",
            "parte do cap 9\n",
            "\n",
            "A descrição completa do frame está disponível em https://framenet.icsi.berkeley.edu/frameIndex.↩︎\n",
            "\n",
            "Uma palavra polissêmica é uma palavra que possui vários significados ou sentidos relacionados entre si, dependendo do contexto em que é usada. Por exemplo, a palavra “banco” pode se referir a uma instituição financeira, um local para sentar, ou a uma elevação de areia no mar.↩︎\n",
            "\n",
            "Mais detalhes sobre os números atuais da FrameNet podem ser acessados em https://framenet.icsi.berkeley.edu/current_status.↩︎\n",
            "\n",
            "A versão atual do SemLink é a versão 2.0 e pode ser acessada pelo GitHub https://github.com/cu-clear/semlink.↩︎\n",
            "\n",
            "Ver descrição completa em https://webtool.framenetbr.ufjf.br/index.php/webtool/report/frame/main↩︎\n",
            "\n",
            "Sua última versão é a ConceptNet 5.8 e a documentação completa está disponível em https://github.com/commonsense/conceptnet5/wiki↩︎\n",
            "\n",
            "Disponível em https://pt.wiktionary.org/wiki/Wikcion%C3%A1rio:P%C3%A1gina_principal↩︎\n",
            "\n",
            "Edges↩︎\n",
            "\n",
            "A lista completa das relações expressas na ConceptNet está disponível em https://github.com/commonsense/conceptnet5/wiki/Relations↩︎\n",
            "\n",
            "Pode ser nulo porque nem todas as afirmações foram derivadas de entrada em linguagem natural↩︎\n",
            "\n",
            "As bases de afirmações da ConceptNet para todas as linguagens naturais suportadas pode ser consultada em https://github.com/commonsense/conceptnet5/wiki/Languages↩︎\n",
            "\n",
            "parte do cap 17\n",
            "\n",
            "As abordagens iniciais para REN baseavam-se, majoritariamente, no emprego de regras lexico-sintáticas e consulta a almanaques (gazeeers). Tais abordagens dependem da construção de listas de nomes próprios como antropônimos, topônimos etc., e outras palavras, como “Ltda.”, “Jr.” etc., que auxiliam no processo de identificação e classificação de ENs complexas ou desconhecidas. Essa é, por exemplo, a abordagem empregada por Wolinski; Vichot; Dillet (1995) que combina almanaques e regras para a identificação e classificação de ENs. Posteriormente, almanaques foram também empregados em conjunção com métodos baseados em dados, como o trabalho de Florian et al. (2003) que os emprega aliados aos classificadores, enquanto Liu; Yao; Lin (2019) os utilizam durante o treinamento de uma rede neural, como um sinal de treinamento (parte da função de perda, ou loss em inglês).\n",
            "\n",
            "Muitos trabalhos debruçaram-se também sobre o problema de construção automática ou semi-automática de almanaques, dos quais os trabalhos de Nadeau (2007), de Riloff; Jones; et al. (1999) e de Etzioni et al. (2005) são alguns dos mais importantes.\n",
            "\n",
            "Enquanto as abordagens iniciais para o problema baseavam-se em regras, com a disponibilidade de dados anotados para a tarefa, tais métodos foram rapidamente suplantados por métodos baseados em dados, tais como: os métodos baseados em classificação (Asahara; Matsumoto, 2003; Sekine, 1998) e classificação sequencial (Bikel; Schwartz; Weischedel, 1999; McCallum; Li, 2003).\n",
            "\n",
            "A redução de REN à tarefa de classificação sequencial merece destaque pelos bons resultados obtidos. Tal redução se dá através de um esquema de codificação do problema que nos permite representar fragmentos textuais e sua classificação como um problema de rotulação ou etiquetação.\n",
            "\n",
            "Partindo-se do pressuposto de que os fragmentos textuais descrevendo entidades nomeadas são contíguos, podemos codificar a tarefa de delimitação de entidades como classificação sequencial empregando rótulos que descrevem os limites de uma EN, e.g. o esquema BIO com os rótulos B (do inglês, begin) para designar a palavra inicial de uma EN, I (do inglês, inside) para designar palavras que fazem parte da EN mas não a iniciam e O (do inglês, outside) para designar palavras que não pertencem a uma entidade. Da mesma forma, podemos estender nosso esquema de codificação para incluir as classes de interesse. Assim, seguindo o esquema BIO, teremos os rótulos B-PER e I-PER para descrever entidades da classe Pessoa.\n",
            "\n",
            "A redução do problema de REN à classificação sequencial está ilustrada no Exemplo 17.1.\n",
            "\n",
            "Exemplo 17.1  \n",
            "\n",
            "Renata/B-PER Silva/I-PER e/O Maria/B-PER Costa/I-PER palestraram/O na/O Universidade/B-ORG Federal/I-ORG da/I-ORG Bahia/I-ORG.\n",
            "\n",
            "Recentemente, destacam-se na literatura abordagens baseadas em redes neurais profundas, com uma grande concentração nos últimos anos em modelos gerativos de linguagem, devido aos resultados positivos obtidos por tais arquiteturas em diversas tarefas.\n",
            "\n",
            "Na literatura são de grande destaque os modelos recentes BART (Lewis et al., 2020), RoBERTa (Liu et al., 2019), T5 (Raffel et al., 2020), BERT (Devlin et al., 2019) e GPT-3 (Brown et al., 2020), conforme descritos no Capítulo 15.\n",
            "\n",
            "Similarmente, na língua portuguesa, nas duas edições do HAREM (Mota; Santos, 2008; Santos; Cardoso, 2007b), o primeiro esforço sistemático de desenvolvimento de soluções para a tarefa na língua, a maioria dos sistemas participantes baseava-se em métodos ricos em conhecimento, como regras e almanaques. De fato, nas duas avaliações, somente os sistemas MALINCHE (Solorio, 2007), NEURA (Ferrández et al., 2007) e R3M (Mota, 2008) não se baseavam em regras. Métodos baseados em classificação sequencial se seguiram para a língua portuguesa, como o RELP-CRF (Amaral; Vieira, 2014) baseado em um classificador sequencial. Mais recentemente, abordagens baseadas em redes neurais e modelos de linguagem foram desenvolvidas tornando-se o estado da arte da tarefa na língua. A Tabela 17.1 apresenta o atual estado da arte em português, com base no corpus HAREM. A métrica de avaliação apresentada, medida F1, será discutida na Seção 17.6.\n",
            "\n",
            "Souza; Nogueira; Lotufo (2020) desenvolveram um modelo BERT para o Português com 2,68 bilhões de tokens e aplicaram o modelo em um classificador CRF. Santos et al., avaliaram o impacto do modelo contextualizado Flair Embeddings aplicado a tarefa de REN junto com uma rede neural BiLSTM-CRF. Os autores também desenvolveram um modelo Flair Embeddings para o português, o FlairBBP, treinado com 4,9 bilhões de tokens (Santos et al., 2019). Castro; Silva; Soares (2018) utilizou uma rede LSTM e um classificador CRF junto com modelos Word Embeddings pré-treinados. Santos; Guimarães (2015) desenvolveram uma rede neural convolucional capaz de capturar características a nível de caracteres e também de incorporar word embeddings pré-treinados.\n",
            "\n",
            "O reconhecimento de entidades tem sido aplicado em muitas áreas específicas, como direito, saúde e geologia. Nesses casos há uma demanda de adaptação dos modelos preditivos de acordo com a nova linguagem especializada do domínio e um novo conjunto de rótulos que devem ser aprendidos. Da mesma forma, são necessários novos conjuntos de dados para o processo de aprendizado, uma vez que abordagens de aprendizado de máquina necessitam de exemplos anotados para se chegar a um modelo preditivo eficaz.\n",
            "\n",
            "Muitos trabalhos endereçam domínios específicos, citamos exemplos em diversas línguas. Para o inglês, uma rede neural BiLSTM-CRF para o domínio biomédico é proposta em (Habibi et al., 2017).\n",
            "\n",
            "Um conjunto de dados do domínio jurídico em língua alemã é apresentado por Leitner; Rehm; Schneider (2019), que empregam redes neurais BiLSTM para a rotulação dos textos. Em (Qiu et al., 2019), uma rede neural BiLSTM-CRF com mecanismo de atenção é aplicada para reconhecer entidades geológicas para a língua chinesa.\n",
            "\n",
            "parte do cap 9\n",
            "\n",
            "A descrição completa do frame está disponível em https://framenet.icsi.berkeley.edu/frameIndex.↩︎\n",
            "\n",
            "Uma palavra polissêmica é uma palavra que possui vários significados ou sentidos relacionados entre si, dependendo do contexto em que é usada. Por exemplo, a palavra “banco” pode se referir a uma instituição financeira, um local para sentar, ou a uma elevação de areia no mar.↩︎\n",
            "\n",
            "Mais detalhes sobre os números atuais da FrameNet podem ser acessados em https://framenet.icsi.berkeley.edu/current_status.↩︎\n",
            "\n",
            "A versão atual do SemLink é a versão 2.0 e pode ser acessada pelo GitHub https://github.com/cu-clear/semlink.↩︎\n",
            "\n",
            "Ver descrição completa em https://webtool.framenetbr.ufjf.br/index.php/webtool/report/frame/main↩︎\n",
            "\n",
            "Sua última versão é a ConceptNet 5.8 e a documentação completa está disponível em https://github.com/commonsense/conceptnet5/wiki↩︎\n",
            "\n",
            "Disponível em https://pt.wiktionary.org/wiki/Wikcion%C3%A1rio:P%C3%A1gina_principal↩︎\n",
            "\n",
            "Edges↩︎\n",
            "\n",
            "A lista completa das relações expressas na ConceptNet está disponível em https://github.com/commonsense/conceptnet5/wiki/Relations↩︎\n",
            "\n",
            "Pode ser nulo porque nem todas as afirmações foram derivadas de entrada em linguagem natural↩︎\n",
            "\n",
            "As bases de afirmações da ConceptNet para todas as linguagens naturais suportadas pode ser consultada em https://github.com/commonsense/conceptnet5/wiki/Languages↩︎\n",
            "\n",
            "parte do cap 17\n",
            "\n",
            "Para o português, um corpus para detecção de eventos de quedas de pacientes em prontuários eletrônicos é descrito em (Santos; Santos; Vieira, 2020). Os autores usaram uma rede neural BiLSTM-CRF+Flair para gerar um modelo classificador de tokens. Um corpus no domínio jurídico, tendo categorias específicas como legislação e jurisprudência é proposto por  Araujo et al. (2018), que usaram uma rede neural BiLSTM-CRF para criar um primeiro baseline para esse corpus. Ademais, Consoli et al. (2020) analisam um corpus no domínio de geologia usando uma rede neural BiLSTM-CRF com um modelo contextualizado Flair Embeddings.\n",
            "\n",
            "As abordagens iniciais para o problema de ER baseavam-se na definição de gabaritos e regras de extração, com base em informação sintática obtida de analisadores sintáticos rasos ou profundos (Cowie, 1983; Sager, 1978). Tais métodos foram rapidamente suplantados por métodos baseados em dados e padrões obtidos de corpora, como os famosos padrões de Hearst (1992) para identificação de relações de hiponímia.\n",
            "\n",
            "O trabalho de Hearst (1992) se baseou na definição de padrões lexico-sintáticos para expressão de relações de hiponímia e hiperonímia a partir de uma análise de corpus. Ao escolher a relação de hiponímia, que ocorre em todo domínio, e padrões gerais baseados em aspectos da língua, como os representados no Quadro 17.3, o autor garante generalizabilidade dos padrões obtidos para diversos domínios e aplicações.\n",
            "\n",
            "Quadro 17.3 Exemplos de Padrões de Hearst para hiponímia\n",
            "\n",
            "Devido à dificuldade de construção manual das regras, os métodos de Riloff et al. (1993), empregam heurísticas para geração de padrões baseadas em informação gramatical, e de Soderland et al. (1995), que se baseia numa semântica de quadros (frames) empregando um analisador semântico e medidas de qualidade de identificação de exemplos, baseado no percentual de acerto sobre relacionamentos previamente conhecidos, para identificação de quadros relevantes.\n",
            "\n",
            "As abordagens baseadas em aprendizado de máquina, hoje as mais comuns e com melhor desempenho na literatura (Konstantinova, 2014; Nasar; Jaffry; Malik, 2021) dividem-se em abordagens que realizam reconhecimento de entidades e extração de relações de forma conjunta e separada.\n",
            "\n",
            "Abordagens baseadas na realização de REN e ER de forma separada baseiam-se em um fluxo de processamento em que, em geral, as entidades são identificadas primeiro e a tarefa de ER se reduz a identificar quando uma sentença ou fragmento textual denota uma relação semântica entre duas entidades. Consideremos o Exemplo 17.2, retirado de (Socher et al., 2012):\n",
            "\n",
            "Exemplo 17.2  \n",
            "\n",
            "Gripe aviária]\\(_{e1}\\) é uma doença infecciosa causada pelo vírus da [influenza tipo a]\\(_{e2}\\)\n",
            "\n",
            "Podemos, então, reduzir o problema de identificar a relação Causa-Efeito(\\(e1\\),\\(e2\\)) a um problema de classificação textual, identificando se a sentença acima fornece indícios para a expressão da relação de interesse. As soluções propostas na literatura para o problema são variadas e baseadas em diferentes métodos.\n",
            "\n",
            "Zelenko; Aone; Richardella (2003), por exemplo, propõem funções de kernel para árvores sintáticas rasas, i.e. funções que descrevem medidas de similaridade entre tais árvores. Eles empregam tais medidas para treinar um classificador de perceptron com votação (voted perceptron) sobre relações no domínio de organizações extraídas de um corpus de textos jornalísticos. De forma similar, Zhao; Grishman (2005) empregam diferentes funções de kernel sobre informações sintáticas relevantes para a identificação de relação e argumentos visando treinar um classificador SVM sobre o corpus de ER da conferência ACE.\n",
            "\n",
            "Culotta; McCallum; Betz (2006), por outro lado, empregam um classificador sequencial baseado em modelos escondidos de Markov para identificação de relações em um texto. Ao restringir sua análise a textos biográficos, os autores reduzem o processo de identificar instâncias de relações à identificação de fragmento textual que delimita o argumento e sua classificação, tarefa para a qual a classificação sequencial já é comumente utilizada. Consideremos o Exemplo 17.3 sobre George W. Bush, retirado de (Culotta; McCallum; Betz, 2006):\n",
            "\n",
            "Exemplo 17.3  \n",
            "\n",
            "George é filho de \\(\\underbrace{\\mbox{George H. W. Bush}}_{\\mbox{pai}}\\) e \\(\\underbrace{\\mbox{Barbara Bush}}_{\\mbox{mãe}}\\).\n",
            "\n",
            "Ao identificar o papel de pai e mãe, os autores conseguem construir a relação Pai(George H. W. Bush, George W. Bush) e Mãe(Barbara Bush, George W. Bush).\n",
            "\n",
            "parte do cap 9\n",
            "\n",
            "A descrição completa do frame está disponível em https://framenet.icsi.berkeley.edu/frameIndex.↩︎\n",
            "\n",
            "Uma palavra polissêmica é uma palavra que possui vários significados ou sentidos relacionados entre si, dependendo do contexto em que é usada. Por exemplo, a palavra “banco” pode se referir a uma instituição financeira, um local para sentar, ou a uma elevação de areia no mar.↩︎\n",
            "\n",
            "Mais detalhes sobre os números atuais da FrameNet podem ser acessados em https://framenet.icsi.berkeley.edu/current_status.↩︎\n",
            "\n",
            "A versão atual do SemLink é a versão 2.0 e pode ser acessada pelo GitHub https://github.com/cu-clear/semlink.↩︎\n",
            "\n",
            "Ver descrição completa em https://webtool.framenetbr.ufjf.br/index.php/webtool/report/frame/main↩︎\n",
            "\n",
            "Sua última versão é a ConceptNet 5.8 e a documentação completa está disponível em https://github.com/commonsense/conceptnet5/wiki↩︎\n",
            "\n",
            "Disponível em https://pt.wiktionary.org/wiki/Wikcion%C3%A1rio:P%C3%A1gina_principal↩︎\n",
            "\n",
            "Edges↩︎\n",
            "\n",
            "A lista completa das relações expressas na ConceptNet está disponível em https://github.com/commonsense/conceptnet5/wiki/Relations↩︎\n",
            "\n",
            "Pode ser nulo porque nem todas as afirmações foram derivadas de entrada em linguagem natural↩︎\n",
            "\n",
            "As bases de afirmações da ConceptNet para todas as linguagens naturais suportadas pode ser consultada em https://github.com/commonsense/conceptnet5/wiki/Languages↩︎\n",
            "\n",
            "parte do cap 17\n",
            "\n",
            "Métodos baseados em redes neurais, de forma geral, costumam empregar técnicas de aprendizado de representação (Bengio; Courville; Vincent, 2013) para aprender representações do conteúdo semântico dos fragmentos textuais e reduzem o problema de ER à classificação textual. É o caso de Socher et al. (2012), que propõem a MV-RNN, uma rede neural que constrói um espaço de representação baseado em matrizes e vetores com o objetivo de capturar a composicionalidade de sentido de sintagmas e sentenças e os aplica para ER. Similarmente, Zeng et al. (2014) e Wang et al. (2016) empregam redes neurais convolucionais para obter representações vetoriais de sentenças que serão empregadas no processo de classificação quanto à relação expressa pela mesma.\n",
            "\n",
            "Abordagens baseadas em identificação sequencial de entidades e relações possuem desvantagens observadas na literatura. Primeiramente, como a ER é guiada pelas entidades identificadas no processo de REN, a propagação de erros da primeira tarefa pode ter impacto considerável na performance dos sistemas desenvolvidos. Segundo, uma vez que o contexto determinado limita tanto as tarefas de REN, quanto as de ER, existe uma interdependência entre as tarefas. Assim, propostas visando realizar a extração de entidades e relações de forma conjunta começaram a surgir na literatura recente, ganhando certo interesse da comunidade.\n",
            "\n",
            "As abordagens empregadas para tal tarefa são diversificadas, incluindo desde métodos de aprendizado relacional a redes neurais\n",
            "\n",
            "Roth; Yih (2007) propõem a utilização de métodos de programação inteira ao problema, baseados na teoria estatística de aprendizado relacional. Os autores utilizam classificadores locais para a identificação de entidades e relações e um classificador global que combina as informações dos classificadores locais em uma predição que maximiza a qualidade da extração, codificada por meio de restrições em programação inteira. Também baseados em modelos estatísticos, Yu; Lam (2010) propõem o uso de modelos gráficos globais para identificação de um descritor de relação e uma segmentação do texto para identificação dos argumentos.\n",
            "\n",
            "Li; Ji (2014) e Miwa; Bansal (2016), por sua vez, reduzem a tarefa de ERE à classificação sequencial, utilizando redes neurais recorrentes bidirecionais sequenciais e estruturadas com base na estrutura superficial e na árvore de dependências sintáticas da entrada para identificação conjunta de entidades e relações.\n",
            "\n",
            "A Extração de Informação Aberta (EIA), também conhecida como Open Information Extraction, Open IE ou OIE em inglês, é a tarefa de extrair informações estruturadas de documentos sem necessitar da pré-definição do contexto da tarefa, i.e. das relações e tipos de entidade de interesse. A tarefa foi inicialmente proposta pelo trabalho de (Banko et al., 2007) e ganhou popularidade nas últimas décadas devido à sua aplicabilidade para processar e estruturar o conhecimento a partir de grandes volumes de dados disponíveis na Web, seguindo o paradigma da Web como um Corpus (WaC) (Meyer et al., 2003).\n",
            "\n",
            "A EIA surge visando generalizar a tarefa de Extração de Relações. A principal diferença entre as duas abordagens, porém, reside na dependência da ER de uma especificação prévia do domínio de aplicação, bem como das relações alvo a serem identificadas, que a EIA visa eliminar.\n",
            "\n",
            "Seguindo o trabalho original de Banko et al. (2007), que propôs o sistema TextRunner, vários métodos e sistemas para EIA foram propostos na literatura (Del Corro; Gemulla, 2013; Fader; Soderland; Etzioni, 2011; Xavier; Lima; Souza, 2015), mas, como observado por Glauber; Claro (2018), os principais avanços na área se concentraram principalmente no idioma inglês.\n",
            "\n",
            "A EIA para a língua portuguesa tem uma história bastante recente. A partir dos trabalhos de Souza; Claro (2014), Pereira; Pinheiro (2015) e de (Barbosa; Glauber; Claro, 2016), têm crescido o número de estudos sobre a tarefa assim como os resultados obtidos por esses estudos, com recentes desenvolvimentos de métodos (Oliveira; Claro; Souza, 2022; Sena; Claro, 2019, 2020; Sena; Glauber; Claro, 2017; Souza; Claro; Glauber, 2018), construção do corpus (Glauber et al., 2018) e avaliação dos sistemas disponíveis (Glauber; Claro; Oliveira, 2019; Glauber; Claro; Sena, 2019; Malenchini et al., 2019).\n",
            "\n",
            "Embora a área tenha visto um crescimento recente para o desenvolvimento de métodos para línguas como o inglês, principalmente com a aplicação de métodos supervisionados e redes neurais, esses avanços ainda não foram incorporados na literatura sobre EIA para a língua portuguesa. A razão para isso é principalmente a falta de recursos linguísticos disponíveis para orientar o desenvolvimento de pesquisas para a língua. Embora o foco no idioma inglês possa ser devido ao seu uso generalizado em todo o mundo, foi reconhecido pela comunidade científica que esse foco no inglês com suas características particulares pode introduzir algum viés na área (Bender, 2009).\n",
            "\n",
            "Assim, esta seção aborda EIA para a língua portuguesa, incluindo uma formalização e a evolução das abordagens da área.\n",
            "\n",
            "A tarefa de EIA pode ser formalmente definida sendo \\(X = \\langle x_{1}, x_{2}, \\cdots, x_{n}\\rangle\\) uma sentença composta de tokens \\(x_i\\). Um extrator EIA é uma função que mapeia \\(X\\) em um conjunto \\(Y = \\langle y_{1}, y_{2}, \\cdots, y_{j} \\rangle\\) como um conjunto de tuplas \\(y \\_i = \\langle rel_i, arg1_i, arg2_i, \\cdots, argn_i\\rangle\\), que descrevem as informações expressas na sentença X. Neste capítulo, consideramos que as tuplas estão sempre no formato \\(y = (arg_{1 }, rel, arg_{2})\\), onde \\(arg1\\) e \\(arg2\\) são sintagmas nominais, não necessariamente formados por tokens presentes em X, e \\(rel\\) é um descritor de um relacionamento entre \\(arg_{1}\\) e \\(arg_{2}\\). Não consideraremos extrações formadas por mais de dois argumentos neste capítulo.\n",
            "\n",
            "Os primeiros métodos de EIA empregavam padrões de inspiração linguística para extração, como ArgOE (Gamallo; Garcia, 2015), ou adaptação de métodos para a língua inglesa, como SGS (Souza; Claro; Glauber, 2018), InferReVerbPT Sena; Glauber; Claro (2017) e RePort Pereira; Pinheiro (2015). Os trabalhos são principalmente influenciados por métodos baseados no inglês da chamada segunda geração de EIA (Fader; Soderland; Etzioni, 2011).\n",
            "\n",
            "O primeiro sistema de EIA para o português de que temos conhecimento foi o DepOE (Gamallo; Garcia; Fernández-Lanza, 2012). Ele executa a extração aberta multilíngue de triplas (inglês, espanhol, português e galego) usando o analisador sintático de dependências baseado em regras DepPattern. No entanto, nenhuma avaliação ou resultados são relatados para a língua portuguesa. Os autores apresentam somente uma comparação dos seus resultados com Reverb na língua inglesa.\n",
            "\n",
            "Souza; Claro (2014) se propuseram a analisar o conjunto de características mais representativas da língua portuguesa para a identificação de extrações válidas no contexto de EIA, tal qual empregado na língua inglesa com o sistema ReVerb (Fader; Soderland; Etzioni, 2011).\n",
            "\n",
            "parte do cap 9\n",
            "\n",
            "A descrição completa do frame está disponível em https://framenet.icsi.berkeley.edu/frameIndex.↩︎\n",
            "\n",
            "Uma palavra polissêmica é uma palavra que possui vários significados ou sentidos relacionados entre si, dependendo do contexto em que é usada. Por exemplo, a palavra “banco” pode se referir a uma instituição financeira, um local para sentar, ou a uma elevação de areia no mar.↩︎\n",
            "\n",
            "Mais detalhes sobre os números atuais da FrameNet podem ser acessados em https://framenet.icsi.berkeley.edu/current_status.↩︎\n",
            "\n",
            "A versão atual do SemLink é a versão 2.0 e pode ser acessada pelo GitHub https://github.com/cu-clear/semlink.↩︎\n",
            "\n",
            "Ver descrição completa em https://webtool.framenetbr.ufjf.br/index.php/webtool/report/frame/main↩︎\n",
            "\n",
            "Sua última versão é a ConceptNet 5.8 e a documentação completa está disponível em https://github.com/commonsense/conceptnet5/wiki↩︎\n",
            "\n",
            "Disponível em https://pt.wiktionary.org/wiki/Wikcion%C3%A1rio:P%C3%A1gina_principal↩︎\n",
            "\n",
            "Edges↩︎\n",
            "\n",
            "A lista completa das relações expressas na ConceptNet está disponível em https://github.com/commonsense/conceptnet5/wiki/Relations↩︎\n",
            "\n",
            "Pode ser nulo porque nem todas as afirmações foram derivadas de entrada em linguagem natural↩︎\n",
            "\n",
            "As bases de afirmações da ConceptNet para todas as linguagens naturais suportadas pode ser consultada em https://github.com/commonsense/conceptnet5/wiki/Languages↩︎\n",
            "\n",
            "parte do cap 17\n",
            "\n",
            "O sistema RePort (Pereira; Pinheiro, 2015), por outro lado, é uma adaptação do ReVerb para a língua portuguesa baseada em análise sintática rasa com regras sintáticas e lexicais. Os autores relatam que suas extrações apresentam grande similaridade com suas correlatas extraídas pelo ReVerb (dos textos traduzidos para o inglês).\n",
            "\n",
            "O RELP, proposto por Abreu; Vieira (2017), é um sistema aberto de extração de relações que extrai relações entre entidades nomeadas em um domínio de organização aplicando classificação sequencial com CRF (Conditional Random Fields). O sistema RelP extrai qualquer descritor de relação que expressa um relacionamento entre pares de entidades nomeadas (Organização, Pessoa ou Lugar), caracterizando-o como uma abordagem híbrida da REN com a EIA.\n",
            "\n",
            "O InferReVerbPT desenvolvido por Sena; Glauber; Claro (2017) baseia-se numa adaptação do sistema ReVerb para a língua portuguesa, expandindo-o com a extração de relacionamentos implícitos obtidos por inferência por propriedades de simetria e transitividade das relações com inferência transitiva e simétrica. Um classificador SVM foi empregado para realizar a inferência baseado nas propriedades semânticas do verbo central no descritor de relação.\n",
            "\n",
            "Souza; Claro; Glauber (2018) analisaram que a maior desvantagem dos estudos baseados em recursos linguísticos, como dados anotados, reside na escassez de tais recursos na maioria dos idiomas além do inglês. Assim, para mitigar esse problema, eles propõem um método de classificação de fatos baseado na similaridade de estruturas gramaticais (SGS). Sua abordagem modela estruturas morfosintáticas dos fatos (triplas descrevendo relacionamentos) para identificar padrões de semelhanças que podem ser usados para distinguir entre fatos válidos e inválidos. Eles aplicaram algoritmos de isomorfismo de grafos para detectar subgrafos descrevendo tais padrões.\n",
            "\n",
            "Um novo sistema de EIA baseado em análise de dependência foi proposto por Gamallo; Garcia (2015), chamado ArgOE. Tal sistema é multilíngue, baseado em heurísticas e utiliza a informação de dependência sintáticas do texto para analisar a estrutura de dependência do verbo, bem como um conjunto de regras para gerar os relacionamentos. A introdução de um Analisador de Dependência em sistemas de EIA focados inteiramente na língua portuguesa foi feita pelos autores Oliveira; Claro; Souza (2022). O DptOIE é baseado em análise de dependência e regras elaboradas manualmente. As sentenças são pré-processadas por meio de um tokenizador, um PoS Tagger e um analisador de dependências. Os autores propõem um acoplamento de três módulos para tratar casos particulares: conjunções coordenadas, orações subordinadas e aposto.\n",
            "\n",
            "Com a evolução dos métodos de EIA para a língua inglesa utilizando os modelos neurais, novas abordagens foram propostas também para a língua portuguesa.\n",
            "\n",
            "O primeiro trabalho que utilizou aprendizado supervisionado com rede neural profunda para o português foi o de Ro; Lee; Kang (2020) que descreve o sistema Multi2OIE. Os autores utilizaram o modelo de linguagem BERT multilíngue (Devlin et al., 2019) para obter representações vetoriais das palavras e reduzem a tarefa de EIA à classificação sequencial, identificado os fragmentos do texto que determinam os argumentos (\\(arg_1, arg_2\\)) e o descritor de relação (\\(rel\\)). Seu sistema foi capaz de produzir extrações para vários idiomas (inglês, português e espanhol), treinados, entretanto, sobre dados traduzidos do inglês.\n",
            "\n",
            "Stanovsky et al. (2018) propuseram uma abordagem de EIA para a língua inglesa baseada em triplas. Os mesmos fazem uso de uma classificação sequencial cuja limitação define uma tripla extraída para cada sentença. Este método utiliza uma arquitetura de Redes Neurais Recursivas (RNN) para realizar EIA. A EIA é formulada como uma tarefa de rotulagem de sequências, utilizando estratégias semelhantes às que foram aplicadas anteriormente a tarefas como o Reconhecimento de Entidades Nomeadas. Já os autores em Cui; Wei; Zhou (2018) e Zhang; Duh; Van Durme (2017) propõem modelar o problema da EIA como um problema de aprendizado sequência a sequência (seq2seq). Eles definem uma estrutura encoder-decoder para aprender argumentos e tuplas de relação inicializadas a partir de um sistema de EIA.\n",
            "\n",
            "Seguindo o trabalho de (Stanovsky et al., 2018), em 2022, Cabral; Souza; Claro (2022) propuseram PortNOIE, uma arquitetura neural para EIA em português que combina representações contextuais de palavras com codificadores neurais para extrair relacionamentos baseado em classificação sequencial iterativa. Diferente de outros métodos de classificação sequencial para EIA, os autores focam na extração de múltiplas triplas de uma mesma sentença.\n",
            "\n",
            "A avaliação sistemática de sistemas de EI foi estabelecida primeiramente nas conferências MUC, em particular na sua segunda edição, com o estabelecimento de gabaritos-padrão que deveriam ser utilizados por todos os sistemas participantes e a adoção de métricas de qualidade, baseadas naquelas usadas na área de recuperação de informação, que foram abordadas no Capítulo 16. Para avaliar a tarefa de extração de relações, a MUC-2 estabeleceu como métricas de qualidade do sistema as medidas de precisão e cobertura, também denominada de Recall ou Revocação.\n",
            "\n",
            "A precisão de um sistema reflete a qualidade de suas extrações, i.e., quantas das extrações realizadas estão corretas, dado um corpus de teste. A medida de precisão pode ser calculada como:\n",
            "\n",
            "P = \\frac{\\#(\\mbox{relacionamentos corretamente extraídos})}{\\#(\\mbox{relacionamentos extraídos pelo sistema})}\n",
            "\n",
            "A cobertura também conhecida como revocação, reflete quão abrangente um sistema é em suas extrações, i.e., quantas das extrações a serem realizadas em um corpus de teste, o sistema é capaz de realizar. A medida de cobertura pode ser calculada como:\n",
            "\n",
            "R = \\frac{\\#(\\mbox{relacionamentos extraídos})}{\\#(\\mbox{relacionamentos no \\textit{corpus}})}\n",
            "\n",
            "Enquanto a MUC-3 adicionou duas novas métricas de avaliação, a saber sobre-geração (overgeneration) e sub-geração (fallout), tais métricas receberam pouco interesse na literatura. De fato, Lehnert; Sundheim (1991) argumentam que tais métricas foram pouco informativas ou difíceis de calcular para a tarefa de EI e, portanto, abandonadas. Foi também empregado nessa conferência um sistema automático de avaliação disponibilizado às equipes participantes que permitiu uma maior compreensão do modelo de avaliação e, como discutem Lehnert; Sundheim (1991), um avanço qualitativo nos sistemas gerados.\n",
            "\n",
            "parte do cap 9\n",
            "\n",
            "A descrição completa do frame está disponível em https://framenet.icsi.berkeley.edu/frameIndex.↩︎\n",
            "\n",
            "Uma palavra polissêmica é uma palavra que possui vários significados ou sentidos relacionados entre si, dependendo do contexto em que é usada. Por exemplo, a palavra “banco” pode se referir a uma instituição financeira, um local para sentar, ou a uma elevação de areia no mar.↩︎\n",
            "\n",
            "Mais detalhes sobre os números atuais da FrameNet podem ser acessados em https://framenet.icsi.berkeley.edu/current_status.↩︎\n",
            "\n",
            "A versão atual do SemLink é a versão 2.0 e pode ser acessada pelo GitHub https://github.com/cu-clear/semlink.↩︎\n",
            "\n",
            "Ver descrição completa em https://webtool.framenetbr.ufjf.br/index.php/webtool/report/frame/main↩︎\n",
            "\n",
            "Sua última versão é a ConceptNet 5.8 e a documentação completa está disponível em https://github.com/commonsense/conceptnet5/wiki↩︎\n",
            "\n",
            "Disponível em https://pt.wiktionary.org/wiki/Wikcion%C3%A1rio:P%C3%A1gina_principal↩︎\n",
            "\n",
            "Edges↩︎\n",
            "\n",
            "A lista completa das relações expressas na ConceptNet está disponível em https://github.com/commonsense/conceptnet5/wiki/Relations↩︎\n",
            "\n",
            "Pode ser nulo porque nem todas as afirmações foram derivadas de entrada em linguagem natural↩︎\n",
            "\n",
            "As bases de afirmações da ConceptNet para todas as linguagens naturais suportadas pode ser consultada em https://github.com/commonsense/conceptnet5/wiki/Languages↩︎\n",
            "\n",
            "parte do cap 17\n",
            "\n",
            "Além das medidas de precisão e cobertura, assim como em tarefas de classificação de texto e recuperação de informação, utilizamos a média harmônica entre essas medidas, chamada medida F1, a fim de condensar a informação contida nas duas. A medida F1 pode ser calculada como:\n",
            "\n",
            "F1 = \\frac{2*P*R}{P+R}\n",
            "\n",
            "A avaliação da tarefa de REN segue padrões semelhantes aos aplicados à tarefa de ER. De fato, desde a MUC-6 (Grishman; Sundheim, 1996), as medidas de precisão, cobertura e F1 tem sido usada consistentemente como métricas de avaliação da tarefa de REN em diversos esforços de avaliação, como a CoNNL (Sang; De Meulder, 2003), para a língua inglesa, e das duas edições do HAREM (Gonçalo Oliveira et al., 2008; Santos; Cardoso; Seco, 2007), com excessão à ACE (Doddington et al., 2004) que apresenta uma combinação da tarefa de REN com reconhecimento de co-referência entre entidades e utiliza um sistema de pontuação próprio.\n",
            "\n",
            "A avaliação de sistemas de EIA, por sua vez, possui algumas peculiaridades que precisam ser discutidas. Uma vez que a tarefa é postulada por Banko et al. (2007) como a extração de todas as relações identificadas em um dado fragmento textual, sem limitação de domínio de interesse, tal tarefa impõe imensa dificuldade aos esforços de avaliação.\n",
            "\n",
            "De fato, Glauber et al. (2018) relatam um esforço de anotação de dados para a tarefa em língua portuguesa em que foram identificados por anotadores humanos mais de 400 relacionamentos em um corpus de 25 sentenças retiradas de textos jornalísticos e de enciclopédia. Assim, a avaliação de EIA deu-se, em grande parte de seu desenvolvimento e maturação, em conjuntos de dados não anotados, recorrendo a avaliações qualitativas das saídas dos sistemas e comparação direta por humanos das extrações obtidas.\n",
            "\n",
            "Nesses esforços de avaliação, a precisão do sistema pode ser mensurada a partir da avaliação humana das saídas. Não é possível, entretanto, avaliar medidas como cobertura e F1, dada a inexistência de uma referência do conjunto total de relacionamentos a serem identificados. Assim, os autores da área propuseram diferentes métricas a fim de estimar tais valores, como a métrica rendimento (yield) (Fader; Soderland; Etzioni, 2011; Schmitz et al., 2012).\n",
            "\n",
            "A métrica de rendimento consiste no núemro de extrações válidas, i.e. corretas, de um dado sistema. Como calcular tal medida é, na maioria dos casos, impraticável dada a grande quantidade de extrações realizadas pelos sistemas, ela pode ser estimada a partir da precisão do sistema calculada sobre uma amostra aleatória das extrações realizadas (\\(P'\\)). Assim, podemos estimar o rendimento como:\n",
            "\n",
            "Y = P'\\cdot \\#(\\mbox{extrações realizadas})\n",
            "\n",
            "Foi também explorada a estratégia de criação (semi-)automática de conjuntos de dados usando vários sistemas (Del Corro; Gemulla, 2013), estratégias de supervisão fraca (Smirnova; Cudré-Mauroux, 2018), ou a geração de corpora para a tarefa a partir da transformação de anotações de tarefas próximas, como identificação de papéis temáticos (Semantic Role Labeling) por (Stanovsky et al., 2018). Corpora gerados de forma semi-automática vêm ganhando atenção na literatura recente, particularmente para a língua inglesa, devido a necessidade de dados anotados para se utilizar técnicas de aprendizado de máquina e redes neurais em EIA. Corpora como o OIE2016 (Stanovsky et al., 2018), Wire57 (Léchelle; Gotti; Langlais, 2018) e CARB (Bhardwaj; Aggarwal; Mausam, 2019) vêm se tornando corpora de referência em língua inglesa para o problema, apesar dos problemas existentes na construção de tais recursos – a não exaustividade das relações anotadas.\n",
            "\n",
            "Para a língua portuguesa, foram propostas algumas iniciativas para avaliar os sistemas da OIE. Uma avaliação conjunta foi promovida durante o Fórum Ibérico de Avaliação de Línguas (IberLEF) em 2019 (Collovini et al., 2019). A avaliação foi feita usando o corpus proposto por Glauber et al. (2018), que é composto por 442 relacionamentos extraídos de 25 frases de fontes como a seção em português da Wikipédia, o corpus CETENFolha, resenhas de filmes do portal Adoro Cinema2 e o corpus Europarl. Apesar desta tarefa ter contemplado quatro cenários de avaliação, a avaliação geral dos sistemas permaneceu consistente nos diferentes cenários, indicando robustez nos resultados da avaliação. No geral, os sistemas DPTOIE (Oliveira; Claro; Souza, 2022) e Linguakit (Gamallo; Garcia, 2015) tiveram o melhor desempenho, com o Linguakit2 dominando as avaliações de correspondência exata e o DPTOIE as avaliações de correspondências parciais (Collovini et al., 2019).\n",
            "\n",
            "Outra abordagem de avaliação foi idealizada por (Malenchini et al., 2019). Seu foco foi a avaliação extrínseca dos sistemas de EIA através de sua contribuição na tarefa de respostas automáticas a perguntas. Os autores apresentaram um conjunto de dados de referência (benchmark) para avaliação extrínseca de sistemas de EIA em textos de língua portuguesa. Os sistemas que alcançaram os melhores valores na avaliação realizada pelos autores foram os sistemas ArgOE (Gamallo; Garcia, 2015), DependentIE (Glauber; Claro; Oliveira, 2019) e DptOIE (Oliveira; Claro; Souza, 2022).\n",
            "\n",
            "Este capítulo descreveu uma visão geral da área de Extração de Informação, apresentando a Extração de Informação Tradicional e a Extração de Informação Aberta. Transversalmente, apresentamos as formalizações necessárias e os conceitos fundamentais para a compreensão da EIA, assim como a avaliação da área e as heranças de outras áreas afins, tais como RI.\n",
            "\n",
            "Nessa primeira versão, este capítulo descreveu de maneira bem sucinta as abordagens propostas para EI e EIA durante seu desenvolvimento histórico e as abordagens atuais da literatura, como as utilizando modelos de linguagens. Especificamente, a utilização da arquitetura Transformers, descritas no Capítulo 15 para as tarefas de EI e EIA tem sido bastante difundida para a língua inglesa e tem atuado em diversas áreas da PLN.\n",
            "\n",
            "Agradecemos as colaborações dos autores deste Capítulo e suas indicações, assim como agradecemos a Adriana Pagano e Aline Macohin pela revisão e comentários.\n",
            "\n",
            "Em nossa terminologia, por um relacionamento.↩︎\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import openai\n",
        "\n",
        "# Função para comparar dois parágrafos usando a API OpenAI\n",
        "def comparar_paragrafos(paragrafo1, paragrafo2):\n",
        "    prompt = f\"Comparar o parágrafo 1:\\n{paragrafo1}\\nCom o parágrafo 2:\\n{paragrafo2}\\n\"\n",
        "    resposta = openai.Completion.create(\n",
        "        model=\"text-davinci-003\",\n",
        "        prompt=prompt,\n",
        "        max_tokens=100,  # Ajuste conforme necessário\n",
        "    )\n",
        "    return resposta.choices[0].text.strip()\n",
        "\n",
        "# Parágrafos de exemplo (substitua pelos parágrafos reais)\n",
        "paragrafo1 = \"Este é o primeiro parágrafo de exemplo.\"\n",
        "paragrafo2 = \"Este é o segundo parágrafo de exemplo.\"\n",
        "\n",
        "# Comparar os parágrafos\n",
        "resultado_comparacao = comparar_paragrafos(paragrafo1, paragrafo2)\n",
        "\n",
        "# Imprimir o resultado\n",
        "print(f\"Resultado da comparação:\\n{resultado_comparacao}\")\n"
      ],
      "metadata": {
        "id": "IrkS1D0lo4FQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b5b62e96-3d73-4371-c78c-fb4929049fdd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Resultado da comparação:\n",
            "Os parágrafos 1 e 2 são iguais pois ambos são parágrafos de exemplo. A única diferença está na numeração e na primeira palavra, pois o primeiro parágrafo começa com o \"Este\" enquanto o segundo parágrafo inicia com o \"Esse\".\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Tradução de textos"
      ],
      "metadata": {
        "id": "J0Kl1bbcSNZ-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Tentando contornar as limitações da API gratuita, em que ficaria inviável traduzir o texto todo, foi feita a tradução apenas das palavras chave, demonstradas abaixo:"
      ],
      "metadata": {
        "id": "kYatHjdQe3M1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def translated_key_words(text) :\n",
        "   paragraphs = get_paragraphs(text)\n",
        "   # separate the text into 8 parts\n",
        "   concanate_paragraphs = concatenate_into_parts(paragraphs, 8)\n",
        "   count = 0\n",
        "   for paragraph in concanate_paragraphs :\n",
        "      res = openai.Completion.create(\n",
        "        model=\"text-davinci-003\",\n",
        "        prompt=f\"Retorne as palavras chaves do seguinte texto traduzidas para inglês:\\n'{paragraph}\",\n",
        "        max_tokens=100,  # Ajuste conforme necessário\n",
        "    )\n",
        "      print(f'PARTE {count + 1} : \\n')\n",
        "      print(res['choices'][0]['text'].strip())\n",
        "      time.sleep(20)\n",
        "      count = count + 1"
      ],
      "metadata": {
        "id": "SPbW3-9FSMdt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "translated_key_words(text_chapther_9)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NpzEiBN-VKqV",
        "outputId": "bd0a9245-7f2f-4824-964e-259305c4f37d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "PARTE 1 : \n",
            "\n",
            "Palavras-chave: Natural Language Understanding, Natural Language Processing, Symbolic Methods, Semantic Parsers, Knowledge Bases, Description Logics, First-Order Logic, Prolog, Intensional Logics, Abstract Meaning Representation, DELPH-IN, WordNet, FrameNet, ConceptNet, WikiData, YAGO, BabelNet.\n",
            "\n",
            "Natural Language Understanding, Natural Language Processing, Symbolic Methods, Semantic Parsers, Knowledge Bases, Description Log\n",
            "PARTE 2 : \n",
            "\n",
            "Palavras-chave: Natural Language Processing (PLN), léxico-semânticos, bases de conhecimento de senso comum, WordNet, desambiguação de sentido, Princeton WordNet, FrameNet, ConceptNet.\n",
            "\n",
            "Keywords: Natural Language Processing (PLN), lexical-semantics, common-sense knowledge bases, WordNet, sense disambiguation, Princeton WordNet, Frame\n",
            "PARTE 3 : \n",
            "\n",
            "WordNet of Princeton, various wordnets proposed for various languages, among them Portuguese, as described in the following section.\n",
            "\n",
            "Several lexico-semantic resources have been created for Portuguese in recent years. Some of them are listed on the Linguateca11 page. NILC12 has a collection of resources listed on the PortLex portal13, among them, among others, VerbNet.br (Scarton; Aluisio, 2012) and PropBank.br (\n",
            "PARTE 4 : \n",
            "\n",
            "Palavras-chave: wordnet, propbank, verbnet, framenet, framenet brasil, léxico-semântico, anotação de papéis semânticos, semantic role labeling, msinsky, recursos léxico-semânticos.\n",
            "\n",
            "Keywords: WordNet, PropBank, VerbNet, FrameNet, FrameNet Brazil, Lexico-semantic,\n",
            "PARTE 5 : \n",
            "\n",
            "Palavras-Chave: Iniciativas, Geração, Frames, Português, Menor Tamanho, Domínios, Bases, FrameFOR,113 Frames, Adaptados, FrameNet, Papéis Semânticos, Unidades Lexicais, Entradas Lexicais, Tipos de Crimes, Perícia Forense, Estado do Ceará, Brasil, FrameNet de Berkeley,\n",
            "PARTE 6 : \n",
            "\n",
            "Palavras chaves: Knowledge unit, ConceptNet, statement, edge, natural language, source, triple, argument, label, relation, vocabulary, language, framework, URI, API, REST, JSON, hub, toolkit, inference, context, chain, analogy, Portuguese, OMCS-BR, UFSCar, MIT, OMCS-Brazil, projekt, InferenceNet-BR, premiss, conclusion, crime, relation.\n",
            "\n",
            "Key words\n",
            "PARTE 7 : \n",
            "\n",
            "Bank robbery, shooting, woman, 42 years old, Professor Costa Mendes street, assault.\n",
            "PARTE 8 : \n",
            "\n",
            "Full frame description, FrameNet, polysemous word, current FrameNet numbers, SemLink version 2.0, FrameWeb tool, ConceptNet 5.8 documentation, Wikcionário, ConceptNet relations, natural language input, ConceptNet assertions.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "translated_key_words(text_chapther_17)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hhALzkfMfwhv",
        "outputId": "1c8fa321-f5ec-409d-ecac-03560deb3aec"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "PARTE 1 : \n",
            "\n",
            "Palavras-chave: Extraction of Information, Named Entity Recognition, Relationship Extraction, Event Extraction, Message Understanding Conference, 1980s, 1990s.\n",
            "PARTE 2 : \n",
            "\n",
            "Palavras-chave: MUC-3, 1991, Processamento de Textos Jornalísticos, DARPA, Relação REN, Nomes Próprios, Aprendizado de Máquina, Aprendizado Semi-Supervisionado, DIPRE, Snowball, Wikipédia, Freebase, Rede Neural, Deep Learning, Grandes Modelos de Linguagem,\n",
            "PARTE 3 : \n",
            "\n",
            "Palavras-chave: Entity Extraction, Relation Extraction, Open Information Extraction, Entity Recognition, Named Entity Recognition, Relation Recognition, Brazil Geography, Knowledge Representation, Knowledge-rich Methods, Data-rich Methods, Machine Learning, Neural Networks.\n",
            "PARTE 4 : \n",
            "\n",
            "Keywords: Initial approaches, lexico-syntactic rules, gazeeers, names, word lists, linguistic feature identification, data-driven methods, classification-based methods, neural networks based methods, specialized domains.\n",
            "PARTE 5 : \n",
            "\n",
            "Palavras-chave: Portuguese Corpus, BiLSTM-CRF+Flair Neural Network, Lexico-Syntactic Patterns, Hearst (1992), Heuristics, Semantics of Frames, Data Patterns, Shallow/Deep Syntactic Analyzers, Voted Perceptron, Kernel Functions, HMM Sequential Classifier.\n",
            "PARTE 6 : \n",
            "\n",
            "Palavras-chave: Neural network based methods, Representation learning, Text classification, Entity relation extraction, Open Information Extraction, Portuguese.\n",
            "PARTE 7 : \n",
            "\n",
            "Keywords: RePort system, ReVerb adaptation, syntactical analysis, lexical rules, RELP system, EIA approach, InferReVerbPT system, semantic properties, SGS method, graph isomorphism, BERT language model, seq2seq learning, PortNOIE architecture, evaluation metrics, overgeneration, fallout.\n",
            "PARTE 8 : \n",
            "\n",
            "Keywords: precision measure, coverage measure, F1 measure, information retrieval, entity extraction, entity relationship extraction, evaluation, data annotation, data semi-automatic construction, Transformers architecture, natural processing language.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Sumarização de textos"
      ],
      "metadata": {
        "id": "krM0xJrzgdoB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Para a sumarização, foi requisitado a API que explicasse o conteúdo do texto resumidamente.\n",
        "Comparativamente, foi pedido que resumisse o texto.\n",
        "A API deu um contexto melhor do que se tratava cada pedaço ao pedir que explicasse o texto."
      ],
      "metadata": {
        "id": "75UTW74UjK2X"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def sumarize_text(text) :\n",
        "   paragraphs = get_paragraphs(text)\n",
        "   # separate the text into 8 parts\n",
        "   concanate_paragraphs = concatenate_into_parts(paragraphs, 8)\n",
        "   count = 0\n",
        "   for paragraph in concanate_paragraphs :\n",
        "      res = openai.Completion.create(\n",
        "        model=\"text-davinci-003\",\n",
        "        prompt=f\"Explique o conteúdo do seguinte texto resumidamente:\\n'{paragraph}\",\n",
        "        max_tokens=1000,  # Ajuste conforme necessário\n",
        "    )\n",
        "      print(f'TEXTO RESUMIDO - PARTE {count + 1} : \\n')\n",
        "      print(res['choices'][0]['text'].strip())\n",
        "      time.sleep(20)\n",
        "      count = count + 1"
      ],
      "metadata": {
        "id": "YeuFYOAcgi3D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sumarize_text(text_chapther_9)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wjlJ9v-pgu6p",
        "outputId": "844e3572-c190-4af7-dd99-42c3e2e32833"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "TEXTO RESUMIDO - PARTE 1 : \n",
            "\n",
            "O texto descreve o uso da lógica e das bases de conhecimento no Processamento de Linguagem Natural (PLN). Esses métodos se especializam na manipulação de símbolos e dados estruturados, como gramáticas, ontologias e bases de conhecimento, para processar e entender palavras em linguagem natural. O texto discute como esses métodos podem ser usados ​​para várias tarefas, desde extrair informações e resumir textos até responder a perguntas. O texto também explica os diferentes tipos de lógicas e bases de conhecimento que podem ser usados, como WordNet e FrameNet.\n",
            "TEXTO RESUMIDO - PARTE 2 : \n",
            "\n",
            "Esse texto discorre sobre as bases de conhecimento relevantes para o Processamento de Linguagem Natural (PLN). Ele apresenta detalhes a respeito da WordNet, uma base léxico-semântica desenvolvida por George A. Miller, Christiane Fellbaum e colaboradores, para o inglês. Esta base de conhecimento organiza os itens lexicais (palavras ou expressões) em synsets. A Figura 9.2 mostra os synsets da palavra \"murder\". Além desta, o texto menciona outras duas bases de conhecimento, o FrameNet e a ConceptNet, que são também importantes para o PLN. Por fim, o texto indica algumas limitações das bases de conhecimento mencionadas.\n",
            "\n",
            "Este texto explica como as bases de conhecimento são importantes para o Processamento de Linguagem Natural (PLN). Ele explica em detalhes a função da WordNet, uma base léxico-semântica desenvolvida para o inglês que organiza os itens lexicais em synsets. O texto também discorre sobre o FrameNet e a ConceptNet, que também são significativos para o PLN. Por fim, são elencadas algumas limitações das bases de conhecimento.\n",
            "TEXTO RESUMIDO - PARTE 3 : \n",
            "\n",
            "O texto explica como diversos recursos lingüísticos foram desenvolvidos para Portugal ao longo dos anos, além de wordnets para várias línguas. Da WordNet de Princeton foi propostas ao português a WordNet.BR, Onto.PT, PULO e OpenWordNet-PT.  No entanto, ainda são limitados e pequenos em comparação à PWN original. Uma ilustração dessas palavras é dada com a palavra assassinar, que possui quatro synsets na OWN-PT. A OWN-PT permitiu também realizar uma análise de sentido (wm)para o exemplo apresentado no início, que inclui afirmações de hiperônima entre os synsets encontrados.\n",
            "TEXTO RESUMIDO - PARTE 4 : \n",
            "\n",
            "O texto explica como a FrameNet fornece uma nova perspectiva para um recurso léxico-semântico, a partir da associação de palavras a synsets e conhecimento léxico e semântico baseado na abrangência e na teoria de frames. O projeto SemLink mapeia vários recursos léxico-semânticos para tarefas como inferência em linguagem natural. Assim, a FrameNet Brasil busca criar e evoluir a contraparte linguística da FrameNet original para o português, bem como adaptar e criar novos frames para domínios específicos.\n",
            "TEXTO RESUMIDO - PARTE 5 : \n",
            "\n",
            "O conteúdo do texto trata da exploração de bases de frames em português para aplicações de Processamento de Linguagem Natural. São descritos diversos estudos de iniciativas de criação de bases de frames em português, para domínios específicos, como crimes investigados no Estado do Ceará. Também são citadas iniciativas gerais de abordagem de peculiarbais linguísticas com perspectivas contextualizadas, tais como a FrameNet de Berkeley e a ConceptNet, que reúne afirmações expressas em linguagem natural, e seu objetivo é representar o conhecimento de senso comum.\n",
            "TEXTO RESUMIDO - PARTE 6 : \n",
            "\n",
            "ConceptNet é um hub de conteúdo semântico desenvolvido pela Universidade de Massachusetts que inclui mais de 21 milhões de edges e quase 10 milhões de nós. Contém definições em 78 línguas, cobrindo Inglês, Francês, Italiano, Alemão, Espanhol, Russo, Português, Japonês entre outras. Possui uma API que prove link para outras bases de dados como a InferenceNet-BR e um toolkit que permite inferência prática de senso comum para textos. Esta base fornece definições URI únicas para termos, afirmações e relações, permitindo aos usuários descobrir contextos, construir cadeias de inferências e identificar analogias conceituais.\n",
            "TEXTO RESUMIDO - PARTE 7 : \n",
            "\n",
            "Neste texto são exploradas três bases de conhecimento fundamentais na área de Processamento de Linguagem Natural (PLN), como WordNet, FrameNet e ConceptNet. A principal característica de cada uma destas bases de dados é abordada, bem como seu aplicativo e limitações nos campos de reconhecimento de sentimentos, desambiguação de sentidos, anotação de papéis semânticos e análise de discurso. As características combinadas dessas bases sugeridas de modo colaborativo e holístico, compõe a necessidade de acesso a fontes de conhecimento e linguagens diferentes, para obter um entendimento mais aprofundado e amplo de sentidos presentes em contextos determinados.\n",
            "\n",
            "Este texto discute o assalto do tipo saidinha bancária que ocorreu na tarde de terça-feira, o qual resultou em uma mulher de 42 anos baleada pelos assaltantes. É debatido as três principais bases de conhecimento para Processamento de Linguagem Natural (PLN): WordNet, FrameNet e ConceptNet. WordNet destaca-se por mapear relações semânticas entre sinônimos, FrameNet por focar nos papéis semânticos, enquanto que ConceptNet tem como característica o caráter colaborativo. Além disso, a possibilidade de usar a abordagem híbrida de tais bases para extração de informação e reconhecimento de implicações textuais é discutida.\n",
            "TEXTO RESUMIDO - PARTE 8 : \n",
            "\n",
            "Este texto promove ferramentas e recursos digitais para a pesquisa em polissemia. Refere-se à FrameNet, SemLink, ConceptNet e Wikcionário, que são ferramentas usadas para estudar o significado de palavras polissêmicas e as relações entre elas, com informações sobre números atuais e últimas versões de cada ferramenta. Estão disponíveis links para o acesso fácil e gratuito de documentações, documentos, afirmações e relações de cada ferramenta.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sumarize_text(text_chapther_17)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BigczuZUkRYU",
        "outputId": "6a37cf22-3252-4d6d-ae85-3b83b388ffc6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "TEXTO RESUMIDO - PARTE 1 : \n",
            "\n",
            "Resumidamente, esse texto faz referência à Extração de Informação (EI) com o objetivo de se obter informação estruturada de dados não-estruturados. Esse termo é frequentemente dividido em diversas tarefas de interesse, com foco no tipo de informação a ser extraída do texto. Elas incluem Reconhecimento de Entidades Nomeadas (REN), Extração de Relações (ER) e Extração de Eventos (EE). É explicado um pouco da história da EI e as conferências MUC, onde foram definidos aspectos cruciais para a área.\n",
            "TEXTO RESUMIDO - PARTE 2 : \n",
            "\n",
            "Este texto mostra os desenvolvimentos que aconteceram na área de Extração de Informação e Reconhecimento de Entidades Nomeadas desde a década de 1990, descrevendo as abordagens mais antigas baseadas em padrões e semi-supervisão, até as mais contemporâneas baseadas em redes neurais. É mostrada ainda a importância da definição das noções de Entidades e Relações para que a tarefa possa ser realizada.\n",
            "\n",
            "O conteúdo deste texto trata sobre a evolução da área de Extração de Informação e Reconhecimento de Entidades Nomeadas desde a década de 1990. Ele aborda as abordagens mais antigas à extração de informação, como a baseada em padrões e semi-supervisão, bem como as mais recentes baseadas em redes neurais. O texto também destaca a importância das definições de Entidade e Relação para o sucesso destas tarefas.\n",
            "TEXTO RESUMIDO - PARTE 3 : \n",
            "\n",
            "Este texto trata sobre as áreas de Extração de Informação e Extração de Informação Aberta, relacionando-os ao Reconhecimento de Entidades Nomeadas (REN) e Extração de Relações (ER). A EI tradicional obtém informação estruturada de textos, identificando e classificando expressões linguísticas chamadas entidades nomeadas, enquanto a ER identifica relações entre entidades nomeadas dentro de um domínio de conhecimento ou aplicação previamente definido. Atualmente, a literatura privilegia abordagens de aprendizado de máquina para resolver tais problemas de forma conjunta, sendo recentemente implementado métodos de redes neurais para tal tarefa.\n",
            "TEXTO RESUMIDO - PARTE 4 : \n",
            "\n",
            "Esta seção discorre sobre a literatura relacionada ao reconhecimento de entidades nomeadas (REN) em línguas humanas. Focaliza-se nas abordagens iniciais baseadas em regras lexico-sintáticas e consulta a almanaques (gizzarders), e métodos baseados em dados, como classificação ou classificação sequencial. A seção também expõe modelos de redes neurais profundas para essa tarefa e modelos específicos para linguagens especializadas.\n",
            "\n",
            "Esta seção resume as abordagens iniciais para o reconhecimento de entidades nomeadas, que se baseavam principalmente em regras lexico-sintáticas e listas de nomes próprios, juntamente com consultas a almanaques. Posteriormente, tecnologias baseadas em dados, como as classificação e classificação sequencial foram incorporadas; sobretudo para línguas portuguesa e inglesa. Além disso, modelos de redes neurais profundas e modelos de linguagem têm sido utilizados para a tarefa, tornando-se o estado da arte da tarefa na língua. Por fim, o reconhecimento de entidades também tem sido aplicado em domínios específicos, como saúde, direito e geologia.\n",
            "TEXTO RESUMIDO - PARTE 5 : \n",
            "\n",
            "Este texto descreve trabalhos relacionados à Extração de Relações (ER) e Reconhecimento de Entidade (RE). Primeiramente é citado o trabalho de Hearst (1992), no qual foram definidos padrões lexico-sintáticos para definir relações de hiponímia e hiperonímia - relacionando conceitos entre si. Posteriormente são descritos trabalhos desenvolvidos por Riloff et al. (1993) e Soderland et al. (1995), com a utilização de heurísticas para a construção de padrões e análise semântica, respectivamente. Atualmente as abordagens mais comuns baseiam-se em aprendizado de máquina, dividindo-se em conjuntas e independentes, onde as identificações de entidades em relações são realizados de forma conjunta ou separada. Por último, são referenciados abordagens que utilizem classificadores para a tarefa de identificar quando uma sentença expressa uma relação semântica.\n",
            "TEXTO RESUMIDO - PARTE 6 : \n",
            "\n",
            "A resumidamente, o conteúdo trata de sistemas desenvolvidos para a extracão de entidades e relações em documentos seguindo a tarefa de Extração de Relações (ER). Empregam técnicas de aprendizado de representação baseadas em redes neurais, métodos de programação inteira, classificadores locais, modelos gráficos globais e redes neurais recorrentes para a identificação de entidades e relações. Também foi abordado o contexto em que nasceu a Extração de Informação Aberta (EIA), sua evolução e desenvolvimentos na língua portuguesa.\n",
            "TEXTO RESUMIDO - PARTE 7 : \n",
            "\n",
            "O texto explica os principais sistemas de Extração de Informação (EIA) desenvolvido para a língua portuguesa. Discute também as métricas de avaliação padrão estimuladas com a Conferência MUC-2, como precisão e cobertura/revocação, e algumas adições feitas em outras conferências.\n",
            "TEXTO RESUMIDO - PARTE 8 : \n",
            "\n",
            "Este texto descreve, em linhas gerais, a área de Extração de Informação, uma área da Processamento de Linguagem Natural. O conteúdo é dividido em duas partes, a Extração de Informação Tradicional e a Extração de Informação Aberta (EIA). O texto foca em discutir como a EIA é avaliada, abordando questões como métricas (precisão, cobertura, F1, criação semi-automática de conjuntos de dados, métrica de rendimento, estimativa de valores, métrica de yield) e corpora de referência para língua portuguesa (Glauber et al., 2018; IberLEF, 2019; Malenchini et al., 2019). Em seguida, discute-se como a EIA é abordada através da arquitetura Transformers para língua inglesa.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def resume_text(text) :\n",
        "   paragraphs = get_paragraphs(text)\n",
        "   # separate the text into 8 parts\n",
        "   concanate_paragraphs = concatenate_into_parts(paragraphs, 8)\n",
        "   count = 0\n",
        "   for paragraph in concanate_paragraphs :\n",
        "      res = openai.Completion.create(\n",
        "        model=\"text-davinci-003\",\n",
        "        prompt=f\"Resuma o conteúdo do seguinte texto:\\n'{paragraph}\",\n",
        "        max_tokens=1000,  # Ajuste conforme necessário\n",
        "    )\n",
        "      print(f'TEXTO RESUMIDO - PARTE {count + 1} : \\n')\n",
        "      print(res['choices'][0]['text'].strip())\n",
        "      time.sleep(20)\n",
        "      count = count + 1"
      ],
      "metadata": {
        "id": "pPRGhJAtjUuf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "resume_text(text_chapther_9)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ug6UPwbgjdbe",
        "outputId": "94c9ae99-3314-4367-f48b-3b328fb4a023"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "TEXTO RESUMIDO - PARTE 1 : \n",
            "\n",
            "Ao lidar com textos em PLN, os métodos simbólicos envolvem a utilização de regras e representações formais para processar linguagem natural. Existem analisadores semânticos e bases de conhecimento semântico, que visam fornecer uma representação semântica dos textos. O processamento sintático lida com detecção de língua, separação de sentenças, tokenização, análise morfológica e sintática. A análise semântica se divide entre reconhecimento de entidades e identificação de expressões, e usa sistemas lógicos que dependem da forma lógica do texto. Além disso, os conceitos relacionados contribuem para a inferência, para além da forma da sentença. As bases de conhecimento mais usadas são WordNet, OpenWordNet-PT, FrameNet e FrameNet Brasil, além das ontologias WikiData, YAGO, BabelNet e as bases de conhecimento voltadas ao senso comum, como ConceptNet, OMCS-BR e InferenceNet-BR. \n",
            "\n",
            "Métodos simbólicos em PLN envolvem a utilização de regras e representações formais para compreender textos em linguagem natural. Analisadores semânticos e bases de conhecimento semântico, como WordNet, OpenWordNet-PT, FrameNet, FrameNet Brasil, entre outras, visam gerar uma representação semântica dos textos. O processamento sintático lida com detecção de língua, separação de sentenças, tokenização, análise morfológica e sintática. A análise semântica, baseada em sistemas lógicos, depende da forma lógica do texto, porém os conceitos relacionados contribuem pela inferência além da forma da sentença. Estas bases de conhecimento suportam diversas tarefas e aplicações relacionadas ao PLN.\n",
            "TEXTO RESUMIDO - PARTE 2 : \n",
            "\n",
            "Resumo: Neste capítulo, foram descritas as bases de conhecimento léxico-semântico (WordNet) e de conhecimento de senso comum (ConceptNet) na área de PLN (Processamento de Linguagem Natural), o que contribui para a análise semântica de textos, e também a base FrameNet para anotação de papéis semânticos. WordNet, desenvolvida por George A. Miller, tem como unidade básica os synsets (conjuntos de palavras sinônimas) e está dividida em quatro redes semânticas, uma para cada classe de palavras; já ConceptNet é o maior recurso de conhecimento de senso comum, com entradas tanto para o inglês quanto para o português. Estas bases são amplamente utilizadas pois possuem aplicações e suportam tarefas como desambiguação de sentido de palavras, perguntas e respostas, e análise semântica em geral. No entanto, não são projetos completos e possuem seus próprios limites.\n",
            "TEXTO RESUMIDO - PARTE 3 : \n",
            "\n",
            "- 00783063-n: hiperónimo cadeia (00700023-n)\n",
            "- 02610845-v: hiperónimo finalizar (01828555-v) \n",
            "\n",
            "A partir da WordNet de Princeton foram propostas diversas wordnets para diversas línguas, sendo destacada a do português, constituida por OpenWordNet-PT, PULO, ONTO.PT e Wordnet.BR. Elas são todas menores e menos desenvolvidas do que a PWN, que possui 16MB e 155.327 palavras organizadas em 175.979 synsets. O OpenWordNet-PT (OWN-PT) possui 47.702 synsets, dos quais 32.855 são substantivos, 5.060 verbos, 8.753 adjetivos e 1.034 advérbios. Pode ser usada para a tarefa de desambiguação de sentidos de palavras. Entre outros recursos para o português, destacam-se o VerbNet.Br, PropBank.Br, NILC e Linguateca. \n",
            "\n",
            "Existem várias alternativas de wordnets para o português, todas menores e menos desenvolvidas que a PWN (Princeton WordNet). Estas incluem Wordnet.Br (Dias-da-Silva, 2005), Onto.PT (Gonçalo Oliveira, 2014), PULO (Simões; Guinovart, 2014) e OpenWordNet-PT14 (De Paiva; Rademaker; Melo, 2012). O OpenWordNet-PT inclui 47.702 synsets, enquanto a PWN conta com 155.327 palavras organizadas em 175.979 synsets. É um recurso usado para desambiguar o sentido de palavras que também pode ser alinhado à PWN. Além do português, existem recursos léxico-semânticos criados para diversas outras línguas.\n",
            "TEXTO RESUMIDO - PARTE 4 : \n",
            "\n",
            "FrameNet Brasil (FN-Br) é um projeto de pesquisa lexicográfica, desenvolvido na Universidade Federal de Juiz de Fora (UFJF), que tem como objetivo construir a contraparte linguística da Semântica de Frames para o português brasileiro. Esta base tem sido ampliada usando a tradução e adaptação dos frames da FrameNet original, e criação de novos frames para usos específicos da cultura brasileira. FN-Br é formado por 16 corpora que totalizam pouco mais de 280 milhões de palavras, sendo conhecido principalmente por fornecer um padrão para a tarefa de anotação de papéis semânticos. Além disso, o projeto SemLink busca vincular diferentes recursos léxico-semânticos para fins de inferência em linguagem natural.\n",
            "TEXTO RESUMIDO - PARTE 5 : \n",
            "\n",
            "Resumo: Esta seção buscou mostrar algumas iniciativas que buscaram levar a concepção da Framenet para à realidade do Português. Foram citados diversos exemplos, tais como a FrameFOR, contendo 113 frames em português adaptados da FrameNet original e que aborda os papéis semânticos relacionados à perícia forense; a PFN-PT, um sistema de anotação semântica automática do português; e a ConceptNet, um banco de conhecimento de senso comum sobre fatos comuns expressos por relações rotuladas e ponderadas entre palavras e fragmentos de texto. Estas iniciativas surgiram com o objetivo de abordar as peculiaridades linguísticas com perspectivas contextualizadas e culturalmente relevantes.\n",
            "TEXTO RESUMIDO - PARTE 6 : \n",
            "\n",
            "A ConceptNet é um projeto de compreensão de linguagem natural de código aberto que provê um extenso conjunto de dados de conhecimento de senso comum para diversas línguas naturais, incluindo o inglês e o português. A base contém mais de 21 milhões de afirmações (ou edges) e 78 linguagens naturais. O projeto também possui ferramentas que possibilitam inferências sobre textos. Além disso, outros projetos que incluem tradução de textos e especificação deregas de conhecimento para outros domínios, baseados na ConceptNet, fazem parte da sua extensão, como a InferenceNet-BR.\n",
            "\n",
            "A ConceptNet é um projeto de compreensão de linguagem natural, com código aberto, que fornece extenso conjunto de dados de conhecimento de senso comum para diversas línguas naturais, como português e inglês. Possui mais de 21 milhões de afirmações, cobrindo 78 línguas naturais, incluindo 10 principais (inglês, francês, italiano, alemão, espanhol, russo, português, japonês, holandês e chinês). Possibilita inferências em textos para a descoberta de contexto, cadeia de inferências e analogia conceitual. A base de termos em português é composta por 473 mil nós. O projeto também possui extensões, como a InferenceNet-BR, que inclue tradução de textos e especificação de regras de conhecimento para domínios específicos.\n",
            "TEXTO RESUMIDO - PARTE 7 : \n",
            "\n",
            "Neste texto são apresentadas diferentes bases de conhecimento da área de Processamento de Linguagem Natural (PLN). WordNet destaca-se por mapear relações semânticas entre conjuntos de sinônimos (synsets), fornecendo análise de sentimentos, antônimos, hiperônimos e desambiguação de sentidos. O FrameNet adota uma abordagem baseada em quadros,ligando elementos lexicais e seus papéis semânticos, e é útil para tarefas de anotação de papéis semânticos e análise de discurso. Por fim, a base ConceptNet tem como destaque a colaboração e versatilidade múltipla de suas fontes, sendo empregada para extração de informação e reconhecimento de implicações em textos. No entanto, todas elas têm problemas de consistência e dificuldades na determinação do limite da cobertura. Em decorrência disso, acredita-se que uma abordagem híbrida entre essas bases de conhecimento, associada a parsers semânticos, resulta no melhor framework para sistemas de entendimento de Linguagem Natural.\n",
            "\n",
            "Um assalto do tipo saidinha bancária ocorreu na tarde desta terça-feira na rua Professor Costa Mendes, e terminou com a baleação de uma mulher de 42 anos pelos assaltantes. Esta notícia evidencia a necessidade de bases de conhecimento para o Processamento de Linguagem Natural, com a finalidade de permitir a análise de sentimentos e o reconhecimento de implicações para melhor interpretar o texto.\n",
            "TEXTO RESUMIDO - PARTE 8 : \n",
            "\n",
            "O FrameNet é uma base de dados de linguagem onde vários sentidos das palavras são relacionados a sentidos específicos de um contexto. Ele contém explicações detalhadas dos sentidos polissêmicos das palavras em relação a frames (conjuntos de propriedades relacionadas). A versão atual é a FrameNet 1.7, com mais de 14.000 frames e mais de 215.000 exemplos de sentenças. É possível acessar para a versão atual da FrameNet em https://framenet.icsi.berkeley.edu. O SemLink é um subset da FrameNet que relaciona estruturas sintáticas ao contexto semântico de frases. A versão atual é a SemLink 2.0. Já a ConceptNet é uma base de dados gramatical inteligente que relaciona informação dos sentidos de palavras, frases e sentenças. Sua última versão é a ConceptNet 5.8 e é possível encontrar documentação completa sobre ela em https://github.com/commonsense/conceptnet5/wiki. Há também o Wiktionary, que é uma base de dados aberta e gratuita. A ConceptNet possui diversas relações que podem ser consultadas em https://github.com/commonsense/conceptnet5/wiki/Relations, sendo que nem todas as afirmações são derivadas de entrada em linguagem natural. Além disso, é possível encontrar as bases de afirmações da ConceptNet para todas as linguagens naturais suportadas em https://github.com/commonsense/conceptnet5/wiki/Languages.\n",
            "\n",
            "O FrameNet é uma base de dados de linguagem que liga os sentidos da palavra a sentidos particularmente relevantes em um contexto; a versão atual é a FrameNet 1.7, com mais de 14.000 frames e mais de 215.000 exemplos de sentenças. O SemLink é um subconjunto da FrameNet que liga estruturas sintáticas ao contexto semântico de frases, sendo a versão atual a SemLink 2.0. A ConceptNet é uma base de dados inteligente de gramática que relaciona informações dos sentidos das palavras, frases e sentenças, cuja versão mais recente é a ConceptNet 5.8. Há também o Wiktionary, uma base de dados aberta e gratuita. A ConceptNet possui diversas relações listadas em https://github.com/commonsense/conceptnet5/wiki/Relations, e as bases de afirmações da ConceptNet para as diversas linguagens naturais suportadas estão disponíveis em https://github.com/commonsense/conceptnet5/wiki/Languages.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "resume_text(text_chapther_17)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ILaqUvQokT2x",
        "outputId": "3df0e8d3-ef81-4ffb-b825-ee52e2d49edc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "TEXTO RESUMIDO - PARTE 1 : \n",
            "\n",
            "Resumidamente, a Extração de Informação (EI) consiste em processar informação não-estruturada e obter informação estruturada. Os primeiros trabalhos remontam à década de 1970 com a aplicação de gramáticas formais e parsers sintáticos. Dentre as tarefas de EI mais abordadas na literatura estão o Reconhecimento de Entidades Nomeadas (REN), Extração de Relações (ER) e Extração de Eventos (EE). As conferências MUC realizadas na década de 1990, promovidas pela DARPA, foram cruciais para definir aspectos centrais da área.\n",
            "TEXTO RESUMIDO - PARTE 2 : \n",
            "\n",
            "Resumo: Na área de Processamento de Linguagem Natural foram apresentados avanços tecnológicos no desenvolvimento de aplicações de Extração de Informação e Reconhecimento de Entidades a partir dos anos 1990, com o uso de dados e análise estatística, semi-supervisão e aprendizado de máquina, além de deep learning. Estes métodos foram fundamentais para a extração de relações entre entidades e extração de informações abertas, sem necessidade de definição de relações pré-definidas. Neste contexto, entidades são objetos concretos ou abstratos enquanto relações são associações entre esses objetos, podendo ser entre propriedades gerais das classes de objetos.\n",
            "TEXTO RESUMIDO - PARTE 3 : \n",
            "\n",
            "A Extração de Informação (EI) é uma tarefa de processamento de linguagem natural que busca obter informações estruturadas a partir de textos. Ela opera em torno de duas tarefas básicas: Reconhecimento de Entidades Nomeadas (REN) e Extração de Relações (ER). As entidades são identificadas e classificadas em categorias semânticas, enquanto nas relações são identificados os relacionamentos entre tais entidades. Por sua vez, a Extração de Informação Aberta (EIA) visa obter informações não estruturadas mais abrangentes, permitindo assim a extração de informações que fogem do escopo pré-definido. A Extração de Informação depende de um conjunto pré-existente de relações específicas relevantes para um domínio, enquanto que demanda mais aprofundamento a Extração de Informação Aberta. De fato, na literatura recente, existem vários trabalhos que consideram a tarefa de Extração Conjunta de Entidades e Relações. Existem várias abordagens descritas na literatura para essas tarefas, muitas delas explorando técnicas de aprendizado de máquina. \n",
            "\n",
            "Extração de Informação (EI) é uma tarefa de processamento de linguagem natural que busca obter informações estruturadas a partir de textos. Há duas tarefas básicas: Reconhecimento de Entidades Nomeadas (REN) e Extração de Relações (ER). Entidades são identificadas e classificadas em categorias semânticas, enquanto relações são identificadas nos relacionamentos entre essas entidades. Extração de Informação Aberta (EIA) busca obter informações não estruturadas mais abrangentes, permitindo assim a extração de informações fora do escopo pré-definido. Existem métodos que privilegiam conhecimento rico, como regras e recursos linguísticos e conhecimento de mundo, e métodos baseados em dados, como o aprendizado de máquina, além da Extração Conjunta de Entidades e Relações.\n",
            "TEXTO RESUMIDO - PARTE 4 : \n",
            "\n",
            "REN é a redução de entidades nomeadas à tarefa de classificação sequencial, possibilitada pelo emprego de um esquema de codificação para a representação de fragmentos textuais e sua classificação. Por meio dessa redução, métodos como classificação e classificação sequencial se tornaram o estado da arte para a tarefa. Os modelos recentes BART, RoBERTa, T5, BERT e GPT-3, frequentemente empregados para diferentes tarefas, tem também resultados positivos para REN. No Brasil, métodos ricos em conhecimento como regras e almanaques eram os principais métodos aplicados, no HAREM. Entretanto, devido aos recentes avanços obtidos por meio de redes neurais e modelos de linguagem, tais abordagens são o estado da arte da tarefa em português. Para diversos domínios específicos, são necessários novos métodos adaptados para cada língua e os respectivos conjuntos de dados.\n",
            "\n",
            "O reconhecimento de entidades nomeadas (REN) se trata, basicamente, um problema de processamento de linguagem natural que tem como objetivo identificar e classificar palavras em um texto que constituem entidades nomeadas. Inicialmente, as abordagens destinadas ao problema usavam regras lexico-sintáticas e consulta a almanaques. Então, métodos baseados em dados como classificação e classificação sequencial se tornaram o estado da arte para a tarefa. Atualmente, modelos gerativos de linguagem e redes neurais profundas têm se mostrado frequentemente eficazes na tarefa. No Brasil, as duas primeiras avaliações HAREM se baseavam em regras e almanaques, mas devido aos últimos avanços obtidos com redes neurais e modelos de linguagem, já são o estado da arte na língua portuguesa. Além disso, em domínios específicos, são necessários sistemas adaptados e os seus respectivos conjuntos de dados.\n",
            "TEXTO RESUMIDO - PARTE 5 : \n",
            "\n",
            "Conteúdo: O trabalho de Hearst (1992) traz a definição de padrões lexico-sintáticos para expressão de relações de hiponímia e hiperonímia a partir de análise de corpus. Posteriormente, trabalhos como o de Riloff et al. (1993) e Soderland et al. (1995) utilizaram heurísticas e semântica de quadros, com base em analisador sintático e semântico, para a criação de padrões. Atualmente, a abordagem mais comum e de melhor desempenho são aquelas baseadas em aprendizado de máquina, que dividem-se em conjuntas e separadas. Essa última consiste do reconhecimento de entidades e depois da identificação de relações semânticas entre elas. Zelenko; Aone; Richardella (2003) propuseram funções de kernel para arvores sintáticas rasas e Zhao; Grishman (2005) empregaram diferentes funções de kernel sobre informações sintáticas para o treinamento de um SVM. Por fim, Culotta; McCallum; Betz (2006) usaram um classificador sequencial para identificar relações em textos biográficos.\n",
            "TEXTO RESUMIDO - PARTE 6 : \n",
            "\n",
            "Métodos baseados em redes neurais costumam empregar técnicas de aprendizado de representação para aprender representações do conteúdo semântico dos fragmentos textuais e reduzem o problema de Extração de Relações (ER) à classificação textual. A Extração de Informação Aberta (EIA) surge visando generalizar a ER, sendo os principais avanços na área para o inglês, possível devido às características do idioma. A EIA para a língua portuguesa tem uma história bastante recente, tendo crescido o número de estudos, métodos e sistemas para a tarefa assim como os resultados obtidos por esses estudos. Embora a área tenha visto um crescimento recente para o desenvolvimento de métodos para línguas como o inglês, os avanços ainda não foram incorporados na literatura sobre EIA para a língua portuguesa, devido às poucas fontes de dados em português.\n",
            "TEXTO RESUMIDO - PARTE 7 : \n",
            "\n",
            "Resumo:\n",
            "\n",
            "Vários métodos de extração de informação (EI) foram desenvolvidos, tanto para a língua inglesa quanto para a língua portuguesa. Alguns sistemas adaptam e melhoram o sistema ReVerb, enquanto outros adotam abordagens de redes neurais profundas, classificação sequencial, seq2seq, etc. A avaliação dos sistemas de EI é baseada na precisão e cobertura das extrações e usa as métricas da MUC-2. Além disso, a MUC-3 também adicionou métricas como sobre-geração e sub-geração, mas elas são raramente usadas.\n",
            "TEXTO RESUMIDO - PARTE 8 : \n",
            "\n",
            "Este capítulo discutiu sobre a Extração de Informação (EI) e Extração de Informação Aberta (EIA), destacando conceitos fundamentais para a compreensão das áreas, junto com as abordagens propostas para cada área durante seu desenvolvimento histórico. Foi citado também a avaliação da EI e EIA, que segue padrões semelhantes às aplicadas à tarefa de Recuperação de Informação (RI) - precisão, cobertura e a medida F1. No que se refere à avaliação de EIA, a precisão do sistema pode ser mensurada a partir da avaliação humana das saídas e a cobertura e F1 podem ser estimados a partir de uma métrica chamada rendimento. Foi também citada uma abordagem de avaliação extrínseca de sistemas de EIA usando sua contribuição na tarefa de respostas automáticas a perguntas. Por último, foi mencionada a arquitetura Transformers como uma abordagem bastante difundida para língua inglesa nas áreas de EI e EIA.\n"
          ]
        }
      ]
    }
  ]
}